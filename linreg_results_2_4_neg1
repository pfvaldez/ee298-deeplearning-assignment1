Input:
2 4 -1

Output:
[[ 2.00130695]
 [ 4.04288974]
 [-1.0215667 ]] loss fxn value:  0.021341818248596416 learn rate: 1.5625e-05 iteration: 25283
[[ 2.00130695]
 [ 4.04288975]
 [-1.02156703]] loss fxn value:  0.02133589053051055 learn rate: 1.5625e-05 iteration: 25284
[[ 2.00130696]
 [ 4.04288975]
 [-1.02156737]] loss fxn value:  0.021329964457818647 learn rate: 1.5625e-05 iteration: 25285
[[ 2.00130696]
 [ 4.04288975]
 [-1.0215677 ]] loss fxn value:  0.0213240400312885 learn rate: 1.5625e-05 iteration: 25286
[[ 2.00130697]
 [ 4.04288975]
 [-1.02156803]] loss fxn value:  0.021318117250680235 learn rate: 1.5625e-05 iteration: 25287
[[ 2.00130697]
 [ 4.04288975]
 [-1.02156837]] loss fxn value:  0.021312196115258055 learn rate: 1.5625e-05 iteration: 25288
[[ 2.00130698]
 [ 4.04288975]
 [-1.0215687 ]] loss fxn value:  0.021306276624332026 learn rate: 1.5625e-05 iteration: 25289
[[ 2.00130699]
 [ 4.04288976]
 [-1.02156903]] loss fxn value:  0.02130035877777758 learn rate: 1.5625e-05 iteration: 25290
[[ 2.00130699]
 [ 4.04288976]
 [-1.02156937]] loss fxn value:  0.021294442574317476 learn rate: 1.5625e-05 iteration: 25291
[[ 2.001307  ]
 [ 4.04288976]
 [-1.0215697 ]] loss fxn value:  0.021288528014288752 learn rate: 1.5625e-05 iteration: 25292
[[ 2.001307  ]
 [ 4.04288976]
 [-1.02157003]] loss fxn value:  0.02128261509790852 learn rate: 1.5625e-05 iteration: 25293
[[ 2.00130701]
 [ 4.04288976]
 [-1.02157036]] loss fxn value:  0.021276703822503486 learn rate: 1.5625e-05 iteration: 25294
[[ 2.00130701]
 [ 4.04288977]
 [-1.0215707 ]] loss fxn value:  0.021270794190063617 learn rate: 1.5625e-05 iteration: 25295
[[ 2.00130702]
 [ 4.04288977]
 [-1.02157103]] loss fxn value:  0.021264886198434613 learn rate: 1.5625e-05 iteration: 25296
[[ 2.00130702]
 [ 4.04288977]
 [-1.02157136]] loss fxn value:  0.021258979847497382 learn rate: 1.5625e-05 iteration: 25297
[[ 2.00130703]
 [ 4.04288977]
 [-1.02157169]] loss fxn value:  0.021253075137001972 learn rate: 1.5625e-05 iteration: 25298
[[ 2.00130704]
 [ 4.04288977]
 [-1.02157203]] loss fxn value:  0.02124717206722687 learn rate: 1.5625e-05 iteration: 25299
[[ 2.00130704]
 [ 4.04288977]
 [-1.02157236]] loss fxn value:  0.021241270636467857 learn rate: 1.5625e-05 iteration: 25300
[[ 2.00130705]
 [ 4.04288978]
 [-1.02157269]] loss fxn value:  0.021235370845443403 learn rate: 1.5625e-05 iteration: 25301
[[ 2.00130705]
 [ 4.04288978]
 [-1.02157302]] loss fxn value:  0.021229472692175937 learn rate: 1.5625e-05 iteration: 25302
[[ 2.00130706]
 [ 4.04288978]
 [-1.02157335]] loss fxn value:  0.02122357617767659 learn rate: 1.5625e-05 iteration: 25303
[[ 2.00130706]
 [ 4.04288978]
 [-1.02157368]] loss fxn value:  0.021217681301024475 learn rate: 1.5625e-05 iteration: 25304
[[ 2.00130707]
 [ 4.04288978]
 [-1.02157402]] loss fxn value:  0.021211788061714743 learn rate: 1.5625e-05 iteration: 25305
[[ 2.00130707]
 [ 4.04288978]
 [-1.02157435]] loss fxn value:  0.02120589645932819 learn rate: 1.5625e-05 iteration: 25306
[[ 2.00130708]
 [ 4.04288979]
 [-1.02157468]] loss fxn value:  0.021200006493877196 learn rate: 1.5625e-05 iteration: 25307
[[ 2.00130709]
 [ 4.04288979]
 [-1.02157501]] loss fxn value:  0.0211941181634335 learn rate: 1.5625e-05 iteration: 25308
[[ 2.00130709]
 [ 4.04288979]
 [-1.02157534]] loss fxn value:  0.021188231468632263 learn rate: 1.5625e-05 iteration: 25309
[[ 2.0013071 ]
 [ 4.04288979]
 [-1.02157567]] loss fxn value:  0.02118234640834357 learn rate: 1.5625e-05 iteration: 25310
[[ 2.0013071 ]
 [ 4.04288979]
 [-1.021576  ]] loss fxn value:  0.0211764629837968 learn rate: 1.5625e-05 iteration: 25311
[[ 2.00130711]
 [ 4.04288979]
 [-1.02157633]] loss fxn value:  0.021170581192339145 learn rate: 1.5625e-05 iteration: 25312
[[ 2.00130711]
 [ 4.0428898 ]
 [-1.02157666]] loss fxn value:  0.02116470103561921 learn rate: 1.5625e-05 iteration: 25313
[[ 2.00130712]
 [ 4.0428898 ]
 [-1.02157699]] loss fxn value:  0.02115882251120243 learn rate: 1.5625e-05 iteration: 25314
[[ 2.00130712]
 [ 4.0428898 ]
 [-1.02157732]] loss fxn value:  0.021152945620152405 learn rate: 1.5625e-05 iteration: 25315
[[ 2.00130713]
 [ 4.0428898 ]
 [-1.02157766]] loss fxn value:  0.021147070360957785 learn rate: 1.5625e-05 iteration: 25316
[[ 2.00130714]
 [ 4.0428898 ]
 [-1.02157799]] loss fxn value:  0.02114119673367334 learn rate: 1.5625e-05 iteration: 25317
[[ 2.00130714]
 [ 4.0428898 ]
 [-1.02157832]] loss fxn value:  0.021135324737879855 learn rate: 1.5625e-05 iteration: 25318
[[ 2.00130715]
 [ 4.04288981]
 [-1.02157865]] loss fxn value:  0.021129454373937158 learn rate: 1.5625e-05 iteration: 25319
[[ 2.00130715]
 [ 4.04288981]
 [-1.02157898]] loss fxn value:  0.021123585639659787 learn rate: 1.5625e-05 iteration: 25320
[[ 2.00130716]
 [ 4.04288981]
 [-1.02157931]] loss fxn value:  0.021117718535483106 learn rate: 1.5625e-05 iteration: 25321
[[ 2.00130716]
 [ 4.04288981]
 [-1.02157964]] loss fxn value:  0.021111853060488538 learn rate: 1.5625e-05 iteration: 25322
[[ 2.00130717]
 [ 4.04288981]
 [-1.02157997]] loss fxn value:  0.021105989214652145 learn rate: 1.5625e-05 iteration: 25323
[[ 2.00130717]
 [ 4.04288981]
 [-1.0215803 ]] loss fxn value:  0.021100126998511933 learn rate: 1.5625e-05 iteration: 25324
[[ 2.00130718]
 [ 4.04288982]
 [-1.02158063]] loss fxn value:  0.021094266409227964 learn rate: 1.5625e-05 iteration: 25325
[[ 2.00130718]
 [ 4.04288982]
 [-1.02158096]] loss fxn value:  0.021088407449156955 learn rate: 1.5625e-05 iteration: 25326
[[ 2.00130719]
 [ 4.04288982]
 [-1.02158128]] loss fxn value:  0.021082550115511443 learn rate: 1.5625e-05 iteration: 25327
[[ 2.0013072 ]
 [ 4.04288982]
 [-1.02158161]] loss fxn value:  0.02107669440929102 learn rate: 1.5625e-05 iteration: 25328
[[ 2.0013072 ]
 [ 4.04288982]
 [-1.02158194]] loss fxn value:  0.02107084032943901 learn rate: 1.5625e-05 iteration: 25329
[[ 2.00130721]
 [ 4.04288982]
 [-1.02158227]] loss fxn value:  0.021064987875193383 learn rate: 1.5625e-05 iteration: 25330
[[ 2.00130721]
 [ 4.04288983]
 [-1.0215826 ]] loss fxn value:  0.021059137046430733 learn rate: 1.5625e-05 iteration: 25331
[[ 2.00130722]
 [ 4.04288983]
 [-1.02158293]] loss fxn value:  0.021053287842855255 learn rate: 1.5625e-05 iteration: 25332
[[ 2.00130722]
 [ 4.04288983]
 [-1.02158326]] loss fxn value:  0.0210474402633154 learn rate: 1.5625e-05 iteration: 25333
[[ 2.00130723]
 [ 4.04288983]
 [-1.02158359]] loss fxn value:  0.02104159430907458 learn rate: 1.5625e-05 iteration: 25334
[[ 2.00130723]
 [ 4.04288983]
 [-1.02158392]] loss fxn value:  0.021035749977900635 learn rate: 1.5625e-05 iteration: 25335
[[ 2.00130724]
 [ 4.04288983]
 [-1.02158425]] loss fxn value:  0.02102990727011446 learn rate: 1.5625e-05 iteration: 25336
[[ 2.00130724]
 [ 4.04288984]
 [-1.02158457]] loss fxn value:  0.021024066185575646 learn rate: 1.5625e-05 iteration: 25337
[[ 2.00130725]
 [ 4.04288984]
 [-1.0215849 ]] loss fxn value:  0.02101822672294178 learn rate: 1.5625e-05 iteration: 25338
[[ 2.00130726]
 [ 4.04288984]
 [-1.02158523]] loss fxn value:  0.02101238888261738 learn rate: 1.5625e-05 iteration: 25339
[[ 2.00130726]
 [ 4.04288984]
 [-1.02158556]] loss fxn value:  0.021006552663385736 learn rate: 1.5625e-05 iteration: 25340
[[ 2.00130727]
 [ 4.04288984]
 [-1.02158589]] loss fxn value:  0.021000718065575817 learn rate: 1.5625e-05 iteration: 25341
[[ 2.00130727]
 [ 4.04288984]
 [-1.02158622]] loss fxn value:  0.020994885087799668 learn rate: 1.5625e-05 iteration: 25342
[[ 2.00130728]
 [ 4.04288985]
 [-1.02158654]] loss fxn value:  0.020989053730195377 learn rate: 1.5625e-05 iteration: 25343
[[ 2.00130728]
 [ 4.04288985]
 [-1.02158687]] loss fxn value:  0.020983223992629467 learn rate: 1.5625e-05 iteration: 25344
[[ 2.00130729]
 [ 4.04288985]
 [-1.0215872 ]] loss fxn value:  0.02097739587330254 learn rate: 1.5625e-05 iteration: 25345
[[ 2.00130729]
 [ 4.04288985]
 [-1.02158753]] loss fxn value:  0.020971569373678098 learn rate: 1.5625e-05 iteration: 25346
[[ 2.0013073 ]
 [ 4.04288985]
 [-1.02158785]] loss fxn value:  0.02096574449229264 learn rate: 1.5625e-05 iteration: 25347
[[ 2.00130731]
 [ 4.04288985]
 [-1.02158818]] loss fxn value:  0.020959921228724636 learn rate: 1.5625e-05 iteration: 25348
[[ 2.00130731]
 [ 4.04288986]
 [-1.02158851]] loss fxn value:  0.020954099582552572 learn rate: 1.5625e-05 iteration: 25349
[[ 2.00130732]
 [ 4.04288986]
 [-1.02158884]] loss fxn value:  0.020948279553222298 learn rate: 1.5625e-05 iteration: 25350
[[ 2.00130732]
 [ 4.04288986]
 [-1.02158916]] loss fxn value:  0.02094246114037399 learn rate: 1.5625e-05 iteration: 25351
[[ 2.00130733]
 [ 4.04288986]
 [-1.02158949]] loss fxn value:  0.020936644344469246 learn rate: 1.5625e-05 iteration: 25352
[[ 2.00130733]
 [ 4.04288986]
 [-1.02158982]] loss fxn value:  0.020930829162625755 learn rate: 1.5625e-05 iteration: 25353
[[ 2.00130734]
 [ 4.04288986]
 [-1.02159015]] loss fxn value:  0.020925015597385323 learn rate: 1.5625e-05 iteration: 25354
[[ 2.00130734]
 [ 4.04288987]
 [-1.02159047]] loss fxn value:  0.02091920364623468 learn rate: 1.5625e-05 iteration: 25355
[[ 2.00130735]
 [ 4.04288987]
 [-1.0215908 ]] loss fxn value:  0.020913393308326176 learn rate: 1.5625e-05 iteration: 25356
[[ 2.00130735]
 [ 4.04288987]
 [-1.02159113]] loss fxn value:  0.020907584586530584 learn rate: 1.5625e-05 iteration: 25357
[[ 2.00130736]
 [ 4.04288987]
 [-1.02159145]] loss fxn value:  0.020901777476468077 learn rate: 1.5625e-05 iteration: 25358
[[ 2.00130737]
 [ 4.04288987]
 [-1.02159178]] loss fxn value:  0.020895971980273636 learn rate: 1.5625e-05 iteration: 25359
[[ 2.00130737]
 [ 4.04288987]
 [-1.02159211]] loss fxn value:  0.02089016809592644 learn rate: 1.5625e-05 iteration: 25360
[[ 2.00130738]
 [ 4.04288988]
 [-1.02159243]] loss fxn value:  0.020884365823461967 learn rate: 1.5625e-05 iteration: 25361
[[ 2.00130738]
 [ 4.04288988]
 [-1.02159276]] loss fxn value:  0.02087856516343982 learn rate: 1.5625e-05 iteration: 25362
[[ 2.00130739]
 [ 4.04288988]
 [-1.02159308]] loss fxn value:  0.020872766113907818 learn rate: 1.5625e-05 iteration: 25363
[[ 2.00130739]
 [ 4.04288988]
 [-1.02159341]] loss fxn value:  0.0208669686748521 learn rate: 1.5625e-05 iteration: 25364
[[ 2.0013074 ]
 [ 4.04288988]
 [-1.02159374]] loss fxn value:  0.020861172846405315 learn rate: 1.5625e-05 iteration: 25365
[[ 2.0013074 ]
 [ 4.04288988]
 [-1.02159406]] loss fxn value:  0.02085537862713479 learn rate: 1.5625e-05 iteration: 25366
[[ 2.00130741]
 [ 4.04288989]
 [-1.02159439]] loss fxn value:  0.02084958601843311 learn rate: 1.5625e-05 iteration: 25367
[[ 2.00130741]
 [ 4.04288989]
 [-1.02159471]] loss fxn value:  0.02084379501745803 learn rate: 1.5625e-05 iteration: 25368
[[ 2.00130742]
 [ 4.04288989]
 [-1.02159504]] loss fxn value:  0.02083800562572092 learn rate: 1.5625e-05 iteration: 25369
[[ 2.00130743]
 [ 4.04288989]
 [-1.02159536]] loss fxn value:  0.02083221784225764 learn rate: 1.5625e-05 iteration: 25370
[[ 2.00130743]
 [ 4.04288989]
 [-1.02159569]] loss fxn value:  0.020826431665606993 learn rate: 1.5625e-05 iteration: 25371
[[ 2.00130744]
 [ 4.04288989]
 [-1.02159602]] loss fxn value:  0.02082064709645892 learn rate: 1.5625e-05 iteration: 25372
[[ 2.00130744]
 [ 4.0428899 ]
 [-1.02159634]] loss fxn value:  0.020814864133651793 learn rate: 1.5625e-05 iteration: 25373
[[ 2.00130745]
 [ 4.0428899 ]
 [-1.02159667]] loss fxn value:  0.020809082776866727 learn rate: 1.5625e-05 iteration: 25374
[[ 2.00130745]
 [ 4.0428899 ]
 [-1.02159699]] loss fxn value:  0.0208033030265584 learn rate: 1.5625e-05 iteration: 25375
[[ 2.00130746]
 [ 4.0428899 ]
 [-1.02159732]] loss fxn value:  0.02079752488173414 learn rate: 1.5625e-05 iteration: 25376
[[ 2.00130746]
 [ 4.0428899 ]
 [-1.02159764]] loss fxn value:  0.020791748341120145 learn rate: 1.5625e-05 iteration: 25377
[[ 2.00130747]
 [ 4.0428899 ]
 [-1.02159797]] loss fxn value:  0.020785973404614643 learn rate: 1.5625e-05 iteration: 25378
[[ 2.00130747]
 [ 4.04288991]
 [-1.02159829]] loss fxn value:  0.0207802000733784 learn rate: 1.5625e-05 iteration: 25379
[[ 2.00130748]
 [ 4.04288991]
 [-1.02159862]] loss fxn value:  0.020774428345170043 learn rate: 1.5625e-05 iteration: 25380
[[ 2.00130748]
 [ 4.04288991]
 [-1.02159894]] loss fxn value:  0.020768658219412633 learn rate: 1.5625e-05 iteration: 25381
[[ 2.00130749]
 [ 4.04288991]
 [-1.02159926]] loss fxn value:  0.020762889696520768 learn rate: 1.5625e-05 iteration: 25382
[[ 2.0013075 ]
 [ 4.04288991]
 [-1.02159959]] loss fxn value:  0.020757122775934837 learn rate: 1.5625e-05 iteration: 25383
[[ 2.0013075 ]
 [ 4.04288991]
 [-1.02159991]] loss fxn value:  0.02075135745724801 learn rate: 1.5625e-05 iteration: 25384
[[ 2.00130751]
 [ 4.04288991]
 [-1.02160024]] loss fxn value:  0.02074559374003877 learn rate: 1.5625e-05 iteration: 25385
[[ 2.00130751]
 [ 4.04288992]
 [-1.02160056]] loss fxn value:  0.02073983162379997 learn rate: 1.5625e-05 iteration: 25386
[[ 2.00130752]
 [ 4.04288992]
 [-1.02160089]] loss fxn value:  0.02073407110761302 learn rate: 1.5625e-05 iteration: 25387
[[ 2.00130752]
 [ 4.04288992]
 [-1.02160121]] loss fxn value:  0.020728312191532698 learn rate: 1.5625e-05 iteration: 25388
[[ 2.00130753]
 [ 4.04288992]
 [-1.02160153]] loss fxn value:  0.02072255487608923 learn rate: 1.5625e-05 iteration: 25389
[[ 2.00130753]
 [ 4.04288992]
 [-1.02160186]] loss fxn value:  0.020716799157760517 learn rate: 1.5625e-05 iteration: 25390
[[ 2.00130754]
 [ 4.04288992]
 [-1.02160218]] loss fxn value:  0.020711045039268853 learn rate: 1.5625e-05 iteration: 25391
[[ 2.00130754]
 [ 4.04288993]
 [-1.0216025 ]] loss fxn value:  0.0207052925189864 learn rate: 1.5625e-05 iteration: 25392
[[ 2.00130755]
 [ 4.04288993]
 [-1.02160283]] loss fxn value:  0.02069954159551828 learn rate: 1.5625e-05 iteration: 25393
[[ 2.00130755]
 [ 4.04288993]
 [-1.02160315]] loss fxn value:  0.020693792270490008 learn rate: 1.5625e-05 iteration: 25394
[[ 2.00130756]
 [ 4.04288993]
 [-1.02160347]] loss fxn value:  0.020688044542216677 learn rate: 1.5625e-05 iteration: 25395
[[ 2.00130757]
 [ 4.04288993]
 [-1.0216038 ]] loss fxn value:  0.0206822984099671 learn rate: 1.5625e-05 iteration: 25396
[[ 2.00130757]
 [ 4.04288993]
 [-1.02160412]] loss fxn value:  0.020676553874195956 learn rate: 1.5625e-05 iteration: 25397
[[ 2.00130758]
 [ 4.04288994]
 [-1.02160444]] loss fxn value:  0.020670810933899032 learn rate: 1.5625e-05 iteration: 25398
[[ 2.00130758]
 [ 4.04288994]
 [-1.02160477]] loss fxn value:  0.02066506958780946 learn rate: 1.5625e-05 iteration: 25399
[[ 2.00130759]
 [ 4.04288994]
 [-1.02160509]] loss fxn value:  0.020659329837282036 learn rate: 1.5625e-05 iteration: 25400
[[ 2.00130759]
 [ 4.04288994]
 [-1.02160541]] loss fxn value:  0.020653591680871726 learn rate: 1.5625e-05 iteration: 25401
[[ 2.0013076 ]
 [ 4.04288994]
 [-1.02160573]] loss fxn value:  0.02064785511824032 learn rate: 1.5625e-05 iteration: 25402
[[ 2.0013076 ]
 [ 4.04288994]
 [-1.02160606]] loss fxn value:  0.020642120148785817 learn rate: 1.5625e-05 iteration: 25403
[[ 2.00130761]
 [ 4.04288995]
 [-1.02160638]] loss fxn value:  0.020636386771741566 learn rate: 1.5625e-05 iteration: 25404
[[ 2.00130761]
 [ 4.04288995]
 [-1.0216067 ]] loss fxn value:  0.020630654987971384 learn rate: 1.5625e-05 iteration: 25405
[[ 2.00130762]
 [ 4.04288995]
 [-1.02160702]] loss fxn value:  0.020624924796028767 learn rate: 1.5625e-05 iteration: 25406
[[ 2.00130762]
 [ 4.04288995]
 [-1.02160735]] loss fxn value:  0.02061919619465838 learn rate: 1.5625e-05 iteration: 25407
[[ 2.00130763]
 [ 4.04288995]
 [-1.02160767]] loss fxn value:  0.020613469185726794 learn rate: 1.5625e-05 iteration: 25408
[[ 2.00130764]
 [ 4.04288995]
 [-1.02160799]] loss fxn value:  0.020607743767641632 learn rate: 1.5625e-05 iteration: 25409
[[ 2.00130764]
 [ 4.04288996]
 [-1.02160831]] loss fxn value:  0.020602019938814827 learn rate: 1.5625e-05 iteration: 25410
[[ 2.00130765]
 [ 4.04288996]
 [-1.02160863]] loss fxn value:  0.02059629769997756 learn rate: 1.5625e-05 iteration: 25411
[[ 2.00130765]
 [ 4.04288996]
 [-1.02160896]] loss fxn value:  0.020590577051372023 learn rate: 1.5625e-05 iteration: 25412
[[ 2.00130766]
 [ 4.04288996]
 [-1.02160928]] loss fxn value:  0.020584857991372673 learn rate: 1.5625e-05 iteration: 25413
[[ 2.00130766]
 [ 4.04288996]
 [-1.0216096 ]] loss fxn value:  0.02057914051866103 learn rate: 1.5625e-05 iteration: 25414
[[ 2.00130767]
 [ 4.04288996]
 [-1.02160992]] loss fxn value:  0.0205734246353026 learn rate: 1.5625e-05 iteration: 25415
[[ 2.00130767]
 [ 4.04288997]
 [-1.02161024]] loss fxn value:  0.02056771033869157 learn rate: 1.5625e-05 iteration: 25416
[[ 2.00130768]
 [ 4.04288997]
 [-1.02161056]] loss fxn value:  0.020561997630374765 learn rate: 1.5625e-05 iteration: 25417
[[ 2.00130768]
 [ 4.04288997]
 [-1.02161089]] loss fxn value:  0.020556286507617195 learn rate: 1.5625e-05 iteration: 25418
[[ 2.00130769]
 [ 4.04288997]
 [-1.02161121]] loss fxn value:  0.0205505769712472 learn rate: 1.5625e-05 iteration: 25419
[[ 2.00130769]
 [ 4.04288997]
 [-1.02161153]] loss fxn value:  0.020544869020926587 learn rate: 1.5625e-05 iteration: 25420
[[ 2.0013077 ]
 [ 4.04288997]
 [-1.02161185]] loss fxn value:  0.02053916265610812 learn rate: 1.5625e-05 iteration: 25421
[[ 2.00130771]
 [ 4.04288998]
 [-1.02161217]] loss fxn value:  0.020533457876374894 learn rate: 1.5625e-05 iteration: 25422
[[ 2.00130771]
 [ 4.04288998]
 [-1.02161249]] loss fxn value:  0.020527754680810636 learn rate: 1.5625e-05 iteration: 25423
[[ 2.00130772]
 [ 4.04288998]
 [-1.02161281]] loss fxn value:  0.02052205306893212 learn rate: 1.5625e-05 iteration: 25424
[[ 2.00130772]
 [ 4.04288998]
 [-1.02161313]] loss fxn value:  0.02051635304176518 learn rate: 1.5625e-05 iteration: 25425
[[ 2.00130773]
 [ 4.04288998]
 [-1.02161345]] loss fxn value:  0.020510654597258152 learn rate: 1.5625e-05 iteration: 25426
[[ 2.00130773]
 [ 4.04288998]
 [-1.02161377]] loss fxn value:  0.02050495773473694 learn rate: 1.5625e-05 iteration: 25427
[[ 2.00130774]
 [ 4.04288999]
 [-1.02161409]] loss fxn value:  0.02049926245596086 learn rate: 1.5625e-05 iteration: 25428
[[ 2.00130774]
 [ 4.04288999]
 [-1.02161441]] loss fxn value:  0.020493568758085372 learn rate: 1.5625e-05 iteration: 25429
[[ 2.00130775]
 [ 4.04288999]
 [-1.02161473]] loss fxn value:  0.020487876642136308 learn rate: 1.5625e-05 iteration: 25430
[[ 2.00130775]
 [ 4.04288999]
 [-1.02161505]] loss fxn value:  0.02048218610671878 learn rate: 1.5625e-05 iteration: 25431
[[ 2.00130776]
 [ 4.04288999]
 [-1.02161537]] loss fxn value:  0.02047649715280385 learn rate: 1.5625e-05 iteration: 25432
[[ 2.00130776]
 [ 4.04288999]
 [-1.02161569]] loss fxn value:  0.02047080977748296 learn rate: 1.5625e-05 iteration: 25433
[[ 2.00130777]
 [ 4.04289   ]
 [-1.02161601]] loss fxn value:  0.020465123982757613 learn rate: 1.5625e-05 iteration: 25434
[[ 2.00130777]
 [ 4.04289   ]
 [-1.02161633]] loss fxn value:  0.020459439767197465 learn rate: 1.5625e-05 iteration: 25435
[[ 2.00130778]
 [ 4.04289   ]
 [-1.02161665]] loss fxn value:  0.020453757130354754 learn rate: 1.5625e-05 iteration: 25436
[[ 2.00130779]
 [ 4.04289   ]
 [-1.02161697]] loss fxn value:  0.020448076072224874 learn rate: 1.5625e-05 iteration: 25437
[[ 2.00130779]
 [ 4.04289   ]
 [-1.02161729]] loss fxn value:  0.02044239659138439 learn rate: 1.5625e-05 iteration: 25438
[[ 2.0013078 ]
 [ 4.04289   ]
 [-1.02161761]] loss fxn value:  0.020436718687952087 learn rate: 1.5625e-05 iteration: 25439
[[ 2.0013078 ]
 [ 4.04289   ]
 [-1.02161793]] loss fxn value:  0.020431042362325565 learn rate: 1.5625e-05 iteration: 25440
[[ 2.00130781]
 [ 4.04289001]
 [-1.02161825]] loss fxn value:  0.0204253676130837 learn rate: 1.5625e-05 iteration: 25441
[[ 2.00130781]
 [ 4.04289001]
 [-1.02161857]] loss fxn value:  0.020419694440336044 learn rate: 1.5625e-05 iteration: 25442
[[ 2.00130782]
 [ 4.04289001]
 [-1.02161889]] loss fxn value:  0.02041402284261132 learn rate: 1.5625e-05 iteration: 25443
[[ 2.00130782]
 [ 4.04289001]
 [-1.02161921]] loss fxn value:  0.020408352820445216 learn rate: 1.5625e-05 iteration: 25444
[[ 2.00130783]
 [ 4.04289001]
 [-1.02161952]] loss fxn value:  0.020402684373352208 learn rate: 1.5625e-05 iteration: 25445
[[ 2.00130783]
 [ 4.04289001]
 [-1.02161984]] loss fxn value:  0.02039701750043216 learn rate: 1.5625e-05 iteration: 25446
[[ 2.00130784]
 [ 4.04289002]
 [-1.02162016]] loss fxn value:  0.020391352201159473 learn rate: 1.5625e-05 iteration: 25447
[[ 2.00130784]
 [ 4.04289002]
 [-1.02162048]] loss fxn value:  0.02038568847572386 learn rate: 1.5625e-05 iteration: 25448
[[ 2.00130785]
 [ 4.04289002]
 [-1.0216208 ]] loss fxn value:  0.020380026323416917 learn rate: 1.5625e-05 iteration: 25449
[[ 2.00130785]
 [ 4.04289002]
 [-1.02162112]] loss fxn value:  0.020374365743982912 learn rate: 1.5625e-05 iteration: 25450
[[ 2.00130786]
 [ 4.04289002]
 [-1.02162144]] loss fxn value:  0.02036870673689393 learn rate: 1.5625e-05 iteration: 25451
[[ 2.00130787]
 [ 4.04289002]
 [-1.02162175]] loss fxn value:  0.020363049300700316 learn rate: 1.5625e-05 iteration: 25452
[[ 2.00130787]
 [ 4.04289003]
 [-1.02162207]] loss fxn value:  0.020357393436515825 learn rate: 1.5625e-05 iteration: 25453
[[ 2.00130788]
 [ 4.04289003]
 [-1.02162239]] loss fxn value:  0.02035173914371453 learn rate: 1.5625e-05 iteration: 25454
[[ 2.00130788]
 [ 4.04289003]
 [-1.02162271]] loss fxn value:  0.020346086420475418 learn rate: 1.5625e-05 iteration: 25455
[[ 2.00130789]
 [ 4.04289003]
 [-1.02162303]] loss fxn value:  0.02034043526785747 learn rate: 1.5625e-05 iteration: 25456
[[ 2.00130789]
 [ 4.04289003]
 [-1.02162334]] loss fxn value:  0.02033478568430694 learn rate: 1.5625e-05 iteration: 25457
[[ 2.0013079 ]
 [ 4.04289003]
 [-1.02162366]] loss fxn value:  0.020329137670503684 learn rate: 1.5625e-05 iteration: 25458
[[ 2.0013079 ]
 [ 4.04289004]
 [-1.02162398]] loss fxn value:  0.020323491225289245 learn rate: 1.5625e-05 iteration: 25459
[[ 2.00130791]
 [ 4.04289004]
 [-1.0216243 ]] loss fxn value:  0.020317846347908508 learn rate: 1.5625e-05 iteration: 25460
[[ 2.00130791]
 [ 4.04289004]
 [-1.02162461]] loss fxn value:  0.02031220303975406 learn rate: 1.5625e-05 iteration: 25461
[[ 2.00130792]
 [ 4.04289004]
 [-1.02162493]] loss fxn value:  0.020306561298402862 learn rate: 1.5625e-05 iteration: 25462
[[ 2.00130792]
 [ 4.04289004]
 [-1.02162525]] loss fxn value:  0.020300921123488185 learn rate: 1.5625e-05 iteration: 25463
[[ 2.00130793]
 [ 4.04289004]
 [-1.02162557]] loss fxn value:  0.020295282515971843 learn rate: 1.5625e-05 iteration: 25464
[[ 2.00130793]
 [ 4.04289005]
 [-1.02162588]] loss fxn value:  0.020289645472992293 learn rate: 1.5625e-05 iteration: 25465
[[ 2.00130794]
 [ 4.04289005]
 [-1.0216262 ]] loss fxn value:  0.020284009997018102 learn rate: 1.5625e-05 iteration: 25466
[[ 2.00130794]
 [ 4.04289005]
 [-1.02162652]] loss fxn value:  0.02027837608697328 learn rate: 1.5625e-05 iteration: 25467
[[ 2.00130795]
 [ 4.04289005]
 [-1.02162683]] loss fxn value:  0.02027274374057751 learn rate: 1.5625e-05 iteration: 25468
[[ 2.00130796]
 [ 4.04289005]
 [-1.02162715]] loss fxn value:  0.020267112958832698 learn rate: 1.5625e-05 iteration: 25469
[[ 2.00130796]
 [ 4.04289005]
 [-1.02162747]] loss fxn value:  0.020261483740367885 learn rate: 1.5625e-05 iteration: 25470
[[ 2.00130797]
 [ 4.04289005]
 [-1.02162778]] loss fxn value:  0.02025585608649464 learn rate: 1.5625e-05 iteration: 25471
[[ 2.00130797]
 [ 4.04289006]
 [-1.0216281 ]] loss fxn value:  0.020250229995901398 learn rate: 1.5625e-05 iteration: 25472
[[ 2.00130798]
 [ 4.04289006]
 [-1.02162842]] loss fxn value:  0.02024460546665989 learn rate: 1.5625e-05 iteration: 25473
[[ 2.00130798]
 [ 4.04289006]
 [-1.02162873]] loss fxn value:  0.020238982501247914 learn rate: 1.5625e-05 iteration: 25474
[[ 2.00130799]
 [ 4.04289006]
 [-1.02162905]] loss fxn value:  0.02023336109669984 learn rate: 1.5625e-05 iteration: 25475
[[ 2.00130799]
 [ 4.04289006]
 [-1.02162936]] loss fxn value:  0.020227741252706006 learn rate: 1.5625e-05 iteration: 25476
[[ 2.001308  ]
 [ 4.04289006]
 [-1.02162968]] loss fxn value:  0.0202221229711399 learn rate: 1.5625e-05 iteration: 25477
[[ 2.001308  ]
 [ 4.04289007]
 [-1.02163   ]] loss fxn value:  0.020216506249047427 learn rate: 1.5625e-05 iteration: 25478
[[ 2.00130801]
 [ 4.04289007]
 [-1.02163031]] loss fxn value:  0.02021089108759943 learn rate: 1.5625e-05 iteration: 25479
[[ 2.00130801]
 [ 4.04289007]
 [-1.02163063]] loss fxn value:  0.0202052774852514 learn rate: 1.5625e-05 iteration: 25480
[[ 2.00130802]
 [ 4.04289007]
 [-1.02163094]] loss fxn value:  0.020199665442526632 learn rate: 1.5625e-05 iteration: 25481
[[ 2.00130802]
 [ 4.04289007]
 [-1.02163126]] loss fxn value:  0.020194054958508845 learn rate: 1.5625e-05 iteration: 25482
[[ 2.00130803]
 [ 4.04289007]
 [-1.02163157]] loss fxn value:  0.020188446032284077 learn rate: 1.5625e-05 iteration: 25483
[[ 2.00130803]
 [ 4.04289008]
 [-1.02163189]] loss fxn value:  0.020182838664768596 learn rate: 1.5625e-05 iteration: 25484
[[ 2.00130804]
 [ 4.04289008]
 [-1.02163221]] loss fxn value:  0.020177232853662783 learn rate: 1.5625e-05 iteration: 25485
[[ 2.00130804]
 [ 4.04289008]
 [-1.02163252]] loss fxn value:  0.020171628600861746 learn rate: 1.5625e-05 iteration: 25486
[[ 2.00130805]
 [ 4.04289008]
 [-1.02163284]] loss fxn value:  0.02016602590392315 learn rate: 1.5625e-05 iteration: 25487
[[ 2.00130806]
 [ 4.04289008]
 [-1.02163315]] loss fxn value:  0.02016042476308917 learn rate: 1.5625e-05 iteration: 25488
[[ 2.00130806]
 [ 4.04289008]
 [-1.02163347]] loss fxn value:  0.020154825178174716 learn rate: 1.5625e-05 iteration: 25489
[[ 2.00130807]
 [ 4.04289009]
 [-1.02163378]] loss fxn value:  0.020149227147844295 learn rate: 1.5625e-05 iteration: 25490
[[ 2.00130807]
 [ 4.04289009]
 [-1.0216341 ]] loss fxn value:  0.020143630674061632 learn rate: 1.5625e-05 iteration: 25491
[[ 2.00130808]
 [ 4.04289009]
 [-1.02163441]] loss fxn value:  0.020138035752873037 learn rate: 1.5625e-05 iteration: 25492
[[ 2.00130808]
 [ 4.04289009]
 [-1.02163472]] loss fxn value:  0.020132442386960717 learn rate: 1.5625e-05 iteration: 25493
[[ 2.00130809]
 [ 4.04289009]
 [-1.02163504]] loss fxn value:  0.02012685057415653 learn rate: 1.5625e-05 iteration: 25494
[[ 2.00130809]
 [ 4.04289009]
 [-1.02163535]] loss fxn value:  0.020121260314691126 learn rate: 1.5625e-05 iteration: 25495
[[ 2.0013081 ]
 [ 4.04289009]
 [-1.02163567]] loss fxn value:  0.020115671607024595 learn rate: 1.5625e-05 iteration: 25496
[[ 2.0013081 ]
 [ 4.0428901 ]
 [-1.02163598]] loss fxn value:  0.020110084452694542 learn rate: 1.5625e-05 iteration: 25497
[[ 2.00130811]
 [ 4.0428901 ]
 [-1.0216363 ]] loss fxn value:  0.020104498850194212 learn rate: 1.5625e-05 iteration: 25498
[[ 2.00130811]
 [ 4.0428901 ]
 [-1.02163661]] loss fxn value:  0.02009891479821666 learn rate: 1.5625e-05 iteration: 25499
[[ 2.00130812]
 [ 4.0428901 ]
 [-1.02163692]] loss fxn value:  0.02009333229764039 learn rate: 1.5625e-05 iteration: 25500
[[ 2.00130812]
 [ 4.0428901 ]
 [-1.02163724]] loss fxn value:  0.020087751347167684 learn rate: 1.5625e-05 iteration: 25501
[[ 2.00130813]
 [ 4.0428901 ]
 [-1.02163755]] loss fxn value:  0.020082171947663204 learn rate: 1.5625e-05 iteration: 25502
[[ 2.00130813]
 [ 4.04289011]
 [-1.02163787]] loss fxn value:  0.020076594097359853 learn rate: 1.5625e-05 iteration: 25503
[[ 2.00130814]
 [ 4.04289011]
 [-1.02163818]] loss fxn value:  0.02007101779657045 learn rate: 1.5625e-05 iteration: 25504
[[ 2.00130814]
 [ 4.04289011]
 [-1.02163849]] loss fxn value:  0.020065443044094435 learn rate: 1.5625e-05 iteration: 25505
[[ 2.00130815]
 [ 4.04289011]
 [-1.02163881]] loss fxn value:  0.02005986984126731 learn rate: 1.5625e-05 iteration: 25506
[[ 2.00130816]
 [ 4.04289011]
 [-1.02163912]] loss fxn value:  0.020054298185685358 learn rate: 1.5625e-05 iteration: 25507
[[ 2.00130816]
 [ 4.04289011]
 [-1.02163943]] loss fxn value:  0.020048728077481204 learn rate: 1.5625e-05 iteration: 25508
[[ 2.00130817]
 [ 4.04289012]
 [-1.02163975]] loss fxn value:  0.020043159515705417 learn rate: 1.5625e-05 iteration: 25509
[[ 2.00130817]
 [ 4.04289012]
 [-1.02164006]] loss fxn value:  0.02003759250172203 learn rate: 1.5625e-05 iteration: 25510
[[ 2.00130818]
 [ 4.04289012]
 [-1.02164037]] loss fxn value:  0.020032027032776737 learn rate: 1.5625e-05 iteration: 25511
[[ 2.00130818]
 [ 4.04289012]
 [-1.02164069]] loss fxn value:  0.020026463111292567 learn rate: 1.5625e-05 iteration: 25512
[[ 2.00130819]
 [ 4.04289012]
 [-1.021641  ]] loss fxn value:  0.02002090073421133 learn rate: 1.5625e-05 iteration: 25513
[[ 2.00130819]
 [ 4.04289012]
 [-1.02164131]] loss fxn value:  0.020015339902346364 learn rate: 1.5625e-05 iteration: 25514
[[ 2.0013082 ]
 [ 4.04289013]
 [-1.02164162]] loss fxn value:  0.020009780614572363 learn rate: 1.5625e-05 iteration: 25515
[[ 2.0013082 ]
 [ 4.04289013]
 [-1.02164194]] loss fxn value:  0.020004222871902774 learn rate: 1.5625e-05 iteration: 25516
[[ 2.00130821]
 [ 4.04289013]
 [-1.02164225]] loss fxn value:  0.019998666671514672 learn rate: 1.5625e-05 iteration: 25517
[[ 2.00130821]
 [ 4.04289013]
 [-1.02164256]] loss fxn value:  0.01999311201534324 learn rate: 1.5625e-05 iteration: 25518
[[ 2.00130822]
 [ 4.04289013]
 [-1.02164287]] loss fxn value:  0.019987558901448682 learn rate: 1.5625e-05 iteration: 25519
[[ 2.00130822]
 [ 4.04289013]
 [-1.02164319]] loss fxn value:  0.01998200733037591 learn rate: 1.5625e-05 iteration: 25520
[[ 2.00130823]
 [ 4.04289013]
 [-1.0216435 ]] loss fxn value:  0.019976457301189337 learn rate: 1.5625e-05 iteration: 25521
[[ 2.00130823]
 [ 4.04289014]
 [-1.02164381]] loss fxn value:  0.01997090881342736 learn rate: 1.5625e-05 iteration: 25522
[[ 2.00130824]
 [ 4.04289014]
 [-1.02164412]] loss fxn value:  0.01996536186658514 learn rate: 1.5625e-05 iteration: 25523
[[ 2.00130824]
 [ 4.04289014]
 [-1.02164443]] loss fxn value:  0.019959816461264684 learn rate: 1.5625e-05 iteration: 25524
[[ 2.00130825]
 [ 4.04289014]
 [-1.02164475]] loss fxn value:  0.019954272594978954 learn rate: 1.5625e-05 iteration: 25525
[[ 2.00130825]
 [ 4.04289014]
 [-1.02164506]] loss fxn value:  0.01994873026887719 learn rate: 1.5625e-05 iteration: 25526
[[ 2.00130826]
 [ 4.04289014]
 [-1.02164537]] loss fxn value:  0.019943189482776593 learn rate: 1.5625e-05 iteration: 25527
[[ 2.00130826]
 [ 4.04289015]
 [-1.02164568]] loss fxn value:  0.019937650234898536 learn rate: 1.5625e-05 iteration: 25528
[[ 2.00130827]
 [ 4.04289015]
 [-1.02164599]] loss fxn value:  0.01993211252529318 learn rate: 1.5625e-05 iteration: 25529
[[ 2.00130827]
 [ 4.04289015]
 [-1.0216463 ]] loss fxn value:  0.019926576354817406 learn rate: 1.5625e-05 iteration: 25530
[[ 2.00130828]
 [ 4.04289015]
 [-1.02164662]] loss fxn value:  0.019921041721704977 learn rate: 1.5625e-05 iteration: 25531
[[ 2.00130829]
 [ 4.04289015]
 [-1.02164693]] loss fxn value:  0.01991550862499176 learn rate: 1.5625e-05 iteration: 25532
[[ 2.00130829]
 [ 4.04289015]
 [-1.02164724]] loss fxn value:  0.019909977066586704 learn rate: 1.5625e-05 iteration: 25533
[[ 2.0013083 ]
 [ 4.04289016]
 [-1.02164755]] loss fxn value:  0.019904447043612113 learn rate: 1.5625e-05 iteration: 25534
[[ 2.0013083 ]
 [ 4.04289016]
 [-1.02164786]] loss fxn value:  0.019898918556153607 learn rate: 1.5625e-05 iteration: 25535
[[ 2.00130831]
 [ 4.04289016]
 [-1.02164817]] loss fxn value:  0.019893391605213095 learn rate: 1.5625e-05 iteration: 25536
[[ 2.00130831]
 [ 4.04289016]
 [-1.02164848]] loss fxn value:  0.019887866189707663 learn rate: 1.5625e-05 iteration: 25537
[[ 2.00130832]
 [ 4.04289016]
 [-1.02164879]] loss fxn value:  0.019882342307894988 learn rate: 1.5625e-05 iteration: 25538
[[ 2.00130832]
 [ 4.04289016]
 [-1.0216491 ]] loss fxn value:  0.019876819961181496 learn rate: 1.5625e-05 iteration: 25539
[[ 2.00130833]
 [ 4.04289016]
 [-1.02164941]] loss fxn value:  0.019871299147222864 learn rate: 1.5625e-05 iteration: 25540
[[ 2.00130833]
 [ 4.04289017]
 [-1.02164972]] loss fxn value:  0.019865779866966225 learn rate: 1.5625e-05 iteration: 25541
[[ 2.00130834]
 [ 4.04289017]
 [-1.02165003]] loss fxn value:  0.01986026212046866 learn rate: 1.5625e-05 iteration: 25542
[[ 2.00130834]
 [ 4.04289017]
 [-1.02165034]] loss fxn value:  0.01985474590621419 learn rate: 1.5625e-05 iteration: 25543
[[ 2.00130835]
 [ 4.04289017]
 [-1.02165065]] loss fxn value:  0.019849231223814462 learn rate: 1.5625e-05 iteration: 25544
[[ 2.00130835]
 [ 4.04289017]
 [-1.02165096]] loss fxn value:  0.019843718072962112 learn rate: 1.5625e-05 iteration: 25545
[[ 2.00130836]
 [ 4.04289017]
 [-1.02165127]] loss fxn value:  0.019838206453898184 learn rate: 1.5625e-05 iteration: 25546
[[ 2.00130836]
 [ 4.04289018]
 [-1.02165158]] loss fxn value:  0.01983269636583672 learn rate: 1.5625e-05 iteration: 25547
[[ 2.00130837]
 [ 4.04289018]
 [-1.02165189]] loss fxn value:  0.019827187807328058 learn rate: 1.5625e-05 iteration: 25548
[[ 2.00130837]
 [ 4.04289018]
 [-1.0216522 ]] loss fxn value:  0.01982168077990287 learn rate: 1.5625e-05 iteration: 25549
[[ 2.00130838]
 [ 4.04289018]
 [-1.02165251]] loss fxn value:  0.019816175281487873 learn rate: 1.5625e-05 iteration: 25550
[[ 2.00130838]
 [ 4.04289018]
 [-1.02165282]] loss fxn value:  0.019810671311823565 learn rate: 1.5625e-05 iteration: 25551
[[ 2.00130839]
 [ 4.04289018]
 [-1.02165313]] loss fxn value:  0.019805168870892946 learn rate: 1.5625e-05 iteration: 25552
[[ 2.00130839]
 [ 4.04289019]
 [-1.02165344]] loss fxn value:  0.01979966795905122 learn rate: 1.5625e-05 iteration: 25553
[[ 2.0013084 ]
 [ 4.04289019]
 [-1.02165375]] loss fxn value:  0.01979416857503152 learn rate: 1.5625e-05 iteration: 25554
[[ 2.0013084 ]
 [ 4.04289019]
 [-1.02165406]] loss fxn value:  0.01978867071785817 learn rate: 1.5625e-05 iteration: 25555
[[ 2.00130841]
 [ 4.04289019]
 [-1.02165437]] loss fxn value:  0.019783174387597486 learn rate: 1.5625e-05 iteration: 25556
[[ 2.00130841]
 [ 4.04289019]
 [-1.02165468]] loss fxn value:  0.01977767958467099 learn rate: 1.5625e-05 iteration: 25557
[[ 2.00130842]
 [ 4.04289019]
 [-1.02165499]] loss fxn value:  0.019772186308138477 learn rate: 1.5625e-05 iteration: 25558
[[ 2.00130842]
 [ 4.04289019]
 [-1.0216553 ]] loss fxn value:  0.019766694556642834 learn rate: 1.5625e-05 iteration: 25559
[[ 2.00130843]
 [ 4.0428902 ]
 [-1.02165561]] loss fxn value:  0.019761204331165197 learn rate: 1.5625e-05 iteration: 25560
[[ 2.00130844]
 [ 4.0428902 ]
 [-1.02165591]] loss fxn value:  0.01975571562978884 learn rate: 1.5625e-05 iteration: 25561
[[ 2.00130844]
 [ 4.0428902 ]
 [-1.02165622]] loss fxn value:  0.019750228453040218 learn rate: 1.5625e-05 iteration: 25562
[[ 2.00130845]
 [ 4.0428902 ]
 [-1.02165653]] loss fxn value:  0.019744742801847154 learn rate: 1.5625e-05 iteration: 25563
[[ 2.00130845]
 [ 4.0428902 ]
 [-1.02165684]] loss fxn value:  0.01973925867289196 learn rate: 1.5625e-05 iteration: 25564
[[ 2.00130846]
 [ 4.0428902 ]
 [-1.02165715]] loss fxn value:  0.019733776066264877 learn rate: 1.5625e-05 iteration: 25565
[[ 2.00130846]
 [ 4.04289021]
 [-1.02165746]] loss fxn value:  0.019728294983908018 learn rate: 1.5625e-05 iteration: 25566
[[ 2.00130847]
 [ 4.04289021]
 [-1.02165777]] loss fxn value:  0.01972281542373887 learn rate: 1.5625e-05 iteration: 25567
[[ 2.00130847]
 [ 4.04289021]
 [-1.02165807]] loss fxn value:  0.01971733738554032 learn rate: 1.5625e-05 iteration: 25568
[[ 2.00130848]
 [ 4.04289021]
 [-1.02165838]] loss fxn value:  0.019711860868729676 learn rate: 1.5625e-05 iteration: 25569
[[ 2.00130848]
 [ 4.04289021]
 [-1.02165869]] loss fxn value:  0.0197063858728638 learn rate: 1.5625e-05 iteration: 25570
[[ 2.00130849]
 [ 4.04289021]
 [-1.021659  ]] loss fxn value:  0.019700912397509627 learn rate: 1.5625e-05 iteration: 25571
[[ 2.00130849]
 [ 4.04289021]
 [-1.0216593 ]] loss fxn value:  0.019695440442693397 learn rate: 1.5625e-05 iteration: 25572
[[ 2.0013085 ]
 [ 4.04289022]
 [-1.02165961]] loss fxn value:  0.019689970007943428 learn rate: 1.5625e-05 iteration: 25573
[[ 2.0013085 ]
 [ 4.04289022]
 [-1.02165992]] loss fxn value:  0.019684501092284045 learn rate: 1.5625e-05 iteration: 25574
[[ 2.00130851]
 [ 4.04289022]
 [-1.02166023]] loss fxn value:  0.019679033695370125 learn rate: 1.5625e-05 iteration: 25575
[[ 2.00130851]
 [ 4.04289022]
 [-1.02166054]] loss fxn value:  0.019673567818032322 learn rate: 1.5625e-05 iteration: 25576
[[ 2.00130852]
 [ 4.04289022]
 [-1.02166084]] loss fxn value:  0.01966810345800186 learn rate: 1.5625e-05 iteration: 25577
[[ 2.00130852]
 [ 4.04289022]
 [-1.02166115]] loss fxn value:  0.019662640615745804 learn rate: 1.5625e-05 iteration: 25578
[[ 2.00130853]
 [ 4.04289023]
 [-1.02166146]] loss fxn value:  0.01965717929134893 learn rate: 1.5625e-05 iteration: 25579
[[ 2.00130853]
 [ 4.04289023]
 [-1.02166176]] loss fxn value:  0.019651719483307656 learn rate: 1.5625e-05 iteration: 25580
[[ 2.00130854]
 [ 4.04289023]
 [-1.02166207]] loss fxn value:  0.019646261192145277 learn rate: 1.5625e-05 iteration: 25581
[[ 2.00130854]
 [ 4.04289023]
 [-1.02166238]] loss fxn value:  0.019640804416069316 learn rate: 1.5625e-05 iteration: 25582
[[ 2.00130855]
 [ 4.04289023]
 [-1.02166268]] loss fxn value:  0.0196353491568414 learn rate: 1.5625e-05 iteration: 25583
[[ 2.00130855]
 [ 4.04289023]
 [-1.02166299]] loss fxn value:  0.019629895412185835 learn rate: 1.5625e-05 iteration: 25584
[[ 2.00130856]
 [ 4.04289024]
 [-1.0216633 ]] loss fxn value:  0.019624443182616687 learn rate: 1.5625e-05 iteration: 25585
[[ 2.00130856]
 [ 4.04289024]
 [-1.0216636 ]] loss fxn value:  0.019618992466712837 learn rate: 1.5625e-05 iteration: 25586
[[ 2.00130857]
 [ 4.04289024]
 [-1.02166391]] loss fxn value:  0.019613543265923947 learn rate: 1.5625e-05 iteration: 25587
[[ 2.00130857]
 [ 4.04289024]
 [-1.02166422]] loss fxn value:  0.01960809557786477 learn rate: 1.5625e-05 iteration: 25588
[[ 2.00130858]
 [ 4.04289024]
 [-1.02166452]] loss fxn value:  0.019602649403006978 learn rate: 1.5625e-05 iteration: 25589
[[ 2.00130858]
 [ 4.04289024]
 [-1.02166483]] loss fxn value:  0.019597204740540695 learn rate: 1.5625e-05 iteration: 25590
[[ 2.00130859]
 [ 4.04289024]
 [-1.02166514]] loss fxn value:  0.019591761591254184 learn rate: 1.5625e-05 iteration: 25591
[[ 2.00130859]
 [ 4.04289025]
 [-1.02166544]] loss fxn value:  0.01958631995295968 learn rate: 1.5625e-05 iteration: 25592
[[ 2.0013086 ]
 [ 4.04289025]
 [-1.02166575]] loss fxn value:  0.019580879826994982 learn rate: 1.5625e-05 iteration: 25593
[[ 2.0013086 ]
 [ 4.04289025]
 [-1.02166605]] loss fxn value:  0.019575441210603478 learn rate: 1.5625e-05 iteration: 25594
[[ 2.00130861]
 [ 4.04289025]
 [-1.02166636]] loss fxn value:  0.01957000410517775 learn rate: 1.5625e-05 iteration: 25595
[[ 2.00130861]
 [ 4.04289025]
 [-1.02166667]] loss fxn value:  0.019564568511258096 learn rate: 1.5625e-05 iteration: 25596
[[ 2.00130862]
 [ 4.04289025]
 [-1.02166697]] loss fxn value:  0.019559134425857265 learn rate: 1.5625e-05 iteration: 25597
[[ 2.00130862]
 [ 4.04289026]
 [-1.02166728]] loss fxn value:  0.019553701850174646 learn rate: 1.5625e-05 iteration: 25598
[[ 2.00130863]
 [ 4.04289026]
 [-1.02166758]] loss fxn value:  0.019548270783158173 learn rate: 1.5625e-05 iteration: 25599
[[ 2.00130864]
 [ 4.04289026]
 [-1.02166789]] loss fxn value:  0.01954284122482716 learn rate: 1.5625e-05 iteration: 25600
[[ 2.00130864]
 [ 4.04289026]
 [-1.02166819]] loss fxn value:  0.019537413174703 learn rate: 1.5625e-05 iteration: 25601
[[ 2.00130865]
 [ 4.04289026]
 [-1.0216685 ]] loss fxn value:  0.019531986631938034 learn rate: 1.5625e-05 iteration: 25602
[[ 2.00130865]
 [ 4.04289026]
 [-1.0216688 ]] loss fxn value:  0.019526561596503723 learn rate: 1.5625e-05 iteration: 25603
[[ 2.00130866]
 [ 4.04289026]
 [-1.02166911]] loss fxn value:  0.019521138068333752 learn rate: 1.5625e-05 iteration: 25604
[[ 2.00130866]
 [ 4.04289027]
 [-1.02166941]] loss fxn value:  0.019515716045221045 learn rate: 1.5625e-05 iteration: 25605
[[ 2.00130867]
 [ 4.04289027]
 [-1.02166972]] loss fxn value:  0.019510295529555466 learn rate: 1.5625e-05 iteration: 25606
[[ 2.00130867]
 [ 4.04289027]
 [-1.02167002]] loss fxn value:  0.019504876519252194 learn rate: 1.5625e-05 iteration: 25607
[[ 2.00130868]
 [ 4.04289027]
 [-1.02167033]] loss fxn value:  0.019499459013113837 learn rate: 1.5625e-05 iteration: 25608
[[ 2.00130868]
 [ 4.04289027]
 [-1.02167063]] loss fxn value:  0.01949404301161122 learn rate: 1.5625e-05 iteration: 25609
[[ 2.00130869]
 [ 4.04289027]
 [-1.02167094]] loss fxn value:  0.01948862851561593 learn rate: 1.5625e-05 iteration: 25610
[[ 2.00130869]
 [ 4.04289028]
 [-1.02167124]] loss fxn value:  0.019483215522832956 learn rate: 1.5625e-05 iteration: 25611
[[ 2.0013087 ]
 [ 4.04289028]
 [-1.02167155]] loss fxn value:  0.01947780403373167 learn rate: 1.5625e-05 iteration: 25612
[[ 2.0013087 ]
 [ 4.04289028]
 [-1.02167185]] loss fxn value:  0.019472394047390332 learn rate: 1.5625e-05 iteration: 25613
[[ 2.00130871]
 [ 4.04289028]
 [-1.02167215]] loss fxn value:  0.019466985563913877 learn rate: 1.5625e-05 iteration: 25614
[[ 2.00130871]
 [ 4.04289028]
 [-1.02167246]] loss fxn value:  0.019461578582643215 learn rate: 1.5625e-05 iteration: 25615
[[ 2.00130872]
 [ 4.04289028]
 [-1.02167276]] loss fxn value:  0.019456173102818625 learn rate: 1.5625e-05 iteration: 25616
[[ 2.00130872]
 [ 4.04289028]
 [-1.02167307]] loss fxn value:  0.01945076912538262 learn rate: 1.5625e-05 iteration: 25617
[[ 2.00130873]
 [ 4.04289029]
 [-1.02167337]] loss fxn value:  0.019445366647907563 learn rate: 1.5625e-05 iteration: 25618
[[ 2.00130873]
 [ 4.04289029]
 [-1.02167367]] loss fxn value:  0.01943996567097384 learn rate: 1.5625e-05 iteration: 25619
[[ 2.00130874]
 [ 4.04289029]
 [-1.02167398]] loss fxn value:  0.019434566195029198 learn rate: 1.5625e-05 iteration: 25620
[[ 2.00130874]
 [ 4.04289029]
 [-1.02167428]] loss fxn value:  0.019429168218197845 learn rate: 1.5625e-05 iteration: 25621
[[ 2.00130875]
 [ 4.04289029]
 [-1.02167459]] loss fxn value:  0.01942377174045355 learn rate: 1.5625e-05 iteration: 25622
[[ 2.00130875]
 [ 4.04289029]
 [-1.02167489]] loss fxn value:  0.019418376761448874 learn rate: 1.5625e-05 iteration: 25623
[[ 2.00130876]
 [ 4.0428903 ]
 [-1.02167519]] loss fxn value:  0.01941298328162149 learn rate: 1.5625e-05 iteration: 25624
[[ 2.00130876]
 [ 4.0428903 ]
 [-1.0216755 ]] loss fxn value:  0.01940759129994327 learn rate: 1.5625e-05 iteration: 25625
[[ 2.00130877]
 [ 4.0428903 ]
 [-1.0216758 ]] loss fxn value:  0.019402200815649865 learn rate: 1.5625e-05 iteration: 25626
[[ 2.00130877]
 [ 4.0428903 ]
 [-1.0216761 ]] loss fxn value:  0.01939681182813235 learn rate: 1.5625e-05 iteration: 25627
[[ 2.00130878]
 [ 4.0428903 ]
 [-1.0216764 ]] loss fxn value:  0.019391424338059047 learn rate: 1.5625e-05 iteration: 25628
[[ 2.00130878]
 [ 4.0428903 ]
 [-1.02167671]] loss fxn value:  0.019386038343826042 learn rate: 1.5625e-05 iteration: 25629
[[ 2.00130879]
 [ 4.0428903 ]
 [-1.02167701]] loss fxn value:  0.01938065384564467 learn rate: 1.5625e-05 iteration: 25630
[[ 2.00130879]
 [ 4.04289031]
 [-1.02167731]] loss fxn value:  0.0193752708424274 learn rate: 1.5625e-05 iteration: 25631
[[ 2.0013088 ]
 [ 4.04289031]
 [-1.02167762]] loss fxn value:  0.019369889335257146 learn rate: 1.5625e-05 iteration: 25632
[[ 2.0013088 ]
 [ 4.04289031]
 [-1.02167792]] loss fxn value:  0.019364509322596313 learn rate: 1.5625e-05 iteration: 25633
[[ 2.00130881]
 [ 4.04289031]
 [-1.02167822]] loss fxn value:  0.019359130804137554 learn rate: 1.5625e-05 iteration: 25634
[[ 2.00130881]
 [ 4.04289031]
 [-1.02167852]] loss fxn value:  0.019353753779755154 learn rate: 1.5625e-05 iteration: 25635
[[ 2.00130882]
 [ 4.04289031]
 [-1.02167883]] loss fxn value:  0.019348378249124765 learn rate: 1.5625e-05 iteration: 25636
[[ 2.00130882]
 [ 4.04289032]
 [-1.02167913]] loss fxn value:  0.019343004211185087 learn rate: 1.5625e-05 iteration: 25637
[[ 2.00130883]
 [ 4.04289032]
 [-1.02167943]] loss fxn value:  0.019337631665169473 learn rate: 1.5625e-05 iteration: 25638
[[ 2.00130883]
 [ 4.04289032]
 [-1.02167973]] loss fxn value:  0.019332260611870798 learn rate: 1.5625e-05 iteration: 25639
[[ 2.00130884]
 [ 4.04289032]
 [-1.02168003]] loss fxn value:  0.019326891050955485 learn rate: 1.5625e-05 iteration: 25640
[[ 2.00130884]
 [ 4.04289032]
 [-1.02168034]] loss fxn value:  0.01932152298097387 learn rate: 1.5625e-05 iteration: 25641
[[ 2.00130885]
 [ 4.04289032]
 [-1.02168064]] loss fxn value:  0.019316156402852308 learn rate: 1.5625e-05 iteration: 25642
[[ 2.00130885]
 [ 4.04289032]
 [-1.02168094]] loss fxn value:  0.01931079131384573 learn rate: 1.5625e-05 iteration: 25643
[[ 2.00130886]
 [ 4.04289033]
 [-1.02168124]] loss fxn value:  0.01930542771630854 learn rate: 1.5625e-05 iteration: 25644
[[ 2.00130886]
 [ 4.04289033]
 [-1.02168154]] loss fxn value:  0.019300065606855887 learn rate: 1.5625e-05 iteration: 25645
[[ 2.00130887]
 [ 4.04289033]
 [-1.02168185]] loss fxn value:  0.019294704988569878 learn rate: 1.5625e-05 iteration: 25646
[[ 2.00130887]
 [ 4.04289033]
 [-1.02168215]] loss fxn value:  0.0192893458583661 learn rate: 1.5625e-05 iteration: 25647
[[ 2.00130888]
 [ 4.04289033]
 [-1.02168245]] loss fxn value:  0.01928398821685117 learn rate: 1.5625e-05 iteration: 25648
[[ 2.00130888]
 [ 4.04289033]
 [-1.02168275]] loss fxn value:  0.019278632062682672 learn rate: 1.5625e-05 iteration: 25649
[[ 2.00130889]
 [ 4.04289034]
 [-1.02168305]] loss fxn value:  0.019273277396746034 learn rate: 1.5625e-05 iteration: 25650
[[ 2.00130889]
 [ 4.04289034]
 [-1.02168335]] loss fxn value:  0.01926792421858889 learn rate: 1.5625e-05 iteration: 25651
[[ 2.0013089 ]
 [ 4.04289034]
 [-1.02168365]] loss fxn value:  0.019262572526809428 learn rate: 1.5625e-05 iteration: 25652
[[ 2.0013089 ]
 [ 4.04289034]
 [-1.02168395]] loss fxn value:  0.019257222321450038 learn rate: 1.5625e-05 iteration: 25653
[[ 2.00130891]
 [ 4.04289034]
 [-1.02168425]] loss fxn value:  0.01925187360203527 learn rate: 1.5625e-05 iteration: 25654
[[ 2.00130891]
 [ 4.04289034]
 [-1.02168455]] loss fxn value:  0.0192465263685859 learn rate: 1.5625e-05 iteration: 25655
[[ 2.00130892]
 [ 4.04289034]
 [-1.02168486]] loss fxn value:  0.019241180619730965 learn rate: 1.5625e-05 iteration: 25656
[[ 2.00130892]
 [ 4.04289035]
 [-1.02168516]] loss fxn value:  0.019235836356375206 learn rate: 1.5625e-05 iteration: 25657
[[ 2.00130893]
 [ 4.04289035]
 [-1.02168546]] loss fxn value:  0.01923049357712605 learn rate: 1.5625e-05 iteration: 25658
[[ 2.00130893]
 [ 4.04289035]
 [-1.02168576]] loss fxn value:  0.01922515228201665 learn rate: 1.5625e-05 iteration: 25659
[[ 2.00130894]
 [ 4.04289035]
 [-1.02168606]] loss fxn value:  0.019219812469682972 learn rate: 1.5625e-05 iteration: 25660
[[ 2.00130894]
 [ 4.04289035]
 [-1.02168636]] loss fxn value:  0.019214474141519902 learn rate: 1.5625e-05 iteration: 25661
[[ 2.00130895]
 [ 4.04289035]
 [-1.02168666]] loss fxn value:  0.019209137295163808 learn rate: 1.5625e-05 iteration: 25662
[[ 2.00130895]
 [ 4.04289036]
 [-1.02168696]] loss fxn value:  0.019203801931154993 learn rate: 1.5625e-05 iteration: 25663
[[ 2.00130896]
 [ 4.04289036]
 [-1.02168726]] loss fxn value:  0.019198468050402814 learn rate: 1.5625e-05 iteration: 25664
[[ 2.00130896]
 [ 4.04289036]
 [-1.02168756]] loss fxn value:  0.019193135649579505 learn rate: 1.5625e-05 iteration: 25665
[[ 2.00130897]
 [ 4.04289036]
 [-1.02168786]] loss fxn value:  0.019187804730708188 learn rate: 1.5625e-05 iteration: 25666
[[ 2.00130897]
 [ 4.04289036]
 [-1.02168816]] loss fxn value:  0.019182475291882217 learn rate: 1.5625e-05 iteration: 25667
[[ 2.00130898]
 [ 4.04289036]
 [-1.02168846]] loss fxn value:  0.019177147333503803 learn rate: 1.5625e-05 iteration: 25668
[[ 2.00130898]
 [ 4.04289036]
 [-1.02168876]] loss fxn value:  0.019171820855684807 learn rate: 1.5625e-05 iteration: 25669
[[ 2.00130899]
 [ 4.04289037]
 [-1.02168906]] loss fxn value:  0.01916649585642834 learn rate: 1.5625e-05 iteration: 25670
[[ 2.00130899]
 [ 4.04289037]
 [-1.02168936]] loss fxn value:  0.01916117233648834 learn rate: 1.5625e-05 iteration: 25671
[[ 2.001309  ]
 [ 4.04289037]
 [-1.02168966]] loss fxn value:  0.019155850295965452 learn rate: 1.5625e-05 iteration: 25672
[[ 2.001309  ]
 [ 4.04289037]
 [-1.02168995]] loss fxn value:  0.01915052973239079 learn rate: 1.5625e-05 iteration: 25673
[[ 2.00130901]
 [ 4.04289037]
 [-1.02169025]] loss fxn value:  0.019145210646528688 learn rate: 1.5625e-05 iteration: 25674
[[ 2.00130901]
 [ 4.04289037]
 [-1.02169055]] loss fxn value:  0.019139893039442756 learn rate: 1.5625e-05 iteration: 25675
[[ 2.00130902]
 [ 4.04289037]
 [-1.02169085]] loss fxn value:  0.01913457690866989 learn rate: 1.5625e-05 iteration: 25676
[[ 2.00130902]
 [ 4.04289038]
 [-1.02169115]] loss fxn value:  0.01912926225385488 learn rate: 1.5625e-05 iteration: 25677
[[ 2.00130903]
 [ 4.04289038]
 [-1.02169145]] loss fxn value:  0.019123949074990803 learn rate: 1.5625e-05 iteration: 25678
[[ 2.00130903]
 [ 4.04289038]
 [-1.02169175]] loss fxn value:  0.019118637373024792 learn rate: 1.5625e-05 iteration: 25679
[[ 2.00130904]
 [ 4.04289038]
 [-1.02169205]] loss fxn value:  0.01911332714561714 learn rate: 1.5625e-05 iteration: 25680
[[ 2.00130904]
 [ 4.04289038]
 [-1.02169235]] loss fxn value:  0.019108018393710357 learn rate: 1.5625e-05 iteration: 25681
[[ 2.00130905]
 [ 4.04289038]
 [-1.02169264]] loss fxn value:  0.019102711116845153 learn rate: 1.5625e-05 iteration: 25682
[[ 2.00130905]
 [ 4.04289039]
 [-1.02169294]] loss fxn value:  0.01909740531224099 learn rate: 1.5625e-05 iteration: 25683
[[ 2.00130906]
 [ 4.04289039]
 [-1.02169324]] loss fxn value:  0.01909210098324725 learn rate: 1.5625e-05 iteration: 25684
[[ 2.00130906]
 [ 4.04289039]
 [-1.02169354]] loss fxn value:  0.01908679812691676 learn rate: 1.5625e-05 iteration: 25685
[[ 2.00130907]
 [ 4.04289039]
 [-1.02169384]] loss fxn value:  0.019081496742471338 learn rate: 1.5625e-05 iteration: 25686
[[ 2.00130907]
 [ 4.04289039]
 [-1.02169414]] loss fxn value:  0.019076196831281936 learn rate: 1.5625e-05 iteration: 25687
[[ 2.00130908]
 [ 4.04289039]
 [-1.02169443]] loss fxn value:  0.019070898391406448 learn rate: 1.5625e-05 iteration: 25688
[[ 2.00130908]
 [ 4.04289039]
 [-1.02169473]] loss fxn value:  0.019065601424420237 learn rate: 1.5625e-05 iteration: 25689
[[ 2.00130909]
 [ 4.0428904 ]
 [-1.02169503]] loss fxn value:  0.01906030592785012 learn rate: 1.5625e-05 iteration: 25690
[[ 2.00130909]
 [ 4.0428904 ]
 [-1.02169533]] loss fxn value:  0.019055011902227168 learn rate: 1.5625e-05 iteration: 25691
[[ 2.0013091 ]
 [ 4.0428904 ]
 [-1.02169562]] loss fxn value:  0.019049719347105934 learn rate: 1.5625e-05 iteration: 25692
[[ 2.0013091 ]
 [ 4.0428904 ]
 [-1.02169592]] loss fxn value:  0.019044428262484113 learn rate: 1.5625e-05 iteration: 25693
[[ 2.00130911]
 [ 4.0428904 ]
 [-1.02169622]] loss fxn value:  0.01903913864656692 learn rate: 1.5625e-05 iteration: 25694
[[ 2.00130911]
 [ 4.0428904 ]
 [-1.02169652]] loss fxn value:  0.019033850500637373 learn rate: 1.5625e-05 iteration: 25695
[[ 2.00130912]
 [ 4.04289041]
 [-1.02169681]] loss fxn value:  0.01902856382299093 learn rate: 1.5625e-05 iteration: 25696
[[ 2.00130912]
 [ 4.04289041]
 [-1.02169711]] loss fxn value:  0.019023278613906406 learn rate: 1.5625e-05 iteration: 25697
[[ 2.00130913]
 [ 4.04289041]
 [-1.02169741]] loss fxn value:  0.01901799487222648 learn rate: 1.5625e-05 iteration: 25698
[[ 2.00130913]
 [ 4.04289041]
 [-1.02169771]] loss fxn value:  0.019012712599248867 learn rate: 1.5625e-05 iteration: 25699
[[ 2.00130914]
 [ 4.04289041]
 [-1.021698  ]] loss fxn value:  0.0190074317935046 learn rate: 1.5625e-05 iteration: 25700
[[ 2.00130914]
 [ 4.04289041]
 [-1.0216983 ]] loss fxn value:  0.019002152453251365 learn rate: 1.5625e-05 iteration: 25701
[[ 2.00130915]
 [ 4.04289041]
 [-1.0216986 ]] loss fxn value:  0.018996874579917198 learn rate: 1.5625e-05 iteration: 25702
[[ 2.00130915]
 [ 4.04289042]
 [-1.02169889]] loss fxn value:  0.018991598172452342 learn rate: 1.5625e-05 iteration: 25703
[[ 2.00130916]
 [ 4.04289042]
 [-1.02169919]] loss fxn value:  0.018986323231023432 learn rate: 1.5625e-05 iteration: 25704
[[ 2.00130916]
 [ 4.04289042]
 [-1.02169949]] loss fxn value:  0.018981049754064335 learn rate: 1.5625e-05 iteration: 25705
[[ 2.00130917]
 [ 4.04289042]
 [-1.02169978]] loss fxn value:  0.018975777742260374 learn rate: 1.5625e-05 iteration: 25706
[[ 2.00130917]
 [ 4.04289042]
 [-1.02170008]] loss fxn value:  0.01897050719447385 learn rate: 1.5625e-05 iteration: 25707
[[ 2.00130918]
 [ 4.04289042]
 [-1.02170038]] loss fxn value:  0.018965238110933105 learn rate: 1.5625e-05 iteration: 25708
[[ 2.00130918]
 [ 4.04289042]
 [-1.02170067]] loss fxn value:  0.018959970490471902 learn rate: 1.5625e-05 iteration: 25709
[[ 2.00130919]
 [ 4.04289043]
 [-1.02170097]] loss fxn value:  0.018954704333349427 learn rate: 1.5625e-05 iteration: 25710
[[ 2.00130919]
 [ 4.04289043]
 [-1.02170127]] loss fxn value:  0.018949439638937443 learn rate: 1.5625e-05 iteration: 25711
[[ 2.0013092 ]
 [ 4.04289043]
 [-1.02170156]] loss fxn value:  0.01894417640592669 learn rate: 1.5625e-05 iteration: 25712
[[ 2.0013092 ]
 [ 4.04289043]
 [-1.02170186]] loss fxn value:  0.018938914636145113 learn rate: 1.5625e-05 iteration: 25713
[[ 2.00130921]
 [ 4.04289043]
 [-1.02170215]] loss fxn value:  0.018933654327307783 learn rate: 1.5625e-05 iteration: 25714
[[ 2.00130921]
 [ 4.04289043]
 [-1.02170245]] loss fxn value:  0.018928395478933786 learn rate: 1.5625e-05 iteration: 25715
[[ 2.00130922]
 [ 4.04289044]
 [-1.02170274]] loss fxn value:  0.0189231380920011 learn rate: 1.5625e-05 iteration: 25716
[[ 2.00130922]
 [ 4.04289044]
 [-1.02170304]] loss fxn value:  0.018917882165074763 learn rate: 1.5625e-05 iteration: 25717
[[ 2.00130923]
 [ 4.04289044]
 [-1.02170334]] loss fxn value:  0.01891262769818562 learn rate: 1.5625e-05 iteration: 25718
[[ 2.00130923]
 [ 4.04289044]
 [-1.02170363]] loss fxn value:  0.01890737469042894 learn rate: 1.5625e-05 iteration: 25719
[[ 2.00130924]
 [ 4.04289044]
 [-1.02170393]] loss fxn value:  0.018902123141771556 learn rate: 1.5625e-05 iteration: 25720
[[ 2.00130924]
 [ 4.04289044]
 [-1.02170422]] loss fxn value:  0.018896873051849034 learn rate: 1.5625e-05 iteration: 25721
[[ 2.00130925]
 [ 4.04289044]
 [-1.02170452]] loss fxn value:  0.01889162442009714 learn rate: 1.5625e-05 iteration: 25722
[[ 2.00130925]
 [ 4.04289045]
 [-1.02170481]] loss fxn value:  0.018886377246554502 learn rate: 1.5625e-05 iteration: 25723
[[ 2.00130926]
 [ 4.04289045]
 [-1.02170511]] loss fxn value:  0.01888113152942548 learn rate: 1.5625e-05 iteration: 25724
[[ 2.00130926]
 [ 4.04289045]
 [-1.0217054 ]] loss fxn value:  0.018875887269598667 learn rate: 1.5625e-05 iteration: 25725
[[ 2.00130927]
 [ 4.04289045]
 [-1.0217057 ]] loss fxn value:  0.01887064446662861 learn rate: 1.5625e-05 iteration: 25726
[[ 2.00130927]
 [ 4.04289045]
 [-1.02170599]] loss fxn value:  0.01886540312055308 learn rate: 1.5625e-05 iteration: 25727
[[ 2.00130928]
 [ 4.04289045]
 [-1.02170629]] loss fxn value:  0.01886016322894214 learn rate: 1.5625e-05 iteration: 25728
[[ 2.00130928]
 [ 4.04289045]
 [-1.02170658]] loss fxn value:  0.018854924793364224 learn rate: 1.5625e-05 iteration: 25729
[[ 2.00130929]
 [ 4.04289046]
 [-1.02170688]] loss fxn value:  0.018849687812788885 learn rate: 1.5625e-05 iteration: 25730
[[ 2.00130929]
 [ 4.04289046]
 [-1.02170717]] loss fxn value:  0.018844452286836996 learn rate: 1.5625e-05 iteration: 25731
[[ 2.0013093 ]
 [ 4.04289046]
 [-1.02170746]] loss fxn value:  0.018839218215404463 learn rate: 1.5625e-05 iteration: 25732
[[ 2.0013093 ]
 [ 4.04289046]
 [-1.02170776]] loss fxn value:  0.01883398559674351 learn rate: 1.5625e-05 iteration: 25733
[[ 2.00130931]
 [ 4.04289046]
 [-1.02170805]] loss fxn value:  0.018828754432237478 learn rate: 1.5625e-05 iteration: 25734
[[ 2.00130931]
 [ 4.04289046]
 [-1.02170835]] loss fxn value:  0.018823524720465248 learn rate: 1.5625e-05 iteration: 25735
[[ 2.00130932]
 [ 4.04289047]
 [-1.02170864]] loss fxn value:  0.01881829646100069 learn rate: 1.5625e-05 iteration: 25736
[[ 2.00130932]
 [ 4.04289047]
 [-1.02170894]] loss fxn value:  0.018813069653879265 learn rate: 1.5625e-05 iteration: 25737
[[ 2.00130932]
 [ 4.04289047]
 [-1.02170923]] loss fxn value:  0.018807844299043884 learn rate: 1.5625e-05 iteration: 25738
[[ 2.00130933]
 [ 4.04289047]
 [-1.02170952]] loss fxn value:  0.018802620395114367 learn rate: 1.5625e-05 iteration: 25739
[[ 2.00130933]
 [ 4.04289047]
 [-1.02170982]] loss fxn value:  0.018797397941683034 learn rate: 1.5625e-05 iteration: 25740
[[ 2.00130934]
 [ 4.04289047]
 [-1.02171011]] loss fxn value:  0.018792176939652322 learn rate: 1.5625e-05 iteration: 25741
[[ 2.00130934]
 [ 4.04289047]
 [-1.0217104 ]] loss fxn value:  0.018786957387234363 learn rate: 1.5625e-05 iteration: 25742
[[ 2.00130935]
 [ 4.04289048]
 [-1.0217107 ]] loss fxn value:  0.018781739284788986 learn rate: 1.5625e-05 iteration: 25743
[[ 2.00130935]
 [ 4.04289048]
 [-1.02171099]] loss fxn value:  0.018776522631539453 learn rate: 1.5625e-05 iteration: 25744
[[ 2.00130936]
 [ 4.04289048]
 [-1.02171128]] loss fxn value:  0.018771307426891544 learn rate: 1.5625e-05 iteration: 25745
[[ 2.00130936]
 [ 4.04289048]
 [-1.02171158]] loss fxn value:  0.018766093670923106 learn rate: 1.5625e-05 iteration: 25746
[[ 2.00130937]
 [ 4.04289048]
 [-1.02171187]] loss fxn value:  0.018760881363622608 learn rate: 1.5625e-05 iteration: 25747
[[ 2.00130937]
 [ 4.04289048]
 [-1.02171216]] loss fxn value:  0.01875567050272357 learn rate: 1.5625e-05 iteration: 25748
[[ 2.00130938]
 [ 4.04289048]
 [-1.02171246]] loss fxn value:  0.018750461091501296 learn rate: 1.5625e-05 iteration: 25749
[[ 2.00130938]
 [ 4.04289049]
 [-1.02171275]] loss fxn value:  0.018745253125102813 learn rate: 1.5625e-05 iteration: 25750
[[ 2.00130939]
 [ 4.04289049]
 [-1.02171304]] loss fxn value:  0.018740046606610238 learn rate: 1.5625e-05 iteration: 25751
[[ 2.00130939]
 [ 4.04289049]
 [-1.02171334]] loss fxn value:  0.01873484153355961 learn rate: 1.5625e-05 iteration: 25752
[[ 2.0013094 ]
 [ 4.04289049]
 [-1.02171363]] loss fxn value:  0.01872963790556572 learn rate: 1.5625e-05 iteration: 25753
[[ 2.0013094 ]
 [ 4.04289049]
 [-1.02171392]] loss fxn value:  0.01872443572345923 learn rate: 1.5625e-05 iteration: 25754
[[ 2.00130941]
 [ 4.04289049]
 [-1.02171421]] loss fxn value:  0.018719234986904244 learn rate: 1.5625e-05 iteration: 25755
[[ 2.00130941]
 [ 4.04289049]
 [-1.02171451]] loss fxn value:  0.018714035693951723 learn rate: 1.5625e-05 iteration: 25756
[[ 2.00130942]
 [ 4.0428905 ]
 [-1.0217148 ]] loss fxn value:  0.018708837846074407 learn rate: 1.5625e-05 iteration: 25757
[[ 2.00130942]
 [ 4.0428905 ]
 [-1.02171509]] loss fxn value:  0.018703641440930282 learn rate: 1.5625e-05 iteration: 25758
[[ 2.00130943]
 [ 4.0428905 ]
 [-1.02171538]] loss fxn value:  0.018698446479902694 learn rate: 1.5625e-05 iteration: 25759
[[ 2.00130943]
 [ 4.0428905 ]
 [-1.02171567]] loss fxn value:  0.01869325296072748 learn rate: 1.5625e-05 iteration: 25760
[[ 2.00130944]
 [ 4.0428905 ]
 [-1.02171597]] loss fxn value:  0.01868806088526344 learn rate: 1.5625e-05 iteration: 25761
[[ 2.00130944]
 [ 4.0428905 ]
 [-1.02171626]] loss fxn value:  0.018682870251093008 learn rate: 1.5625e-05 iteration: 25762
[[ 2.00130945]
 [ 4.04289051]
 [-1.02171655]] loss fxn value:  0.018677681058424364 learn rate: 1.5625e-05 iteration: 25763
[[ 2.00130945]
 [ 4.04289051]
 [-1.02171684]] loss fxn value:  0.018672493307970224 learn rate: 1.5625e-05 iteration: 25764
[[ 2.00130946]
 [ 4.04289051]
 [-1.02171713]] loss fxn value:  0.01866730699714754 learn rate: 1.5625e-05 iteration: 25765
[[ 2.00130946]
 [ 4.04289051]
 [-1.02171743]] loss fxn value:  0.01866212212860798 learn rate: 1.5625e-05 iteration: 25766
[[ 2.00130947]
 [ 4.04289051]
 [-1.02171772]] loss fxn value:  0.01865693869916419 learn rate: 1.5625e-05 iteration: 25767
[[ 2.00130947]
 [ 4.04289051]
 [-1.02171801]] loss fxn value:  0.01865175670841626 learn rate: 1.5625e-05 iteration: 25768
[[ 2.00130948]
 [ 4.04289051]
 [-1.0217183 ]] loss fxn value:  0.018646576159096883 learn rate: 1.5625e-05 iteration: 25769
[[ 2.00130948]
 [ 4.04289052]
 [-1.02171859]] loss fxn value:  0.01864139704739045 learn rate: 1.5625e-05 iteration: 25770
[[ 2.00130949]
 [ 4.04289052]
 [-1.02171888]] loss fxn value:  0.018636219373620155 learn rate: 1.5625e-05 iteration: 25771
[[ 2.00130949]
 [ 4.04289052]
 [-1.02171917]] loss fxn value:  0.01863104313930776 learn rate: 1.5625e-05 iteration: 25772
[[ 2.0013095 ]
 [ 4.04289052]
 [-1.02171946]] loss fxn value:  0.01862586834236496 learn rate: 1.5625e-05 iteration: 25773
[[ 2.0013095 ]
 [ 4.04289052]
 [-1.02171976]] loss fxn value:  0.018620694982149685 learn rate: 1.5625e-05 iteration: 25774
[[ 2.00130951]
 [ 4.04289052]
 [-1.02172005]] loss fxn value:  0.018615523059820383 learn rate: 1.5625e-05 iteration: 25775
[[ 2.00130951]
 [ 4.04289052]
 [-1.02172034]] loss fxn value:  0.01861035257339487 learn rate: 1.5625e-05 iteration: 25776
[[ 2.00130952]
 [ 4.04289053]
 [-1.02172063]] loss fxn value:  0.018605183522370613 learn rate: 1.5625e-05 iteration: 25777
[[ 2.00130952]
 [ 4.04289053]
 [-1.02172092]] loss fxn value:  0.018600015907861377 learn rate: 1.5625e-05 iteration: 25778
[[ 2.00130952]
 [ 4.04289053]
 [-1.02172121]] loss fxn value:  0.018594849728265563 learn rate: 1.5625e-05 iteration: 25779
[[ 2.00130953]
 [ 4.04289053]
 [-1.0217215 ]] loss fxn value:  0.018589684984242256 learn rate: 1.5625e-05 iteration: 25780
[[ 2.00130953]
 [ 4.04289053]
 [-1.02172179]] loss fxn value:  0.01858452167425386 learn rate: 1.5625e-05 iteration: 25781
[[ 2.00130954]
 [ 4.04289053]
 [-1.02172208]] loss fxn value:  0.018579359798416857 learn rate: 1.5625e-05 iteration: 25782
[[ 2.00130954]
 [ 4.04289053]
 [-1.02172237]] loss fxn value:  0.0185741993567644 learn rate: 1.5625e-05 iteration: 25783
[[ 2.00130955]
 [ 4.04289054]
 [-1.02172266]] loss fxn value:  0.018569040347268747 learn rate: 1.5625e-05 iteration: 25784
[[ 2.00130955]
 [ 4.04289054]
 [-1.02172295]] loss fxn value:  0.01856388277155774 learn rate: 1.5625e-05 iteration: 25785
[[ 2.00130956]
 [ 4.04289054]
 [-1.02172324]] loss fxn value:  0.0185587266285747 learn rate: 1.5625e-05 iteration: 25786
[[ 2.00130956]
 [ 4.04289054]
 [-1.02172353]] loss fxn value:  0.018553571916962507 learn rate: 1.5625e-05 iteration: 25787
[[ 2.00130957]
 [ 4.04289054]
 [-1.02172382]] loss fxn value:  0.018548418638130747 learn rate: 1.5625e-05 iteration: 25788
[[ 2.00130957]
 [ 4.04289054]
 [-1.02172411]] loss fxn value:  0.018543266789698785 learn rate: 1.5625e-05 iteration: 25789
[[ 2.00130958]
 [ 4.04289055]
 [-1.0217244 ]] loss fxn value:  0.018538116372259387 learn rate: 1.5625e-05 iteration: 25790
[[ 2.00130958]
 [ 4.04289055]
 [-1.02172469]] loss fxn value:  0.018532967386257156 learn rate: 1.5625e-05 iteration: 25791
[[ 2.00130959]
 [ 4.04289055]
 [-1.02172498]] loss fxn value:  0.01852781982974075 learn rate: 1.5625e-05 iteration: 25792
[[ 2.00130959]
 [ 4.04289055]
 [-1.02172527]] loss fxn value:  0.01852267370236273 learn rate: 1.5625e-05 iteration: 25793
[[ 2.0013096 ]
 [ 4.04289055]
 [-1.02172556]] loss fxn value:  0.018517529005050923 learn rate: 1.5625e-05 iteration: 25794
[[ 2.0013096 ]
 [ 4.04289055]
 [-1.02172585]] loss fxn value:  0.01851238573683196 learn rate: 1.5625e-05 iteration: 25795
[[ 2.00130961]
 [ 4.04289055]
 [-1.02172614]] loss fxn value:  0.018507243896765634 learn rate: 1.5625e-05 iteration: 25796
[[ 2.00130961]
 [ 4.04289056]
 [-1.02172643]] loss fxn value:  0.018502103485003887 learn rate: 1.5625e-05 iteration: 25797
[[ 2.00130962]
 [ 4.04289056]
 [-1.02172672]] loss fxn value:  0.01849696450138555 learn rate: 1.5625e-05 iteration: 25798
[[ 2.00130962]
 [ 4.04289056]
 [-1.021727  ]] loss fxn value:  0.01849182694461521 learn rate: 1.5625e-05 iteration: 25799
[[ 2.00130963]
 [ 4.04289056]
 [-1.02172729]] loss fxn value:  0.01848669081469517 learn rate: 1.5625e-05 iteration: 25800
[[ 2.00130963]
 [ 4.04289056]
 [-1.02172758]] loss fxn value:  0.01848155611208242 learn rate: 1.5625e-05 iteration: 25801
[[ 2.00130964]
 [ 4.04289056]
 [-1.02172787]] loss fxn value:  0.01847642283489193 learn rate: 1.5625e-05 iteration: 25802
[[ 2.00130964]
 [ 4.04289056]
 [-1.02172816]] loss fxn value:  0.018471290982299975 learn rate: 1.5625e-05 iteration: 25803
[[ 2.00130965]
 [ 4.04289057]
 [-1.02172845]] loss fxn value:  0.01846616055758415 learn rate: 1.5625e-05 iteration: 25804
[[ 2.00130965]
 [ 4.04289057]
 [-1.02172874]] loss fxn value:  0.018461031556296012 learn rate: 1.5625e-05 iteration: 25805
[[ 2.00130966]
 [ 4.04289057]
 [-1.02172902]] loss fxn value:  0.01845590398070086 learn rate: 1.5625e-05 iteration: 25806
[[ 2.00130966]
 [ 4.04289057]
 [-1.02172931]] loss fxn value:  0.01845077782859047 learn rate: 1.5625e-05 iteration: 25807
[[ 2.00130966]
 [ 4.04289057]
 [-1.0217296 ]] loss fxn value:  0.018445653099783202 learn rate: 1.5625e-05 iteration: 25808
[[ 2.00130967]
 [ 4.04289057]
 [-1.02172989]] loss fxn value:  0.01844052979554823 learn rate: 1.5625e-05 iteration: 25809
[[ 2.00130967]
 [ 4.04289057]
 [-1.02173018]] loss fxn value:  0.018435407913581312 learn rate: 1.5625e-05 iteration: 25810
[[ 2.00130968]
 [ 4.04289058]
 [-1.02173047]] loss fxn value:  0.018430287454374906 learn rate: 1.5625e-05 iteration: 25811
[[ 2.00130968]
 [ 4.04289058]
 [-1.02173075]] loss fxn value:  0.018425168417472017 learn rate: 1.5625e-05 iteration: 25812
[[ 2.00130969]
 [ 4.04289058]
 [-1.02173104]] loss fxn value:  0.01842005080235396 learn rate: 1.5625e-05 iteration: 25813
[[ 2.00130969]
 [ 4.04289058]
 [-1.02173133]] loss fxn value:  0.018414934608713393 learn rate: 1.5625e-05 iteration: 25814
[[ 2.0013097 ]
 [ 4.04289058]
 [-1.02173162]] loss fxn value:  0.018409819835493627 learn rate: 1.5625e-05 iteration: 25815
[[ 2.0013097 ]
 [ 4.04289058]
 [-1.0217319 ]] loss fxn value:  0.01840470648409416 learn rate: 1.5625e-05 iteration: 25816
[[ 2.00130971]
 [ 4.04289058]
 [-1.02173219]] loss fxn value:  0.01839959455141326 learn rate: 1.5625e-05 iteration: 25817
[[ 2.00130971]
 [ 4.04289059]
 [-1.02173248]] loss fxn value:  0.018394484039581604 learn rate: 1.5625e-05 iteration: 25818
[[ 2.00130972]
 [ 4.04289059]
 [-1.02173277]] loss fxn value:  0.018389374946925496 learn rate: 1.5625e-05 iteration: 25819
[[ 2.00130972]
 [ 4.04289059]
 [-1.02173305]] loss fxn value:  0.018384267273387857 learn rate: 1.5625e-05 iteration: 25820
[[ 2.00130973]
 [ 4.04289059]
 [-1.02173334]] loss fxn value:  0.018379161018487772 learn rate: 1.5625e-05 iteration: 25821
[[ 2.00130973]
 [ 4.04289059]
 [-1.02173363]] loss fxn value:  0.01837405618225147 learn rate: 1.5625e-05 iteration: 25822
[[ 2.00130974]
 [ 4.04289059]
 [-1.02173392]] loss fxn value:  0.01836895276324861 learn rate: 1.5625e-05 iteration: 25823
[[ 2.00130974]
 [ 4.04289059]
 [-1.0217342 ]] loss fxn value:  0.018363850762571337 learn rate: 1.5625e-05 iteration: 25824
[[ 2.00130975]
 [ 4.0428906 ]
 [-1.02173449]] loss fxn value:  0.018358750177691684 learn rate: 1.5625e-05 iteration: 25825
[[ 2.00130975]
 [ 4.0428906 ]
 [-1.02173478]] loss fxn value:  0.018353651010678325 learn rate: 1.5625e-05 iteration: 25826
[[ 2.00130976]
 [ 4.0428906 ]
 [-1.02173506]] loss fxn value:  0.018348553259508134 learn rate: 1.5625e-05 iteration: 25827
[[ 2.00130976]
 [ 4.0428906 ]
 [-1.02173535]] loss fxn value:  0.018343456924275973 learn rate: 1.5625e-05 iteration: 25828
[[ 2.00130977]
 [ 4.0428906 ]
 [-1.02173564]] loss fxn value:  0.018338362004551082 learn rate: 1.5625e-05 iteration: 25829
[[ 2.00130977]
 [ 4.0428906 ]
 [-1.02173592]] loss fxn value:  0.018333268499826322 learn rate: 1.5625e-05 iteration: 25830
[[ 2.00130978]
 [ 4.04289061]
 [-1.02173621]] loss fxn value:  0.018328176409697174 learn rate: 1.5625e-05 iteration: 25831
[[ 2.00130978]
 [ 4.04289061]
 [-1.0217365 ]] loss fxn value:  0.018323085734596692 learn rate: 1.5625e-05 iteration: 25832
[[ 2.00130978]
 [ 4.04289061]
 [-1.02173678]] loss fxn value:  0.01831799647261824 learn rate: 1.5625e-05 iteration: 25833
[[ 2.00130979]
 [ 4.04289061]
 [-1.02173707]] loss fxn value:  0.018312908624387732 learn rate: 1.5625e-05 iteration: 25834
[[ 2.00130979]
 [ 4.04289061]
 [-1.02173735]] loss fxn value:  0.018307822189755553 learn rate: 1.5625e-05 iteration: 25835
[[ 2.0013098 ]
 [ 4.04289061]
 [-1.02173764]] loss fxn value:  0.018302737167421663 learn rate: 1.5625e-05 iteration: 25836
[[ 2.0013098 ]
 [ 4.04289061]
 [-1.02173793]] loss fxn value:  0.018297653557388372 learn rate: 1.5625e-05 iteration: 25837
[[ 2.00130981]
 [ 4.04289062]
 [-1.02173821]] loss fxn value:  0.018292571359591676 learn rate: 1.5625e-05 iteration: 25838
[[ 2.00130981]
 [ 4.04289062]
 [-1.0217385 ]] loss fxn value:  0.018287490574240603 learn rate: 1.5625e-05 iteration: 25839
[[ 2.00130982]
 [ 4.04289062]
 [-1.02173878]] loss fxn value:  0.0182824111987054 learn rate: 1.5625e-05 iteration: 25840
[[ 2.00130982]
 [ 4.04289062]
 [-1.02173907]] loss fxn value:  0.01827733323425409 learn rate: 1.5625e-05 iteration: 25841
[[ 2.00130983]
 [ 4.04289062]
 [-1.02173935]] loss fxn value:  0.01827225668067765 learn rate: 1.5625e-05 iteration: 25842
[[ 2.00130983]
 [ 4.04289062]
 [-1.02173964]] loss fxn value:  0.01826718153666682 learn rate: 1.5625e-05 iteration: 25843
[[ 2.00130984]
 [ 4.04289062]
 [-1.02173993]] loss fxn value:  0.018262107803164108 learn rate: 1.5625e-05 iteration: 25844
[[ 2.00130984]
 [ 4.04289063]
 [-1.02174021]] loss fxn value:  0.018257035477755725 learn rate: 1.5625e-05 iteration: 25845
[[ 2.00130985]
 [ 4.04289063]
 [-1.0217405 ]] loss fxn value:  0.018251964562484103 learn rate: 1.5625e-05 iteration: 25846
[[ 2.00130985]
 [ 4.04289063]
 [-1.02174078]] loss fxn value:  0.018246895054873754 learn rate: 1.5625e-05 iteration: 25847
[[ 2.00130986]
 [ 4.04289063]
 [-1.02174107]] loss fxn value:  0.018241826954588775 learn rate: 1.5625e-05 iteration: 25848
[[ 2.00130986]
 [ 4.04289063]
 [-1.02174135]] loss fxn value:  0.01823676026297159 learn rate: 1.5625e-05 iteration: 25849
[[ 2.00130987]
 [ 4.04289063]
 [-1.02174164]] loss fxn value:  0.018231694978154172 learn rate: 1.5625e-05 iteration: 25850
[[ 2.00130987]
 [ 4.04289063]
 [-1.02174192]] loss fxn value:  0.01822663110069759 learn rate: 1.5625e-05 iteration: 25851
[[ 2.00130988]
 [ 4.04289064]
 [-1.02174221]] loss fxn value:  0.018221568629512012 learn rate: 1.5625e-05 iteration: 25852
[[ 2.00130988]
 [ 4.04289064]
 [-1.02174249]] loss fxn value:  0.018216507564337934 learn rate: 1.5625e-05 iteration: 25853
[[ 2.00130988]
 [ 4.04289064]
 [-1.02174277]] loss fxn value:  0.018211447905560563 learn rate: 1.5625e-05 iteration: 25854
[[ 2.00130989]
 [ 4.04289064]
 [-1.02174306]] loss fxn value:  0.018206389651223943 learn rate: 1.5625e-05 iteration: 25855
[[ 2.00130989]
 [ 4.04289064]
 [-1.02174334]] loss fxn value:  0.018201332802029544 learn rate: 1.5625e-05 iteration: 25856
[[ 2.0013099 ]
 [ 4.04289064]
 [-1.02174363]] loss fxn value:  0.01819627735734452 learn rate: 1.5625e-05 iteration: 25857
[[ 2.0013099 ]
 [ 4.04289064]
 [-1.02174391]] loss fxn value:  0.01819122331677358 learn rate: 1.5625e-05 iteration: 25858
[[ 2.00130991]
 [ 4.04289065]
 [-1.0217442 ]] loss fxn value:  0.018186170680319032 learn rate: 1.5625e-05 iteration: 25859
[[ 2.00130991]
 [ 4.04289065]
 [-1.02174448]] loss fxn value:  0.018181119447521585 learn rate: 1.5625e-05 iteration: 25860
[[ 2.00130992]
 [ 4.04289065]
 [-1.02174476]] loss fxn value:  0.018176069616500826 learn rate: 1.5625e-05 iteration: 25861
[[ 2.00130992]
 [ 4.04289065]
 [-1.02174505]] loss fxn value:  0.0181710211887488 learn rate: 1.5625e-05 iteration: 25862
[[ 2.00130993]
 [ 4.04289065]
 [-1.02174533]] loss fxn value:  0.018165974163252066 learn rate: 1.5625e-05 iteration: 25863
[[ 2.00130993]
 [ 4.04289065]
 [-1.02174562]] loss fxn value:  0.018160928540057627 learn rate: 1.5625e-05 iteration: 25864
[[ 2.00130994]
 [ 4.04289065]
 [-1.0217459 ]] loss fxn value:  0.01815588431776368 learn rate: 1.5625e-05 iteration: 25865
[[ 2.00130994]
 [ 4.04289066]
 [-1.02174618]] loss fxn value:  0.018150841497336655 learn rate: 1.5625e-05 iteration: 25866
[[ 2.00130995]
 [ 4.04289066]
 [-1.02174647]] loss fxn value:  0.01814580007641524 learn rate: 1.5625e-05 iteration: 25867
[[ 2.00130995]
 [ 4.04289066]
 [-1.02174675]] loss fxn value:  0.018140760056060724 learn rate: 1.5625e-05 iteration: 25868
[[ 2.00130996]
 [ 4.04289066]
 [-1.02174703]] loss fxn value:  0.018135721435157032 learn rate: 1.5625e-05 iteration: 25869
[[ 2.00130996]
 [ 4.04289066]
 [-1.02174732]] loss fxn value:  0.01813068421481563 learn rate: 1.5625e-05 iteration: 25870
[[ 2.00130997]
 [ 4.04289066]
 [-1.0217476 ]] loss fxn value:  0.01812564839255179 learn rate: 1.5625e-05 iteration: 25871
[[ 2.00130997]
 [ 4.04289066]
 [-1.02174788]] loss fxn value:  0.01812061396955713 learn rate: 1.5625e-05 iteration: 25872
[[ 2.00130997]
 [ 4.04289067]
 [-1.02174817]] loss fxn value:  0.0181155809450924 learn rate: 1.5625e-05 iteration: 25873
[[ 2.00130998]
 [ 4.04289067]
 [-1.02174845]] loss fxn value:  0.018110549317923892 learn rate: 1.5625e-05 iteration: 25874
[[ 2.00130998]
 [ 4.04289067]
 [-1.02174873]] loss fxn value:  0.018105519088051605 learn rate: 1.5625e-05 iteration: 25875
[[ 2.00130999]
 [ 4.04289067]
 [-1.02174902]] loss fxn value:  0.018100490256011223 learn rate: 1.5625e-05 iteration: 25876
[[ 2.00130999]
 [ 4.04289067]
 [-1.0217493 ]] loss fxn value:  0.018095462820236614 learn rate: 1.5625e-05 iteration: 25877
[[ 2.00131   ]
 [ 4.04289067]
 [-1.02174958]] loss fxn value:  0.01809043678226999 learn rate: 1.5625e-05 iteration: 25878
[[ 2.00131   ]
 [ 4.04289067]
 [-1.02174986]] loss fxn value:  0.01808541213880751 learn rate: 1.5625e-05 iteration: 25879
[[ 2.00131001]
 [ 4.04289068]
 [-1.02175015]] loss fxn value:  0.01808038889172958 learn rate: 1.5625e-05 iteration: 25880
[[ 2.00131001]
 [ 4.04289068]
 [-1.02175043]] loss fxn value:  0.01807536703921288 learn rate: 1.5625e-05 iteration: 25881
[[ 2.00131002]
 [ 4.04289068]
 [-1.02175071]] loss fxn value:  0.018070346582195307 learn rate: 1.5625e-05 iteration: 25882
[[ 2.00131002]
 [ 4.04289068]
 [-1.02175099]] loss fxn value:  0.018065327518812603 learn rate: 1.5625e-05 iteration: 25883
[[ 2.00131003]
 [ 4.04289068]
 [-1.02175128]] loss fxn value:  0.018060309850478958 learn rate: 1.5625e-05 iteration: 25884
[[ 2.00131003]
 [ 4.04289068]
 [-1.02175156]] loss fxn value:  0.018055293575283116 learn rate: 1.5625e-05 iteration: 25885
[[ 2.00131004]
 [ 4.04289068]
 [-1.02175184]] loss fxn value:  0.018050278692379726 learn rate: 1.5625e-05 iteration: 25886
[[ 2.00131004]
 [ 4.04289069]
 [-1.02175212]] loss fxn value:  0.018045265204068413 learn rate: 1.5625e-05 iteration: 25887
[[ 2.00131005]
 [ 4.04289069]
 [-1.0217524 ]] loss fxn value:  0.018040253107080805 learn rate: 1.5625e-05 iteration: 25888
[[ 2.00131005]
 [ 4.04289069]
 [-1.02175269]] loss fxn value:  0.018035242402899717 learn rate: 1.5625e-05 iteration: 25889
[[ 2.00131005]
 [ 4.04289069]
 [-1.02175297]] loss fxn value:  0.018030233089552188 learn rate: 1.5625e-05 iteration: 25890
[[ 2.00131006]
 [ 4.04289069]
 [-1.02175325]] loss fxn value:  0.018025225168070976 learn rate: 1.5625e-05 iteration: 25891
[[ 2.00131006]
 [ 4.04289069]
 [-1.02175353]] loss fxn value:  0.018020218638489235 learn rate: 1.5625e-05 iteration: 25892
[[ 2.00131007]
 [ 4.04289069]
 [-1.02175381]] loss fxn value:  0.018015213498377022 learn rate: 1.5625e-05 iteration: 25893
[[ 2.00131007]
 [ 4.0428907 ]
 [-1.02175409]] loss fxn value:  0.018010209748310104 learn rate: 1.5625e-05 iteration: 25894
[[ 2.00131008]
 [ 4.0428907 ]
 [-1.02175438]] loss fxn value:  0.01800520738872154 learn rate: 1.5625e-05 iteration: 25895
[[ 2.00131008]
 [ 4.0428907 ]
 [-1.02175466]] loss fxn value:  0.018000206417792618 learn rate: 1.5625e-05 iteration: 25896
[[ 2.00131009]
 [ 4.0428907 ]
 [-1.02175494]] loss fxn value:  0.017995206836783285 learn rate: 1.5625e-05 iteration: 25897
[[ 2.00131009]
 [ 4.0428907 ]
 [-1.02175522]] loss fxn value:  0.01799020864409539 learn rate: 1.5625e-05 iteration: 25898
[[ 2.0013101]
 [ 4.0428907]
 [-1.0217555]] loss fxn value:  0.01798521183996997 learn rate: 1.5625e-05 iteration: 25899
[[ 2.0013101 ]
 [ 4.0428907 ]
 [-1.02175578]] loss fxn value:  0.017980216422711713 learn rate: 1.5625e-05 iteration: 25900
[[ 2.00131011]
 [ 4.04289071]
 [-1.02175606]] loss fxn value:  0.017975222393101963 learn rate: 1.5625e-05 iteration: 25901
[[ 2.00131011]
 [ 4.04289071]
 [-1.02175634]] loss fxn value:  0.01797022975138521 learn rate: 1.5625e-05 iteration: 25902
[[ 2.00131012]
 [ 4.04289071]
 [-1.02175662]] loss fxn value:  0.01796523849593592 learn rate: 1.5625e-05 iteration: 25903
[[ 2.00131012]
 [ 4.04289071]
 [-1.0217569 ]] loss fxn value:  0.017960248626446747 learn rate: 1.5625e-05 iteration: 25904
[[ 2.00131012]
 [ 4.04289071]
 [-1.02175718]] loss fxn value:  0.01795526014329682 learn rate: 1.5625e-05 iteration: 25905
[[ 2.00131013]
 [ 4.04289071]
 [-1.02175747]] loss fxn value:  0.017950273046135546 learn rate: 1.5625e-05 iteration: 25906
[[ 2.00131013]
 [ 4.04289071]
 [-1.02175775]] loss fxn value:  0.017945287333875404 learn rate: 1.5625e-05 iteration: 25907
[[ 2.00131014]
 [ 4.04289072]
 [-1.02175803]] loss fxn value:  0.01794030300626611 learn rate: 1.5625e-05 iteration: 25908
[[ 2.00131014]
 [ 4.04289072]
 [-1.02175831]] loss fxn value:  0.017935320063219743 learn rate: 1.5625e-05 iteration: 25909
[[ 2.00131015]
 [ 4.04289072]
 [-1.02175859]] loss fxn value:  0.0179303385041536 learn rate: 1.5625e-05 iteration: 25910
[[ 2.00131015]
 [ 4.04289072]
 [-1.02175887]] loss fxn value:  0.01792535832794815 learn rate: 1.5625e-05 iteration: 25911
[[ 2.00131016]
 [ 4.04289072]
 [-1.02175915]] loss fxn value:  0.01792037953576762 learn rate: 1.5625e-05 iteration: 25912
[[ 2.00131016]
 [ 4.04289072]
 [-1.02175943]] loss fxn value:  0.017915402126381465 learn rate: 1.5625e-05 iteration: 25913
[[ 2.00131017]
 [ 4.04289072]
 [-1.02175971]] loss fxn value:  0.017910426099682433 learn rate: 1.5625e-05 iteration: 25914
[[ 2.00131017]
 [ 4.04289073]
 [-1.02175999]] loss fxn value:  0.017905451455332323 learn rate: 1.5625e-05 iteration: 25915
[[ 2.00131018]
 [ 4.04289073]
 [-1.02176027]] loss fxn value:  0.017900478191788926 learn rate: 1.5625e-05 iteration: 25916
[[ 2.00131018]
 [ 4.04289073]
 [-1.02176055]] loss fxn value:  0.017895506310168317 learn rate: 1.5625e-05 iteration: 25917
[[ 2.00131019]
 [ 4.04289073]
 [-1.02176083]] loss fxn value:  0.017890535808954517 learn rate: 1.5625e-05 iteration: 25918
[[ 2.00131019]
 [ 4.04289073]
 [-1.0217611 ]] loss fxn value:  0.01788556668917567 learn rate: 1.5625e-05 iteration: 25919
[[ 2.0013102 ]
 [ 4.04289073]
 [-1.02176138]] loss fxn value:  0.01788059894844652 learn rate: 1.5625e-05 iteration: 25920
[[ 2.0013102 ]
 [ 4.04289073]
 [-1.02176166]] loss fxn value:  0.017875632588214427 learn rate: 1.5625e-05 iteration: 25921
[[ 2.0013102 ]
 [ 4.04289074]
 [-1.02176194]] loss fxn value:  0.017870667607941388 learn rate: 1.5625e-05 iteration: 25922
[[ 2.00131021]
 [ 4.04289074]
 [-1.02176222]] loss fxn value:  0.0178657040058897 learn rate: 1.5625e-05 iteration: 25923
[[ 2.00131021]
 [ 4.04289074]
 [-1.0217625 ]] loss fxn value:  0.01786074178294249 learn rate: 1.5625e-05 iteration: 25924
[[ 2.00131022]
 [ 4.04289074]
 [-1.02176278]] loss fxn value:  0.017855780937711795 learn rate: 1.5625e-05 iteration: 25925
[[ 2.00131022]
 [ 4.04289074]
 [-1.02176306]] loss fxn value:  0.01785082147064076 learn rate: 1.5625e-05 iteration: 25926
[[ 2.00131023]
 [ 4.04289074]
 [-1.02176334]] loss fxn value:  0.017845863380950337 learn rate: 1.5625e-05 iteration: 25927
[[ 2.00131023]
 [ 4.04289074]
 [-1.02176362]] loss fxn value:  0.017840906668943272 learn rate: 1.5625e-05 iteration: 25928
[[ 2.00131024]
 [ 4.04289075]
 [-1.0217639 ]] loss fxn value:  0.017835951333250916 learn rate: 1.5625e-05 iteration: 25929
[[ 2.00131024]
 [ 4.04289075]
 [-1.02176417]] loss fxn value:  0.017830997373049537 learn rate: 1.5625e-05 iteration: 25930
[[ 2.00131025]
 [ 4.04289075]
 [-1.02176445]] loss fxn value:  0.01782604479017169 learn rate: 1.5625e-05 iteration: 25931
[[ 2.00131025]
 [ 4.04289075]
 [-1.02176473]] loss fxn value:  0.017821093582727744 learn rate: 1.5625e-05 iteration: 25932
[[ 2.00131026]
 [ 4.04289075]
 [-1.02176501]] loss fxn value:  0.01781614374935365 learn rate: 1.5625e-05 iteration: 25933
[[ 2.00131026]
 [ 4.04289075]
 [-1.02176529]] loss fxn value:  0.0178111952919676 learn rate: 1.5625e-05 iteration: 25934
[[ 2.00131026]
 [ 4.04289075]
 [-1.02176557]] loss fxn value:  0.017806248208137344 learn rate: 1.5625e-05 iteration: 25935
[[ 2.00131027]
 [ 4.04289076]
 [-1.02176584]] loss fxn value:  0.017801302499868988 learn rate: 1.5625e-05 iteration: 25936
[[ 2.00131027]
 [ 4.04289076]
 [-1.02176612]] loss fxn value:  0.017796358163311477 learn rate: 1.5625e-05 iteration: 25937
[[ 2.00131028]
 [ 4.04289076]
 [-1.0217664 ]] loss fxn value:  0.017791415201337892 learn rate: 1.5625e-05 iteration: 25938
[[ 2.00131028]
 [ 4.04289076]
 [-1.02176668]] loss fxn value:  0.01778647361219584 learn rate: 1.5625e-05 iteration: 25939
[[ 2.00131029]
 [ 4.04289076]
 [-1.02176696]] loss fxn value:  0.017781533394707543 learn rate: 1.5625e-05 iteration: 25940
[[ 2.00131029]
 [ 4.04289076]
 [-1.02176723]] loss fxn value:  0.017776594550586465 learn rate: 1.5625e-05 iteration: 25941
[[ 2.0013103 ]
 [ 4.04289076]
 [-1.02176751]] loss fxn value:  0.017771657077245255 learn rate: 1.5625e-05 iteration: 25942
[[ 2.0013103 ]
 [ 4.04289077]
 [-1.02176779]] loss fxn value:  0.0177667209758216 learn rate: 1.5625e-05 iteration: 25943
[[ 2.00131031]
 [ 4.04289077]
 [-1.02176807]] loss fxn value:  0.017761786244709286 learn rate: 1.5625e-05 iteration: 25944
[[ 2.00131031]
 [ 4.04289077]
 [-1.02176834]] loss fxn value:  0.01775685288564024 learn rate: 1.5625e-05 iteration: 25945
[[ 2.00131032]
 [ 4.04289077]
 [-1.02176862]] loss fxn value:  0.017751920895951557 learn rate: 1.5625e-05 iteration: 25946
[[ 2.00131032]
 [ 4.04289077]
 [-1.0217689 ]] loss fxn value:  0.01774699027489591 learn rate: 1.5625e-05 iteration: 25947
[[ 2.00131033]
 [ 4.04289077]
 [-1.02176918]] loss fxn value:  0.017742061025409532 learn rate: 1.5625e-05 iteration: 25948
[[ 2.00131033]
 [ 4.04289077]
 [-1.02176945]] loss fxn value:  0.01773713314432785 learn rate: 1.5625e-05 iteration: 25949
[[ 2.00131033]
 [ 4.04289078]
 [-1.02176973]] loss fxn value:  0.01773220663203576 learn rate: 1.5625e-05 iteration: 25950
[[ 2.00131034]
 [ 4.04289078]
 [-1.02177001]] loss fxn value:  0.017727281486886105 learn rate: 1.5625e-05 iteration: 25951
[[ 2.00131034]
 [ 4.04289078]
 [-1.02177028]] loss fxn value:  0.017722357711466248 learn rate: 1.5625e-05 iteration: 25952
[[ 2.00131035]
 [ 4.04289078]
 [-1.02177056]] loss fxn value:  0.017717435302705607 learn rate: 1.5625e-05 iteration: 25953
[[ 2.00131035]
 [ 4.04289078]
 [-1.02177084]] loss fxn value:  0.017712514261341978 learn rate: 1.5625e-05 iteration: 25954
[[ 2.00131036]
 [ 4.04289078]
 [-1.02177111]] loss fxn value:  0.017707594586713966 learn rate: 1.5625e-05 iteration: 25955
[[ 2.00131036]
 [ 4.04289078]
 [-1.02177139]] loss fxn value:  0.017702676278457133 learn rate: 1.5625e-05 iteration: 25956
[[ 2.00131037]
 [ 4.04289079]
 [-1.02177167]] loss fxn value:  0.017697759336637787 learn rate: 1.5625e-05 iteration: 25957
[[ 2.00131037]
 [ 4.04289079]
 [-1.02177194]] loss fxn value:  0.01769284376067786 learn rate: 1.5625e-05 iteration: 25958
[[ 2.00131038]
 [ 4.04289079]
 [-1.02177222]] loss fxn value:  0.0176879295492704 learn rate: 1.5625e-05 iteration: 25959
[[ 2.00131038]
 [ 4.04289079]
 [-1.0217725 ]] loss fxn value:  0.017683016703788672 learn rate: 1.5625e-05 iteration: 25960
[[ 2.00131039]
 [ 4.04289079]
 [-1.02177277]] loss fxn value:  0.017678105221916894 learn rate: 1.5625e-05 iteration: 25961
[[ 2.00131039]
 [ 4.04289079]
 [-1.02177305]] loss fxn value:  0.01767319510417837 learn rate: 1.5625e-05 iteration: 25962
[[ 2.00131039]
 [ 4.04289079]
 [-1.02177333]] loss fxn value:  0.01766828635050909 learn rate: 1.5625e-05 iteration: 25963
[[ 2.0013104 ]
 [ 4.04289079]
 [-1.0217736 ]] loss fxn value:  0.017663378960968444 learn rate: 1.5625e-05 iteration: 25964
[[ 2.0013104 ]
 [ 4.0428908 ]
 [-1.02177388]] loss fxn value:  0.017658472933628173 learn rate: 1.5625e-05 iteration: 25965
[[ 2.00131041]
 [ 4.0428908 ]
 [-1.02177415]] loss fxn value:  0.017653568268683452 learn rate: 1.5625e-05 iteration: 25966
[[ 2.00131041]
 [ 4.0428908 ]
 [-1.02177443]] loss fxn value:  0.01764866496632285 learn rate: 1.5625e-05 iteration: 25967
[[ 2.00131042]
 [ 4.0428908 ]
 [-1.02177471]] loss fxn value:  0.017643763026852555 learn rate: 1.5625e-05 iteration: 25968
[[ 2.00131042]
 [ 4.0428908 ]
 [-1.02177498]] loss fxn value:  0.017638862447669067 learn rate: 1.5625e-05 iteration: 25969
[[ 2.00131043]
 [ 4.0428908 ]
 [-1.02177526]] loss fxn value:  0.017633963230426448 learn rate: 1.5625e-05 iteration: 25970
[[ 2.00131043]
 [ 4.0428908 ]
 [-1.02177553]] loss fxn value:  0.01762906537313012 learn rate: 1.5625e-05 iteration: 25971
[[ 2.00131044]
 [ 4.04289081]
 [-1.02177581]] loss fxn value:  0.01762416887629646 learn rate: 1.5625e-05 iteration: 25972
[[ 2.00131044]
 [ 4.04289081]
 [-1.02177608]] loss fxn value:  0.017619273739963245 learn rate: 1.5625e-05 iteration: 25973
[[ 2.00131044]
 [ 4.04289081]
 [-1.02177636]] loss fxn value:  0.01761437996266466 learn rate: 1.5625e-05 iteration: 25974
[[ 2.00131045]
 [ 4.04289081]
 [-1.02177663]] loss fxn value:  0.01760948754543576 learn rate: 1.5625e-05 iteration: 25975
[[ 2.00131045]
 [ 4.04289081]
 [-1.02177691]] loss fxn value:  0.017604596487239183 learn rate: 1.5625e-05 iteration: 25976
[[ 2.00131046]
 [ 4.04289081]
 [-1.02177718]] loss fxn value:  0.017599706786786434 learn rate: 1.5625e-05 iteration: 25977
[[ 2.00131046]
 [ 4.04289081]
 [-1.02177746]] loss fxn value:  0.01759481844449212 learn rate: 1.5625e-05 iteration: 25978
[[ 2.00131047]
 [ 4.04289082]
 [-1.02177773]] loss fxn value:  0.017589931459958633 learn rate: 1.5625e-05 iteration: 25979
[[ 2.00131047]
 [ 4.04289082]
 [-1.02177801]] loss fxn value:  0.017585045833188293 learn rate: 1.5625e-05 iteration: 25980
[[ 2.00131048]
 [ 4.04289082]
 [-1.02177828]] loss fxn value:  0.017580161563157566 learn rate: 1.5625e-05 iteration: 25981
[[ 2.00131048]
 [ 4.04289082]
 [-1.02177856]] loss fxn value:  0.017575278649066658 learn rate: 1.5625e-05 iteration: 25982
[[ 2.00131049]
 [ 4.04289082]
 [-1.02177883]] loss fxn value:  0.01757039709225567 learn rate: 1.5625e-05 iteration: 25983
[[ 2.00131049]
 [ 4.04289082]
 [-1.02177911]] loss fxn value:  0.017565516891336643 learn rate: 1.5625e-05 iteration: 25984
[[ 2.0013105 ]
 [ 4.04289082]
 [-1.02177938]] loss fxn value:  0.01756063804454333 learn rate: 1.5625e-05 iteration: 25985
[[ 2.0013105 ]
 [ 4.04289083]
 [-1.02177966]] loss fxn value:  0.01755576055460611 learn rate: 1.5625e-05 iteration: 25986
[[ 2.0013105 ]
 [ 4.04289083]
 [-1.02177993]] loss fxn value:  0.017550884418194915 learn rate: 1.5625e-05 iteration: 25987
[[ 2.00131051]
 [ 4.04289083]
 [-1.0217802 ]] loss fxn value:  0.017546009637328244 learn rate: 1.5625e-05 iteration: 25988
[[ 2.00131051]
 [ 4.04289083]
 [-1.02178048]] loss fxn value:  0.01754113620910909 learn rate: 1.5625e-05 iteration: 25989
[[ 2.00131052]
 [ 4.04289083]
 [-1.02178075]] loss fxn value:  0.01753626413549656 learn rate: 1.5625e-05 iteration: 25990
[[ 2.00131052]
 [ 4.04289083]
 [-1.02178103]] loss fxn value:  0.01753139341410772 learn rate: 1.5625e-05 iteration: 25991
[[ 2.00131053]
 [ 4.04289083]
 [-1.0217813 ]] loss fxn value:  0.017526524046449304 learn rate: 1.5625e-05 iteration: 25992
[[ 2.00131053]
 [ 4.04289084]
 [-1.02178157]] loss fxn value:  0.017521656030469658 learn rate: 1.5625e-05 iteration: 25993
[[ 2.00131054]
 [ 4.04289084]
 [-1.02178185]] loss fxn value:  0.017516789366878026 learn rate: 1.5625e-05 iteration: 25994
[[ 2.00131054]
 [ 4.04289084]
 [-1.02178212]] loss fxn value:  0.017511924055060017 learn rate: 1.5625e-05 iteration: 25995
[[ 2.00131055]
 [ 4.04289084]
 [-1.02178239]] loss fxn value:  0.017507060095063483 learn rate: 1.5625e-05 iteration: 25996
[[ 2.00131055]
 [ 4.04289084]
 [-1.02178267]] loss fxn value:  0.01750219748503886 learn rate: 1.5625e-05 iteration: 25997
[[ 2.00131055]
 [ 4.04289084]
 [-1.02178294]] loss fxn value:  0.01749733622738756 learn rate: 1.5625e-05 iteration: 25998
[[ 2.00131056]
 [ 4.04289084]
 [-1.02178321]] loss fxn value:  0.01749247631864918 learn rate: 1.5625e-05 iteration: 25999
[[ 2.00131056]
 [ 4.04289085]
 [-1.02178349]] loss fxn value:  0.017487617759096755 learn rate: 1.5625e-05 iteration: 26000
[[ 2.00131057]
 [ 4.04289085]
 [-1.02178376]] loss fxn value:  0.017482760550028006 learn rate: 1.5625e-05 iteration: 26001
[[ 2.00131057]
 [ 4.04289085]
 [-1.02178403]] loss fxn value:  0.01747790469002643 learn rate: 1.5625e-05 iteration: 26002
[[ 2.00131058]
 [ 4.04289085]
 [-1.02178431]] loss fxn value:  0.01747305017909664 learn rate: 1.5625e-05 iteration: 26003
[[ 2.00131058]
 [ 4.04289085]
 [-1.02178458]] loss fxn value:  0.01746819701638175 learn rate: 1.5625e-05 iteration: 26004
[[ 2.00131059]
 [ 4.04289085]
 [-1.02178485]] loss fxn value:  0.017463345200851316 learn rate: 1.5625e-05 iteration: 26005
[[ 2.00131059]
 [ 4.04289085]
 [-1.02178513]] loss fxn value:  0.01745849473311426 learn rate: 1.5625e-05 iteration: 26006
[[ 2.0013106 ]
 [ 4.04289085]
 [-1.0217854 ]] loss fxn value:  0.01745364561313973 learn rate: 1.5625e-05 iteration: 26007
[[ 2.0013106 ]
 [ 4.04289086]
 [-1.02178567]] loss fxn value:  0.017448797838471548 learn rate: 1.5625e-05 iteration: 26008
[[ 2.0013106 ]
 [ 4.04289086]
 [-1.02178594]] loss fxn value:  0.017443951412653428 learn rate: 1.5625e-05 iteration: 26009
[[ 2.00131061]
 [ 4.04289086]
 [-1.02178622]] loss fxn value:  0.01743910633117521 learn rate: 1.5625e-05 iteration: 26010
[[ 2.00131061]
 [ 4.04289086]
 [-1.02178649]] loss fxn value:  0.01743426259666665 learn rate: 1.5625e-05 iteration: 26011
[[ 2.00131062]
 [ 4.04289086]
 [-1.02178676]] loss fxn value:  0.017429420206531147 learn rate: 1.5625e-05 iteration: 26012
[[ 2.00131062]
 [ 4.04289086]
 [-1.02178703]] loss fxn value:  0.01742457916112506 learn rate: 1.5625e-05 iteration: 26013
[[ 2.00131063]
 [ 4.04289086]
 [-1.02178731]] loss fxn value:  0.01741973946148 learn rate: 1.5625e-05 iteration: 26014
[[ 2.00131063]
 [ 4.04289087]
 [-1.02178758]] loss fxn value:  0.01741490110601251 learn rate: 1.5625e-05 iteration: 26015
[[ 2.00131064]
 [ 4.04289087]
 [-1.02178785]] loss fxn value:  0.017410064093615753 learn rate: 1.5625e-05 iteration: 26016
[[ 2.00131064]
 [ 4.04289087]
 [-1.02178812]] loss fxn value:  0.017405228424527294 learn rate: 1.5625e-05 iteration: 26017
[[ 2.00131065]
 [ 4.04289087]
 [-1.02178839]] loss fxn value:  0.01740039409901209 learn rate: 1.5625e-05 iteration: 26018
[[ 2.00131065]
 [ 4.04289087]
 [-1.02178867]] loss fxn value:  0.017395561116200872 learn rate: 1.5625e-05 iteration: 26019
[[ 2.00131065]
 [ 4.04289087]
 [-1.02178894]] loss fxn value:  0.017390729476662488 learn rate: 1.5625e-05 iteration: 26020
[[ 2.00131066]
 [ 4.04289087]
 [-1.02178921]] loss fxn value:  0.017385899177376523 learn rate: 1.5625e-05 iteration: 26021
[[ 2.00131066]
 [ 4.04289088]
 [-1.02178948]] loss fxn value:  0.017381070221051415 learn rate: 1.5625e-05 iteration: 26022
[[ 2.00131067]
 [ 4.04289088]
 [-1.02178975]] loss fxn value:  0.01737624260497181 learn rate: 1.5625e-05 iteration: 26023
[[ 2.00131067]
 [ 4.04289088]
 [-1.02179002]] loss fxn value:  0.017371416330812534 learn rate: 1.5625e-05 iteration: 26024
[[ 2.00131068]
 [ 4.04289088]
 [-1.0217903 ]] loss fxn value:  0.01736659139619381 learn rate: 1.5625e-05 iteration: 26025
[[ 2.00131068]
 [ 4.04289088]
 [-1.02179057]] loss fxn value:  0.01736176780197483 learn rate: 1.5625e-05 iteration: 26026
[[ 2.00131069]
 [ 4.04289088]
 [-1.02179084]] loss fxn value:  0.017356945548267454 learn rate: 1.5625e-05 iteration: 26027
[[ 2.00131069]
 [ 4.04289088]
 [-1.02179111]] loss fxn value:  0.017352124634050465 learn rate: 1.5625e-05 iteration: 26028
[[ 2.0013107 ]
 [ 4.04289089]
 [-1.02179138]] loss fxn value:  0.017347305057593083 learn rate: 1.5625e-05 iteration: 26029
[[ 2.0013107 ]
 [ 4.04289089]
 [-1.02179165]] loss fxn value:  0.017342486820159875 learn rate: 1.5625e-05 iteration: 26030
[[ 2.0013107 ]
 [ 4.04289089]
 [-1.02179192]] loss fxn value:  0.017337669921404862 learn rate: 1.5625e-05 iteration: 26031
[[ 2.00131071]
 [ 4.04289089]
 [-1.02179219]] loss fxn value:  0.017332854360861825 learn rate: 1.5625e-05 iteration: 26032
[[ 2.00131071]
 [ 4.04289089]
 [-1.02179246]] loss fxn value:  0.017328040137047952 learn rate: 1.5625e-05 iteration: 26033
[[ 2.00131072]
 [ 4.04289089]
 [-1.02179273]] loss fxn value:  0.017323227251017616 learn rate: 1.5625e-05 iteration: 26034
[[ 2.00131072]
 [ 4.04289089]
 [-1.021793  ]] loss fxn value:  0.01731841570132115 learn rate: 1.5625e-05 iteration: 26035
[[ 2.00131073]
 [ 4.04289089]
 [-1.02179328]] loss fxn value:  0.017313605487501577 learn rate: 1.5625e-05 iteration: 26036
[[ 2.00131073]
 [ 4.0428909 ]
 [-1.02179355]] loss fxn value:  0.017308796610541483 learn rate: 1.5625e-05 iteration: 26037
[[ 2.00131074]
 [ 4.0428909 ]
 [-1.02179382]] loss fxn value:  0.017303989069486825 learn rate: 1.5625e-05 iteration: 26038
[[ 2.00131074]
 [ 4.0428909 ]
 [-1.02179409]] loss fxn value:  0.017299182863340302 learn rate: 1.5625e-05 iteration: 26039
[[ 2.00131075]
 [ 4.0428909 ]
 [-1.02179436]] loss fxn value:  0.017294377992280098 learn rate: 1.5625e-05 iteration: 26040
[[ 2.00131075]
 [ 4.0428909 ]
 [-1.02179463]] loss fxn value:  0.01728957445531584 learn rate: 1.5625e-05 iteration: 26041
[[ 2.00131075]
 [ 4.0428909 ]
 [-1.0217949 ]] loss fxn value:  0.01728477225280966 learn rate: 1.5625e-05 iteration: 26042
[[ 2.00131076]
 [ 4.0428909 ]
 [-1.02179517]] loss fxn value:  0.01727997138396637 learn rate: 1.5625e-05 iteration: 26043
[[ 2.00131076]
 [ 4.04289091]
 [-1.02179544]] loss fxn value:  0.017275171849273803 learn rate: 1.5625e-05 iteration: 26044
[[ 2.00131077]
 [ 4.04289091]
 [-1.02179571]] loss fxn value:  0.017270373646223313 learn rate: 1.5625e-05 iteration: 26045
[[ 2.00131077]
 [ 4.04289091]
 [-1.02179598]] loss fxn value:  0.017265576776985345 learn rate: 1.5625e-05 iteration: 26046
[[ 2.00131078]
 [ 4.04289091]
 [-1.02179625]] loss fxn value:  0.01726078124034897 learn rate: 1.5625e-05 iteration: 26047
[[ 2.00131078]
 [ 4.04289091]
 [-1.02179652]] loss fxn value:  0.017255987036080073 learn rate: 1.5625e-05 iteration: 26048
[[ 2.00131079]
 [ 4.04289091]
 [-1.02179679]] loss fxn value:  0.017251194161625304 learn rate: 1.5625e-05 iteration: 26049
[[ 2.00131079]
 [ 4.04289091]
 [-1.02179706]] loss fxn value:  0.017246402619173574 learn rate: 1.5625e-05 iteration: 26050
[[ 2.00131079]
 [ 4.04289092]
 [-1.02179732]] loss fxn value:  0.01724161240847809 learn rate: 1.5625e-05 iteration: 26051
[[ 2.0013108 ]
 [ 4.04289092]
 [-1.02179759]] loss fxn value:  0.01723682352721068 learn rate: 1.5625e-05 iteration: 26052
[[ 2.0013108 ]
 [ 4.04289092]
 [-1.02179786]] loss fxn value:  0.01723203597602351 learn rate: 1.5625e-05 iteration: 26053
[[ 2.00131081]
 [ 4.04289092]
 [-1.02179813]] loss fxn value:  0.017227249755356566 learn rate: 1.5625e-05 iteration: 26054
[[ 2.00131081]
 [ 4.04289092]
 [-1.0217984 ]] loss fxn value:  0.017222464863632166 learn rate: 1.5625e-05 iteration: 26055
[[ 2.00131082]
 [ 4.04289092]
 [-1.02179867]] loss fxn value:  0.01721768130062166 learn rate: 1.5625e-05 iteration: 26056
[[ 2.00131082]
 [ 4.04289092]
 [-1.02179894]] loss fxn value:  0.017212899067164944 learn rate: 1.5625e-05 iteration: 26057
[[ 2.00131083]
 [ 4.04289092]
 [-1.02179921]] loss fxn value:  0.017208118161312968 learn rate: 1.5625e-05 iteration: 26058
[[ 2.00131083]
 [ 4.04289093]
 [-1.02179948]] loss fxn value:  0.017203338582815475 learn rate: 1.5625e-05 iteration: 26059
[[ 2.00131084]
 [ 4.04289093]
 [-1.02179975]] loss fxn value:  0.01719856033201066 learn rate: 1.5625e-05 iteration: 26060
[[ 2.00131084]
 [ 4.04289093]
 [-1.02180002]] loss fxn value:  0.017193783409421827 learn rate: 1.5625e-05 iteration: 26061
[[ 2.00131084]
 [ 4.04289093]
 [-1.02180028]] loss fxn value:  0.017189007813133098 learn rate: 1.5625e-05 iteration: 26062
[[ 2.00131085]
 [ 4.04289093]
 [-1.02180055]] loss fxn value:  0.017184233543173017 learn rate: 1.5625e-05 iteration: 26063
[[ 2.00131085]
 [ 4.04289093]
 [-1.02180082]] loss fxn value:  0.01717946059876024 learn rate: 1.5625e-05 iteration: 26064
[[ 2.00131086]
 [ 4.04289093]
 [-1.02180109]] loss fxn value:  0.017174688981523762 learn rate: 1.5625e-05 iteration: 26065
[[ 2.00131086]
 [ 4.04289094]
 [-1.02180136]] loss fxn value:  0.017169918688375703 learn rate: 1.5625e-05 iteration: 26066
[[ 2.00131087]
 [ 4.04289094]
 [-1.02180163]] loss fxn value:  0.01716514972028249 learn rate: 1.5625e-05 iteration: 26067
[[ 2.00131087]
 [ 4.04289094]
 [-1.02180189]] loss fxn value:  0.017160382077582338 learn rate: 1.5625e-05 iteration: 26068
[[ 2.00131088]
 [ 4.04289094]
 [-1.02180216]] loss fxn value:  0.017155615758004155 learn rate: 1.5625e-05 iteration: 26069
[[ 2.00131088]
 [ 4.04289094]
 [-1.02180243]] loss fxn value:  0.01715085076359961 learn rate: 1.5625e-05 iteration: 26070
[[ 2.00131088]
 [ 4.04289094]
 [-1.0218027 ]] loss fxn value:  0.017146087091653335 learn rate: 1.5625e-05 iteration: 26071
[[ 2.00131089]
 [ 4.04289094]
 [-1.02180297]] loss fxn value:  0.017141324743059672 learn rate: 1.5625e-05 iteration: 26072
[[ 2.00131089]
 [ 4.04289095]
 [-1.02180323]] loss fxn value:  0.01713656371664547 learn rate: 1.5625e-05 iteration: 26073
[[ 2.0013109 ]
 [ 4.04289095]
 [-1.0218035 ]] loss fxn value:  0.017131804012524895 learn rate: 1.5625e-05 iteration: 26074
[[ 2.0013109 ]
 [ 4.04289095]
 [-1.02180377]] loss fxn value:  0.017127045631592605 learn rate: 1.5625e-05 iteration: 26075
[[ 2.00131091]
 [ 4.04289095]
 [-1.02180404]] loss fxn value:  0.017122288571525902 learn rate: 1.5625e-05 iteration: 26076
[[ 2.00131091]
 [ 4.04289095]
 [-1.0218043 ]] loss fxn value:  0.017117532833768975 learn rate: 1.5625e-05 iteration: 26077
[[ 2.00131092]
 [ 4.04289095]
 [-1.02180457]] loss fxn value:  0.017112778415425668 learn rate: 1.5625e-05 iteration: 26078
[[ 2.00131092]
 [ 4.04289095]
 [-1.02180484]] loss fxn value:  0.017108025318596953 learn rate: 1.5625e-05 iteration: 26079
[[ 2.00131092]
 [ 4.04289095]
 [-1.02180511]] loss fxn value:  0.017103273541641144 learn rate: 1.5625e-05 iteration: 26080
[[ 2.00131093]
 [ 4.04289096]
 [-1.02180537]] loss fxn value:  0.01709852308425551 learn rate: 1.5625e-05 iteration: 26081
[[ 2.00131093]
 [ 4.04289096]
 [-1.02180564]] loss fxn value:  0.01709377394689473 learn rate: 1.5625e-05 iteration: 26082
[[ 2.00131094]
 [ 4.04289096]
 [-1.02180591]] loss fxn value:  0.017089026127557295 learn rate: 1.5625e-05 iteration: 26083
[[ 2.00131094]
 [ 4.04289096]
 [-1.02180617]] loss fxn value:  0.01708427962752045 learn rate: 1.5625e-05 iteration: 26084
[[ 2.00131095]
 [ 4.04289096]
 [-1.02180644]] loss fxn value:  0.017079534445935397 learn rate: 1.5625e-05 iteration: 26085
[[ 2.00131095]
 [ 4.04289096]
 [-1.02180671]] loss fxn value:  0.017074790583099093 learn rate: 1.5625e-05 iteration: 26086
[[ 2.00131096]
 [ 4.04289096]
 [-1.02180697]] loss fxn value:  0.01707004803644581 learn rate: 1.5625e-05 iteration: 26087
[[ 2.00131096]
 [ 4.04289097]
 [-1.02180724]] loss fxn value:  0.017065306808629204 learn rate: 1.5625e-05 iteration: 26088
[[ 2.00131096]
 [ 4.04289097]
 [-1.02180751]] loss fxn value:  0.017060566896081646 learn rate: 1.5625e-05 iteration: 26089
[[ 2.00131097]
 [ 4.04289097]
 [-1.02180777]] loss fxn value:  0.0170558283013187 learn rate: 1.5625e-05 iteration: 26090
[[ 2.00131097]
 [ 4.04289097]
 [-1.02180804]] loss fxn value:  0.01705109102197213 learn rate: 1.5625e-05 iteration: 26091
[[ 2.00131098]
 [ 4.04289097]
 [-1.02180831]] loss fxn value:  0.017046355059046135 learn rate: 1.5625e-05 iteration: 26092
[[ 2.00131098]
 [ 4.04289097]
 [-1.02180857]] loss fxn value:  0.01704162041053461 learn rate: 1.5625e-05 iteration: 26093
[[ 2.00131099]
 [ 4.04289097]
 [-1.02180884]] loss fxn value:  0.017036887078048377 learn rate: 1.5625e-05 iteration: 26094
[[ 2.00131099]
 [ 4.04289098]
 [-1.02180911]] loss fxn value:  0.01703215505904102 learn rate: 1.5625e-05 iteration: 26095
[[ 2.001311  ]
 [ 4.04289098]
 [-1.02180937]] loss fxn value:  0.017027424355632818 learn rate: 1.5625e-05 iteration: 26096
[[ 2.001311  ]
 [ 4.04289098]
 [-1.02180964]] loss fxn value:  0.017022694966158172 learn rate: 1.5625e-05 iteration: 26097
[[ 2.001311  ]
 [ 4.04289098]
 [-1.0218099 ]] loss fxn value:  0.017017966889495223 learn rate: 1.5625e-05 iteration: 26098
[[ 2.00131101]
 [ 4.04289098]
 [-1.02181017]] loss fxn value:  0.01701324012640139 learn rate: 1.5625e-05 iteration: 26099
[[ 2.00131101]
 [ 4.04289098]
 [-1.02181044]] loss fxn value:  0.01700851467602901 learn rate: 1.5625e-05 iteration: 26100
[[ 2.00131102]
 [ 4.04289098]
 [-1.0218107 ]] loss fxn value:  0.0170037905379211 learn rate: 1.5625e-05 iteration: 26101
[[ 2.00131102]
 [ 4.04289098]
 [-1.02181097]] loss fxn value:  0.016999067713048724 learn rate: 1.5625e-05 iteration: 26102
[[ 2.00131103]
 [ 4.04289099]
 [-1.02181123]] loss fxn value:  0.016994346199360206 learn rate: 1.5625e-05 iteration: 26103
[[ 2.00131103]
 [ 4.04289099]
 [-1.0218115 ]] loss fxn value:  0.016989625996288702 learn rate: 1.5625e-05 iteration: 26104
[[ 2.00131104]
 [ 4.04289099]
 [-1.02181176]] loss fxn value:  0.016984907104908208 learn rate: 1.5625e-05 iteration: 26105
[[ 2.00131104]
 [ 4.04289099]
 [-1.02181203]] loss fxn value:  0.01698018952446361 learn rate: 1.5625e-05 iteration: 26106
[[ 2.00131104]
 [ 4.04289099]
 [-1.02181229]] loss fxn value:  0.01697547325450024 learn rate: 1.5625e-05 iteration: 26107
[[ 2.00131105]
 [ 4.04289099]
 [-1.02181256]] loss fxn value:  0.016970758293497503 learn rate: 1.5625e-05 iteration: 26108
[[ 2.00131105]
 [ 4.04289099]
 [-1.02181282]] loss fxn value:  0.01696604464260232 learn rate: 1.5625e-05 iteration: 26109
[[ 2.00131106]
 [ 4.042891  ]
 [-1.02181309]] loss fxn value:  0.016961332301614902 learn rate: 1.5625e-05 iteration: 26110
[[ 2.00131106]
 [ 4.042891  ]
 [-1.02181335]] loss fxn value:  0.01695662126834517 learn rate: 1.5625e-05 iteration: 26111
[[ 2.00131107]
 [ 4.042891  ]
 [-1.02181362]] loss fxn value:  0.016951911544185707 learn rate: 1.5625e-05 iteration: 26112
[[ 2.00131107]
 [ 4.042891  ]
 [-1.02181388]] loss fxn value:  0.016947203127260713 learn rate: 1.5625e-05 iteration: 26113
[[ 2.00131108]
 [ 4.042891  ]
 [-1.02181415]] loss fxn value:  0.016942496019445984 learn rate: 1.5625e-05 iteration: 26114
[[ 2.00131108]
 [ 4.042891  ]
 [-1.02181441]] loss fxn value:  0.016937790218325418 learn rate: 1.5625e-05 iteration: 26115
[[ 2.00131108]
 [ 4.042891  ]
 [-1.02181468]] loss fxn value:  0.01693308572458665 learn rate: 1.5625e-05 iteration: 26116
[[ 2.00131109]
 [ 4.042891  ]
 [-1.02181494]] loss fxn value:  0.01692838253714445 learn rate: 1.5625e-05 iteration: 26117
[[ 2.00131109]
 [ 4.04289101]
 [-1.02181521]] loss fxn value:  0.01692368065654374 learn rate: 1.5625e-05 iteration: 26118
[[ 2.0013111 ]
 [ 4.04289101]
 [-1.02181547]] loss fxn value:  0.016918980081263933 learn rate: 1.5625e-05 iteration: 26119
[[ 2.0013111 ]
 [ 4.04289101]
 [-1.02181574]] loss fxn value:  0.016914280811547205 learn rate: 1.5625e-05 iteration: 26120
[[ 2.00131111]
 [ 4.04289101]
 [-1.021816  ]] loss fxn value:  0.016909582847705523 learn rate: 1.5625e-05 iteration: 26121
[[ 2.00131111]
 [ 4.04289101]
 [-1.02181626]] loss fxn value:  0.016904886188760918 learn rate: 1.5625e-05 iteration: 26122
[[ 2.00131112]
 [ 4.04289101]
 [-1.02181653]] loss fxn value:  0.01690019083350821 learn rate: 1.5625e-05 iteration: 26123
[[ 2.00131112]
 [ 4.04289101]
 [-1.02181679]] loss fxn value:  0.01689549678320966 learn rate: 1.5625e-05 iteration: 26124
[[ 2.00131112]
 [ 4.04289102]
 [-1.02181706]] loss fxn value:  0.016890804036565236 learn rate: 1.5625e-05 iteration: 26125
[[ 2.00131113]
 [ 4.04289102]
 [-1.02181732]] loss fxn value:  0.016886112593072405 learn rate: 1.5625e-05 iteration: 26126
[[ 2.00131113]
 [ 4.04289102]
 [-1.02181758]] loss fxn value:  0.01688142245271733 learn rate: 1.5625e-05 iteration: 26127
[[ 2.00131114]
 [ 4.04289102]
 [-1.02181785]] loss fxn value:  0.01687673361510933 learn rate: 1.5625e-05 iteration: 26128
[[ 2.00131114]
 [ 4.04289102]
 [-1.02181811]] loss fxn value:  0.016872046079672638 learn rate: 1.5625e-05 iteration: 26129
[[ 2.00131115]
 [ 4.04289102]
 [-1.02181838]] loss fxn value:  0.016867359846201684 learn rate: 1.5625e-05 iteration: 26130
[[ 2.00131115]
 [ 4.04289102]
 [-1.02181864]] loss fxn value:  0.016862674914319347 learn rate: 1.5625e-05 iteration: 26131
[[ 2.00131115]
 [ 4.04289102]
 [-1.0218189 ]] loss fxn value:  0.01685799128351501 learn rate: 1.5625e-05 iteration: 26132
[[ 2.00131116]
 [ 4.04289103]
 [-1.02181917]] loss fxn value:  0.016853308954886594 learn rate: 1.5625e-05 iteration: 26133
[[ 2.00131116]
 [ 4.04289103]
 [-1.02181943]] loss fxn value:  0.016848627925277592 learn rate: 1.5625e-05 iteration: 26134
[[ 2.00131117]
 [ 4.04289103]
 [-1.02181969]] loss fxn value:  0.016843948196168513 learn rate: 1.5625e-05 iteration: 26135
[[ 2.00131117]
 [ 4.04289103]
 [-1.02181996]] loss fxn value:  0.016839269767054514 learn rate: 1.5625e-05 iteration: 26136
[[ 2.00131118]
 [ 4.04289103]
 [-1.02182022]] loss fxn value:  0.016834592636931385 learn rate: 1.5625e-05 iteration: 26137
[[ 2.00131118]
 [ 4.04289103]
 [-1.02182048]] loss fxn value:  0.016829916806941438 learn rate: 1.5625e-05 iteration: 26138
[[ 2.00131119]
 [ 4.04289103]
 [-1.02182074]] loss fxn value:  0.01682524227449731 learn rate: 1.5625e-05 iteration: 26139
[[ 2.00131119]
 [ 4.04289104]
 [-1.02182101]] loss fxn value:  0.016820569040760628 learn rate: 1.5625e-05 iteration: 26140
[[ 2.00131119]
 [ 4.04289104]
 [-1.02182127]] loss fxn value:  0.016815897106105055 learn rate: 1.5625e-05 iteration: 26141
[[ 2.0013112 ]
 [ 4.04289104]
 [-1.02182153]] loss fxn value:  0.01681122646770767 learn rate: 1.5625e-05 iteration: 26142
[[ 2.0013112 ]
 [ 4.04289104]
 [-1.0218218 ]] loss fxn value:  0.016806557127119908 learn rate: 1.5625e-05 iteration: 26143
[[ 2.00131121]
 [ 4.04289104]
 [-1.02182206]] loss fxn value:  0.01680188908327817 learn rate: 1.5625e-05 iteration: 26144
[[ 2.00131121]
 [ 4.04289104]
 [-1.02182232]] loss fxn value:  0.016797222335268477 learn rate: 1.5625e-05 iteration: 26145
[[ 2.00131122]
 [ 4.04289104]
 [-1.02182258]] loss fxn value:  0.0167925568851278 learn rate: 1.5625e-05 iteration: 26146
[[ 2.00131122]
 [ 4.04289104]
 [-1.02182285]] loss fxn value:  0.016787892729800268 learn rate: 1.5625e-05 iteration: 26147
[[ 2.00131122]
 [ 4.04289105]
 [-1.02182311]] loss fxn value:  0.016783229869999736 learn rate: 1.5625e-05 iteration: 26148
[[ 2.00131123]
 [ 4.04289105]
 [-1.02182337]] loss fxn value:  0.01677856830606441 learn rate: 1.5625e-05 iteration: 26149
[[ 2.00131123]
 [ 4.04289105]
 [-1.02182363]] loss fxn value:  0.016773908035273146 learn rate: 1.5625e-05 iteration: 26150
[[ 2.00131124]
 [ 4.04289105]
 [-1.02182389]] loss fxn value:  0.016769249060922854 learn rate: 1.5625e-05 iteration: 26151
[[ 2.00131124]
 [ 4.04289105]
 [-1.02182416]] loss fxn value:  0.016764591379100777 learn rate: 1.5625e-05 iteration: 26152
[[ 2.00131125]
 [ 4.04289105]
 [-1.02182442]] loss fxn value:  0.016759934991505673 learn rate: 1.5625e-05 iteration: 26153
[[ 2.00131125]
 [ 4.04289105]
 [-1.02182468]] loss fxn value:  0.016755279896514326 learn rate: 1.5625e-05 iteration: 26154
[[ 2.00131126]
 [ 4.04289106]
 [-1.02182494]] loss fxn value:  0.016750626095681332 learn rate: 1.5625e-05 iteration: 26155
[[ 2.00131126]
 [ 4.04289106]
 [-1.0218252 ]] loss fxn value:  0.016745973586083443 learn rate: 1.5625e-05 iteration: 26156
[[ 2.00131126]
 [ 4.04289106]
 [-1.02182546]] loss fxn value:  0.016741322370255544 learn rate: 1.5625e-05 iteration: 26157
[[ 2.00131127]
 [ 4.04289106]
 [-1.02182573]] loss fxn value:  0.01673667244514407 learn rate: 1.5625e-05 iteration: 26158
[[ 2.00131127]
 [ 4.04289106]
 [-1.02182599]] loss fxn value:  0.01673202381241923 learn rate: 1.5625e-05 iteration: 26159
[[ 2.00131128]
 [ 4.04289106]
 [-1.02182625]] loss fxn value:  0.01672737647049414 learn rate: 1.5625e-05 iteration: 26160
[[ 2.00131128]
 [ 4.04289106]
 [-1.02182651]] loss fxn value:  0.016722730419039808 learn rate: 1.5625e-05 iteration: 26161
[[ 2.00131129]
 [ 4.04289106]
 [-1.02182677]] loss fxn value:  0.01671808565802309 learn rate: 1.5625e-05 iteration: 26162
[[ 2.00131129]
 [ 4.04289107]
 [-1.02182703]] loss fxn value:  0.016713442187422364 learn rate: 1.5625e-05 iteration: 26163
[[ 2.00131129]
 [ 4.04289107]
 [-1.02182729]] loss fxn value:  0.016708800006376125 learn rate: 1.5625e-05 iteration: 26164
[[ 2.0013113 ]
 [ 4.04289107]
 [-1.02182755]] loss fxn value:  0.016704159115234114 learn rate: 1.5625e-05 iteration: 26165
[[ 2.0013113 ]
 [ 4.04289107]
 [-1.02182782]] loss fxn value:  0.016699519512313403 learn rate: 1.5625e-05 iteration: 26166
[[ 2.00131131]
 [ 4.04289107]
 [-1.02182808]] loss fxn value:  0.016694881198923258 learn rate: 1.5625e-05 iteration: 26167
[[ 2.00131131]
 [ 4.04289107]
 [-1.02182834]] loss fxn value:  0.016690244172764046 learn rate: 1.5625e-05 iteration: 26168
[[ 2.00131132]
 [ 4.04289107]
 [-1.0218286 ]] loss fxn value:  0.016685608435195187 learn rate: 1.5625e-05 iteration: 26169
[[ 2.00131132]
 [ 4.04289108]
 [-1.02182886]] loss fxn value:  0.016680973985369028 learn rate: 1.5625e-05 iteration: 26170
[[ 2.00131133]
 [ 4.04289108]
 [-1.02182912]] loss fxn value:  0.016676340821835903 learn rate: 1.5625e-05 iteration: 26171
[[ 2.00131133]
 [ 4.04289108]
 [-1.02182938]] loss fxn value:  0.016671708946097947 learn rate: 1.5625e-05 iteration: 26172
[[ 2.00131133]
 [ 4.04289108]
 [-1.02182964]] loss fxn value:  0.016667078356134343 learn rate: 1.5625e-05 iteration: 26173
[[ 2.00131134]
 [ 4.04289108]
 [-1.0218299 ]] loss fxn value:  0.016662449053068087 learn rate: 1.5625e-05 iteration: 26174
[[ 2.00131134]
 [ 4.04289108]
 [-1.02183016]] loss fxn value:  0.016657821036257094 learn rate: 1.5625e-05 iteration: 26175
[[ 2.00131135]
 [ 4.04289108]
 [-1.02183042]] loss fxn value:  0.01665319430403921 learn rate: 1.5625e-05 iteration: 26176
[[ 2.00131135]
 [ 4.04289108]
 [-1.02183068]] loss fxn value:  0.01664856885625788 learn rate: 1.5625e-05 iteration: 26177
[[ 2.00131136]
 [ 4.04289109]
 [-1.02183094]] loss fxn value:  0.01664394469492383 learn rate: 1.5625e-05 iteration: 26178
[[ 2.00131136]
 [ 4.04289109]
 [-1.0218312 ]] loss fxn value:  0.016639321816198392 learn rate: 1.5625e-05 iteration: 26179
[[ 2.00131136]
 [ 4.04289109]
 [-1.02183146]] loss fxn value:  0.01663470022206837 learn rate: 1.5625e-05 iteration: 26180
[[ 2.00131137]
 [ 4.04289109]
 [-1.02183172]] loss fxn value:  0.016630079912408054 learn rate: 1.5625e-05 iteration: 26181
[[ 2.00131137]
 [ 4.04289109]
 [-1.02183198]] loss fxn value:  0.016625460885910496 learn rate: 1.5625e-05 iteration: 26182
[[ 2.00131138]
 [ 4.04289109]
 [-1.02183224]] loss fxn value:  0.0166208431407616 learn rate: 1.5625e-05 iteration: 26183
[[ 2.00131138]
 [ 4.04289109]
 [-1.0218325 ]] loss fxn value:  0.016616226680144112 learn rate: 1.5625e-05 iteration: 26184
[[ 2.00131139]
 [ 4.0428911 ]
 [-1.02183276]] loss fxn value:  0.016611611500875284 learn rate: 1.5625e-05 iteration: 26185
[[ 2.00131139]
 [ 4.0428911 ]
 [-1.02183302]] loss fxn value:  0.016606997603345792 learn rate: 1.5625e-05 iteration: 26186
[[ 2.00131139]
 [ 4.0428911 ]
 [-1.02183328]] loss fxn value:  0.01660238498767441 learn rate: 1.5625e-05 iteration: 26187
[[ 2.0013114 ]
 [ 4.0428911 ]
 [-1.02183354]] loss fxn value:  0.016597773652837624 learn rate: 1.5625e-05 iteration: 26188
[[ 2.0013114]
 [ 4.0428911]
 [-1.0218338]] loss fxn value:  0.0165931635989519 learn rate: 1.5625e-05 iteration: 26189
[[ 2.00131141]
 [ 4.0428911 ]
 [-1.02183406]] loss fxn value:  0.01658855482586992 learn rate: 1.5625e-05 iteration: 26190
[[ 2.00131141]
 [ 4.0428911 ]
 [-1.02183432]] loss fxn value:  0.01658394733189175 learn rate: 1.5625e-05 iteration: 26191
[[ 2.00131142]
 [ 4.0428911 ]
 [-1.02183458]] loss fxn value:  0.01657934111883149 learn rate: 1.5625e-05 iteration: 26192
[[ 2.00131142]
 [ 4.04289111]
 [-1.02183483]] loss fxn value:  0.01657473618475395 learn rate: 1.5625e-05 iteration: 26193
[[ 2.00131142]
 [ 4.04289111]
 [-1.02183509]] loss fxn value:  0.01657013252933016 learn rate: 1.5625e-05 iteration: 26194
[[ 2.00131143]
 [ 4.04289111]
 [-1.02183535]] loss fxn value:  0.016565530152522347 learn rate: 1.5625e-05 iteration: 26195
[[ 2.00131143]
 [ 4.04289111]
 [-1.02183561]] loss fxn value:  0.01656092905482296 learn rate: 1.5625e-05 iteration: 26196
[[ 2.00131144]
 [ 4.04289111]
 [-1.02183587]] loss fxn value:  0.016556329234735333 learn rate: 1.5625e-05 iteration: 26197
[[ 2.00131144]
 [ 4.04289111]
 [-1.02183613]] loss fxn value:  0.016551730691454204 learn rate: 1.5625e-05 iteration: 26198
[[ 2.00131145]
 [ 4.04289111]
 [-1.02183639]] loss fxn value:  0.01654713342641769 learn rate: 1.5625e-05 iteration: 26199
[[ 2.00131145]
 [ 4.04289111]
 [-1.02183665]] loss fxn value:  0.016542537437618826 learn rate: 1.5625e-05 iteration: 26200
[[ 2.00131146]
 [ 4.04289112]
 [-1.0218369 ]] loss fxn value:  0.016537942726157526 learn rate: 1.5625e-05 iteration: 26201
[[ 2.00131146]
 [ 4.04289112]
 [-1.02183716]] loss fxn value:  0.016533349290008367 learn rate: 1.5625e-05 iteration: 26202
[[ 2.00131146]
 [ 4.04289112]
 [-1.02183742]] loss fxn value:  0.016528757130298954 learn rate: 1.5625e-05 iteration: 26203
[[ 2.00131147]
 [ 4.04289112]
 [-1.02183768]] loss fxn value:  0.01652416624596338 learn rate: 1.5625e-05 iteration: 26204
[[ 2.00131147]
 [ 4.04289112]
 [-1.02183794]] loss fxn value:  0.016519576635673074 learn rate: 1.5625e-05 iteration: 26205
[[ 2.00131148]
 [ 4.04289112]
 [-1.0218382 ]] loss fxn value:  0.01651498830230343 learn rate: 1.5625e-05 iteration: 26206
[[ 2.00131148]
 [ 4.04289112]
 [-1.02183845]] loss fxn value:  0.016510401241941683 learn rate: 1.5625e-05 iteration: 26207
[[ 2.00131149]
 [ 4.04289113]
 [-1.02183871]] loss fxn value:  0.0165058154556869 learn rate: 1.5625e-05 iteration: 26208
[[ 2.00131149]
 [ 4.04289113]
 [-1.02183897]] loss fxn value:  0.01650123094352755 learn rate: 1.5625e-05 iteration: 26209
[[ 2.00131149]
 [ 4.04289113]
 [-1.02183923]] loss fxn value:  0.016496647704927935 learn rate: 1.5625e-05 iteration: 26210
[[ 2.0013115 ]
 [ 4.04289113]
 [-1.02183948]] loss fxn value:  0.01649206573909518 learn rate: 1.5625e-05 iteration: 26211
[[ 2.0013115 ]
 [ 4.04289113]
 [-1.02183974]] loss fxn value:  0.01648748504539874 learn rate: 1.5625e-05 iteration: 26212
[[ 2.00131151]
 [ 4.04289113]
 [-1.02184   ]] loss fxn value:  0.016482905624038407 learn rate: 1.5625e-05 iteration: 26213
[[ 2.00131151]
 [ 4.04289113]
 [-1.02184026]] loss fxn value:  0.01647832747445226 learn rate: 1.5625e-05 iteration: 26214
[[ 2.00131152]
 [ 4.04289113]
 [-1.02184051]] loss fxn value:  0.016473750598028254 learn rate: 1.5625e-05 iteration: 26215
[[ 2.00131152]
 [ 4.04289114]
 [-1.02184077]] loss fxn value:  0.01646917499201209 learn rate: 1.5625e-05 iteration: 26216
[[ 2.00131152]
 [ 4.04289114]
 [-1.02184103]] loss fxn value:  0.01646460065639223 learn rate: 1.5625e-05 iteration: 26217
[[ 2.00131153]
 [ 4.04289114]
 [-1.02184129]] loss fxn value:  0.016460027591270455 learn rate: 1.5625e-05 iteration: 26218
[[ 2.00131153]
 [ 4.04289114]
 [-1.02184154]] loss fxn value:  0.016455455796037837 learn rate: 1.5625e-05 iteration: 26219
[[ 2.00131154]
 [ 4.04289114]
 [-1.0218418 ]] loss fxn value:  0.016450885271331844 learn rate: 1.5625e-05 iteration: 26220
[[ 2.00131154]
 [ 4.04289114]
 [-1.02184206]] loss fxn value:  0.016446316016000932 learn rate: 1.5625e-05 iteration: 26221
[[ 2.00131155]
 [ 4.04289114]
 [-1.02184231]] loss fxn value:  0.016441748029861158 learn rate: 1.5625e-05 iteration: 26222
[[ 2.00131155]
 [ 4.04289114]
 [-1.02184257]] loss fxn value:  0.01643718131230128 learn rate: 1.5625e-05 iteration: 26223
[[ 2.00131155]
 [ 4.04289115]
 [-1.02184283]] loss fxn value:  0.016432615863297376 learn rate: 1.5625e-05 iteration: 26224
[[ 2.00131156]
 [ 4.04289115]
 [-1.02184309]] loss fxn value:  0.01642805168158257 learn rate: 1.5625e-05 iteration: 26225
[[ 2.00131156]
 [ 4.04289115]
 [-1.02184334]] loss fxn value:  0.016423488768471592 learn rate: 1.5625e-05 iteration: 26226
[[ 2.00131157]
 [ 4.04289115]
 [-1.0218436 ]] loss fxn value:  0.016418927122557166 learn rate: 1.5625e-05 iteration: 26227
[[ 2.00131157]
 [ 4.04289115]
 [-1.02184385]] loss fxn value:  0.016414366743048716 learn rate: 1.5625e-05 iteration: 26228
[[ 2.00131158]
 [ 4.04289115]
 [-1.02184411]] loss fxn value:  0.01640980763075844 learn rate: 1.5625e-05 iteration: 26229
[[ 2.00131158]
 [ 4.04289115]
 [-1.02184437]] loss fxn value:  0.0164052497847839 learn rate: 1.5625e-05 iteration: 26230
[[ 2.00131158]
 [ 4.04289116]
 [-1.02184462]] loss fxn value:  0.01640069320469435 learn rate: 1.5625e-05 iteration: 26231
[[ 2.00131159]
 [ 4.04289116]
 [-1.02184488]] loss fxn value:  0.016396137890973002 learn rate: 1.5625e-05 iteration: 26232
[[ 2.00131159]
 [ 4.04289116]
 [-1.02184514]] loss fxn value:  0.016391583841232304 learn rate: 1.5625e-05 iteration: 26233
[[ 2.0013116 ]
 [ 4.04289116]
 [-1.02184539]] loss fxn value:  0.016387031057442904 learn rate: 1.5625e-05 iteration: 26234
[[ 2.0013116 ]
 [ 4.04289116]
 [-1.02184565]] loss fxn value:  0.016382479537234255 learn rate: 1.5625e-05 iteration: 26235
[[ 2.00131161]
 [ 4.04289116]
 [-1.0218459 ]] loss fxn value:  0.016377929281546553 learn rate: 1.5625e-05 iteration: 26236
[[ 2.00131161]
 [ 4.04289116]
 [-1.02184616]] loss fxn value:  0.01637338029035357 learn rate: 1.5625e-05 iteration: 26237
[[ 2.00131161]
 [ 4.04289116]
 [-1.02184642]] loss fxn value:  0.016368832561895984 learn rate: 1.5625e-05 iteration: 26238
[[ 2.00131162]
 [ 4.04289117]
 [-1.02184667]] loss fxn value:  0.016364286096514302 learn rate: 1.5625e-05 iteration: 26239
[[ 2.00131162]
 [ 4.04289117]
 [-1.02184693]] loss fxn value:  0.016359740893913566 learn rate: 1.5625e-05 iteration: 26240
[[ 2.00131163]
 [ 4.04289117]
 [-1.02184718]] loss fxn value:  0.01635519695347707 learn rate: 1.5625e-05 iteration: 26241
[[ 2.00131163]
 [ 4.04289117]
 [-1.02184744]] loss fxn value:  0.016350654276323196 learn rate: 1.5625e-05 iteration: 26242
[[ 2.00131164]
 [ 4.04289117]
 [-1.02184769]] loss fxn value:  0.016346112859874674 learn rate: 1.5625e-05 iteration: 26243
[[ 2.00131164]
 [ 4.04289117]
 [-1.02184795]] loss fxn value:  0.01634157270582796 learn rate: 1.5625e-05 iteration: 26244
[[ 2.00131164]
 [ 4.04289117]
 [-1.0218482 ]] loss fxn value:  0.016337033812058154 learn rate: 1.5625e-05 iteration: 26245
[[ 2.00131165]
 [ 4.04289117]
 [-1.02184846]] loss fxn value:  0.016332496178812054 learn rate: 1.5625e-05 iteration: 26246
[[ 2.00131165]
 [ 4.04289118]
 [-1.02184871]] loss fxn value:  0.016327959805445266 learn rate: 1.5625e-05 iteration: 26247
[[ 2.00131166]
 [ 4.04289118]
 [-1.02184897]] loss fxn value:  0.016323424693116248 learn rate: 1.5625e-05 iteration: 26248
[[ 2.00131166]
 [ 4.04289118]
 [-1.02184923]] loss fxn value:  0.016318890840166324 learn rate: 1.5625e-05 iteration: 26249
[[ 2.00131166]
 [ 4.04289118]
 [-1.02184948]] loss fxn value:  0.016314358246219515 learn rate: 1.5625e-05 iteration: 26250
[[ 2.00131167]
 [ 4.04289118]
 [-1.02184973]] loss fxn value:  0.01630982691197037 learn rate: 1.5625e-05 iteration: 26251
[[ 2.00131167]
 [ 4.04289118]
 [-1.02184999]] loss fxn value:  0.016305296834796073 learn rate: 1.5625e-05 iteration: 26252
[[ 2.00131168]
 [ 4.04289118]
 [-1.02185024]] loss fxn value:  0.016300768016774523 learn rate: 1.5625e-05 iteration: 26253
[[ 2.00131168]
 [ 4.04289119]
 [-1.0218505 ]] loss fxn value:  0.01629624045736311 learn rate: 1.5625e-05 iteration: 26254
[[ 2.00131169]
 [ 4.04289119]
 [-1.02185075]] loss fxn value:  0.016291714155121397 learn rate: 1.5625e-05 iteration: 26255
[[ 2.00131169]
 [ 4.04289119]
 [-1.02185101]] loss fxn value:  0.016287189108300154 learn rate: 1.5625e-05 iteration: 26256
[[ 2.00131169]
 [ 4.04289119]
 [-1.02185126]] loss fxn value:  0.016282665320664812 learn rate: 1.5625e-05 iteration: 26257
[[ 2.0013117 ]
 [ 4.04289119]
 [-1.02185152]] loss fxn value:  0.01627814278737625 learn rate: 1.5625e-05 iteration: 26258
[[ 2.0013117 ]
 [ 4.04289119]
 [-1.02185177]] loss fxn value:  0.016273621511902633 learn rate: 1.5625e-05 iteration: 26259
[[ 2.00131171]
 [ 4.04289119]
 [-1.02185203]] loss fxn value:  0.016269101491775396 learn rate: 1.5625e-05 iteration: 26260
[[ 2.00131171]
 [ 4.04289119]
 [-1.02185228]] loss fxn value:  0.016264582727101774 learn rate: 1.5625e-05 iteration: 26261
[[ 2.00131172]
 [ 4.0428912 ]
 [-1.02185253]] loss fxn value:  0.01626006521740779 learn rate: 1.5625e-05 iteration: 26262
[[ 2.00131172]
 [ 4.0428912 ]
 [-1.02185279]] loss fxn value:  0.01625554896265105 learn rate: 1.5625e-05 iteration: 26263
[[ 2.00131172]
 [ 4.0428912 ]
 [-1.02185304]] loss fxn value:  0.016251033961966893 learn rate: 1.5625e-05 iteration: 26264
[[ 2.00131173]
 [ 4.0428912 ]
 [-1.0218533 ]] loss fxn value:  0.016246520216283988 learn rate: 1.5625e-05 iteration: 26265
[[ 2.00131173]
 [ 4.0428912 ]
 [-1.02185355]] loss fxn value:  0.01624200772317931 learn rate: 1.5625e-05 iteration: 26266
[[ 2.00131174]
 [ 4.0428912 ]
 [-1.0218538 ]] loss fxn value:  0.01623749648378278 learn rate: 1.5625e-05 iteration: 26267
[[ 2.00131174]
 [ 4.0428912 ]
 [-1.02185406]] loss fxn value:  0.016232986497507082 learn rate: 1.5625e-05 iteration: 26268
[[ 2.00131175]
 [ 4.0428912 ]
 [-1.02185431]] loss fxn value:  0.01622847776393994 learn rate: 1.5625e-05 iteration: 26269
[[ 2.00131175]
 [ 4.04289121]
 [-1.02185456]] loss fxn value:  0.016223970282551122 learn rate: 1.5625e-05 iteration: 26270
[[ 2.00131175]
 [ 4.04289121]
 [-1.02185482]] loss fxn value:  0.01621946405301858 learn rate: 1.5625e-05 iteration: 26271
[[ 2.00131176]
 [ 4.04289121]
 [-1.02185507]] loss fxn value:  0.016214959074764237 learn rate: 1.5625e-05 iteration: 26272
[[ 2.00131176]
 [ 4.04289121]
 [-1.02185532]] loss fxn value:  0.01621045534833532 learn rate: 1.5625e-05 iteration: 26273
[[ 2.00131177]
 [ 4.04289121]
 [-1.02185558]] loss fxn value:  0.016205952872751544 learn rate: 1.5625e-05 iteration: 26274
[[ 2.00131177]
 [ 4.04289121]
 [-1.02185583]] loss fxn value:  0.016201451647148247 learn rate: 1.5625e-05 iteration: 26275
[[ 2.00131178]
 [ 4.04289121]
 [-1.02185608]] loss fxn value:  0.0161969516723924 learn rate: 1.5625e-05 iteration: 26276
[[ 2.00131178]
 [ 4.04289121]
 [-1.02185634]] loss fxn value:  0.01619245294764096 learn rate: 1.5625e-05 iteration: 26277
[[ 2.00131178]
 [ 4.04289122]
 [-1.02185659]] loss fxn value:  0.016187955472375237 learn rate: 1.5625e-05 iteration: 26278
[[ 2.00131179]
 [ 4.04289122]
 [-1.02185684]] loss fxn value:  0.01618345924571904 learn rate: 1.5625e-05 iteration: 26279
[[ 2.00131179]
 [ 4.04289122]
 [-1.0218571 ]] loss fxn value:  0.01617896426852925 learn rate: 1.5625e-05 iteration: 26280
[[ 2.0013118 ]
 [ 4.04289122]
 [-1.02185735]] loss fxn value:  0.01617447053954216 learn rate: 1.5625e-05 iteration: 26281
[[ 2.0013118 ]
 [ 4.04289122]
 [-1.0218576 ]] loss fxn value:  0.016169978058200456 learn rate: 1.5625e-05 iteration: 26282
[[ 2.0013118 ]
 [ 4.04289122]
 [-1.02185785]] loss fxn value:  0.016165486825068374 learn rate: 1.5625e-05 iteration: 26283
[[ 2.00131181]
 [ 4.04289122]
 [-1.02185811]] loss fxn value:  0.01616099683909846 learn rate: 1.5625e-05 iteration: 26284
[[ 2.00131181]
 [ 4.04289122]
 [-1.02185836]] loss fxn value:  0.016156508101397557 learn rate: 1.5625e-05 iteration: 26285
[[ 2.00131182]
 [ 4.04289123]
 [-1.02185861]] loss fxn value:  0.016152020609376008 learn rate: 1.5625e-05 iteration: 26286
[[ 2.00131182]
 [ 4.04289123]
 [-1.02185886]] loss fxn value:  0.016147534364318827 learn rate: 1.5625e-05 iteration: 26287
[[ 2.00131183]
 [ 4.04289123]
 [-1.02185912]] loss fxn value:  0.016143049365507534 learn rate: 1.5625e-05 iteration: 26288
[[ 2.00131183]
 [ 4.04289123]
 [-1.02185937]] loss fxn value:  0.016138565611121113 learn rate: 1.5625e-05 iteration: 26289
[[ 2.00131183]
 [ 4.04289123]
 [-1.02185962]] loss fxn value:  0.016134083102763465 learn rate: 1.5625e-05 iteration: 26290
[[ 2.00131184]
 [ 4.04289123]
 [-1.02185987]] loss fxn value:  0.016129601839782435 learn rate: 1.5625e-05 iteration: 26291
[[ 2.00131184]
 [ 4.04289123]
 [-1.02186012]] loss fxn value:  0.016125121821195423 learn rate: 1.5625e-05 iteration: 26292
[[ 2.00131185]
 [ 4.04289124]
 [-1.02186038]] loss fxn value:  0.016120643047273155 learn rate: 1.5625e-05 iteration: 26293
[[ 2.00131185]
 [ 4.04289124]
 [-1.02186063]] loss fxn value:  0.016116165517347313 learn rate: 1.5625e-05 iteration: 26294
[[ 2.00131186]
 [ 4.04289124]
 [-1.02186088]] loss fxn value:  0.01611168923049384 learn rate: 1.5625e-05 iteration: 26295
[[ 2.00131186]
 [ 4.04289124]
 [-1.02186113]] loss fxn value:  0.016107214187329442 learn rate: 1.5625e-05 iteration: 26296
[[ 2.00131186]
 [ 4.04289124]
 [-1.02186138]] loss fxn value:  0.016102740387292196 learn rate: 1.5625e-05 iteration: 26297
[[ 2.00131187]
 [ 4.04289124]
 [-1.02186163]] loss fxn value:  0.016098267828987208 learn rate: 1.5625e-05 iteration: 26298
[[ 2.00131187]
 [ 4.04289124]
 [-1.02186189]] loss fxn value:  0.016093796513921232 learn rate: 1.5625e-05 iteration: 26299
[[ 2.00131188]
 [ 4.04289124]
 [-1.02186214]] loss fxn value:  0.01608932643961647 learn rate: 1.5625e-05 iteration: 26300
[[ 2.00131188]
 [ 4.04289125]
 [-1.02186239]] loss fxn value:  0.01608485760809834 learn rate: 1.5625e-05 iteration: 26301
[[ 2.00131188]
 [ 4.04289125]
 [-1.02186264]] loss fxn value:  0.01608039001736766 learn rate: 1.5625e-05 iteration: 26302
[[ 2.00131189]
 [ 4.04289125]
 [-1.02186289]] loss fxn value:  0.016075923667552432 learn rate: 1.5625e-05 iteration: 26303
[[ 2.00131189]
 [ 4.04289125]
 [-1.02186314]] loss fxn value:  0.016071458558612584 learn rate: 1.5625e-05 iteration: 26304
[[ 2.0013119 ]
 [ 4.04289125]
 [-1.02186339]] loss fxn value:  0.01606699468818448 learn rate: 1.5625e-05 iteration: 26305
[[ 2.0013119 ]
 [ 4.04289125]
 [-1.02186364]] loss fxn value:  0.0160625320601855 learn rate: 1.5625e-05 iteration: 26306
[[ 2.00131191]
 [ 4.04289125]
 [-1.0218639 ]] loss fxn value:  0.01605807067009857 learn rate: 1.5625e-05 iteration: 26307
[[ 2.00131191]
 [ 4.04289125]
 [-1.02186415]] loss fxn value:  0.0160536105197297 learn rate: 1.5625e-05 iteration: 26308
[[ 2.00131191]
 [ 4.04289126]
 [-1.0218644 ]] loss fxn value:  0.01604915160730834 learn rate: 1.5625e-05 iteration: 26309
[[ 2.00131192]
 [ 4.04289126]
 [-1.02186465]] loss fxn value:  0.016044693934519415 learn rate: 1.5625e-05 iteration: 26310
[[ 2.00131192]
 [ 4.04289126]
 [-1.0218649 ]] loss fxn value:  0.016040237498937595 learn rate: 1.5625e-05 iteration: 26311
[[ 2.00131193]
 [ 4.04289126]
 [-1.02186515]] loss fxn value:  0.016035782301455227 learn rate: 1.5625e-05 iteration: 26312
[[ 2.00131193]
 [ 4.04289126]
 [-1.0218654 ]] loss fxn value:  0.01603132834172719 learn rate: 1.5625e-05 iteration: 26313
[[ 2.00131193]
 [ 4.04289126]
 [-1.02186565]] loss fxn value:  0.01602687561872534 learn rate: 1.5625e-05 iteration: 26314
[[ 2.00131194]
 [ 4.04289126]
 [-1.0218659 ]] loss fxn value:  0.016022424132509074 learn rate: 1.5625e-05 iteration: 26315
[[ 2.00131194]
 [ 4.04289126]
 [-1.02186615]] loss fxn value:  0.01601797388314239 learn rate: 1.5625e-05 iteration: 26316
[[ 2.00131195]
 [ 4.04289127]
 [-1.0218664 ]] loss fxn value:  0.016013524868566713 learn rate: 1.5625e-05 iteration: 26317
[[ 2.00131195]
 [ 4.04289127]
 [-1.02186665]] loss fxn value:  0.016009077090985636 learn rate: 1.5625e-05 iteration: 26318
[[ 2.00131196]
 [ 4.04289127]
 [-1.0218669 ]] loss fxn value:  0.016004630548195564 learn rate: 1.5625e-05 iteration: 26319
[[ 2.00131196]
 [ 4.04289127]
 [-1.02186715]] loss fxn value:  0.016000185240943512 learn rate: 1.5625e-05 iteration: 26320
[[ 2.00131196]
 [ 4.04289127]
 [-1.0218674 ]] loss fxn value:  0.01599574116763942 learn rate: 1.5625e-05 iteration: 26321
[[ 2.00131197]
 [ 4.04289127]
 [-1.02186765]] loss fxn value:  0.015991298329383206 learn rate: 1.5625e-05 iteration: 26322
[[ 2.00131197]
 [ 4.04289127]
 [-1.0218679 ]] loss fxn value:  0.01598685672507264 learn rate: 1.5625e-05 iteration: 26323
[[ 2.00131198]
 [ 4.04289127]
 [-1.02186815]] loss fxn value:  0.01598241635399586 learn rate: 1.5625e-05 iteration: 26324
[[ 2.00131198]
 [ 4.04289128]
 [-1.0218684 ]] loss fxn value:  0.015977977216467137 learn rate: 1.5625e-05 iteration: 26325
[[ 2.00131198]
 [ 4.04289128]
 [-1.02186865]] loss fxn value:  0.015973539312088874 learn rate: 1.5625e-05 iteration: 26326
[[ 2.00131199]
 [ 4.04289128]
 [-1.0218689 ]] loss fxn value:  0.01596910263991856 learn rate: 1.5625e-05 iteration: 26327
[[ 2.00131199]
 [ 4.04289128]
 [-1.02186915]] loss fxn value:  0.01596466720004644 learn rate: 1.5625e-05 iteration: 26328
[[ 2.001312  ]
 [ 4.04289128]
 [-1.0218694 ]] loss fxn value:  0.01596023299229664 learn rate: 1.5625e-05 iteration: 26329
[[ 2.001312  ]
 [ 4.04289128]
 [-1.02186965]] loss fxn value:  0.015955800016935272 learn rate: 1.5625e-05 iteration: 26330
[[ 2.00131201]
 [ 4.04289128]
 [-1.0218699 ]] loss fxn value:  0.01595136827185128 learn rate: 1.5625e-05 iteration: 26331
[[ 2.00131201]
 [ 4.04289128]
 [-1.02187015]] loss fxn value:  0.01594693775767521 learn rate: 1.5625e-05 iteration: 26332
[[ 2.00131201]
 [ 4.04289129]
 [-1.0218704 ]] loss fxn value:  0.015942508474887974 learn rate: 1.5625e-05 iteration: 26333
[[ 2.00131202]
 [ 4.04289129]
 [-1.02187064]] loss fxn value:  0.015938080421490378 learn rate: 1.5625e-05 iteration: 26334
[[ 2.00131202]
 [ 4.04289129]
 [-1.02187089]] loss fxn value:  0.015933653598119886 learn rate: 1.5625e-05 iteration: 26335
[[ 2.00131203]
 [ 4.04289129]
 [-1.02187114]] loss fxn value:  0.015929228004683955 learn rate: 1.5625e-05 iteration: 26336
[[ 2.00131203]
 [ 4.04289129]
 [-1.02187139]] loss fxn value:  0.015924803639884858 learn rate: 1.5625e-05 iteration: 26337
[[ 2.00131203]
 [ 4.04289129]
 [-1.02187164]] loss fxn value:  0.0159203805045371 learn rate: 1.5625e-05 iteration: 26338
[[ 2.00131204]
 [ 4.04289129]
 [-1.02187189]] loss fxn value:  0.01591595859781926 learn rate: 1.5625e-05 iteration: 26339
[[ 2.00131204]
 [ 4.04289129]
 [-1.02187214]] loss fxn value:  0.015911537918771815 learn rate: 1.5625e-05 iteration: 26340
[[ 2.00131205]
 [ 4.0428913 ]
 [-1.02187239]] loss fxn value:  0.015907118467347766 learn rate: 1.5625e-05 iteration: 26341
[[ 2.00131205]
 [ 4.0428913 ]
 [-1.02187263]] loss fxn value:  0.01590270024416988 learn rate: 1.5625e-05 iteration: 26342
[[ 2.00131206]
 [ 4.0428913 ]
 [-1.02187288]] loss fxn value:  0.015898283248624624 learn rate: 1.5625e-05 iteration: 26343
[[ 2.00131206]
 [ 4.0428913 ]
 [-1.02187313]] loss fxn value:  0.015893867478948054 learn rate: 1.5625e-05 iteration: 26344
[[ 2.00131206]
 [ 4.0428913 ]
 [-1.02187338]] loss fxn value:  0.015889452935547 learn rate: 1.5625e-05 iteration: 26345
[[ 2.00131207]
 [ 4.0428913 ]
 [-1.02187363]] loss fxn value:  0.01588503961855955 learn rate: 1.5625e-05 iteration: 26346
[[ 2.00131207]
 [ 4.0428913 ]
 [-1.02187388]] loss fxn value:  0.015880627527852232 learn rate: 1.5625e-05 iteration: 26347
[[ 2.00131208]
 [ 4.04289131]
 [-1.02187412]] loss fxn value:  0.015876216662042544 learn rate: 1.5625e-05 iteration: 26348
[[ 2.00131208]
 [ 4.04289131]
 [-1.02187437]] loss fxn value:  0.015871807021258504 learn rate: 1.5625e-05 iteration: 26349
[[ 2.00131208]
 [ 4.04289131]
 [-1.02187462]] loss fxn value:  0.01586739860589309 learn rate: 1.5625e-05 iteration: 26350
[[ 2.00131209]
 [ 4.04289131]
 [-1.02187487]] loss fxn value:  0.015862991415008406 learn rate: 1.5625e-05 iteration: 26351
[[ 2.00131209]
 [ 4.04289131]
 [-1.02187512]] loss fxn value:  0.01585858544718102 learn rate: 1.5625e-05 iteration: 26352
[[ 2.0013121 ]
 [ 4.04289131]
 [-1.02187536]] loss fxn value:  0.015854180704464906 learn rate: 1.5625e-05 iteration: 26353
[[ 2.0013121 ]
 [ 4.04289131]
 [-1.02187561]] loss fxn value:  0.01584977718474901 learn rate: 1.5625e-05 iteration: 26354
[[ 2.00131211]
 [ 4.04289131]
 [-1.02187586]] loss fxn value:  0.01584537488778537 learn rate: 1.5625e-05 iteration: 26355
[[ 2.00131211]
 [ 4.04289132]
 [-1.02187611]] loss fxn value:  0.01584097381351459 learn rate: 1.5625e-05 iteration: 26356
[[ 2.00131211]
 [ 4.04289132]
 [-1.02187635]] loss fxn value:  0.01583657396187267 learn rate: 1.5625e-05 iteration: 26357
[[ 2.00131212]
 [ 4.04289132]
 [-1.0218766 ]] loss fxn value:  0.015832175332528328 learn rate: 1.5625e-05 iteration: 26358
[[ 2.00131212]
 [ 4.04289132]
 [-1.02187685]] loss fxn value:  0.01582777792442719 learn rate: 1.5625e-05 iteration: 26359
[[ 2.00131213]
 [ 4.04289132]
 [-1.0218771 ]] loss fxn value:  0.01582338173770504 learn rate: 1.5625e-05 iteration: 26360
[[ 2.00131213]
 [ 4.04289132]
 [-1.02187734]] loss fxn value:  0.015818986772709317 learn rate: 1.5625e-05 iteration: 26361
[[ 2.00131213]
 [ 4.04289132]
 [-1.02187759]] loss fxn value:  0.01581459302770693 learn rate: 1.5625e-05 iteration: 26362
[[ 2.00131214]
 [ 4.04289132]
 [-1.02187784]] loss fxn value:  0.01581020050354553 learn rate: 1.5625e-05 iteration: 26363
[[ 2.00131214]
 [ 4.04289133]
 [-1.02187808]] loss fxn value:  0.01580580919887033 learn rate: 1.5625e-05 iteration: 26364
[[ 2.00131215]
 [ 4.04289133]
 [-1.02187833]] loss fxn value:  0.015801419113241334 learn rate: 1.5625e-05 iteration: 26365
[[ 2.00131215]
 [ 4.04289133]
 [-1.02187858]] loss fxn value:  0.0157970302490291 learn rate: 1.5625e-05 iteration: 26366
[[ 2.00131215]
 [ 4.04289133]
 [-1.02187882]] loss fxn value:  0.01579264260236094 learn rate: 1.5625e-05 iteration: 26367
[[ 2.00131216]
 [ 4.04289133]
 [-1.02187907]] loss fxn value:  0.015788256175295452 learn rate: 1.5625e-05 iteration: 26368
[[ 2.00131216]
 [ 4.04289133]
 [-1.02187932]] loss fxn value:  0.015783870966283496 learn rate: 1.5625e-05 iteration: 26369
[[ 2.00131217]
 [ 4.04289133]
 [-1.02187956]] loss fxn value:  0.015779486974565347 learn rate: 1.5625e-05 iteration: 26370
[[ 2.00131217]
 [ 4.04289133]
 [-1.02187981]] loss fxn value:  0.015775104200446057 learn rate: 1.5625e-05 iteration: 26371
[[ 2.00131218]
 [ 4.04289134]
 [-1.02188006]] loss fxn value:  0.015770722644560777 learn rate: 1.5625e-05 iteration: 26372
[[ 2.00131218]
 [ 4.04289134]
 [-1.0218803 ]] loss fxn value:  0.015766342305433622 learn rate: 1.5625e-05 iteration: 26373
[[ 2.00131218]
 [ 4.04289134]
 [-1.02188055]] loss fxn value:  0.01576196318256752 learn rate: 1.5625e-05 iteration: 26374
[[ 2.00131219]
 [ 4.04289134]
 [-1.0218808 ]] loss fxn value:  0.01575758527554095 learn rate: 1.5625e-05 iteration: 26375
[[ 2.00131219]
 [ 4.04289134]
 [-1.02188104]] loss fxn value:  0.01575320858538667 learn rate: 1.5625e-05 iteration: 26376
[[ 2.0013122 ]
 [ 4.04289134]
 [-1.02188129]] loss fxn value:  0.015748833111012533 learn rate: 1.5625e-05 iteration: 26377
[[ 2.0013122 ]
 [ 4.04289134]
 [-1.02188154]] loss fxn value:  0.0157444588511779 learn rate: 1.5625e-05 iteration: 26378
[[ 2.0013122 ]
 [ 4.04289134]
 [-1.02188178]] loss fxn value:  0.01574008580676128 learn rate: 1.5625e-05 iteration: 26379
[[ 2.00131221]
 [ 4.04289135]
 [-1.02188203]] loss fxn value:  0.015735713977246296 learn rate: 1.5625e-05 iteration: 26380
[[ 2.00131221]
 [ 4.04289135]
 [-1.02188227]] loss fxn value:  0.015731343360869007 learn rate: 1.5625e-05 iteration: 26381
[[ 2.00131222]
 [ 4.04289135]
 [-1.02188252]] loss fxn value:  0.015726973959064385 learn rate: 1.5625e-05 iteration: 26382
[[ 2.00131222]
 [ 4.04289135]
 [-1.02188276]] loss fxn value:  0.015722605771673562 learn rate: 1.5625e-05 iteration: 26383
[[ 2.00131222]
 [ 4.04289135]
 [-1.02188301]] loss fxn value:  0.015718238796125026 learn rate: 1.5625e-05 iteration: 26384
[[ 2.00131223]
 [ 4.04289135]
 [-1.02188326]] loss fxn value:  0.015713873034599618 learn rate: 1.5625e-05 iteration: 26385
[[ 2.00131223]
 [ 4.04289135]
 [-1.0218835 ]] loss fxn value:  0.015709508485728687 learn rate: 1.5625e-05 iteration: 26386
[[ 2.00131224]
 [ 4.04289135]
 [-1.02188375]] loss fxn value:  0.01570514514906448 learn rate: 1.5625e-05 iteration: 26387
[[ 2.00131224]
 [ 4.04289136]
 [-1.02188399]] loss fxn value:  0.01570078302330466 learn rate: 1.5625e-05 iteration: 26388
[[ 2.00131224]
 [ 4.04289136]
 [-1.02188424]] loss fxn value:  0.015696422109744642 learn rate: 1.5625e-05 iteration: 26389
[[ 2.00131225]
 [ 4.04289136]
 [-1.02188448]] loss fxn value:  0.015692062407510532 learn rate: 1.5625e-05 iteration: 26390
[[ 2.00131225]
 [ 4.04289136]
 [-1.02188473]] loss fxn value:  0.015687703916143037 learn rate: 1.5625e-05 iteration: 26391
[[ 2.00131226]
 [ 4.04289136]
 [-1.02188497]] loss fxn value:  0.015683346635161244 learn rate: 1.5625e-05 iteration: 26392
[[ 2.00131226]
 [ 4.04289136]
 [-1.02188522]] loss fxn value:  0.015678990564598313 learn rate: 1.5625e-05 iteration: 26393
[[ 2.00131227]
 [ 4.04289136]
 [-1.02188546]] loss fxn value:  0.015674635704509016 learn rate: 1.5625e-05 iteration: 26394
[[ 2.00131227]
 [ 4.04289136]
 [-1.02188571]] loss fxn value:  0.015670282053260903 learn rate: 1.5625e-05 iteration: 26395
[[ 2.00131227]
 [ 4.04289137]
 [-1.02188595]] loss fxn value:  0.0156659296117244 learn rate: 1.5625e-05 iteration: 26396
[[ 2.00131228]
 [ 4.04289137]
 [-1.0218862 ]] loss fxn value:  0.015661578378186037 learn rate: 1.5625e-05 iteration: 26397
[[ 2.00131228]
 [ 4.04289137]
 [-1.02188644]] loss fxn value:  0.01565722835378582 learn rate: 1.5625e-05 iteration: 26398
[[ 2.00131229]
 [ 4.04289137]
 [-1.02188669]] loss fxn value:  0.015652879538402654 learn rate: 1.5625e-05 iteration: 26399
[[ 2.00131229]
 [ 4.04289137]
 [-1.02188693]] loss fxn value:  0.015648531930169976 learn rate: 1.5625e-05 iteration: 26400
[[ 2.00131229]
 [ 4.04289137]
 [-1.02188718]] loss fxn value:  0.015644185528797434 learn rate: 1.5625e-05 iteration: 26401
[[ 2.0013123 ]
 [ 4.04289137]
 [-1.02188742]] loss fxn value:  0.015639840335515583 learn rate: 1.5625e-05 iteration: 26402
[[ 2.0013123 ]
 [ 4.04289137]
 [-1.02188766]] loss fxn value:  0.015635496348977398 learn rate: 1.5625e-05 iteration: 26403
[[ 2.00131231]
 [ 4.04289137]
 [-1.02188791]] loss fxn value:  0.015631153568328292 learn rate: 1.5625e-05 iteration: 26404
[[ 2.00131231]
 [ 4.04289138]
 [-1.02188815]] loss fxn value:  0.015626811994948454 learn rate: 1.5625e-05 iteration: 26405
[[ 2.00131231]
 [ 4.04289138]
 [-1.0218884 ]] loss fxn value:  0.015622471626381708 learn rate: 1.5625e-05 iteration: 26406
[[ 2.00131232]
 [ 4.04289138]
 [-1.02188864]] loss fxn value:  0.015618132464798496 learn rate: 1.5625e-05 iteration: 26407
[[ 2.00131232]
 [ 4.04289138]
 [-1.02188888]] loss fxn value:  0.015613794506991003 learn rate: 1.5625e-05 iteration: 26408
[[ 2.00131233]
 [ 4.04289138]
 [-1.02188913]] loss fxn value:  0.015609457755269228 learn rate: 1.5625e-05 iteration: 26409
[[ 2.00131233]
 [ 4.04289138]
 [-1.02188937]] loss fxn value:  0.015605122206987275 learn rate: 1.5625e-05 iteration: 26410
[[ 2.00131233]
 [ 4.04289138]
 [-1.02188962]] loss fxn value:  0.015600787864243813 learn rate: 1.5625e-05 iteration: 26411
[[ 2.00131234]
 [ 4.04289138]
 [-1.02188986]] loss fxn value:  0.015596454724006892 learn rate: 1.5625e-05 iteration: 26412
[[ 2.00131234]
 [ 4.04289139]
 [-1.0218901 ]] loss fxn value:  0.01559212278747821 learn rate: 1.5625e-05 iteration: 26413
[[ 2.00131235]
 [ 4.04289139]
 [-1.02189035]] loss fxn value:  0.01558779205502682 learn rate: 1.5625e-05 iteration: 26414
[[ 2.00131235]
 [ 4.04289139]
 [-1.02189059]] loss fxn value:  0.015583462525117435 learn rate: 1.5625e-05 iteration: 26415
[[ 2.00131235]
 [ 4.04289139]
 [-1.02189083]] loss fxn value:  0.015579134197064418 learn rate: 1.5625e-05 iteration: 26416
[[ 2.00131236]
 [ 4.04289139]
 [-1.02189108]] loss fxn value:  0.015574807071617416 learn rate: 1.5625e-05 iteration: 26417
[[ 2.00131236]
 [ 4.04289139]
 [-1.02189132]] loss fxn value:  0.015570481148483768 learn rate: 1.5625e-05 iteration: 26418
[[ 2.00131237]
 [ 4.04289139]
 [-1.02189156]] loss fxn value:  0.01556615642610426 learn rate: 1.5625e-05 iteration: 26419
[[ 2.00131237]
 [ 4.04289139]
 [-1.02189181]] loss fxn value:  0.015561832905157294 learn rate: 1.5625e-05 iteration: 26420
[[ 2.00131238]
 [ 4.0428914 ]
 [-1.02189205]] loss fxn value:  0.015557510585383684 learn rate: 1.5625e-05 iteration: 26421
[[ 2.00131238]
 [ 4.0428914 ]
 [-1.02189229]] loss fxn value:  0.01555318946571866 learn rate: 1.5625e-05 iteration: 26422
[[ 2.00131238]
 [ 4.0428914 ]
 [-1.02189254]] loss fxn value:  0.015548869546779235 learn rate: 1.5625e-05 iteration: 26423
[[ 2.00131239]
 [ 4.0428914 ]
 [-1.02189278]] loss fxn value:  0.015544550827389633 learn rate: 1.5625e-05 iteration: 26424
[[ 2.00131239]
 [ 4.0428914 ]
 [-1.02189302]] loss fxn value:  0.015540233307475762 learn rate: 1.5625e-05 iteration: 26425
[[ 2.0013124 ]
 [ 4.0428914 ]
 [-1.02189326]] loss fxn value:  0.015535916986578333 learn rate: 1.5625e-05 iteration: 26426
[[ 2.0013124 ]
 [ 4.0428914 ]
 [-1.02189351]] loss fxn value:  0.015531601865732405 learn rate: 1.5625e-05 iteration: 26427
[[ 2.0013124 ]
 [ 4.0428914 ]
 [-1.02189375]] loss fxn value:  0.015527287941453659 learn rate: 1.5625e-05 iteration: 26428
[[ 2.00131241]
 [ 4.04289141]
 [-1.02189399]] loss fxn value:  0.015522975217393051 learn rate: 1.5625e-05 iteration: 26429
[[ 2.00131241]
 [ 4.04289141]
 [-1.02189424]] loss fxn value:  0.015518663689847157 learn rate: 1.5625e-05 iteration: 26430
[[ 2.00131242]
 [ 4.04289141]
 [-1.02189448]] loss fxn value:  0.015514353360098685 learn rate: 1.5625e-05 iteration: 26431
[[ 2.00131242]
 [ 4.04289141]
 [-1.02189472]] loss fxn value:  0.01551004422755025 learn rate: 1.5625e-05 iteration: 26432
[[ 2.00131242]
 [ 4.04289141]
 [-1.02189496]] loss fxn value:  0.015505736292744458 learn rate: 1.5625e-05 iteration: 26433
[[ 2.00131243]
 [ 4.04289141]
 [-1.0218952 ]] loss fxn value:  0.015501429553174972 learn rate: 1.5625e-05 iteration: 26434
[[ 2.00131243]
 [ 4.04289141]
 [-1.02189545]] loss fxn value:  0.015497124010493551 learn rate: 1.5625e-05 iteration: 26435
[[ 2.00131244]
 [ 4.04289141]
 [-1.02189569]] loss fxn value:  0.015492819664107425 learn rate: 1.5625e-05 iteration: 26436
[[ 2.00131244]
 [ 4.04289142]
 [-1.02189593]] loss fxn value:  0.015488516511733968 learn rate: 1.5625e-05 iteration: 26437
[[ 2.00131244]
 [ 4.04289142]
 [-1.02189617]] loss fxn value:  0.015484214555679734 learn rate: 1.5625e-05 iteration: 26438
[[ 2.00131245]
 [ 4.04289142]
 [-1.02189641]] loss fxn value:  0.015479913795094755 learn rate: 1.5625e-05 iteration: 26439
[[ 2.00131245]
 [ 4.04289142]
 [-1.02189666]] loss fxn value:  0.01547561422840828 learn rate: 1.5625e-05 iteration: 26440
[[ 2.00131246]
 [ 4.04289142]
 [-1.0218969 ]] loss fxn value:  0.015471315855372347 learn rate: 1.5625e-05 iteration: 26441
[[ 2.00131246]
 [ 4.04289142]
 [-1.02189714]] loss fxn value:  0.015467018676417707 learn rate: 1.5625e-05 iteration: 26442
[[ 2.00131246]
 [ 4.04289142]
 [-1.02189738]] loss fxn value:  0.015462722690985597 learn rate: 1.5625e-05 iteration: 26443
[[ 2.00131247]
 [ 4.04289142]
 [-1.02189762]] loss fxn value:  0.015458427899637089 learn rate: 1.5625e-05 iteration: 26444
[[ 2.00131247]
 [ 4.04289143]
 [-1.02189786]] loss fxn value:  0.015454134300453998 learn rate: 1.5625e-05 iteration: 26445
[[ 2.00131248]
 [ 4.04289143]
 [-1.02189811]] loss fxn value:  0.015449841893988165 learn rate: 1.5625e-05 iteration: 26446
[[ 2.00131248]
 [ 4.04289143]
 [-1.02189835]] loss fxn value:  0.015445550679713985 learn rate: 1.5625e-05 iteration: 26447
[[ 2.00131248]
 [ 4.04289143]
 [-1.02189859]] loss fxn value:  0.015441260657216856 learn rate: 1.5625e-05 iteration: 26448
[[ 2.00131249]
 [ 4.04289143]
 [-1.02189883]] loss fxn value:  0.015436971826463626 learn rate: 1.5625e-05 iteration: 26449
[[ 2.00131249]
 [ 4.04289143]
 [-1.02189907]] loss fxn value:  0.015432684186602017 learn rate: 1.5625e-05 iteration: 26450
[[ 2.0013125 ]
 [ 4.04289143]
 [-1.02189931]] loss fxn value:  0.015428397737989546 learn rate: 1.5625e-05 iteration: 26451
[[ 2.0013125 ]
 [ 4.04289143]
 [-1.02189955]] loss fxn value:  0.015424112479854103 learn rate: 1.5625e-05 iteration: 26452
[[ 2.0013125 ]
 [ 4.04289144]
 [-1.02189979]] loss fxn value:  0.015419828412524655 learn rate: 1.5625e-05 iteration: 26453
[[ 2.00131251]
 [ 4.04289144]
 [-1.02190004]] loss fxn value:  0.01541554553378259 learn rate: 1.5625e-05 iteration: 26454
[[ 2.00131251]
 [ 4.04289144]
 [-1.02190028]] loss fxn value:  0.01541126384635598 learn rate: 1.5625e-05 iteration: 26455
[[ 2.00131252]
 [ 4.04289144]
 [-1.02190052]] loss fxn value:  0.015406983346581159 learn rate: 1.5625e-05 iteration: 26456
[[ 2.00131252]
 [ 4.04289144]
 [-1.02190076]] loss fxn value:  0.015402704036310002 learn rate: 1.5625e-05 iteration: 26457
[[ 2.00131252]
 [ 4.04289144]
 [-1.021901  ]] loss fxn value:  0.015398425914597686 learn rate: 1.5625e-05 iteration: 26458
[[ 2.00131253]
 [ 4.04289144]
 [-1.02190124]] loss fxn value:  0.015394148981501295 learn rate: 1.5625e-05 iteration: 26459
[[ 2.00131253]
 [ 4.04289144]
 [-1.02190148]] loss fxn value:  0.015389873236054386 learn rate: 1.5625e-05 iteration: 26460
[[ 2.00131254]
 [ 4.04289145]
 [-1.02190172]] loss fxn value:  0.015385598677356838 learn rate: 1.5625e-05 iteration: 26461
[[ 2.00131254]
 [ 4.04289145]
 [-1.02190196]] loss fxn value:  0.015381325306846771 learn rate: 1.5625e-05 iteration: 26462
[[ 2.00131254]
 [ 4.04289145]
 [-1.0219022 ]] loss fxn value:  0.015377053124419247 learn rate: 1.5625e-05 iteration: 26463
[[ 2.00131255]
 [ 4.04289145]
 [-1.02190244]] loss fxn value:  0.015372782125937469 learn rate: 1.5625e-05 iteration: 26464
[[ 2.00131255]
 [ 4.04289145]
 [-1.02190268]] loss fxn value:  0.015368512315773492 learn rate: 1.5625e-05 iteration: 26465
[[ 2.00131256]
 [ 4.04289145]
 [-1.02190292]] loss fxn value:  0.015364243690864516 learn rate: 1.5625e-05 iteration: 26466
[[ 2.00131256]
 [ 4.04289145]
 [-1.02190316]] loss fxn value:  0.015359976252307306 learn rate: 1.5625e-05 iteration: 26467
[[ 2.00131256]
 [ 4.04289145]
 [-1.0219034 ]] loss fxn value:  0.015355709997731308 learn rate: 1.5625e-05 iteration: 26468
[[ 2.00131257]
 [ 4.04289145]
 [-1.02190364]] loss fxn value:  0.015351444928193198 learn rate: 1.5625e-05 iteration: 26469
[[ 2.00131257]
 [ 4.04289146]
 [-1.02190388]] loss fxn value:  0.015347181044014176 learn rate: 1.5625e-05 iteration: 26470
[[ 2.00131258]
 [ 4.04289146]
 [-1.02190412]] loss fxn value:  0.015342918344290355 learn rate: 1.5625e-05 iteration: 26471
[[ 2.00131258]
 [ 4.04289146]
 [-1.02190436]] loss fxn value:  0.015338656827219174 learn rate: 1.5625e-05 iteration: 26472
[[ 2.00131258]
 [ 4.04289146]
 [-1.0219046 ]] loss fxn value:  0.015334396495221348 learn rate: 1.5625e-05 iteration: 26473
[[ 2.00131259]
 [ 4.04289146]
 [-1.02190484]] loss fxn value:  0.015330137346174284 learn rate: 1.5625e-05 iteration: 26474
[[ 2.00131259]
 [ 4.04289146]
 [-1.02190508]] loss fxn value:  0.0153258793799318 learn rate: 1.5625e-05 iteration: 26475
[[ 2.0013126 ]
 [ 4.04289146]
 [-1.02190532]] loss fxn value:  0.015321622596732627 learn rate: 1.5625e-05 iteration: 26476
[[ 2.0013126 ]
 [ 4.04289146]
 [-1.02190556]] loss fxn value:  0.015317366994845986 learn rate: 1.5625e-05 iteration: 26477
[[ 2.0013126 ]
 [ 4.04289147]
 [-1.0219058 ]] loss fxn value:  0.015313112575671375 learn rate: 1.5625e-05 iteration: 26478
[[ 2.00131261]
 [ 4.04289147]
 [-1.02190604]] loss fxn value:  0.015308859338714037 learn rate: 1.5625e-05 iteration: 26479
[[ 2.00131261]
 [ 4.04289147]
 [-1.02190628]] loss fxn value:  0.015304607282050322 learn rate: 1.5625e-05 iteration: 26480
[[ 2.00131262]
 [ 4.04289147]
 [-1.02190651]] loss fxn value:  0.015300356407301142 learn rate: 1.5625e-05 iteration: 26481
[[ 2.00131262]
 [ 4.04289147]
 [-1.02190675]] loss fxn value:  0.01529610671329334 learn rate: 1.5625e-05 iteration: 26482
[[ 2.00131262]
 [ 4.04289147]
 [-1.02190699]] loss fxn value:  0.015291858198812512 learn rate: 1.5625e-05 iteration: 26483
[[ 2.00131263]
 [ 4.04289147]
 [-1.02190723]] loss fxn value:  0.015287610864253948 learn rate: 1.5625e-05 iteration: 26484
[[ 2.00131263]
 [ 4.04289147]
 [-1.02190747]] loss fxn value:  0.015283364710096252 learn rate: 1.5625e-05 iteration: 26485
[[ 2.00131264]
 [ 4.04289148]
 [-1.02190771]] loss fxn value:  0.015279119734982312 learn rate: 1.5625e-05 iteration: 26486
[[ 2.00131264]
 [ 4.04289148]
 [-1.02190795]] loss fxn value:  0.015274875938912127 learn rate: 1.5625e-05 iteration: 26487
[[ 2.00131264]
 [ 4.04289148]
 [-1.02190819]] loss fxn value:  0.015270633321821691 learn rate: 1.5625e-05 iteration: 26488
[[ 2.00131265]
 [ 4.04289148]
 [-1.02190842]] loss fxn value:  0.015266391883379724 learn rate: 1.5625e-05 iteration: 26489
[[ 2.00131265]
 [ 4.04289148]
 [-1.02190866]] loss fxn value:  0.015262151622553472 learn rate: 1.5625e-05 iteration: 26490
[[ 2.00131266]
 [ 4.04289148]
 [-1.0219089 ]] loss fxn value:  0.015257912539406941 learn rate: 1.5625e-05 iteration: 26491
[[ 2.00131266]
 [ 4.04289148]
 [-1.02190914]] loss fxn value:  0.015253674633452296 learn rate: 1.5625e-05 iteration: 26492
[[ 2.00131266]
 [ 4.04289148]
 [-1.02190938]] loss fxn value:  0.015249437905232147 learn rate: 1.5625e-05 iteration: 26493
[[ 2.00131267]
 [ 4.04289149]
 [-1.02190962]] loss fxn value:  0.015245202353692124 learn rate: 1.5625e-05 iteration: 26494
[[ 2.00131267]
 [ 4.04289149]
 [-1.02190985]] loss fxn value:  0.01524096797803934 learn rate: 1.5625e-05 iteration: 26495
[[ 2.00131268]
 [ 4.04289149]
 [-1.02191009]] loss fxn value:  0.015236734778188175 learn rate: 1.5625e-05 iteration: 26496
[[ 2.00131268]
 [ 4.04289149]
 [-1.02191033]] loss fxn value:  0.01523250275477148 learn rate: 1.5625e-05 iteration: 26497
[[ 2.00131268]
 [ 4.04289149]
 [-1.02191057]] loss fxn value:  0.015228271907054622 learn rate: 1.5625e-05 iteration: 26498
[[ 2.00131269]
 [ 4.04289149]
 [-1.02191081]] loss fxn value:  0.015224042233931902 learn rate: 1.5625e-05 iteration: 26499
[[ 2.00131269]
 [ 4.04289149]
 [-1.02191104]] loss fxn value:  0.015219813736122963 learn rate: 1.5625e-05 iteration: 26500
[[ 2.0013127 ]
 [ 4.04289149]
 [-1.02191128]] loss fxn value:  0.015215586412349397 learn rate: 1.5625e-05 iteration: 26501
[[ 2.0013127 ]
 [ 4.04289149]
 [-1.02191152]] loss fxn value:  0.015211360263160736 learn rate: 1.5625e-05 iteration: 26502
[[ 2.0013127 ]
 [ 4.0428915 ]
 [-1.02191176]] loss fxn value:  0.015207135286953076 learn rate: 1.5625e-05 iteration: 26503
[[ 2.00131271]
 [ 4.0428915 ]
 [-1.021912  ]] loss fxn value:  0.015202911485361173 learn rate: 1.5625e-05 iteration: 26504
[[ 2.00131271]
 [ 4.0428915 ]
 [-1.02191223]] loss fxn value:  0.01519868885629559 learn rate: 1.5625e-05 iteration: 26505
[[ 2.00131272]
 [ 4.0428915 ]
 [-1.02191247]] loss fxn value:  0.015194467400020128 learn rate: 1.5625e-05 iteration: 26506
[[ 2.00131272]
 [ 4.0428915 ]
 [-1.02191271]] loss fxn value:  0.015190247115889545 learn rate: 1.5625e-05 iteration: 26507
[[ 2.00131272]
 [ 4.0428915 ]
 [-1.02191294]] loss fxn value:  0.01518602800445192 learn rate: 1.5625e-05 iteration: 26508
[[ 2.00131273]
 [ 4.0428915 ]
 [-1.02191318]] loss fxn value:  0.015181810064726116 learn rate: 1.5625e-05 iteration: 26509
[[ 2.00131273]
 [ 4.0428915 ]
 [-1.02191342]] loss fxn value:  0.01517759329685484 learn rate: 1.5625e-05 iteration: 26510
[[ 2.00131274]
 [ 4.04289151]
 [-1.02191366]] loss fxn value:  0.015173377699236495 learn rate: 1.5625e-05 iteration: 26511
[[ 2.00131274]
 [ 4.04289151]
 [-1.02191389]] loss fxn value:  0.015169163273989057 learn rate: 1.5625e-05 iteration: 26512
[[ 2.00131274]
 [ 4.04289151]
 [-1.02191413]] loss fxn value:  0.015164950019030014 learn rate: 1.5625e-05 iteration: 26513
[[ 2.00131275]
 [ 4.04289151]
 [-1.02191437]] loss fxn value:  0.015160737933559562 learn rate: 1.5625e-05 iteration: 26514
[[ 2.00131275]
 [ 4.04289151]
 [-1.0219146 ]] loss fxn value:  0.015156527018032377 learn rate: 1.5625e-05 iteration: 26515
[[ 2.00131276]
 [ 4.04289151]
 [-1.02191484]] loss fxn value:  0.015152317272488542 learn rate: 1.5625e-05 iteration: 26516
[[ 2.00131276]
 [ 4.04289151]
 [-1.02191508]] loss fxn value:  0.015148108695438313 learn rate: 1.5625e-05 iteration: 26517
[[ 2.00131276]
 [ 4.04289151]
 [-1.02191531]] loss fxn value:  0.015143901287966919 learn rate: 1.5625e-05 iteration: 26518
[[ 2.00131277]
 [ 4.04289152]
 [-1.02191555]] loss fxn value:  0.015139695049476968 learn rate: 1.5625e-05 iteration: 26519
[[ 2.00131277]
 [ 4.04289152]
 [-1.02191579]] loss fxn value:  0.01513548997956625 learn rate: 1.5625e-05 iteration: 26520
[[ 2.00131278]
 [ 4.04289152]
 [-1.02191602]] loss fxn value:  0.015131286076822877 learn rate: 1.5625e-05 iteration: 26521
[[ 2.00131278]
 [ 4.04289152]
 [-1.02191626]] loss fxn value:  0.015127083341292398 learn rate: 1.5625e-05 iteration: 26522
[[ 2.00131278]
 [ 4.04289152]
 [-1.0219165 ]] loss fxn value:  0.015122881773464953 learn rate: 1.5625e-05 iteration: 26523
[[ 2.00131279]
 [ 4.04289152]
 [-1.02191673]] loss fxn value:  0.015118681373830685 learn rate: 1.5625e-05 iteration: 26524
[[ 2.00131279]
 [ 4.04289152]
 [-1.02191697]] loss fxn value:  0.015114482139440964 learn rate: 1.5625e-05 iteration: 26525
[[ 2.00131279]
 [ 4.04289152]
 [-1.02191721]] loss fxn value:  0.015110284071854153 learn rate: 1.5625e-05 iteration: 26526
[[ 2.0013128 ]
 [ 4.04289152]
 [-1.02191744]] loss fxn value:  0.015106087170149355 learn rate: 1.5625e-05 iteration: 26527
[[ 2.0013128 ]
 [ 4.04289153]
 [-1.02191768]] loss fxn value:  0.015101891433790883 learn rate: 1.5625e-05 iteration: 26528
[[ 2.00131281]
 [ 4.04289153]
 [-1.02191791]] loss fxn value:  0.015097696863336044 learn rate: 1.5625e-05 iteration: 26529
[[ 2.00131281]
 [ 4.04289153]
 [-1.02191815]] loss fxn value:  0.015093503457782083 learn rate: 1.5625e-05 iteration: 26530
[[ 2.00131281]
 [ 4.04289153]
 [-1.02191838]] loss fxn value:  0.015089311217167624 learn rate: 1.5625e-05 iteration: 26531
[[ 2.00131282]
 [ 4.04289153]
 [-1.02191862]] loss fxn value:  0.015085120140587922 learn rate: 1.5625e-05 iteration: 26532
[[ 2.00131282]
 [ 4.04289153]
 [-1.02191886]] loss fxn value:  0.015080930228469118 learn rate: 1.5625e-05 iteration: 26533
[[ 2.00131283]
 [ 4.04289153]
 [-1.02191909]] loss fxn value:  0.015076741479899547 learn rate: 1.5625e-05 iteration: 26534
[[ 2.00131283]
 [ 4.04289153]
 [-1.02191933]] loss fxn value:  0.015072553894976368 learn rate: 1.5625e-05 iteration: 26535
[[ 2.00131283]
 [ 4.04289154]
 [-1.02191956]] loss fxn value:  0.015068367472640598 learn rate: 1.5625e-05 iteration: 26536
[[ 2.00131284]
 [ 4.04289154]
 [-1.0219198 ]] loss fxn value:  0.015064182213970535 learn rate: 1.5625e-05 iteration: 26537
[[ 2.00131284]
 [ 4.04289154]
 [-1.02192003]] loss fxn value:  0.015059998115981231 learn rate: 1.5625e-05 iteration: 26538
[[ 2.00131285]
 [ 4.04289154]
 [-1.02192027]] loss fxn value:  0.015055815181778726 learn rate: 1.5625e-05 iteration: 26539
[[ 2.00131285]
 [ 4.04289154]
 [-1.0219205 ]] loss fxn value:  0.015051633409187958 learn rate: 1.5625e-05 iteration: 26540
[[ 2.00131285]
 [ 4.04289154]
 [-1.02192074]] loss fxn value:  0.01504745279791311 learn rate: 1.5625e-05 iteration: 26541
[[ 2.00131286]
 [ 4.04289154]
 [-1.02192097]] loss fxn value:  0.015043273347966572 learn rate: 1.5625e-05 iteration: 26542
[[ 2.00131286]
 [ 4.04289154]
 [-1.02192121]] loss fxn value:  0.015039095057881677 learn rate: 1.5625e-05 iteration: 26543
[[ 2.00131287]
 [ 4.04289155]
 [-1.02192144]] loss fxn value:  0.015034917929705478 learn rate: 1.5625e-05 iteration: 26544
[[ 2.00131287]
 [ 4.04289155]
 [-1.02192168]] loss fxn value:  0.015030741961300682 learn rate: 1.5625e-05 iteration: 26545
[[ 2.00131287]
 [ 4.04289155]
 [-1.02192191]] loss fxn value:  0.015026567151503049 learn rate: 1.5625e-05 iteration: 26546
[[ 2.00131288]
 [ 4.04289155]
 [-1.02192215]] loss fxn value:  0.015022393503102346 learn rate: 1.5625e-05 iteration: 26547
[[ 2.00131288]
 [ 4.04289155]
 [-1.02192238]] loss fxn value:  0.015018221013166098 learn rate: 1.5625e-05 iteration: 26548
[[ 2.00131289]
 [ 4.04289155]
 [-1.02192262]] loss fxn value:  0.015014049682317926 learn rate: 1.5625e-05 iteration: 26549
[[ 2.00131289]
 [ 4.04289155]
 [-1.02192285]] loss fxn value:  0.015009879509967364 learn rate: 1.5625e-05 iteration: 26550
[[ 2.00131289]
 [ 4.04289155]
 [-1.02192309]] loss fxn value:  0.01500571049537169 learn rate: 1.5625e-05 iteration: 26551
[[ 2.0013129 ]
 [ 4.04289155]
 [-1.02192332]] loss fxn value:  0.015001542639726001 learn rate: 1.5625e-05 iteration: 26552
[[ 2.0013129 ]
 [ 4.04289156]
 [-1.02192356]] loss fxn value:  0.01499737594132113 learn rate: 1.5625e-05 iteration: 26553
[[ 2.0013129 ]
 [ 4.04289156]
 [-1.02192379]] loss fxn value:  0.014993210399621393 learn rate: 1.5625e-05 iteration: 26554
[[ 2.00131291]
 [ 4.04289156]
 [-1.02192402]] loss fxn value:  0.014989046016135838 learn rate: 1.5625e-05 iteration: 26555
[[ 2.00131291]
 [ 4.04289156]
 [-1.02192426]] loss fxn value:  0.014984882787448769 learn rate: 1.5625e-05 iteration: 26556
[[ 2.00131292]
 [ 4.04289156]
 [-1.02192449]] loss fxn value:  0.014980720716064221 learn rate: 1.5625e-05 iteration: 26557
[[ 2.00131292]
 [ 4.04289156]
 [-1.02192473]] loss fxn value:  0.014976559801472738 learn rate: 1.5625e-05 iteration: 26558
[[ 2.00131292]
 [ 4.04289156]
 [-1.02192496]] loss fxn value:  0.014972400042648487 learn rate: 1.5625e-05 iteration: 26559
[[ 2.00131293]
 [ 4.04289156]
 [-1.02192519]] loss fxn value:  0.014968241437335083 learn rate: 1.5625e-05 iteration: 26560
[[ 2.00131293]
 [ 4.04289157]
 [-1.02192543]] loss fxn value:  0.014964083988450309 learn rate: 1.5625e-05 iteration: 26561
[[ 2.00131294]
 [ 4.04289157]
 [-1.02192566]] loss fxn value:  0.014959927693933268 learn rate: 1.5625e-05 iteration: 26562
[[ 2.00131294]
 [ 4.04289157]
 [-1.0219259 ]] loss fxn value:  0.014955772553509765 learn rate: 1.5625e-05 iteration: 26563
[[ 2.00131294]
 [ 4.04289157]
 [-1.02192613]] loss fxn value:  0.014951618568032073 learn rate: 1.5625e-05 iteration: 26564
[[ 2.00131295]
 [ 4.04289157]
 [-1.02192636]] loss fxn value:  0.014947465735586623 learn rate: 1.5625e-05 iteration: 26565
[[ 2.00131295]
 [ 4.04289157]
 [-1.0219266 ]] loss fxn value:  0.01494331405723471 learn rate: 1.5625e-05 iteration: 26566
[[ 2.00131296]
 [ 4.04289157]
 [-1.02192683]] loss fxn value:  0.014939163532429108 learn rate: 1.5625e-05 iteration: 26567
[[ 2.00131296]
 [ 4.04289157]
 [-1.02192706]] loss fxn value:  0.014935014159360334 learn rate: 1.5625e-05 iteration: 26568
[[ 2.00131296]
 [ 4.04289157]
 [-1.0219273 ]] loss fxn value:  0.014930865939409428 learn rate: 1.5625e-05 iteration: 26569
[[ 2.00131297]
 [ 4.04289158]
 [-1.02192753]] loss fxn value:  0.01492671887073606 learn rate: 1.5625e-05 iteration: 26570
[[ 2.00131297]
 [ 4.04289158]
 [-1.02192776]] loss fxn value:  0.01492257295527772 learn rate: 1.5625e-05 iteration: 26571
[[ 2.00131298]
 [ 4.04289158]
 [-1.021928  ]] loss fxn value:  0.014918428190582847 learn rate: 1.5625e-05 iteration: 26572
[[ 2.00131298]
 [ 4.04289158]
 [-1.02192823]] loss fxn value:  0.014914284577160895 learn rate: 1.5625e-05 iteration: 26573
[[ 2.00131298]
 [ 4.04289158]
 [-1.02192846]] loss fxn value:  0.01491014211459034 learn rate: 1.5625e-05 iteration: 26574
[[ 2.00131299]
 [ 4.04289158]
 [-1.0219287 ]] loss fxn value:  0.014906000802478206 learn rate: 1.5625e-05 iteration: 26575
[[ 2.00131299]
 [ 4.04289158]
 [-1.02192893]] loss fxn value:  0.01490186064108715 learn rate: 1.5625e-05 iteration: 26576
[[ 2.00131299]
 [ 4.04289158]
 [-1.02192916]] loss fxn value:  0.014897721628342724 learn rate: 1.5625e-05 iteration: 26577
[[ 2.001313  ]
 [ 4.04289159]
 [-1.02192939]] loss fxn value:  0.01489358376686891 learn rate: 1.5625e-05 iteration: 26578
[[ 2.001313  ]
 [ 4.04289159]
 [-1.02192963]] loss fxn value:  0.01488944705443009 learn rate: 1.5625e-05 iteration: 26579
[[ 2.00131301]
 [ 4.04289159]
 [-1.02192986]] loss fxn value:  0.014885311489569682 learn rate: 1.5625e-05 iteration: 26580
[[ 2.00131301]
 [ 4.04289159]
 [-1.02193009]] loss fxn value:  0.014881177075734232 learn rate: 1.5625e-05 iteration: 26581
[[ 2.00131301]
 [ 4.04289159]
 [-1.02193032]] loss fxn value:  0.014877043807994374 learn rate: 1.5625e-05 iteration: 26582
[[ 2.00131302]
 [ 4.04289159]
 [-1.02193056]] loss fxn value:  0.01487291168940137 learn rate: 1.5625e-05 iteration: 26583
[[ 2.00131302]
 [ 4.04289159]
 [-1.02193079]] loss fxn value:  0.014868780717974487 learn rate: 1.5625e-05 iteration: 26584
[[ 2.00131303]
 [ 4.04289159]
 [-1.02193102]] loss fxn value:  0.014864650894633161 learn rate: 1.5625e-05 iteration: 26585
[[ 2.00131303]
 [ 4.04289159]
 [-1.02193125]] loss fxn value:  0.014860522218115136 learn rate: 1.5625e-05 iteration: 26586
[[ 2.00131303]
 [ 4.0428916 ]
 [-1.02193149]] loss fxn value:  0.01485639468729511 learn rate: 1.5625e-05 iteration: 26587
[[ 2.00131304]
 [ 4.0428916 ]
 [-1.02193172]] loss fxn value:  0.014852268303803226 learn rate: 1.5625e-05 iteration: 26588
[[ 2.00131304]
 [ 4.0428916 ]
 [-1.02193195]] loss fxn value:  0.014848143067072944 learn rate: 1.5625e-05 iteration: 26589
[[ 2.00131304]
 [ 4.0428916 ]
 [-1.02193218]] loss fxn value:  0.01484401897470286 learn rate: 1.5625e-05 iteration: 26590
[[ 2.00131305]
 [ 4.0428916 ]
 [-1.02193241]] loss fxn value:  0.014839896029189236 learn rate: 1.5625e-05 iteration: 26591
[[ 2.00131305]
 [ 4.0428916 ]
 [-1.02193265]] loss fxn value:  0.01483577422809751 learn rate: 1.5625e-05 iteration: 26592
[[ 2.00131306]
 [ 4.0428916 ]
 [-1.02193288]] loss fxn value:  0.01483165357194175 learn rate: 1.5625e-05 iteration: 26593
[[ 2.00131306]
 [ 4.0428916 ]
 [-1.02193311]] loss fxn value:  0.014827534060247968 learn rate: 1.5625e-05 iteration: 26594
[[ 2.00131306]
 [ 4.04289161]
 [-1.02193334]] loss fxn value:  0.014823415693092559 learn rate: 1.5625e-05 iteration: 26595
[[ 2.00131307]
 [ 4.04289161]
 [-1.02193357]] loss fxn value:  0.014819298469430378 learn rate: 1.5625e-05 iteration: 26596
[[ 2.00131307]
 [ 4.04289161]
 [-1.0219338 ]] loss fxn value:  0.01481518238930928 learn rate: 1.5625e-05 iteration: 26597
[[ 2.00131308]
 [ 4.04289161]
 [-1.02193404]] loss fxn value:  0.014811067452883514 learn rate: 1.5625e-05 iteration: 26598
[[ 2.00131308]
 [ 4.04289161]
 [-1.02193427]] loss fxn value:  0.014806953658522937 learn rate: 1.5625e-05 iteration: 26599
[[ 2.00131308]
 [ 4.04289161]
 [-1.0219345 ]] loss fxn value:  0.014802841007365238 learn rate: 1.5625e-05 iteration: 26600
[[ 2.00131309]
 [ 4.04289161]
 [-1.02193473]] loss fxn value:  0.014798729499276941 learn rate: 1.5625e-05 iteration: 26601
[[ 2.00131309]
 [ 4.04289161]
 [-1.02193496]] loss fxn value:  0.014794619131063759 learn rate: 1.5625e-05 iteration: 26602
[[ 2.0013131 ]
 [ 4.04289161]
 [-1.02193519]] loss fxn value:  0.014790509906538987 learn rate: 1.5625e-05 iteration: 26603
[[ 2.0013131 ]
 [ 4.04289162]
 [-1.02193542]] loss fxn value:  0.014786401822296152 learn rate: 1.5625e-05 iteration: 26604
[[ 2.0013131 ]
 [ 4.04289162]
 [-1.02193565]] loss fxn value:  0.014782294879385016 learn rate: 1.5625e-05 iteration: 26605
[[ 2.00131311]
 [ 4.04289162]
 [-1.02193588]] loss fxn value:  0.014778189077746189 learn rate: 1.5625e-05 iteration: 26606
[[ 2.00131311]
 [ 4.04289162]
 [-1.02193612]] loss fxn value:  0.014774084415618038 learn rate: 1.5625e-05 iteration: 26607
[[ 2.00131311]
 [ 4.04289162]
 [-1.02193635]] loss fxn value:  0.014769980893831221 learn rate: 1.5625e-05 iteration: 26608
[[ 2.00131312]
 [ 4.04289162]
 [-1.02193658]] loss fxn value:  0.014765878511095787 learn rate: 1.5625e-05 iteration: 26609
[[ 2.00131312]
 [ 4.04289162]
 [-1.02193681]] loss fxn value:  0.01476177726966351 learn rate: 1.5625e-05 iteration: 26610
[[ 2.00131313]
 [ 4.04289162]
 [-1.02193704]] loss fxn value:  0.014757677165352045 learn rate: 1.5625e-05 iteration: 26611
[[ 2.00131313]
 [ 4.04289163]
 [-1.02193727]] loss fxn value:  0.01475357820200784 learn rate: 1.5625e-05 iteration: 26612
[[ 2.00131313]
 [ 4.04289163]
 [-1.0219375 ]] loss fxn value:  0.014749480375237222 learn rate: 1.5625e-05 iteration: 26613
[[ 2.00131314]
 [ 4.04289163]
 [-1.02193773]] loss fxn value:  0.014745383686708103 learn rate: 1.5625e-05 iteration: 26614
[[ 2.00131314]
 [ 4.04289163]
 [-1.02193796]] loss fxn value:  0.014741288137182515 learn rate: 1.5625e-05 iteration: 26615
[[ 2.00131315]
 [ 4.04289163]
 [-1.02193819]] loss fxn value:  0.014737193724825593 learn rate: 1.5625e-05 iteration: 26616
[[ 2.00131315]
 [ 4.04289163]
 [-1.02193842]] loss fxn value:  0.014733100449203425 learn rate: 1.5625e-05 iteration: 26617
[[ 2.00131315]
 [ 4.04289163]
 [-1.02193865]] loss fxn value:  0.014729008311270915 learn rate: 1.5625e-05 iteration: 26618
[[ 2.00131316]
 [ 4.04289163]
 [-1.02193888]] loss fxn value:  0.014724917309609254 learn rate: 1.5625e-05 iteration: 26619
[[ 2.00131316]
 [ 4.04289163]
 [-1.02193911]] loss fxn value:  0.014720827443766068 learn rate: 1.5625e-05 iteration: 26620
[[ 2.00131316]
 [ 4.04289164]
 [-1.02193934]] loss fxn value:  0.014716738714257735 learn rate: 1.5625e-05 iteration: 26621
[[ 2.00131317]
 [ 4.04289164]
 [-1.02193957]] loss fxn value:  0.014712651120530105 learn rate: 1.5625e-05 iteration: 26622
[[ 2.00131317]
 [ 4.04289164]
 [-1.0219398 ]] loss fxn value:  0.014708564661740137 learn rate: 1.5625e-05 iteration: 26623
[[ 2.00131318]
 [ 4.04289164]
 [-1.02194003]] loss fxn value:  0.014704479337942607 learn rate: 1.5625e-05 iteration: 26624
[[ 2.00131318]
 [ 4.04289164]
 [-1.02194026]] loss fxn value:  0.014700395149478029 learn rate: 1.5625e-05 iteration: 26625
[[ 2.00131318]
 [ 4.04289164]
 [-1.02194049]] loss fxn value:  0.01469631209498236 learn rate: 1.5625e-05 iteration: 26626
[[ 2.00131319]
 [ 4.04289164]
 [-1.02194072]] loss fxn value:  0.014692230174602932 learn rate: 1.5625e-05 iteration: 26627
[[ 2.00131319]
 [ 4.04289164]
 [-1.02194095]] loss fxn value:  0.014688149388590012 learn rate: 1.5625e-05 iteration: 26628
[[ 2.00131319]
 [ 4.04289165]
 [-1.02194118]] loss fxn value:  0.014684069734874619 learn rate: 1.5625e-05 iteration: 26629
[[ 2.0013132 ]
 [ 4.04289165]
 [-1.02194141]] loss fxn value:  0.014679991214637995 learn rate: 1.5625e-05 iteration: 26630
[[ 2.0013132 ]
 [ 4.04289165]
 [-1.02194164]] loss fxn value:  0.01467591382711811 learn rate: 1.5625e-05 iteration: 26631
[[ 2.00131321]
 [ 4.04289165]
 [-1.02194187]] loss fxn value:  0.014671837572667013 learn rate: 1.5625e-05 iteration: 26632
[[ 2.00131321]
 [ 4.04289165]
 [-1.0219421 ]] loss fxn value:  0.014667762450418587 learn rate: 1.5625e-05 iteration: 26633
[[ 2.00131321]
 [ 4.04289165]
 [-1.02194232]] loss fxn value:  0.014663688459955925 learn rate: 1.5625e-05 iteration: 26634
[[ 2.00131322]
 [ 4.04289165]
 [-1.02194255]] loss fxn value:  0.0146596156011317 learn rate: 1.5625e-05 iteration: 26635
[[ 2.00131322]
 [ 4.04289165]
 [-1.02194278]] loss fxn value:  0.014655543872779366 learn rate: 1.5625e-05 iteration: 26636
[[ 2.00131323]
 [ 4.04289165]
 [-1.02194301]] loss fxn value:  0.0146514732756748 learn rate: 1.5625e-05 iteration: 26637
[[ 2.00131323]
 [ 4.04289166]
 [-1.02194324]] loss fxn value:  0.01464740380946826 learn rate: 1.5625e-05 iteration: 26638
[[ 2.00131323]
 [ 4.04289166]
 [-1.02194347]] loss fxn value:  0.014643335473079139 learn rate: 1.5625e-05 iteration: 26639
[[ 2.00131324]
 [ 4.04289166]
 [-1.0219437 ]] loss fxn value:  0.014639268267645129 learn rate: 1.5625e-05 iteration: 26640
[[ 2.00131324]
 [ 4.04289166]
 [-1.02194393]] loss fxn value:  0.014635202191583088 learn rate: 1.5625e-05 iteration: 26641
[[ 2.00131324]
 [ 4.04289166]
 [-1.02194416]] loss fxn value:  0.014631137244090906 learn rate: 1.5625e-05 iteration: 26642
[[ 2.00131325]
 [ 4.04289166]
 [-1.02194438]] loss fxn value:  0.014627073426165874 learn rate: 1.5625e-05 iteration: 26643
[[ 2.00131325]
 [ 4.04289166]
 [-1.02194461]] loss fxn value:  0.014623010736663375 learn rate: 1.5625e-05 iteration: 26644
[[ 2.00131326]
 [ 4.04289166]
 [-1.02194484]] loss fxn value:  0.014618949175816362 learn rate: 1.5625e-05 iteration: 26645
[[ 2.00131326]
 [ 4.04289167]
 [-1.02194507]] loss fxn value:  0.014614888743060604 learn rate: 1.5625e-05 iteration: 26646
[[ 2.00131326]
 [ 4.04289167]
 [-1.0219453 ]] loss fxn value:  0.014610829438810698 learn rate: 1.5625e-05 iteration: 26647
[[ 2.00131327]
 [ 4.04289167]
 [-1.02194553]] loss fxn value:  0.014606771261349712 learn rate: 1.5625e-05 iteration: 26648
[[ 2.00131327]
 [ 4.04289167]
 [-1.02194575]] loss fxn value:  0.01460271421060902 learn rate: 1.5625e-05 iteration: 26649
[[ 2.00131328]
 [ 4.04289167]
 [-1.02194598]] loss fxn value:  0.01459865828710731 learn rate: 1.5625e-05 iteration: 26650
[[ 2.00131328]
 [ 4.04289167]
 [-1.02194621]] loss fxn value:  0.01459460348984037 learn rate: 1.5625e-05 iteration: 26651
[[ 2.00131328]
 [ 4.04289167]
 [-1.02194644]] loss fxn value:  0.014590549819845571 learn rate: 1.5625e-05 iteration: 26652
[[ 2.00131329]
 [ 4.04289167]
 [-1.02194667]] loss fxn value:  0.014586497274657497 learn rate: 1.5625e-05 iteration: 26653
[[ 2.00131329]
 [ 4.04289167]
 [-1.02194689]] loss fxn value:  0.014582445855858439 learn rate: 1.5625e-05 iteration: 26654
[[ 2.00131329]
 [ 4.04289168]
 [-1.02194712]] loss fxn value:  0.014578395561930118 learn rate: 1.5625e-05 iteration: 26655
[[ 2.0013133 ]
 [ 4.04289168]
 [-1.02194735]] loss fxn value:  0.014574346392907995 learn rate: 1.5625e-05 iteration: 26656
[[ 2.0013133 ]
 [ 4.04289168]
 [-1.02194758]] loss fxn value:  0.014570298348392168 learn rate: 1.5625e-05 iteration: 26657
[[ 2.00131331]
 [ 4.04289168]
 [-1.02194781]] loss fxn value:  0.014566251428841933 learn rate: 1.5625e-05 iteration: 26658
[[ 2.00131331]
 [ 4.04289168]
 [-1.02194803]] loss fxn value:  0.0145622056331983 learn rate: 1.5625e-05 iteration: 26659
[[ 2.00131331]
 [ 4.04289168]
 [-1.02194826]] loss fxn value:  0.01455816096072547 learn rate: 1.5625e-05 iteration: 26660
[[ 2.00131332]
 [ 4.04289168]
 [-1.02194849]] loss fxn value:  0.014554117412249485 learn rate: 1.5625e-05 iteration: 26661
[[ 2.00131332]
 [ 4.04289168]
 [-1.02194872]] loss fxn value:  0.014550074986882603 learn rate: 1.5625e-05 iteration: 26662
[[ 2.00131332]
 [ 4.04289168]
 [-1.02194894]] loss fxn value:  0.014546033683727009 learn rate: 1.5625e-05 iteration: 26663
[[ 2.00131333]
 [ 4.04289169]
 [-1.02194917]] loss fxn value:  0.014541993503204223 learn rate: 1.5625e-05 iteration: 26664
[[ 2.00131333]
 [ 4.04289169]
 [-1.0219494 ]] loss fxn value:  0.014537954445333557 learn rate: 1.5625e-05 iteration: 26665
[[ 2.00131334]
 [ 4.04289169]
 [-1.02194962]] loss fxn value:  0.014533916508705431 learn rate: 1.5625e-05 iteration: 26666
[[ 2.00131334]
 [ 4.04289169]
 [-1.02194985]] loss fxn value:  0.014529879693910307 learn rate: 1.5625e-05 iteration: 26667
[[ 2.00131334]
 [ 4.04289169]
 [-1.02195008]] loss fxn value:  0.014525844000326874 learn rate: 1.5625e-05 iteration: 26668
[[ 2.00131335]
 [ 4.04289169]
 [-1.02195031]] loss fxn value:  0.014521809427552922 learn rate: 1.5625e-05 iteration: 26669
[[ 2.00131335]
 [ 4.04289169]
 [-1.02195053]] loss fxn value:  0.01451777597570723 learn rate: 1.5625e-05 iteration: 26670
[[ 2.00131335]
 [ 4.04289169]
 [-1.02195076]] loss fxn value:  0.014513743644130717 learn rate: 1.5625e-05 iteration: 26671
[[ 2.00131336]
 [ 4.0428917 ]
 [-1.02195099]] loss fxn value:  0.014509712432575417 learn rate: 1.5625e-05 iteration: 26672
[[ 2.00131336]
 [ 4.0428917 ]
 [-1.02195121]] loss fxn value:  0.014505682340379937 learn rate: 1.5625e-05 iteration: 26673
[[ 2.00131337]
 [ 4.0428917 ]
 [-1.02195144]] loss fxn value:  0.014501653368234212 learn rate: 1.5625e-05 iteration: 26674
[[ 2.00131337]
 [ 4.0428917 ]
 [-1.02195167]] loss fxn value:  0.014497625514508101 learn rate: 1.5625e-05 iteration: 26675
[[ 2.00131337]
 [ 4.0428917 ]
 [-1.02195189]] loss fxn value:  0.014493598778953645 learn rate: 1.5625e-05 iteration: 26676
[[ 2.00131338]
 [ 4.0428917 ]
 [-1.02195212]] loss fxn value:  0.014489573162444728 learn rate: 1.5625e-05 iteration: 26677
[[ 2.00131338]
 [ 4.0428917 ]
 [-1.02195234]] loss fxn value:  0.0144855486643932 learn rate: 1.5625e-05 iteration: 26678
[[ 2.00131339]
 [ 4.0428917 ]
 [-1.02195257]] loss fxn value:  0.014481525284113419 learn rate: 1.5625e-05 iteration: 26679
[[ 2.00131339]
 [ 4.0428917 ]
 [-1.0219528 ]] loss fxn value:  0.014477503019982171 learn rate: 1.5625e-05 iteration: 26680
[[ 2.00131339]
 [ 4.04289171]
 [-1.02195302]] loss fxn value:  0.01447348187450118 learn rate: 1.5625e-05 iteration: 26681
[[ 2.0013134 ]
 [ 4.04289171]
 [-1.02195325]] loss fxn value:  0.014469461845777642 learn rate: 1.5625e-05 iteration: 26682
[[ 2.0013134 ]
 [ 4.04289171]
 [-1.02195348]] loss fxn value:  0.014465442933740632 learn rate: 1.5625e-05 iteration: 26683
[[ 2.0013134 ]
 [ 4.04289171]
 [-1.0219537 ]] loss fxn value:  0.014461425137516259 learn rate: 1.5625e-05 iteration: 26684
[[ 2.00131341]
 [ 4.04289171]
 [-1.02195393]] loss fxn value:  0.01445740845715468 learn rate: 1.5625e-05 iteration: 26685
[[ 2.00131341]
 [ 4.04289171]
 [-1.02195415]] loss fxn value:  0.014453392892612658 learn rate: 1.5625e-05 iteration: 26686
[[ 2.00131342]
 [ 4.04289171]
 [-1.02195438]] loss fxn value:  0.014449378443447906 learn rate: 1.5625e-05 iteration: 26687
[[ 2.00131342]
 [ 4.04289171]
 [-1.0219546 ]] loss fxn value:  0.014445365108731754 learn rate: 1.5625e-05 iteration: 26688
[[ 2.00131342]
 [ 4.04289171]
 [-1.02195483]] loss fxn value:  0.014441352889913862 learn rate: 1.5625e-05 iteration: 26689
[[ 2.00131343]
 [ 4.04289172]
 [-1.02195506]] loss fxn value:  0.014437341784057138 learn rate: 1.5625e-05 iteration: 26690
[[ 2.00131343]
 [ 4.04289172]
 [-1.02195528]] loss fxn value:  0.014433331793274945 learn rate: 1.5625e-05 iteration: 26691
[[ 2.00131343]
 [ 4.04289172]
 [-1.02195551]] loss fxn value:  0.014429322916429588 learn rate: 1.5625e-05 iteration: 26692
[[ 2.00131344]
 [ 4.04289172]
 [-1.02195573]] loss fxn value:  0.014425315153092626 learn rate: 1.5625e-05 iteration: 26693
[[ 2.00131344]
 [ 4.04289172]
 [-1.02195596]] loss fxn value:  0.014421308501495507 learn rate: 1.5625e-05 iteration: 26694
[[ 2.00131345]
 [ 4.04289172]
 [-1.02195618]] loss fxn value:  0.014417302964529779 learn rate: 1.5625e-05 iteration: 26695
[[ 2.00131345]
 [ 4.04289172]
 [-1.02195641]] loss fxn value:  0.01441329853819013 learn rate: 1.5625e-05 iteration: 26696
[[ 2.00131345]
 [ 4.04289172]
 [-1.02195663]] loss fxn value:  0.014409295225991724 learn rate: 1.5625e-05 iteration: 26697
[[ 2.00131346]
 [ 4.04289172]
 [-1.02195686]] loss fxn value:  0.01440529302548531 learn rate: 1.5625e-05 iteration: 26698
[[ 2.00131346]
 [ 4.04289173]
 [-1.02195708]] loss fxn value:  0.014401291935264461 learn rate: 1.5625e-05 iteration: 26699
[[ 2.00131346]
 [ 4.04289173]
 [-1.02195731]] loss fxn value:  0.014397291957856289 learn rate: 1.5625e-05 iteration: 26700
[[ 2.00131347]
 [ 4.04289173]
 [-1.02195753]] loss fxn value:  0.014393293090226538 learn rate: 1.5625e-05 iteration: 26701
[[ 2.00131347]
 [ 4.04289173]
 [-1.02195776]] loss fxn value:  0.014389295333950572 learn rate: 1.5625e-05 iteration: 26702
[[ 2.00131348]
 [ 4.04289173]
 [-1.02195798]] loss fxn value:  0.01438529868805734 learn rate: 1.5625e-05 iteration: 26703
[[ 2.00131348]
 [ 4.04289173]
 [-1.02195821]] loss fxn value:  0.014381303151971066 learn rate: 1.5625e-05 iteration: 26704
[[ 2.00131348]
 [ 4.04289173]
 [-1.02195843]] loss fxn value:  0.014377308725960172 learn rate: 1.5625e-05 iteration: 26705
[[ 2.00131349]
 [ 4.04289173]
 [-1.02195866]] loss fxn value:  0.01437331540885842 learn rate: 1.5625e-05 iteration: 26706
[[ 2.00131349]
 [ 4.04289174]
 [-1.02195888]] loss fxn value:  0.01436932320170634 learn rate: 1.5625e-05 iteration: 26707
[[ 2.00131349]
 [ 4.04289174]
 [-1.02195911]] loss fxn value:  0.014365332102144916 learn rate: 1.5625e-05 iteration: 26708
[[ 2.0013135 ]
 [ 4.04289174]
 [-1.02195933]] loss fxn value:  0.014361342112641865 learn rate: 1.5625e-05 iteration: 26709
[[ 2.0013135 ]
 [ 4.04289174]
 [-1.02195956]] loss fxn value:  0.014357353230584452 learn rate: 1.5625e-05 iteration: 26710
[[ 2.00131351]
 [ 4.04289174]
 [-1.02195978]] loss fxn value:  0.014353365456298174 learn rate: 1.5625e-05 iteration: 26711
[[ 2.00131351]
 [ 4.04289174]
 [-1.02196   ]] loss fxn value:  0.01434937878963571 learn rate: 1.5625e-05 iteration: 26712
[[ 2.00131351]
 [ 4.04289174]
 [-1.02196023]] loss fxn value:  0.014345393230632521 learn rate: 1.5625e-05 iteration: 26713
[[ 2.00131352]
 [ 4.04289174]
 [-1.02196045]] loss fxn value:  0.014341408778798467 learn rate: 1.5625e-05 iteration: 26714
[[ 2.00131352]
 [ 4.04289174]
 [-1.02196068]] loss fxn value:  0.014337425433219574 learn rate: 1.5625e-05 iteration: 26715
[[ 2.00131352]
 [ 4.04289175]
 [-1.0219609 ]] loss fxn value:  0.014333443193971389 learn rate: 1.5625e-05 iteration: 26716
[[ 2.00131353]
 [ 4.04289175]
 [-1.02196112]] loss fxn value:  0.014329462060492838 learn rate: 1.5625e-05 iteration: 26717
[[ 2.00131353]
 [ 4.04289175]
 [-1.02196135]] loss fxn value:  0.014325482033335763 learn rate: 1.5625e-05 iteration: 26718
[[ 2.00131354]
 [ 4.04289175]
 [-1.02196157]] loss fxn value:  0.014321503111557651 learn rate: 1.5625e-05 iteration: 26719
[[ 2.00131354]
 [ 4.04289175]
 [-1.0219618 ]] loss fxn value:  0.01431752529467759 learn rate: 1.5625e-05 iteration: 26720
[[ 2.00131354]
 [ 4.04289175]
 [-1.02196202]] loss fxn value:  0.014313548582700194 learn rate: 1.5625e-05 iteration: 26721
[[ 2.00131355]
 [ 4.04289175]
 [-1.02196224]] loss fxn value:  0.01430957297613261 learn rate: 1.5625e-05 iteration: 26722
[[ 2.00131355]
 [ 4.04289175]
 [-1.02196247]] loss fxn value:  0.014305598472580358 learn rate: 1.5625e-05 iteration: 26723
[[ 2.00131355]
 [ 4.04289175]
 [-1.02196269]] loss fxn value:  0.014301625073590259 learn rate: 1.5625e-05 iteration: 26724
[[ 2.00131356]
 [ 4.04289176]
 [-1.02196291]] loss fxn value:  0.014297652778077093 learn rate: 1.5625e-05 iteration: 26725
[[ 2.00131356]
 [ 4.04289176]
 [-1.02196314]] loss fxn value:  0.014293681585702656 learn rate: 1.5625e-05 iteration: 26726
[[ 2.00131357]
 [ 4.04289176]
 [-1.02196336]] loss fxn value:  0.014289711496859927 learn rate: 1.5625e-05 iteration: 26727
[[ 2.00131357]
 [ 4.04289176]
 [-1.02196358]] loss fxn value:  0.014285742510241953 learn rate: 1.5625e-05 iteration: 26728
[[ 2.00131357]
 [ 4.04289176]
 [-1.02196381]] loss fxn value:  0.01428177462619848 learn rate: 1.5625e-05 iteration: 26729
[[ 2.00131358]
 [ 4.04289176]
 [-1.02196403]] loss fxn value:  0.014277807843949013 learn rate: 1.5625e-05 iteration: 26730
[[ 2.00131358]
 [ 4.04289176]
 [-1.02196425]] loss fxn value:  0.014273842164357361 learn rate: 1.5625e-05 iteration: 26731
[[ 2.00131358]
 [ 4.04289176]
 [-1.02196448]] loss fxn value:  0.014269877585026737 learn rate: 1.5625e-05 iteration: 26732
[[ 2.00131359]
 [ 4.04289176]
 [-1.0219647 ]] loss fxn value:  0.014265914107101756 learn rate: 1.5625e-05 iteration: 26733
[[ 2.00131359]
 [ 4.04289177]
 [-1.02196492]] loss fxn value:  0.014261951731320518 learn rate: 1.5625e-05 iteration: 26734
[[ 2.00131359]
 [ 4.04289177]
 [-1.02196514]] loss fxn value:  0.014257990454950345 learn rate: 1.5625e-05 iteration: 26735
[[ 2.0013136 ]
 [ 4.04289177]
 [-1.02196537]] loss fxn value:  0.014254030278531537 learn rate: 1.5625e-05 iteration: 26736
[[ 2.0013136 ]
 [ 4.04289177]
 [-1.02196559]] loss fxn value:  0.014250071202521083 learn rate: 1.5625e-05 iteration: 26737
[[ 2.00131361]
 [ 4.04289177]
 [-1.02196581]] loss fxn value:  0.01424611322586922 learn rate: 1.5625e-05 iteration: 26738
[[ 2.00131361]
 [ 4.04289177]
 [-1.02196603]] loss fxn value:  0.014242156349285202 learn rate: 1.5625e-05 iteration: 26739
[[ 2.00131361]
 [ 4.04289177]
 [-1.02196626]] loss fxn value:  0.01423820057157194 learn rate: 1.5625e-05 iteration: 26740
[[ 2.00131362]
 [ 4.04289177]
 [-1.02196648]] loss fxn value:  0.01423424589196279 learn rate: 1.5625e-05 iteration: 26741
[[ 2.00131362]
 [ 4.04289177]
 [-1.0219667 ]] loss fxn value:  0.01423029231191664 learn rate: 1.5625e-05 iteration: 26742
[[ 2.00131362]
 [ 4.04289178]
 [-1.02196692]] loss fxn value:  0.014226339828010874 learn rate: 1.5625e-05 iteration: 26743
[[ 2.00131363]
 [ 4.04289178]
 [-1.02196715]] loss fxn value:  0.014222388443692035 learn rate: 1.5625e-05 iteration: 26744
[[ 2.00131363]
 [ 4.04289178]
 [-1.02196737]] loss fxn value:  0.014218438156446862 learn rate: 1.5625e-05 iteration: 26745
[[ 2.00131364]
 [ 4.04289178]
 [-1.02196759]] loss fxn value:  0.014214488965558018 learn rate: 1.5625e-05 iteration: 26746
[[ 2.00131364]
 [ 4.04289178]
 [-1.02196781]] loss fxn value:  0.014210540872278526 learn rate: 1.5625e-05 iteration: 26747
[[ 2.00131364]
 [ 4.04289178]
 [-1.02196804]] loss fxn value:  0.014206593875752956 learn rate: 1.5625e-05 iteration: 26748
[[ 2.00131365]
 [ 4.04289178]
 [-1.02196826]] loss fxn value:  0.014202647974963251 learn rate: 1.5625e-05 iteration: 26749
[[ 2.00131365]
 [ 4.04289178]
 [-1.02196848]] loss fxn value:  0.014198703170617808 learn rate: 1.5625e-05 iteration: 26750
[[ 2.00131365]
 [ 4.04289179]
 [-1.0219687 ]] loss fxn value:  0.014194759461498774 learn rate: 1.5625e-05 iteration: 26751
[[ 2.00131366]
 [ 4.04289179]
 [-1.02196892]] loss fxn value:  0.014190816848702912 learn rate: 1.5625e-05 iteration: 26752
[[ 2.00131366]
 [ 4.04289179]
 [-1.02196914]] loss fxn value:  0.014186875329852742 learn rate: 1.5625e-05 iteration: 26753
[[ 2.00131367]
 [ 4.04289179]
 [-1.02196937]] loss fxn value:  0.014182934906049643 learn rate: 1.5625e-05 iteration: 26754
[[ 2.00131367]
 [ 4.04289179]
 [-1.02196959]] loss fxn value:  0.014178995577536959 learn rate: 1.5625e-05 iteration: 26755
[[ 2.00131367]
 [ 4.04289179]
 [-1.02196981]] loss fxn value:  0.014175057342038994 learn rate: 1.5625e-05 iteration: 26756
[[ 2.00131368]
 [ 4.04289179]
 [-1.02197003]] loss fxn value:  0.014171120201616639 learn rate: 1.5625e-05 iteration: 26757
[[ 2.00131368]
 [ 4.04289179]
 [-1.02197025]] loss fxn value:  0.014167184153176249 learn rate: 1.5625e-05 iteration: 26758
[[ 2.00131368]
 [ 4.04289179]
 [-1.02197047]] loss fxn value:  0.014163249199470958 learn rate: 1.5625e-05 iteration: 26759
[[ 2.00131369]
 [ 4.0428918 ]
 [-1.02197069]] loss fxn value:  0.014159315337664314 learn rate: 1.5625e-05 iteration: 26760
[[ 2.00131369]
 [ 4.0428918 ]
 [-1.02197092]] loss fxn value:  0.014155382568662197 learn rate: 1.5625e-05 iteration: 26761
[[ 2.00131369]
 [ 4.0428918 ]
 [-1.02197114]] loss fxn value:  0.014151450891765442 learn rate: 1.5625e-05 iteration: 26762
[[ 2.0013137 ]
 [ 4.0428918 ]
 [-1.02197136]] loss fxn value:  0.014147520307602286 learn rate: 1.5625e-05 iteration: 26763
[[ 2.0013137 ]
 [ 4.0428918 ]
 [-1.02197158]] loss fxn value:  0.014143590815556028 learn rate: 1.5625e-05 iteration: 26764
[[ 2.00131371]
 [ 4.0428918 ]
 [-1.0219718 ]] loss fxn value:  0.014139662413851197 learn rate: 1.5625e-05 iteration: 26765
[[ 2.00131371]
 [ 4.0428918 ]
 [-1.02197202]] loss fxn value:  0.014135735103456537 learn rate: 1.5625e-05 iteration: 26766
[[ 2.00131371]
 [ 4.0428918 ]
 [-1.02197224]] loss fxn value:  0.014131808884388204 learn rate: 1.5625e-05 iteration: 26767
[[ 2.00131372]
 [ 4.0428918 ]
 [-1.02197246]] loss fxn value:  0.014127883755568746 learn rate: 1.5625e-05 iteration: 26768
[[ 2.00131372]
 [ 4.04289181]
 [-1.02197268]] loss fxn value:  0.014123959716283135 learn rate: 1.5625e-05 iteration: 26769
[[ 2.00131372]
 [ 4.04289181]
 [-1.0219729 ]] loss fxn value:  0.014120036768310005 learn rate: 1.5625e-05 iteration: 26770
[[ 2.00131373]
 [ 4.04289181]
 [-1.02197312]] loss fxn value:  0.014116114908319283 learn rate: 1.5625e-05 iteration: 26771
[[ 2.00131373]
 [ 4.04289181]
 [-1.02197334]] loss fxn value:  0.014112194139245755 learn rate: 1.5625e-05 iteration: 26772
[[ 2.00131374]
 [ 4.04289181]
 [-1.02197357]] loss fxn value:  0.014108274459163463 learn rate: 1.5625e-05 iteration: 26773
[[ 2.00131374]
 [ 4.04289181]
 [-1.02197379]] loss fxn value:  0.014104355866180454 learn rate: 1.5625e-05 iteration: 26774
[[ 2.00131374]
 [ 4.04289181]
 [-1.02197401]] loss fxn value:  0.014100438362724371 learn rate: 1.5625e-05 iteration: 26775
[[ 2.00131375]
 [ 4.04289181]
 [-1.02197423]] loss fxn value:  0.014096521947376402 learn rate: 1.5625e-05 iteration: 26776
[[ 2.00131375]
 [ 4.04289181]
 [-1.02197445]] loss fxn value:  0.014092606618677657 learn rate: 1.5625e-05 iteration: 26777
[[ 2.00131375]
 [ 4.04289182]
 [-1.02197467]] loss fxn value:  0.014088692378625022 learn rate: 1.5625e-05 iteration: 26778
[[ 2.00131376]
 [ 4.04289182]
 [-1.02197489]] loss fxn value:  0.014084779226130965 learn rate: 1.5625e-05 iteration: 26779
[[ 2.00131376]
 [ 4.04289182]
 [-1.02197511]] loss fxn value:  0.014080867159469322 learn rate: 1.5625e-05 iteration: 26780
[[ 2.00131376]
 [ 4.04289182]
 [-1.02197533]] loss fxn value:  0.014076956179121008 learn rate: 1.5625e-05 iteration: 26781
[[ 2.00131377]
 [ 4.04289182]
 [-1.02197555]] loss fxn value:  0.014073046285940602 learn rate: 1.5625e-05 iteration: 26782
[[ 2.00131377]
 [ 4.04289182]
 [-1.02197577]] loss fxn value:  0.014069137479040367 learn rate: 1.5625e-05 iteration: 26783
[[ 2.00131378]
 [ 4.04289182]
 [-1.02197599]] loss fxn value:  0.01406522975697064 learn rate: 1.5625e-05 iteration: 26784
[[ 2.00131378]
 [ 4.04289182]
 [-1.02197621]] loss fxn value:  0.014061323120366582 learn rate: 1.5625e-05 iteration: 26785
[[ 2.00131378]
 [ 4.04289182]
 [-1.02197643]] loss fxn value:  0.014057417568628501 learn rate: 1.5625e-05 iteration: 26786
[[ 2.00131379]
 [ 4.04289183]
 [-1.02197665]] loss fxn value:  0.01405351310273984 learn rate: 1.5625e-05 iteration: 26787
[[ 2.00131379]
 [ 4.04289183]
 [-1.02197686]] loss fxn value:  0.014049609720814718 learn rate: 1.5625e-05 iteration: 26788
[[ 2.00131379]
 [ 4.04289183]
 [-1.02197708]] loss fxn value:  0.014045707422408541 learn rate: 1.5625e-05 iteration: 26789
[[ 2.0013138 ]
 [ 4.04289183]
 [-1.0219773 ]] loss fxn value:  0.014041806208080073 learn rate: 1.5625e-05 iteration: 26790
[[ 2.0013138 ]
 [ 4.04289183]
 [-1.02197752]] loss fxn value:  0.014037906078153669 learn rate: 1.5625e-05 iteration: 26791
[[ 2.00131381]
 [ 4.04289183]
 [-1.02197774]] loss fxn value:  0.014034007029932113 learn rate: 1.5625e-05 iteration: 26792
[[ 2.00131381]
 [ 4.04289183]
 [-1.02197796]] loss fxn value:  0.014030109066723858 learn rate: 1.5625e-05 iteration: 26793
[[ 2.00131381]
 [ 4.04289183]
 [-1.02197818]] loss fxn value:  0.014026212184646985 learn rate: 1.5625e-05 iteration: 26794
[[ 2.00131382]
 [ 4.04289183]
 [-1.0219784 ]] loss fxn value:  0.014022316385762394 learn rate: 1.5625e-05 iteration: 26795
[[ 2.00131382]
 [ 4.04289184]
 [-1.02197862]] loss fxn value:  0.01401842166810635 learn rate: 1.5625e-05 iteration: 26796
[[ 2.00131382]
 [ 4.04289184]
 [-1.02197884]] loss fxn value:  0.014014528033573965 learn rate: 1.5625e-05 iteration: 26797
[[ 2.00131383]
 [ 4.04289184]
 [-1.02197906]] loss fxn value:  0.014010635478903785 learn rate: 1.5625e-05 iteration: 26798
[[ 2.00131383]
 [ 4.04289184]
 [-1.02197928]] loss fxn value:  0.014006744005966994 learn rate: 1.5625e-05 iteration: 26799
[[ 2.00131383]
 [ 4.04289184]
 [-1.02197949]] loss fxn value:  0.014002853614836828 learn rate: 1.5625e-05 iteration: 26800
[[ 2.00131384]
 [ 4.04289184]
 [-1.02197971]] loss fxn value:  0.013998964303469398 learn rate: 1.5625e-05 iteration: 26801
[[ 2.00131384]
 [ 4.04289184]
 [-1.02197993]] loss fxn value:  0.013995076072144657 learn rate: 1.5625e-05 iteration: 26802
[[ 2.00131385]
 [ 4.04289184]
 [-1.02198015]] loss fxn value:  0.013991188921099029 learn rate: 1.5625e-05 iteration: 26803
[[ 2.00131385]
 [ 4.04289184]
 [-1.02198037]] loss fxn value:  0.01398730284908957 learn rate: 1.5625e-05 iteration: 26804
[[ 2.00131385]
 [ 4.04289185]
 [-1.02198059]] loss fxn value:  0.013983417857430151 learn rate: 1.5625e-05 iteration: 26805
[[ 2.00131386]
 [ 4.04289185]
 [-1.02198081]] loss fxn value:  0.013979533944330604 learn rate: 1.5625e-05 iteration: 26806
[[ 2.00131386]
 [ 4.04289185]
 [-1.02198102]] loss fxn value:  0.013975651110205527 learn rate: 1.5625e-05 iteration: 26807
[[ 2.00131386]
 [ 4.04289185]
 [-1.02198124]] loss fxn value:  0.013971769354609472 learn rate: 1.5625e-05 iteration: 26808
[[ 2.00131387]
 [ 4.04289185]
 [-1.02198146]] loss fxn value:  0.013967888676716398 learn rate: 1.5625e-05 iteration: 26809
[[ 2.00131387]
 [ 4.04289185]
 [-1.02198168]] loss fxn value:  0.013964009076802815 learn rate: 1.5625e-05 iteration: 26810
[[ 2.00131387]
 [ 4.04289185]
 [-1.0219819 ]] loss fxn value:  0.01396013055517029 learn rate: 1.5625e-05 iteration: 26811
[[ 2.00131388]
 [ 4.04289185]
 [-1.02198212]] loss fxn value:  0.013956253109520363 learn rate: 1.5625e-05 iteration: 26812
[[ 2.00131388]
 [ 4.04289185]
 [-1.02198233]] loss fxn value:  0.01395237674174929 learn rate: 1.5625e-05 iteration: 26813
[[ 2.00131389]
 [ 4.04289186]
 [-1.02198255]] loss fxn value:  0.013948501450659982 learn rate: 1.5625e-05 iteration: 26814
[[ 2.00131389]
 [ 4.04289186]
 [-1.02198277]] loss fxn value:  0.013944627235281386 learn rate: 1.5625e-05 iteration: 26815
[[ 2.00131389]
 [ 4.04289186]
 [-1.02198299]] loss fxn value:  0.01394075409672265 learn rate: 1.5625e-05 iteration: 26816
[[ 2.0013139 ]
 [ 4.04289186]
 [-1.02198321]] loss fxn value:  0.013936882033450797 learn rate: 1.5625e-05 iteration: 26817
[[ 2.0013139 ]
 [ 4.04289186]
 [-1.02198342]] loss fxn value:  0.013933011045606231 learn rate: 1.5625e-05 iteration: 26818
[[ 2.0013139 ]
 [ 4.04289186]
 [-1.02198364]] loss fxn value:  0.013929141133562615 learn rate: 1.5625e-05 iteration: 26819
[[ 2.00131391]
 [ 4.04289186]
 [-1.02198386]] loss fxn value:  0.013925272295463467 learn rate: 1.5625e-05 iteration: 26820
[[ 2.00131391]
 [ 4.04289186]
 [-1.02198408]] loss fxn value:  0.01392140453192002 learn rate: 1.5625e-05 iteration: 26821
[[ 2.00131391]
 [ 4.04289186]
 [-1.02198429]] loss fxn value:  0.013917537844594432 learn rate: 1.5625e-05 iteration: 26822
[[ 2.00131392]
 [ 4.04289187]
 [-1.02198451]] loss fxn value:  0.013913672229377594 learn rate: 1.5625e-05 iteration: 26823
[[ 2.00131392]
 [ 4.04289187]
 [-1.02198473]] loss fxn value:  0.013909807687790945 learn rate: 1.5625e-05 iteration: 26824
[[ 2.00131393]
 [ 4.04289187]
 [-1.02198495]] loss fxn value:  0.01390594422064814 learn rate: 1.5625e-05 iteration: 26825
[[ 2.00131393]
 [ 4.04289187]
 [-1.02198516]] loss fxn value:  0.0139020818260503 learn rate: 1.5625e-05 iteration: 26826
[[ 2.00131393]
 [ 4.04289187]
 [-1.02198538]] loss fxn value:  0.01389822050373708 learn rate: 1.5625e-05 iteration: 26827
[[ 2.00131394]
 [ 4.04289187]
 [-1.0219856 ]] loss fxn value:  0.013894360254946805 learn rate: 1.5625e-05 iteration: 26828
[[ 2.00131394]
 [ 4.04289187]
 [-1.02198581]] loss fxn value:  0.013890501076892015 learn rate: 1.5625e-05 iteration: 26829
[[ 2.00131394]
 [ 4.04289187]
 [-1.02198603]] loss fxn value:  0.013886642972024275 learn rate: 1.5625e-05 iteration: 26830
[[ 2.00131395]
 [ 4.04289187]
 [-1.02198625]] loss fxn value:  0.01388278593886077 learn rate: 1.5625e-05 iteration: 26831
[[ 2.00131395]
 [ 4.04289188]
 [-1.02198647]] loss fxn value:  0.01387892997595876 learn rate: 1.5625e-05 iteration: 26832
[[ 2.00131395]
 [ 4.04289188]
 [-1.02198668]] loss fxn value:  0.013875075084446707 learn rate: 1.5625e-05 iteration: 26833
[[ 2.00131396]
 [ 4.04289188]
 [-1.0219869 ]] loss fxn value:  0.013871221264127126 learn rate: 1.5625e-05 iteration: 26834
[[ 2.00131396]
 [ 4.04289188]
 [-1.02198712]] loss fxn value:  0.013867368513780998 learn rate: 1.5625e-05 iteration: 26835
[[ 2.00131397]
 [ 4.04289188]
 [-1.02198733]] loss fxn value:  0.013863516834172664 learn rate: 1.5625e-05 iteration: 26836
[[ 2.00131397]
 [ 4.04289188]
 [-1.02198755]] loss fxn value:  0.013859666222659679 learn rate: 1.5625e-05 iteration: 26837
[[ 2.00131397]
 [ 4.04289188]
 [-1.02198777]] loss fxn value:  0.013855816682036426 learn rate: 1.5625e-05 iteration: 26838
[[ 2.00131398]
 [ 4.04289188]
 [-1.02198798]] loss fxn value:  0.013851968210815475 learn rate: 1.5625e-05 iteration: 26839
[[ 2.00131398]
 [ 4.04289188]
 [-1.0219882 ]] loss fxn value:  0.013848120808139937 learn rate: 1.5625e-05 iteration: 26840
[[ 2.00131398]
 [ 4.04289189]
 [-1.02198841]] loss fxn value:  0.01384427447395734 learn rate: 1.5625e-05 iteration: 26841
[[ 2.00131399]
 [ 4.04289189]
 [-1.02198863]] loss fxn value:  0.01384042920835793 learn rate: 1.5625e-05 iteration: 26842
[[ 2.00131399]
 [ 4.04289189]
 [-1.02198885]] loss fxn value:  0.01383658500946591 learn rate: 1.5625e-05 iteration: 26843
[[ 2.00131399]
 [ 4.04289189]
 [-1.02198906]] loss fxn value:  0.013832741880545034 learn rate: 1.5625e-05 iteration: 26844
[[ 2.001314  ]
 [ 4.04289189]
 [-1.02198928]] loss fxn value:  0.013828899817779704 learn rate: 1.5625e-05 iteration: 26845
[[ 2.001314  ]
 [ 4.04289189]
 [-1.0219895 ]] loss fxn value:  0.013825058822266681 learn rate: 1.5625e-05 iteration: 26846
[[ 2.001314  ]
 [ 4.04289189]
 [-1.02198971]] loss fxn value:  0.01382121889391111 learn rate: 1.5625e-05 iteration: 26847
[[ 2.00131401]
 [ 4.04289189]
 [-1.02198993]] loss fxn value:  0.013817380030865738 learn rate: 1.5625e-05 iteration: 26848
[[ 2.00131401]
 [ 4.04289189]
 [-1.02199014]] loss fxn value:  0.01381354223554666 learn rate: 1.5625e-05 iteration: 26849
[[ 2.00131402]
 [ 4.04289189]
 [-1.02199036]] loss fxn value:  0.013809705506477985 learn rate: 1.5625e-05 iteration: 26850
[[ 2.00131402]
 [ 4.0428919 ]
 [-1.02199057]] loss fxn value:  0.013805869841686752 learn rate: 1.5625e-05 iteration: 26851
[[ 2.00131402]
 [ 4.0428919 ]
 [-1.02199079]] loss fxn value:  0.013802035242481053 learn rate: 1.5625e-05 iteration: 26852
[[ 2.00131403]
 [ 4.0428919 ]
 [-1.02199101]] loss fxn value:  0.013798201709457137 learn rate: 1.5625e-05 iteration: 26853
[[ 2.00131403]
 [ 4.0428919 ]
 [-1.02199122]] loss fxn value:  0.013794369239922393 learn rate: 1.5625e-05 iteration: 26854
[[ 2.00131403]
 [ 4.0428919 ]
 [-1.02199144]] loss fxn value:  0.013790537835795013 learn rate: 1.5625e-05 iteration: 26855
[[ 2.00131404]
 [ 4.0428919 ]
 [-1.02199165]] loss fxn value:  0.01378670749518535 learn rate: 1.5625e-05 iteration: 26856
[[ 2.00131404]
 [ 4.0428919 ]
 [-1.02199187]] loss fxn value:  0.013782878218614398 learn rate: 1.5625e-05 iteration: 26857
[[ 2.00131404]
 [ 4.0428919 ]
 [-1.02199208]] loss fxn value:  0.013779050005982682 learn rate: 1.5625e-05 iteration: 26858
[[ 2.00131405]
 [ 4.0428919 ]
 [-1.0219923 ]] loss fxn value:  0.013775222856447165 learn rate: 1.5625e-05 iteration: 26859
[[ 2.00131405]
 [ 4.04289191]
 [-1.02199251]] loss fxn value:  0.013771396770005537 learn rate: 1.5625e-05 iteration: 26860
[[ 2.00131406]
 [ 4.04289191]
 [-1.02199273]] loss fxn value:  0.013767571746207736 learn rate: 1.5625e-05 iteration: 26861
[[ 2.00131406]
 [ 4.04289191]
 [-1.02199294]] loss fxn value:  0.013763747784080398 learn rate: 1.5625e-05 iteration: 26862
[[ 2.00131406]
 [ 4.04289191]
 [-1.02199316]] loss fxn value:  0.01375992488465166 learn rate: 1.5625e-05 iteration: 26863
[[ 2.00131407]
 [ 4.04289191]
 [-1.02199337]] loss fxn value:  0.013756103047350374 learn rate: 1.5625e-05 iteration: 26864
[[ 2.00131407]
 [ 4.04289191]
 [-1.02199359]] loss fxn value:  0.01375228227178125 learn rate: 1.5625e-05 iteration: 26865
[[ 2.00131407]
 [ 4.04289191]
 [-1.0219938 ]] loss fxn value:  0.013748462556523167 learn rate: 1.5625e-05 iteration: 26866
[[ 2.00131408]
 [ 4.04289191]
 [-1.02199402]] loss fxn value:  0.013744643902601963 learn rate: 1.5625e-05 iteration: 26867
[[ 2.00131408]
 [ 4.04289191]
 [-1.02199423]] loss fxn value:  0.013740826308525586 learn rate: 1.5625e-05 iteration: 26868
[[ 2.00131408]
 [ 4.04289192]
 [-1.02199445]] loss fxn value:  0.01373700977624076 learn rate: 1.5625e-05 iteration: 26869
[[ 2.00131409]
 [ 4.04289192]
 [-1.02199466]] loss fxn value:  0.01373319430330054 learn rate: 1.5625e-05 iteration: 26870
[[ 2.00131409]
 [ 4.04289192]
 [-1.02199488]] loss fxn value:  0.013729379890392551 learn rate: 1.5625e-05 iteration: 26871
[[ 2.00131409]
 [ 4.04289192]
 [-1.02199509]] loss fxn value:  0.013725566536303559 learn rate: 1.5625e-05 iteration: 26872
[[ 2.0013141 ]
 [ 4.04289192]
 [-1.02199531]] loss fxn value:  0.01372175424231542 learn rate: 1.5625e-05 iteration: 26873
[[ 2.0013141 ]
 [ 4.04289192]
 [-1.02199552]] loss fxn value:  0.013717943006689291 learn rate: 1.5625e-05 iteration: 26874
[[ 2.00131411]
 [ 4.04289192]
 [-1.02199573]] loss fxn value:  0.013714132829729051 learn rate: 1.5625e-05 iteration: 26875
[[ 2.00131411]
 [ 4.04289192]
 [-1.02199595]] loss fxn value:  0.013710323710261547 learn rate: 1.5625e-05 iteration: 26876
[[ 2.00131411]
 [ 4.04289192]
 [-1.02199616]] loss fxn value:  0.01370651564994546 learn rate: 1.5625e-05 iteration: 26877
[[ 2.00131412]
 [ 4.04289193]
 [-1.02199638]] loss fxn value:  0.013702708647152955 learn rate: 1.5625e-05 iteration: 26878
[[ 2.00131412]
 [ 4.04289193]
 [-1.02199659]] loss fxn value:  0.013698902700574776 learn rate: 1.5625e-05 iteration: 26879
[[ 2.00131412]
 [ 4.04289193]
 [-1.02199681]] loss fxn value:  0.013695097813176557 learn rate: 1.5625e-05 iteration: 26880
[[ 2.00131413]
 [ 4.04289193]
 [-1.02199702]] loss fxn value:  0.013691293980902823 learn rate: 1.5625e-05 iteration: 26881
[[ 2.00131413]
 [ 4.04289193]
 [-1.02199723]] loss fxn value:  0.01368749120551173 learn rate: 1.5625e-05 iteration: 26882
[[ 2.00131413]
 [ 4.04289193]
 [-1.02199745]] loss fxn value:  0.013683689486794258 learn rate: 1.5625e-05 iteration: 26883
[[ 2.00131414]
 [ 4.04289193]
 [-1.02199766]] loss fxn value:  0.013679888822927073 learn rate: 1.5625e-05 iteration: 26884
[[ 2.00131414]
 [ 4.04289193]
 [-1.02199787]] loss fxn value:  0.013676089216780958 learn rate: 1.5625e-05 iteration: 26885
[[ 2.00131414]
 [ 4.04289193]
 [-1.02199809]] loss fxn value:  0.013672290664037781 learn rate: 1.5625e-05 iteration: 26886
[[ 2.00131415]
 [ 4.04289194]
 [-1.0219983 ]] loss fxn value:  0.01366849316725866 learn rate: 1.5625e-05 iteration: 26887
[[ 2.00131415]
 [ 4.04289194]
 [-1.02199851]] loss fxn value:  0.01366469672528428 learn rate: 1.5625e-05 iteration: 26888
[[ 2.00131416]
 [ 4.04289194]
 [-1.02199873]] loss fxn value:  0.013660901337303305 learn rate: 1.5625e-05 iteration: 26889
[[ 2.00131416]
 [ 4.04289194]
 [-1.02199894]] loss fxn value:  0.013657107003748791 learn rate: 1.5625e-05 iteration: 26890
[[ 2.00131416]
 [ 4.04289194]
 [-1.02199916]] loss fxn value:  0.013653313723799314 learn rate: 1.5625e-05 iteration: 26891
[[ 2.00131417]
 [ 4.04289194]
 [-1.02199937]] loss fxn value:  0.013649521497343015 learn rate: 1.5625e-05 iteration: 26892
[[ 2.00131417]
 [ 4.04289194]
 [-1.02199958]] loss fxn value:  0.013645730324430057 learn rate: 1.5625e-05 iteration: 26893
[[ 2.00131417]
 [ 4.04289194]
 [-1.02199979]] loss fxn value:  0.01364194020506736 learn rate: 1.5625e-05 iteration: 26894
[[ 2.00131418]
 [ 4.04289194]
 [-1.02200001]] loss fxn value:  0.013638151137829192 learn rate: 1.5625e-05 iteration: 26895
[[ 2.00131418]
 [ 4.04289194]
 [-1.02200022]] loss fxn value:  0.013634363122768021 learn rate: 1.5625e-05 iteration: 26896
[[ 2.00131418]
 [ 4.04289195]
 [-1.02200043]] loss fxn value:  0.01363057615995016 learn rate: 1.5625e-05 iteration: 26897
[[ 2.00131419]
 [ 4.04289195]
 [-1.02200065]] loss fxn value:  0.013626790249254521 learn rate: 1.5625e-05 iteration: 26898
[[ 2.00131419]
 [ 4.04289195]
 [-1.02200086]] loss fxn value:  0.01362300539025958 learn rate: 1.5625e-05 iteration: 26899
[[ 2.00131419]
 [ 4.04289195]
 [-1.02200107]] loss fxn value:  0.013619221582536896 learn rate: 1.5625e-05 iteration: 26900
[[ 2.0013142 ]
 [ 4.04289195]
 [-1.02200129]] loss fxn value:  0.013615438825634098 learn rate: 1.5625e-05 iteration: 26901
[[ 2.0013142 ]
 [ 4.04289195]
 [-1.0220015 ]] loss fxn value:  0.013611657118582437 learn rate: 1.5625e-05 iteration: 26902
[[ 2.0013142 ]
 [ 4.04289195]
 [-1.02200171]] loss fxn value:  0.013607876462860114 learn rate: 1.5625e-05 iteration: 26903
[[ 2.00131421]
 [ 4.04289195]
 [-1.02200192]] loss fxn value:  0.013604096857026703 learn rate: 1.5625e-05 iteration: 26904
[[ 2.00131421]
 [ 4.04289195]
 [-1.02200214]] loss fxn value:  0.013600318300575905 learn rate: 1.5625e-05 iteration: 26905
[[ 2.00131422]
 [ 4.04289196]
 [-1.02200235]] loss fxn value:  0.01359654079406879 learn rate: 1.5625e-05 iteration: 26906
[[ 2.00131422]
 [ 4.04289196]
 [-1.02200256]] loss fxn value:  0.013592764336081937 learn rate: 1.5625e-05 iteration: 26907
[[ 2.00131422]
 [ 4.04289196]
 [-1.02200277]] loss fxn value:  0.013588988928488832 learn rate: 1.5625e-05 iteration: 26908
[[ 2.00131423]
 [ 4.04289196]
 [-1.02200299]] loss fxn value:  0.013585214568016488 learn rate: 1.5625e-05 iteration: 26909
[[ 2.00131423]
 [ 4.04289196]
 [-1.0220032 ]] loss fxn value:  0.013581441256995381 learn rate: 1.5625e-05 iteration: 26910
[[ 2.00131423]
 [ 4.04289196]
 [-1.02200341]] loss fxn value:  0.01357766899315904 learn rate: 1.5625e-05 iteration: 26911
[[ 2.00131424]
 [ 4.04289196]
 [-1.02200362]] loss fxn value:  0.01357389777686498 learn rate: 1.5625e-05 iteration: 26912
[[ 2.00131424]
 [ 4.04289196]
 [-1.02200383]] loss fxn value:  0.013570127609238505 learn rate: 1.5625e-05 iteration: 26913
[[ 2.00131424]
 [ 4.04289196]
 [-1.02200405]] loss fxn value:  0.013566358488737405 learn rate: 1.5625e-05 iteration: 26914
[[ 2.00131425]
 [ 4.04289197]
 [-1.02200426]] loss fxn value:  0.013562590414445403 learn rate: 1.5625e-05 iteration: 26915
[[ 2.00131425]
 [ 4.04289197]
 [-1.02200447]] loss fxn value:  0.013558823386421887 learn rate: 1.5625e-05 iteration: 26916
[[ 2.00131425]
 [ 4.04289197]
 [-1.02200468]] loss fxn value:  0.013555057405218701 learn rate: 1.5625e-05 iteration: 26917
[[ 2.00131426]
 [ 4.04289197]
 [-1.02200489]] loss fxn value:  0.013551292468713253 learn rate: 1.5625e-05 iteration: 26918
[[ 2.00131426]
 [ 4.04289197]
 [-1.02200511]] loss fxn value:  0.013547528580023116 learn rate: 1.5625e-05 iteration: 26919
[[ 2.00131427]
 [ 4.04289197]
 [-1.02200532]] loss fxn value:  0.013543765735692515 learn rate: 1.5625e-05 iteration: 26920
[[ 2.00131427]
 [ 4.04289197]
 [-1.02200553]] loss fxn value:  0.013540003936247052 learn rate: 1.5625e-05 iteration: 26921
[[ 2.00131427]
 [ 4.04289197]
 [-1.02200574]] loss fxn value:  0.013536243181734587 learn rate: 1.5625e-05 iteration: 26922
[[ 2.00131428]
 [ 4.04289197]
 [-1.02200595]] loss fxn value:  0.013532483473012006 learn rate: 1.5625e-05 iteration: 26923
[[ 2.00131428]
 [ 4.04289198]
 [-1.02200616]] loss fxn value:  0.013528724807798992 learn rate: 1.5625e-05 iteration: 26924
[[ 2.00131428]
 [ 4.04289198]
 [-1.02200637]] loss fxn value:  0.01352496718616417 learn rate: 1.5625e-05 iteration: 26925
[[ 2.00131429]
 [ 4.04289198]
 [-1.02200659]] loss fxn value:  0.01352121060795329 learn rate: 1.5625e-05 iteration: 26926
[[ 2.00131429]
 [ 4.04289198]
 [-1.0220068 ]] loss fxn value:  0.01351745507388714 learn rate: 1.5625e-05 iteration: 26927
[[ 2.00131429]
 [ 4.04289198]
 [-1.02200701]] loss fxn value:  0.013513700582797179 learn rate: 1.5625e-05 iteration: 26928
[[ 2.0013143 ]
 [ 4.04289198]
 [-1.02200722]] loss fxn value:  0.013509947134366821 learn rate: 1.5625e-05 iteration: 26929
[[ 2.0013143 ]
 [ 4.04289198]
 [-1.02200743]] loss fxn value:  0.01350619472851275 learn rate: 1.5625e-05 iteration: 26930
[[ 2.0013143 ]
 [ 4.04289198]
 [-1.02200764]] loss fxn value:  0.01350244336489676 learn rate: 1.5625e-05 iteration: 26931
[[ 2.00131431]
 [ 4.04289198]
 [-1.02200785]] loss fxn value:  0.013498693043404685 learn rate: 1.5625e-05 iteration: 26932
[[ 2.00131431]
 [ 4.04289198]
 [-1.02200806]] loss fxn value:  0.013494943762658647 learn rate: 1.5625e-05 iteration: 26933
[[ 2.00131431]
 [ 4.04289199]
 [-1.02200827]] loss fxn value:  0.013491195523762328 learn rate: 1.5625e-05 iteration: 26934
[[ 2.00131432]
 [ 4.04289199]
 [-1.02200848]] loss fxn value:  0.013487448326021176 learn rate: 1.5625e-05 iteration: 26935
[[ 2.00131432]
 [ 4.04289199]
 [-1.0220087 ]] loss fxn value:  0.013483702169575593 learn rate: 1.5625e-05 iteration: 26936
[[ 2.00131433]
 [ 4.04289199]
 [-1.02200891]] loss fxn value:  0.013479957053461448 learn rate: 1.5625e-05 iteration: 26937
[[ 2.00131433]
 [ 4.04289199]
 [-1.02200912]] loss fxn value:  0.01347621297725491 learn rate: 1.5625e-05 iteration: 26938
[[ 2.00131433]
 [ 4.04289199]
 [-1.02200933]] loss fxn value:  0.01347246994046353 learn rate: 1.5625e-05 iteration: 26939
[[ 2.00131434]
 [ 4.04289199]
 [-1.02200954]] loss fxn value:  0.013468727944522271 learn rate: 1.5625e-05 iteration: 26940
[[ 2.00131434]
 [ 4.04289199]
 [-1.02200975]] loss fxn value:  0.013464986987519875 learn rate: 1.5625e-05 iteration: 26941
[[ 2.00131434]
 [ 4.04289199]
 [-1.02200996]] loss fxn value:  0.013461247068604063 learn rate: 1.5625e-05 iteration: 26942
[[ 2.00131435]
 [ 4.042892  ]
 [-1.02201017]] loss fxn value:  0.013457508189619789 learn rate: 1.5625e-05 iteration: 26943
[[ 2.00131435]
 [ 4.042892  ]
 [-1.02201038]] loss fxn value:  0.01345377034912431 learn rate: 1.5625e-05 iteration: 26944
[[ 2.00131435]
 [ 4.042892  ]
 [-1.02201059]] loss fxn value:  0.01345003354577752 learn rate: 1.5625e-05 iteration: 26945
[[ 2.00131436]
 [ 4.042892  ]
 [-1.0220108 ]] loss fxn value:  0.01344629778100054 learn rate: 1.5625e-05 iteration: 26946
[[ 2.00131436]
 [ 4.042892  ]
 [-1.02201101]] loss fxn value:  0.01344256305431476 learn rate: 1.5625e-05 iteration: 26947
[[ 2.00131436]
 [ 4.042892  ]
 [-1.02201122]] loss fxn value:  0.013438829363802002 learn rate: 1.5625e-05 iteration: 26948
[[ 2.00131437]
 [ 4.042892  ]
 [-1.02201143]] loss fxn value:  0.013435096711501535 learn rate: 1.5625e-05 iteration: 26949
[[ 2.00131437]
 [ 4.042892  ]
 [-1.02201164]] loss fxn value:  0.013431365095352468 learn rate: 1.5625e-05 iteration: 26950
[[ 2.00131437]
 [ 4.042892  ]
 [-1.02201185]] loss fxn value:  0.013427634515925954 learn rate: 1.5625e-05 iteration: 26951
[[ 2.00131438]
 [ 4.04289201]
 [-1.02201206]] loss fxn value:  0.013423904971396358 learn rate: 1.5625e-05 iteration: 26952
[[ 2.00131438]
 [ 4.04289201]
 [-1.02201227]] loss fxn value:  0.013420176465019664 learn rate: 1.5625e-05 iteration: 26953
[[ 2.00131438]
 [ 4.04289201]
 [-1.02201248]] loss fxn value:  0.013416448992466202 learn rate: 1.5625e-05 iteration: 26954
[[ 2.00131439]
 [ 4.04289201]
 [-1.02201269]] loss fxn value:  0.013412722556321017 learn rate: 1.5625e-05 iteration: 26955
[[ 2.00131439]
 [ 4.04289201]
 [-1.0220129 ]] loss fxn value:  0.013408997154080076 learn rate: 1.5625e-05 iteration: 26956
[[ 2.0013144 ]
 [ 4.04289201]
 [-1.02201311]] loss fxn value:  0.013405272787204572 learn rate: 1.5625e-05 iteration: 26957
[[ 2.0013144 ]
 [ 4.04289201]
 [-1.02201332]] loss fxn value:  0.013401549454773619 learn rate: 1.5625e-05 iteration: 26958
[[ 2.0013144 ]
 [ 4.04289201]
 [-1.02201353]] loss fxn value:  0.013397827156310913 learn rate: 1.5625e-05 iteration: 26959
[[ 2.00131441]
 [ 4.04289201]
 [-1.02201373]] loss fxn value:  0.013394105891873542 learn rate: 1.5625e-05 iteration: 26960
[[ 2.00131441]
 [ 4.04289201]
 [-1.02201394]] loss fxn value:  0.013390385660916585 learn rate: 1.5625e-05 iteration: 26961
[[ 2.00131441]
 [ 4.04289202]
 [-1.02201415]] loss fxn value:  0.013386666463954111 learn rate: 1.5625e-05 iteration: 26962
[[ 2.00131442]
 [ 4.04289202]
 [-1.02201436]] loss fxn value:  0.013382948298681882 learn rate: 1.5625e-05 iteration: 26963
[[ 2.00131442]
 [ 4.04289202]
 [-1.02201457]] loss fxn value:  0.013379231166984919 learn rate: 1.5625e-05 iteration: 26964
[[ 2.00131442]
 [ 4.04289202]
 [-1.02201478]] loss fxn value:  0.01337551506834916 learn rate: 1.5625e-05 iteration: 26965
[[ 2.00131443]
 [ 4.04289202]
 [-1.02201499]] loss fxn value:  0.013371800000487365 learn rate: 1.5625e-05 iteration: 26966
[[ 2.00131443]
 [ 4.04289202]
 [-1.0220152 ]] loss fxn value:  0.013368085965282253 learn rate: 1.5625e-05 iteration: 26967
[[ 2.00131443]
 [ 4.04289202]
 [-1.02201541]] loss fxn value:  0.0133643729612957 learn rate: 1.5625e-05 iteration: 26968
[[ 2.00131444]
 [ 4.04289202]
 [-1.02201562]] loss fxn value:  0.013360660988597185 learn rate: 1.5625e-05 iteration: 26969
[[ 2.00131444]
 [ 4.04289202]
 [-1.02201582]] loss fxn value:  0.013356950047600447 learn rate: 1.5625e-05 iteration: 26970
[[ 2.00131444]
 [ 4.04289203]
 [-1.02201603]] loss fxn value:  0.013353240136896764 learn rate: 1.5625e-05 iteration: 26971
[[ 2.00131445]
 [ 4.04289203]
 [-1.02201624]] loss fxn value:  0.013349531256609528 learn rate: 1.5625e-05 iteration: 26972
[[ 2.00131445]
 [ 4.04289203]
 [-1.02201645]] loss fxn value:  0.01334582340661996 learn rate: 1.5625e-05 iteration: 26973
[[ 2.00131445]
 [ 4.04289203]
 [-1.02201666]] loss fxn value:  0.013342116585625723 learn rate: 1.5625e-05 iteration: 26974
[[ 2.00131446]
 [ 4.04289203]
 [-1.02201687]] loss fxn value:  0.013338410794531559 learn rate: 1.5625e-05 iteration: 26975
[[ 2.00131446]
 [ 4.04289203]
 [-1.02201708]] loss fxn value:  0.013334706033344386 learn rate: 1.5625e-05 iteration: 26976
[[ 2.00131446]
 [ 4.04289203]
 [-1.02201728]] loss fxn value:  0.013331002301117084 learn rate: 1.5625e-05 iteration: 26977
[[ 2.00131447]
 [ 4.04289203]
 [-1.02201749]] loss fxn value:  0.013327299597401893 learn rate: 1.5625e-05 iteration: 26978
[[ 2.00131447]
 [ 4.04289203]
 [-1.0220177 ]] loss fxn value:  0.013323597921801215 learn rate: 1.5625e-05 iteration: 26979
[[ 2.00131448]
 [ 4.04289203]
 [-1.02201791]] loss fxn value:  0.0133198972746818 learn rate: 1.5625e-05 iteration: 26980
[[ 2.00131448]
 [ 4.04289204]
 [-1.02201812]] loss fxn value:  0.013316197656160121 learn rate: 1.5625e-05 iteration: 26981
[[ 2.00131448]
 [ 4.04289204]
 [-1.02201832]] loss fxn value:  0.013312499063299087 learn rate: 1.5625e-05 iteration: 26982
[[ 2.00131449]
 [ 4.04289204]
 [-1.02201853]] loss fxn value:  0.013308801498638195 learn rate: 1.5625e-05 iteration: 26983
[[ 2.00131449]
 [ 4.04289204]
 [-1.02201874]] loss fxn value:  0.013305104962491722 learn rate: 1.5625e-05 iteration: 26984
[[ 2.00131449]
 [ 4.04289204]
 [-1.02201895]] loss fxn value:  0.013301409451610605 learn rate: 1.5625e-05 iteration: 26985
[[ 2.0013145 ]
 [ 4.04289204]
 [-1.02201916]] loss fxn value:  0.013297714967537054 learn rate: 1.5625e-05 iteration: 26986
[[ 2.0013145 ]
 [ 4.04289204]
 [-1.02201936]] loss fxn value:  0.013294021509157304 learn rate: 1.5625e-05 iteration: 26987
[[ 2.0013145 ]
 [ 4.04289204]
 [-1.02201957]] loss fxn value:  0.013290329076671149 learn rate: 1.5625e-05 iteration: 26988
[[ 2.00131451]
 [ 4.04289204]
 [-1.02201978]] loss fxn value:  0.01328663766942873 learn rate: 1.5625e-05 iteration: 26989
[[ 2.00131451]
 [ 4.04289205]
 [-1.02201999]] loss fxn value:  0.01328294728808452 learn rate: 1.5625e-05 iteration: 26990
[[ 2.00131451]
 [ 4.04289205]
 [-1.02202019]] loss fxn value:  0.013279257932069674 learn rate: 1.5625e-05 iteration: 26991
[[ 2.00131452]
 [ 4.04289205]
 [-1.0220204 ]] loss fxn value:  0.013275569600463298 learn rate: 1.5625e-05 iteration: 26992
[[ 2.00131452]
 [ 4.04289205]
 [-1.02202061]] loss fxn value:  0.013271882293226768 learn rate: 1.5625e-05 iteration: 26993
[[ 2.00131452]
 [ 4.04289205]
 [-1.02202082]] loss fxn value:  0.013268196010098276 learn rate: 1.5625e-05 iteration: 26994
[[ 2.00131453]
 [ 4.04289205]
 [-1.02202102]] loss fxn value:  0.013264510750380962 learn rate: 1.5625e-05 iteration: 26995
[[ 2.00131453]
 [ 4.04289205]
 [-1.02202123]] loss fxn value:  0.013260826515204749 learn rate: 1.5625e-05 iteration: 26996
[[ 2.00131453]
 [ 4.04289205]
 [-1.02202144]] loss fxn value:  0.013257143302537277 learn rate: 1.5625e-05 iteration: 26997
[[ 2.00131454]
 [ 4.04289205]
 [-1.02202165]] loss fxn value:  0.013253461113532398 learn rate: 1.5625e-05 iteration: 26998
[[ 2.00131454]
 [ 4.04289205]
 [-1.02202185]] loss fxn value:  0.013249779946515272 learn rate: 1.5625e-05 iteration: 26999
[[ 2.00131454]
 [ 4.04289206]
 [-1.02202206]] loss fxn value:  0.01324609980318005 learn rate: 1.5625e-05 iteration: 27000
[[ 2.00131455]
 [ 4.04289206]
 [-1.02202227]] loss fxn value:  0.01324242068096561 learn rate: 1.5625e-05 iteration: 27001
[[ 2.00131455]
 [ 4.04289206]
 [-1.02202247]] loss fxn value:  0.013238742581009646 learn rate: 1.5625e-05 iteration: 27002
[[ 2.00131455]
 [ 4.04289206]
 [-1.02202268]] loss fxn value:  0.0132350655022624 learn rate: 1.5625e-05 iteration: 27003
[[ 2.00131456]
 [ 4.04289206]
 [-1.02202289]] loss fxn value:  0.013231389445228711 learn rate: 1.5625e-05 iteration: 27004
[[ 2.00131456]
 [ 4.04289206]
 [-1.02202309]] loss fxn value:  0.013227714408953676 learn rate: 1.5625e-05 iteration: 27005
[[ 2.00131457]
 [ 4.04289206]
 [-1.0220233 ]] loss fxn value:  0.013224040393542235 learn rate: 1.5625e-05 iteration: 27006
[[ 2.00131457]
 [ 4.04289206]
 [-1.02202351]] loss fxn value:  0.013220367398946532 learn rate: 1.5625e-05 iteration: 27007
[[ 2.00131457]
 [ 4.04289206]
 [-1.02202371]] loss fxn value:  0.013216695424126889 learn rate: 1.5625e-05 iteration: 27008
[[ 2.00131458]
 [ 4.04289207]
 [-1.02202392]] loss fxn value:  0.013213024469259175 learn rate: 1.5625e-05 iteration: 27009
[[ 2.00131458]
 [ 4.04289207]
 [-1.02202413]] loss fxn value:  0.013209354533357635 learn rate: 1.5625e-05 iteration: 27010
[[ 2.00131458]
 [ 4.04289207]
 [-1.02202433]] loss fxn value:  0.013205685617871934 learn rate: 1.5625e-05 iteration: 27011
[[ 2.00131459]
 [ 4.04289207]
 [-1.02202454]] loss fxn value:  0.013202017721255243 learn rate: 1.5625e-05 iteration: 27012
[[ 2.00131459]
 [ 4.04289207]
 [-1.02202475]] loss fxn value:  0.013198350842752457 learn rate: 1.5625e-05 iteration: 27013
[[ 2.00131459]
 [ 4.04289207]
 [-1.02202495]] loss fxn value:  0.013194684983272932 learn rate: 1.5625e-05 iteration: 27014
[[ 2.0013146 ]
 [ 4.04289207]
 [-1.02202516]] loss fxn value:  0.013191020142262515 learn rate: 1.5625e-05 iteration: 27015
[[ 2.0013146 ]
 [ 4.04289207]
 [-1.02202536]] loss fxn value:  0.013187356318364098 learn rate: 1.5625e-05 iteration: 27016
[[ 2.0013146 ]
 [ 4.04289207]
 [-1.02202557]] loss fxn value:  0.01318369351266521 learn rate: 1.5625e-05 iteration: 27017
[[ 2.00131461]
 [ 4.04289207]
 [-1.02202578]] loss fxn value:  0.013180031723992694 learn rate: 1.5625e-05 iteration: 27018
[[ 2.00131461]
 [ 4.04289208]
 [-1.02202598]] loss fxn value:  0.013176370953029566 learn rate: 1.5625e-05 iteration: 27019
[[ 2.00131461]
 [ 4.04289208]
 [-1.02202619]] loss fxn value:  0.013172711197790475 learn rate: 1.5625e-05 iteration: 27020
[[ 2.00131462]
 [ 4.04289208]
 [-1.02202639]] loss fxn value:  0.013169052459784473 learn rate: 1.5625e-05 iteration: 27021
[[ 2.00131462]
 [ 4.04289208]
 [-1.0220266 ]] loss fxn value:  0.013165394737978803 learn rate: 1.5625e-05 iteration: 27022
[[ 2.00131462]
 [ 4.04289208]
 [-1.0220268 ]] loss fxn value:  0.013161738031528121 learn rate: 1.5625e-05 iteration: 27023
[[ 2.00131463]
 [ 4.04289208]
 [-1.02202701]] loss fxn value:  0.013158082341277771 learn rate: 1.5625e-05 iteration: 27024
[[ 2.00131463]
 [ 4.04289208]
 [-1.02202722]] loss fxn value:  0.013154427666470342 learn rate: 1.5625e-05 iteration: 27025
[[ 2.00131463]
 [ 4.04289208]
 [-1.02202742]] loss fxn value:  0.013150774006927655 learn rate: 1.5625e-05 iteration: 27026
[[ 2.00131464]
 [ 4.04289208]
 [-1.02202763]] loss fxn value:  0.013147121361345068 learn rate: 1.5625e-05 iteration: 27027
[[ 2.00131464]
 [ 4.04289209]
 [-1.02202783]] loss fxn value:  0.013143469730776958 learn rate: 1.5625e-05 iteration: 27028
[[ 2.00131464]
 [ 4.04289209]
 [-1.02202804]] loss fxn value:  0.0131398191144763 learn rate: 1.5625e-05 iteration: 27029
[[ 2.00131465]
 [ 4.04289209]
 [-1.02202824]] loss fxn value:  0.01313616951176438 learn rate: 1.5625e-05 iteration: 27030
[[ 2.00131465]
 [ 4.04289209]
 [-1.02202845]] loss fxn value:  0.013132520923045721 learn rate: 1.5625e-05 iteration: 27031
[[ 2.00131465]
 [ 4.04289209]
 [-1.02202865]] loss fxn value:  0.013128873348324936 learn rate: 1.5625e-05 iteration: 27032
[[ 2.00131466]
 [ 4.04289209]
 [-1.02202886]] loss fxn value:  0.013125226785700841 learn rate: 1.5625e-05 iteration: 27033
[[ 2.00131466]
 [ 4.04289209]
 [-1.02202906]] loss fxn value:  0.013121581237100855 learn rate: 1.5625e-05 iteration: 27034
[[ 2.00131466]
 [ 4.04289209]
 [-1.02202927]] loss fxn value:  0.013117936699704355 learn rate: 1.5625e-05 iteration: 27035
[[ 2.00131467]
 [ 4.04289209]
 [-1.02202947]] loss fxn value:  0.013114293175413379 learn rate: 1.5625e-05 iteration: 27036
[[ 2.00131467]
 [ 4.04289209]
 [-1.02202968]] loss fxn value:  0.013110650662813727 learn rate: 1.5625e-05 iteration: 27037
[[ 2.00131468]
 [ 4.0428921 ]
 [-1.02202988]] loss fxn value:  0.01310700916186532 learn rate: 1.5625e-05 iteration: 27038
[[ 2.00131468]
 [ 4.0428921 ]
 [-1.02203009]] loss fxn value:  0.013103368672750946 learn rate: 1.5625e-05 iteration: 27039
[[ 2.00131468]
 [ 4.0428921 ]
 [-1.02203029]] loss fxn value:  0.013099729194723587 learn rate: 1.5625e-05 iteration: 27040
[[ 2.00131469]
 [ 4.0428921 ]
 [-1.0220305 ]] loss fxn value:  0.013096090727675683 learn rate: 1.5625e-05 iteration: 27041
[[ 2.00131469]
 [ 4.0428921 ]
 [-1.0220307 ]] loss fxn value:  0.013092453270798513 learn rate: 1.5625e-05 iteration: 27042
[[ 2.00131469]
 [ 4.0428921 ]
 [-1.02203091]] loss fxn value:  0.013088816824343489 learn rate: 1.5625e-05 iteration: 27043
[[ 2.0013147 ]
 [ 4.0428921 ]
 [-1.02203111]] loss fxn value:  0.013085181387716383 learn rate: 1.5625e-05 iteration: 27044
[[ 2.0013147 ]
 [ 4.0428921 ]
 [-1.02203132]] loss fxn value:  0.013081546960592836 learn rate: 1.5625e-05 iteration: 27045
[[ 2.0013147 ]
 [ 4.0428921 ]
 [-1.02203152]] loss fxn value:  0.01307791354376342 learn rate: 1.5625e-05 iteration: 27046
[[ 2.00131471]
 [ 4.0428921 ]
 [-1.02203172]] loss fxn value:  0.013074281135914266 learn rate: 1.5625e-05 iteration: 27047
[[ 2.00131471]
 [ 4.04289211]
 [-1.02203193]] loss fxn value:  0.01307064973657138 learn rate: 1.5625e-05 iteration: 27048
[[ 2.00131471]
 [ 4.04289211]
 [-1.02203213]] loss fxn value:  0.01306701934718904 learn rate: 1.5625e-05 iteration: 27049
[[ 2.00131472]
 [ 4.04289211]
 [-1.02203234]] loss fxn value:  0.013063389964337702 learn rate: 1.5625e-05 iteration: 27050
[[ 2.00131472]
 [ 4.04289211]
 [-1.02203254]] loss fxn value:  0.013059761590627795 learn rate: 1.5625e-05 iteration: 27051
[[ 2.00131472]
 [ 4.04289211]
 [-1.02203274]] loss fxn value:  0.013056134224448485 learn rate: 1.5625e-05 iteration: 27052
[[ 2.00131473]
 [ 4.04289211]
 [-1.02203295]] loss fxn value:  0.013052507864982965 learn rate: 1.5625e-05 iteration: 27053
[[ 2.00131473]
 [ 4.04289211]
 [-1.02203315]] loss fxn value:  0.01304888251313598 learn rate: 1.5625e-05 iteration: 27054
[[ 2.00131473]
 [ 4.04289211]
 [-1.02203336]] loss fxn value:  0.013045258168945298 learn rate: 1.5625e-05 iteration: 27055
[[ 2.00131474]
 [ 4.04289211]
 [-1.02203356]] loss fxn value:  0.013041634830958954 learn rate: 1.5625e-05 iteration: 27056
[[ 2.00131474]
 [ 4.04289212]
 [-1.02203376]] loss fxn value:  0.013038012499653244 learn rate: 1.5625e-05 iteration: 27057
[[ 2.00131474]
 [ 4.04289212]
 [-1.02203397]] loss fxn value:  0.013034391173692674 learn rate: 1.5625e-05 iteration: 27058
[[ 2.00131475]
 [ 4.04289212]
 [-1.02203417]] loss fxn value:  0.01303077085445282 learn rate: 1.5625e-05 iteration: 27059
[[ 2.00131475]
 [ 4.04289212]
 [-1.02203437]] loss fxn value:  0.013027151540558106 learn rate: 1.5625e-05 iteration: 27060
[[ 2.00131475]
 [ 4.04289212]
 [-1.02203458]] loss fxn value:  0.013023533231956064 learn rate: 1.5625e-05 iteration: 27061
[[ 2.00131476]
 [ 4.04289212]
 [-1.02203478]] loss fxn value:  0.013019915927825271 learn rate: 1.5625e-05 iteration: 27062
[[ 2.00131476]
 [ 4.04289212]
 [-1.02203499]] loss fxn value:  0.01301629962852786 learn rate: 1.5625e-05 iteration: 27063
[[ 2.00131476]
 [ 4.04289212]
 [-1.02203519]] loss fxn value:  0.013012684334184918 learn rate: 1.5625e-05 iteration: 27064
[[ 2.00131477]
 [ 4.04289212]
 [-1.02203539]] loss fxn value:  0.013009070044225291 learn rate: 1.5625e-05 iteration: 27065
[[ 2.00131477]
 [ 4.04289212]
 [-1.0220356 ]] loss fxn value:  0.013005456756851887 learn rate: 1.5625e-05 iteration: 27066
[[ 2.00131477]
 [ 4.04289213]
 [-1.0220358 ]] loss fxn value:  0.013001844474439875 learn rate: 1.5625e-05 iteration: 27067
[[ 2.00131478]
 [ 4.04289213]
 [-1.022036  ]] loss fxn value:  0.012998233195013989 learn rate: 1.5625e-05 iteration: 27068
[[ 2.00131478]
 [ 4.04289213]
 [-1.0220362 ]] loss fxn value:  0.01299462291729351 learn rate: 1.5625e-05 iteration: 27069
[[ 2.00131478]
 [ 4.04289213]
 [-1.02203641]] loss fxn value:  0.012991013643565676 learn rate: 1.5625e-05 iteration: 27070
[[ 2.00131479]
 [ 4.04289213]
 [-1.02203661]] loss fxn value:  0.012987405372516614 learn rate: 1.5625e-05 iteration: 27071
[[ 2.00131479]
 [ 4.04289213]
 [-1.02203681]] loss fxn value:  0.012983798102549337 learn rate: 1.5625e-05 iteration: 27072
[[ 2.00131479]
 [ 4.04289213]
 [-1.02203702]] loss fxn value:  0.012980191835801135 learn rate: 1.5625e-05 iteration: 27073
[[ 2.0013148 ]
 [ 4.04289213]
 [-1.02203722]] loss fxn value:  0.01297658657022496 learn rate: 1.5625e-05 iteration: 27074
[[ 2.0013148 ]
 [ 4.04289213]
 [-1.02203742]] loss fxn value:  0.012972982305939594 learn rate: 1.5625e-05 iteration: 27075
[[ 2.0013148 ]
 [ 4.04289213]
 [-1.02203762]] loss fxn value:  0.012969379041879127 learn rate: 1.5625e-05 iteration: 27076
[[ 2.00131481]
 [ 4.04289214]
 [-1.02203783]] loss fxn value:  0.012965776780132993 learn rate: 1.5625e-05 iteration: 27077
[[ 2.00131481]
 [ 4.04289214]
 [-1.02203803]] loss fxn value:  0.01296217551810461 learn rate: 1.5625e-05 iteration: 27078
[[ 2.00131481]
 [ 4.04289214]
 [-1.02203823]] loss fxn value:  0.012958575256117173 learn rate: 1.5625e-05 iteration: 27079
[[ 2.00131482]
 [ 4.04289214]
 [-1.02203843]] loss fxn value:  0.012954975994302162 learn rate: 1.5625e-05 iteration: 27080
[[ 2.00131482]
 [ 4.04289214]
 [-1.02203864]] loss fxn value:  0.012951377733463686 learn rate: 1.5625e-05 iteration: 27081
[[ 2.00131482]
 [ 4.04289214]
 [-1.02203884]] loss fxn value:  0.01294778047000787 learn rate: 1.5625e-05 iteration: 27082
[[ 2.00131483]
 [ 4.04289214]
 [-1.02203904]] loss fxn value:  0.012944184207109376 learn rate: 1.5625e-05 iteration: 27083
[[ 2.00131483]
 [ 4.04289214]
 [-1.02203924]] loss fxn value:  0.012940588943045511 learn rate: 1.5625e-05 iteration: 27084
[[ 2.00131483]
 [ 4.04289214]
 [-1.02203945]] loss fxn value:  0.012936994676606486 learn rate: 1.5625e-05 iteration: 27085
[[ 2.00131484]
 [ 4.04289215]
 [-1.02203965]] loss fxn value:  0.01293340140917565 learn rate: 1.5625e-05 iteration: 27086
[[ 2.00131484]
 [ 4.04289215]
 [-1.02203985]] loss fxn value:  0.01292980913930796 learn rate: 1.5625e-05 iteration: 27087
[[ 2.00131484]
 [ 4.04289215]
 [-1.02204005]] loss fxn value:  0.012926217867548329 learn rate: 1.5625e-05 iteration: 27088
[[ 2.00131485]
 [ 4.04289215]
 [-1.02204025]] loss fxn value:  0.012922627593885223 learn rate: 1.5625e-05 iteration: 27089
[[ 2.00131485]
 [ 4.04289215]
 [-1.02204046]] loss fxn value:  0.012919038316337908 learn rate: 1.5625e-05 iteration: 27090
[[ 2.00131485]
 [ 4.04289215]
 [-1.02204066]] loss fxn value:  0.012915450036041767 learn rate: 1.5625e-05 iteration: 27091
[[ 2.00131486]
 [ 4.04289215]
 [-1.02204086]] loss fxn value:  0.012911862752423339 learn rate: 1.5625e-05 iteration: 27092
[[ 2.00131486]
 [ 4.04289215]
 [-1.02204106]] loss fxn value:  0.012908276465496471 learn rate: 1.5625e-05 iteration: 27093
[[ 2.00131486]
 [ 4.04289215]
 [-1.02204126]] loss fxn value:  0.012904691174359578 learn rate: 1.5625e-05 iteration: 27094
[[ 2.00131487]
 [ 4.04289215]
 [-1.02204146]] loss fxn value:  0.01290110687854098 learn rate: 1.5625e-05 iteration: 27095
[[ 2.00131487]
 [ 4.04289216]
 [-1.02204167]] loss fxn value:  0.012897523579440174 learn rate: 1.5625e-05 iteration: 27096
[[ 2.00131487]
 [ 4.04289216]
 [-1.02204187]] loss fxn value:  0.012893941274772234 learn rate: 1.5625e-05 iteration: 27097
[[ 2.00131488]
 [ 4.04289216]
 [-1.02204207]] loss fxn value:  0.012890359965453436 learn rate: 1.5625e-05 iteration: 27098
[[ 2.00131488]
 [ 4.04289216]
 [-1.02204227]] loss fxn value:  0.012886779650960481 learn rate: 1.5625e-05 iteration: 27099
[[ 2.00131489]
 [ 4.04289216]
 [-1.02204247]] loss fxn value:  0.012883200330914238 learn rate: 1.5625e-05 iteration: 27100
[[ 2.00131489]
 [ 4.04289216]
 [-1.02204267]] loss fxn value:  0.012879622004382271 learn rate: 1.5625e-05 iteration: 27101
[[ 2.00131489]
 [ 4.04289216]
 [-1.02204287]] loss fxn value:  0.012876044671811486 learn rate: 1.5625e-05 iteration: 27102
[[ 2.0013149 ]
 [ 4.04289216]
 [-1.02204308]] loss fxn value:  0.012872468333735267 learn rate: 1.5625e-05 iteration: 27103
[[ 2.0013149 ]
 [ 4.04289216]
 [-1.02204328]] loss fxn value:  0.012868892987680423 learn rate: 1.5625e-05 iteration: 27104
[[ 2.0013149 ]
 [ 4.04289216]
 [-1.02204348]] loss fxn value:  0.012865318636148688 learn rate: 1.5625e-05 iteration: 27105
[[ 2.00131491]
 [ 4.04289217]
 [-1.02204368]] loss fxn value:  0.012861745275807674 learn rate: 1.5625e-05 iteration: 27106
[[ 2.00131491]
 [ 4.04289217]
 [-1.02204388]] loss fxn value:  0.01285817290903025 learn rate: 1.5625e-05 iteration: 27107
[[ 2.00131491]
 [ 4.04289217]
 [-1.02204408]] loss fxn value:  0.012854601534416915 learn rate: 1.5625e-05 iteration: 27108
[[ 2.00131492]
 [ 4.04289217]
 [-1.02204428]] loss fxn value:  0.012851031151387284 learn rate: 1.5625e-05 iteration: 27109
[[ 2.00131492]
 [ 4.04289217]
 [-1.02204448]] loss fxn value:  0.012847461760185848 learn rate: 1.5625e-05 iteration: 27110
[[ 2.00131492]
 [ 4.04289217]
 [-1.02204468]] loss fxn value:  0.012843893361096028 learn rate: 1.5625e-05 iteration: 27111
[[ 2.00131493]
 [ 4.04289217]
 [-1.02204488]] loss fxn value:  0.012840325952254423 learn rate: 1.5625e-05 iteration: 27112
[[ 2.00131493]
 [ 4.04289217]
 [-1.02204508]] loss fxn value:  0.012836759534788638 learn rate: 1.5625e-05 iteration: 27113
[[ 2.00131493]
 [ 4.04289217]
 [-1.02204528]] loss fxn value:  0.012833194108006433 learn rate: 1.5625e-05 iteration: 27114
[[ 2.00131494]
 [ 4.04289217]
 [-1.02204548]] loss fxn value:  0.012829629670651016 learn rate: 1.5625e-05 iteration: 27115
[[ 2.00131494]
 [ 4.04289218]
 [-1.02204569]] loss fxn value:  0.012826066224164274 learn rate: 1.5625e-05 iteration: 27116
[[ 2.00131494]
 [ 4.04289218]
 [-1.02204589]] loss fxn value:  0.01282250376699477 learn rate: 1.5625e-05 iteration: 27117
[[ 2.00131495]
 [ 4.04289218]
 [-1.02204609]] loss fxn value:  0.012818942298859076 learn rate: 1.5625e-05 iteration: 27118
[[ 2.00131495]
 [ 4.04289218]
 [-1.02204629]] loss fxn value:  0.012815381820618693 learn rate: 1.5625e-05 iteration: 27119
[[ 2.00131495]
 [ 4.04289218]
 [-1.02204649]] loss fxn value:  0.012811822331297953 learn rate: 1.5625e-05 iteration: 27120
[[ 2.00131496]
 [ 4.04289218]
 [-1.02204669]] loss fxn value:  0.012808263830501567 learn rate: 1.5625e-05 iteration: 27121
[[ 2.00131496]
 [ 4.04289218]
 [-1.02204689]] loss fxn value:  0.012804706318267309 learn rate: 1.5625e-05 iteration: 27122
[[ 2.00131496]
 [ 4.04289218]
 [-1.02204709]] loss fxn value:  0.01280114979355781 learn rate: 1.5625e-05 iteration: 27123
[[ 2.00131497]
 [ 4.04289218]
 [-1.02204729]] loss fxn value:  0.012797594257917584 learn rate: 1.5625e-05 iteration: 27124
[[ 2.00131497]
 [ 4.04289218]
 [-1.02204749]] loss fxn value:  0.012794039707950244 learn rate: 1.5625e-05 iteration: 27125
[[ 2.00131497]
 [ 4.04289219]
 [-1.02204769]] loss fxn value:  0.012790486146088048 learn rate: 1.5625e-05 iteration: 27126
[[ 2.00131498]
 [ 4.04289219]
 [-1.02204789]] loss fxn value:  0.012786933571878623 learn rate: 1.5625e-05 iteration: 27127
[[ 2.00131498]
 [ 4.04289219]
 [-1.02204809]] loss fxn value:  0.012783381983339778 learn rate: 1.5625e-05 iteration: 27128
[[ 2.00131498]
 [ 4.04289219]
 [-1.02204829]] loss fxn value:  0.012779831382570179 learn rate: 1.5625e-05 iteration: 27129
[[ 2.00131499]
 [ 4.04289219]
 [-1.02204849]] loss fxn value:  0.012776281766933163 learn rate: 1.5625e-05 iteration: 27130
[[ 2.00131499]
 [ 4.04289219]
 [-1.02204869]] loss fxn value:  0.012772733138158346 learn rate: 1.5625e-05 iteration: 27131
[[ 2.00131499]
 [ 4.04289219]
 [-1.02204888]] loss fxn value:  0.01276918549366384 learn rate: 1.5625e-05 iteration: 27132
[[ 2.001315  ]
 [ 4.04289219]
 [-1.02204908]] loss fxn value:  0.012765638835574545 learn rate: 1.5625e-05 iteration: 27133
[[ 2.001315  ]
 [ 4.04289219]
 [-1.02204928]] loss fxn value:  0.012762093162708075 learn rate: 1.5625e-05 iteration: 27134
[[ 2.001315  ]
 [ 4.04289219]
 [-1.02204948]] loss fxn value:  0.012758548474252236 learn rate: 1.5625e-05 iteration: 27135
[[ 2.00131501]
 [ 4.0428922 ]
 [-1.02204968]] loss fxn value:  0.012755004769769356 learn rate: 1.5625e-05 iteration: 27136
[[ 2.00131501]
 [ 4.0428922 ]
 [-1.02204988]] loss fxn value:  0.01275146205023049 learn rate: 1.5625e-05 iteration: 27137
[[ 2.00131501]
 [ 4.0428922 ]
 [-1.02205008]] loss fxn value:  0.012747920315069099 learn rate: 1.5625e-05 iteration: 27138
[[ 2.00131502]
 [ 4.0428922 ]
 [-1.02205028]] loss fxn value:  0.012744379562923455 learn rate: 1.5625e-05 iteration: 27139
[[ 2.00131502]
 [ 4.0428922 ]
 [-1.02205048]] loss fxn value:  0.01274083979435779 learn rate: 1.5625e-05 iteration: 27140
[[ 2.00131502]
 [ 4.0428922 ]
 [-1.02205068]] loss fxn value:  0.012737301009257936 learn rate: 1.5625e-05 iteration: 27141
[[ 2.00131503]
 [ 4.0428922 ]
 [-1.02205088]] loss fxn value:  0.012733763206776235 learn rate: 1.5625e-05 iteration: 27142
[[ 2.00131503]
 [ 4.0428922 ]
 [-1.02205108]] loss fxn value:  0.012730226386420237 learn rate: 1.5625e-05 iteration: 27143
[[ 2.00131503]
 [ 4.0428922 ]
 [-1.02205127]] loss fxn value:  0.012726690549163306 learn rate: 1.5625e-05 iteration: 27144
[[ 2.00131504]
 [ 4.04289221]
 [-1.02205147]] loss fxn value:  0.012723155694526835 learn rate: 1.5625e-05 iteration: 27145
[[ 2.00131504]
 [ 4.04289221]
 [-1.02205167]] loss fxn value:  0.01271962182011173 learn rate: 1.5625e-05 iteration: 27146
[[ 2.00131504]
 [ 4.04289221]
 [-1.02205187]] loss fxn value:  0.012716088928459796 learn rate: 1.5625e-05 iteration: 27147
[[ 2.00131505]
 [ 4.04289221]
 [-1.02205207]] loss fxn value:  0.012712557018333868 learn rate: 1.5625e-05 iteration: 27148
[[ 2.00131505]
 [ 4.04289221]
 [-1.02205227]] loss fxn value:  0.012709026088183651 learn rate: 1.5625e-05 iteration: 27149
[[ 2.00131505]
 [ 4.04289221]
 [-1.02205247]] loss fxn value:  0.012705496138744941 learn rate: 1.5625e-05 iteration: 27150
[[ 2.00131506]
 [ 4.04289221]
 [-1.02205267]] loss fxn value:  0.012701967171131505 learn rate: 1.5625e-05 iteration: 27151
[[ 2.00131506]
 [ 4.04289221]
 [-1.02205286]] loss fxn value:  0.01269843918228285 learn rate: 1.5625e-05 iteration: 27152
[[ 2.00131506]
 [ 4.04289221]
 [-1.02205306]] loss fxn value:  0.012694912173500144 learn rate: 1.5625e-05 iteration: 27153
[[ 2.00131507]
 [ 4.04289221]
 [-1.02205326]] loss fxn value:  0.012691386145426638 learn rate: 1.5625e-05 iteration: 27154
[[ 2.00131507]
 [ 4.04289222]
 [-1.02205346]] loss fxn value:  0.012687861094910435 learn rate: 1.5625e-05 iteration: 27155
[[ 2.00131507]
 [ 4.04289222]
 [-1.02205366]] loss fxn value:  0.012684337024334478 learn rate: 1.5625e-05 iteration: 27156
[[ 2.00131507]
 [ 4.04289222]
 [-1.02205386]] loss fxn value:  0.012680813933591521 learn rate: 1.5625e-05 iteration: 27157
[[ 2.00131508]
 [ 4.04289222]
 [-1.02205405]] loss fxn value:  0.012677291820486875 learn rate: 1.5625e-05 iteration: 27158
[[ 2.00131508]
 [ 4.04289222]
 [-1.02205425]] loss fxn value:  0.012673770684908681 learn rate: 1.5625e-05 iteration: 27159
[[ 2.00131508]
 [ 4.04289222]
 [-1.02205445]] loss fxn value:  0.012670250528851523 learn rate: 1.5625e-05 iteration: 27160
[[ 2.00131509]
 [ 4.04289222]
 [-1.02205465]] loss fxn value:  0.012666731349380608 learn rate: 1.5625e-05 iteration: 27161
[[ 2.00131509]
 [ 4.04289222]
 [-1.02205485]] loss fxn value:  0.01266321314803584 learn rate: 1.5625e-05 iteration: 27162
[[ 2.00131509]
 [ 4.04289222]
 [-1.02205504]] loss fxn value:  0.012659695923400719 learn rate: 1.5625e-05 iteration: 27163
[[ 2.0013151 ]
 [ 4.04289222]
 [-1.02205524]] loss fxn value:  0.01265617967632059 learn rate: 1.5625e-05 iteration: 27164
[[ 2.0013151 ]
 [ 4.04289223]
 [-1.02205544]] loss fxn value:  0.012652664405462272 learn rate: 1.5625e-05 iteration: 27165
[[ 2.0013151 ]
 [ 4.04289223]
 [-1.02205564]] loss fxn value:  0.012649150110871308 learn rate: 1.5625e-05 iteration: 27166
[[ 2.00131511]
 [ 4.04289223]
 [-1.02205583]] loss fxn value:  0.012645636792052089 learn rate: 1.5625e-05 iteration: 27167
[[ 2.00131511]
 [ 4.04289223]
 [-1.02205603]] loss fxn value:  0.01264212444994021 learn rate: 1.5625e-05 iteration: 27168
[[ 2.00131511]
 [ 4.04289223]
 [-1.02205623]] loss fxn value:  0.012638613082676872 learn rate: 1.5625e-05 iteration: 27169
[[ 2.00131512]
 [ 4.04289223]
 [-1.02205643]] loss fxn value:  0.012635102691699351 learn rate: 1.5625e-05 iteration: 27170
[[ 2.00131512]
 [ 4.04289223]
 [-1.02205662]] loss fxn value:  0.012631593274573085 learn rate: 1.5625e-05 iteration: 27171
[[ 2.00131512]
 [ 4.04289223]
 [-1.02205682]] loss fxn value:  0.012628084832456532 learn rate: 1.5625e-05 iteration: 27172
[[ 2.00131513]
 [ 4.04289223]
 [-1.02205702]] loss fxn value:  0.012624577365621585 learn rate: 1.5625e-05 iteration: 27173
[[ 2.00131513]
 [ 4.04289223]
 [-1.02205722]] loss fxn value:  0.012621070872218676 learn rate: 1.5625e-05 iteration: 27174
[[ 2.00131513]
 [ 4.04289224]
 [-1.02205741]] loss fxn value:  0.012617565352395133 learn rate: 1.5625e-05 iteration: 27175
[[ 2.00131514]
 [ 4.04289224]
 [-1.02205761]] loss fxn value:  0.012614060807005537 learn rate: 1.5625e-05 iteration: 27176
[[ 2.00131514]
 [ 4.04289224]
 [-1.02205781]] loss fxn value:  0.012610557234155629 learn rate: 1.5625e-05 iteration: 27177
[[ 2.00131514]
 [ 4.04289224]
 [-1.022058  ]] loss fxn value:  0.01260705463532276 learn rate: 1.5625e-05 iteration: 27178
[[ 2.00131515]
 [ 4.04289224]
 [-1.0220582 ]] loss fxn value:  0.012603553009041119 learn rate: 1.5625e-05 iteration: 27179
[[ 2.00131515]
 [ 4.04289224]
 [-1.0220584 ]] loss fxn value:  0.012600052354432194 learn rate: 1.5625e-05 iteration: 27180
[[ 2.00131515]
 [ 4.04289224]
 [-1.02205859]] loss fxn value:  0.012596552674433086 learn rate: 1.5625e-05 iteration: 27181
[[ 2.00131516]
 [ 4.04289224]
 [-1.02205879]] loss fxn value:  0.012593053964926614 learn rate: 1.5625e-05 iteration: 27182
[[ 2.00131516]
 [ 4.04289224]
 [-1.02205899]] loss fxn value:  0.012589556227304195 learn rate: 1.5625e-05 iteration: 27183
[[ 2.00131516]
 [ 4.04289224]
 [-1.02205918]] loss fxn value:  0.012586059460354898 learn rate: 1.5625e-05 iteration: 27184
[[ 2.00131517]
 [ 4.04289225]
 [-1.02205938]] loss fxn value:  0.01258256366610646 learn rate: 1.5625e-05 iteration: 27185
[[ 2.00131517]
 [ 4.04289225]
 [-1.02205958]] loss fxn value:  0.012579068841621788 learn rate: 1.5625e-05 iteration: 27186
[[ 2.00131517]
 [ 4.04289225]
 [-1.02205977]] loss fxn value:  0.012575574988450012 learn rate: 1.5625e-05 iteration: 27187
[[ 2.00131518]
 [ 4.04289225]
 [-1.02205997]] loss fxn value:  0.012572082105551457 learn rate: 1.5625e-05 iteration: 27188
[[ 2.00131518]
 [ 4.04289225]
 [-1.02206017]] loss fxn value:  0.012568590193506505 learn rate: 1.5625e-05 iteration: 27189
[[ 2.00131518]
 [ 4.04289225]
 [-1.02206036]] loss fxn value:  0.012565099250839262 learn rate: 1.5625e-05 iteration: 27190
[[ 2.00131519]
 [ 4.04289225]
 [-1.02206056]] loss fxn value:  0.012561609277502727 learn rate: 1.5625e-05 iteration: 27191
[[ 2.00131519]
 [ 4.04289225]
 [-1.02206076]] loss fxn value:  0.012558120272781869 learn rate: 1.5625e-05 iteration: 27192
[[ 2.00131519]
 [ 4.04289225]
 [-1.02206095]] loss fxn value:  0.0125546322397862 learn rate: 1.5625e-05 iteration: 27193
[[ 2.0013152 ]
 [ 4.04289225]
 [-1.02206115]] loss fxn value:  0.012551145172866708 learn rate: 1.5625e-05 iteration: 27194
[[ 2.0013152 ]
 [ 4.04289226]
 [-1.02206134]] loss fxn value:  0.012547659075034577 learn rate: 1.5625e-05 iteration: 27195
[[ 2.0013152 ]
 [ 4.04289226]
 [-1.02206154]] loss fxn value:  0.012544173946601775 learn rate: 1.5625e-05 iteration: 27196
[[ 2.00131521]
 [ 4.04289226]
 [-1.02206174]] loss fxn value:  0.012540689785270981 learn rate: 1.5625e-05 iteration: 27197
[[ 2.00131521]
 [ 4.04289226]
 [-1.02206193]] loss fxn value:  0.012537206591570968 learn rate: 1.5625e-05 iteration: 27198
[[ 2.00131521]
 [ 4.04289226]
 [-1.02206213]] loss fxn value:  0.012533724366370154 learn rate: 1.5625e-05 iteration: 27199
[[ 2.00131522]
 [ 4.04289226]
 [-1.02206232]] loss fxn value:  0.012530243107379 learn rate: 1.5625e-05 iteration: 27200
[[ 2.00131522]
 [ 4.04289226]
 [-1.02206252]] loss fxn value:  0.012526762815575479 learn rate: 1.5625e-05 iteration: 27201
[[ 2.00131522]
 [ 4.04289226]
 [-1.02206272]] loss fxn value:  0.012523283489966923 learn rate: 1.5625e-05 iteration: 27202
[[ 2.00131523]
 [ 4.04289226]
 [-1.02206291]] loss fxn value:  0.012519805131536771 learn rate: 1.5625e-05 iteration: 27203
[[ 2.00131523]
 [ 4.04289226]
 [-1.02206311]] loss fxn value:  0.01251632773932551 learn rate: 1.5625e-05 iteration: 27204
[[ 2.00131523]
 [ 4.04289227]
 [-1.0220633 ]] loss fxn value:  0.01251285131239293 learn rate: 1.5625e-05 iteration: 27205
[[ 2.00131524]
 [ 4.04289227]
 [-1.0220635 ]] loss fxn value:  0.0125093758507915 learn rate: 1.5625e-05 iteration: 27206
[[ 2.00131524]
 [ 4.04289227]
 [-1.02206369]] loss fxn value:  0.012505901355044523 learn rate: 1.5625e-05 iteration: 27207
[[ 2.00131524]
 [ 4.04289227]
 [-1.02206389]] loss fxn value:  0.01250242782363833 learn rate: 1.5625e-05 iteration: 27208
[[ 2.00131525]
 [ 4.04289227]
 [-1.02206408]] loss fxn value:  0.012498955257594138 learn rate: 1.5625e-05 iteration: 27209
[[ 2.00131525]
 [ 4.04289227]
 [-1.02206428]] loss fxn value:  0.012495483655954735 learn rate: 1.5625e-05 iteration: 27210
[[ 2.00131525]
 [ 4.04289227]
 [-1.02206447]] loss fxn value:  0.012492013019677334 learn rate: 1.5625e-05 iteration: 27211
[[ 2.00131526]
 [ 4.04289227]
 [-1.02206467]] loss fxn value:  0.01248854334589577 learn rate: 1.5625e-05 iteration: 27212
[[ 2.00131526]
 [ 4.04289227]
 [-1.02206486]] loss fxn value:  0.01248507463616464 learn rate: 1.5625e-05 iteration: 27213
[[ 2.00131526]
 [ 4.04289227]
 [-1.02206506]] loss fxn value:  0.01248160688987417 learn rate: 1.5625e-05 iteration: 27214
[[ 2.00131527]
 [ 4.04289228]
 [-1.02206526]] loss fxn value:  0.01247814010667 learn rate: 1.5625e-05 iteration: 27215
[[ 2.00131527]
 [ 4.04289228]
 [-1.02206545]] loss fxn value:  0.01247467428701835 learn rate: 1.5625e-05 iteration: 27216
[[ 2.00131527]
 [ 4.04289228]
 [-1.02206564]] loss fxn value:  0.012471209429860228 learn rate: 1.5625e-05 iteration: 27217
[[ 2.00131527]
 [ 4.04289228]
 [-1.02206584]] loss fxn value:  0.012467745534481458 learn rate: 1.5625e-05 iteration: 27218
[[ 2.00131528]
 [ 4.04289228]
 [-1.02206603]] loss fxn value:  0.01246428260117239 learn rate: 1.5625e-05 iteration: 27219
[[ 2.00131528]
 [ 4.04289228]
 [-1.02206623]] loss fxn value:  0.012460820629557045 learn rate: 1.5625e-05 iteration: 27220
[[ 2.00131528]
 [ 4.04289228]
 [-1.02206642]] loss fxn value:  0.012457359620613406 learn rate: 1.5625e-05 iteration: 27221
[[ 2.00131529]
 [ 4.04289228]
 [-1.02206662]] loss fxn value:  0.01245389957237774 learn rate: 1.5625e-05 iteration: 27222
[[ 2.00131529]
 [ 4.04289228]
 [-1.02206681]] loss fxn value:  0.012450440484890978 learn rate: 1.5625e-05 iteration: 27223
[[ 2.00131529]
 [ 4.04289228]
 [-1.02206701]] loss fxn value:  0.012446982358261822 learn rate: 1.5625e-05 iteration: 27224
[[ 2.0013153 ]
 [ 4.04289228]
 [-1.0220672 ]] loss fxn value:  0.012443525192336024 learn rate: 1.5625e-05 iteration: 27225
[[ 2.0013153 ]
 [ 4.04289229]
 [-1.0220674 ]] loss fxn value:  0.012440068986344631 learn rate: 1.5625e-05 iteration: 27226
[[ 2.0013153 ]
 [ 4.04289229]
 [-1.02206759]] loss fxn value:  0.01243661374063046 learn rate: 1.5625e-05 iteration: 27227
[[ 2.00131531]
 [ 4.04289229]
 [-1.02206779]] loss fxn value:  0.012433159454343548 learn rate: 1.5625e-05 iteration: 27228
[[ 2.00131531]
 [ 4.04289229]
 [-1.02206798]] loss fxn value:  0.012429706127967111 learn rate: 1.5625e-05 iteration: 27229
[[ 2.00131531]
 [ 4.04289229]
 [-1.02206817]] loss fxn value:  0.012426253760442164 learn rate: 1.5625e-05 iteration: 27230
[[ 2.00131532]
 [ 4.04289229]
 [-1.02206837]] loss fxn value:  0.01242280235246095 learn rate: 1.5625e-05 iteration: 27231
[[ 2.00131532]
 [ 4.04289229]
 [-1.02206856]] loss fxn value:  0.012419351901910104 learn rate: 1.5625e-05 iteration: 27232
[[ 2.00131532]
 [ 4.04289229]
 [-1.02206876]] loss fxn value:  0.012415902410507705 learn rate: 1.5625e-05 iteration: 27233
[[ 2.00131533]
 [ 4.04289229]
 [-1.02206895]] loss fxn value:  0.012412453876052457 learn rate: 1.5625e-05 iteration: 27234
[[ 2.00131533]
 [ 4.04289229]
 [-1.02206914]] loss fxn value:  0.012409006301171789 learn rate: 1.5625e-05 iteration: 27235
[[ 2.00131533]
 [ 4.0428923 ]
 [-1.02206934]] loss fxn value:  0.012405559683354746 learn rate: 1.5625e-05 iteration: 27236
[[ 2.00131534]
 [ 4.0428923 ]
 [-1.02206953]] loss fxn value:  0.012402114022203736 learn rate: 1.5625e-05 iteration: 27237
[[ 2.00131534]
 [ 4.0428923 ]
 [-1.02206972]] loss fxn value:  0.012398669317780454 learn rate: 1.5625e-05 iteration: 27238
[[ 2.00131534]
 [ 4.0428923 ]
 [-1.02206992]] loss fxn value:  0.012395225571413473 learn rate: 1.5625e-05 iteration: 27239
[[ 2.00131535]
 [ 4.0428923 ]
 [-1.02207011]] loss fxn value:  0.012391782780272094 learn rate: 1.5625e-05 iteration: 27240
[[ 2.00131535]
 [ 4.0428923 ]
 [-1.02207031]] loss fxn value:  0.012388340945939453 learn rate: 1.5625e-05 iteration: 27241
[[ 2.00131535]
 [ 4.0428923 ]
 [-1.0220705 ]] loss fxn value:  0.01238490006779193 learn rate: 1.5625e-05 iteration: 27242
[[ 2.00131536]
 [ 4.0428923 ]
 [-1.02207069]] loss fxn value:  0.012381460145379466 learn rate: 1.5625e-05 iteration: 27243
[[ 2.00131536]
 [ 4.0428923 ]
 [-1.02207089]] loss fxn value:  0.01237802117835693 learn rate: 1.5625e-05 iteration: 27244
[[ 2.00131536]
 [ 4.0428923 ]
 [-1.02207108]] loss fxn value:  0.012374583166124628 learn rate: 1.5625e-05 iteration: 27245
[[ 2.00131537]
 [ 4.04289231]
 [-1.02207127]] loss fxn value:  0.012371146109256019 learn rate: 1.5625e-05 iteration: 27246
[[ 2.00131537]
 [ 4.04289231]
 [-1.02207147]] loss fxn value:  0.012367710007294122 learn rate: 1.5625e-05 iteration: 27247
[[ 2.00131537]
 [ 4.04289231]
 [-1.02207166]] loss fxn value:  0.01236427485921541 learn rate: 1.5625e-05 iteration: 27248
[[ 2.00131538]
 [ 4.04289231]
 [-1.02207185]] loss fxn value:  0.012360840665100894 learn rate: 1.5625e-05 iteration: 27249
[[ 2.00131538]
 [ 4.04289231]
 [-1.02207205]] loss fxn value:  0.012357407425414482 learn rate: 1.5625e-05 iteration: 27250
[[ 2.00131538]
 [ 4.04289231]
 [-1.02207224]] loss fxn value:  0.012353975137849627 learn rate: 1.5625e-05 iteration: 27251
[[ 2.00131538]
 [ 4.04289231]
 [-1.02207243]] loss fxn value:  0.012350543805220023 learn rate: 1.5625e-05 iteration: 27252
[[ 2.00131539]
 [ 4.04289231]
 [-1.02207262]] loss fxn value:  0.012347113425118801 learn rate: 1.5625e-05 iteration: 27253
[[ 2.00131539]
 [ 4.04289231]
 [-1.02207282]] loss fxn value:  0.012343683998072416 learn rate: 1.5625e-05 iteration: 27254
[[ 2.00131539]
 [ 4.04289231]
 [-1.02207301]] loss fxn value:  0.012340255523142975 learn rate: 1.5625e-05 iteration: 27255
[[ 2.0013154 ]
 [ 4.04289232]
 [-1.0220732 ]] loss fxn value:  0.012336828001334687 learn rate: 1.5625e-05 iteration: 27256
[[ 2.0013154 ]
 [ 4.04289232]
 [-1.0220734 ]] loss fxn value:  0.012333401431136192 learn rate: 1.5625e-05 iteration: 27257
[[ 2.0013154 ]
 [ 4.04289232]
 [-1.02207359]] loss fxn value:  0.012329975811721454 learn rate: 1.5625e-05 iteration: 27258
[[ 2.00131541]
 [ 4.04289232]
 [-1.02207378]] loss fxn value:  0.012326551144463738 learn rate: 1.5625e-05 iteration: 27259
[[ 2.00131541]
 [ 4.04289232]
 [-1.02207397]] loss fxn value:  0.012323127428896826 learn rate: 1.5625e-05 iteration: 27260
[[ 2.00131541]
 [ 4.04289232]
 [-1.02207417]] loss fxn value:  0.012319704663144922 learn rate: 1.5625e-05 iteration: 27261
[[ 2.00131542]
 [ 4.04289232]
 [-1.02207436]] loss fxn value:  0.012316282849123903 learn rate: 1.5625e-05 iteration: 27262
[[ 2.00131542]
 [ 4.04289232]
 [-1.02207455]] loss fxn value:  0.012312861984496371 learn rate: 1.5625e-05 iteration: 27263
[[ 2.00131542]
 [ 4.04289232]
 [-1.02207474]] loss fxn value:  0.012309442070167067 learn rate: 1.5625e-05 iteration: 27264
[[ 2.00131543]
 [ 4.04289232]
 [-1.02207494]] loss fxn value:  0.012306023106264006 learn rate: 1.5625e-05 iteration: 27265
[[ 2.00131543]
 [ 4.04289233]
 [-1.02207513]] loss fxn value:  0.012302605092088019 learn rate: 1.5625e-05 iteration: 27266
[[ 2.00131543]
 [ 4.04289233]
 [-1.02207532]] loss fxn value:  0.012299188026938775 learn rate: 1.5625e-05 iteration: 27267
[[ 2.00131544]
 [ 4.04289233]
 [-1.02207551]] loss fxn value:  0.012295771911183017 learn rate: 1.5625e-05 iteration: 27268
[[ 2.00131544]
 [ 4.04289233]
 [-1.0220757 ]] loss fxn value:  0.012292356743425862 learn rate: 1.5625e-05 iteration: 27269
[[ 2.00131544]
 [ 4.04289233]
 [-1.0220759 ]] loss fxn value:  0.012288942525635655 learn rate: 1.5625e-05 iteration: 27270
[[ 2.00131545]
 [ 4.04289233]
 [-1.02207609]] loss fxn value:  0.01228552925531067 learn rate: 1.5625e-05 iteration: 27271
[[ 2.00131545]
 [ 4.04289233]
 [-1.02207628]] loss fxn value:  0.012282116933148617 learn rate: 1.5625e-05 iteration: 27272
[[ 2.00131545]
 [ 4.04289233]
 [-1.02207647]] loss fxn value:  0.01227870555847802 learn rate: 1.5625e-05 iteration: 27273
[[ 2.00131546]
 [ 4.04289233]
 [-1.02207666]] loss fxn value:  0.012275295131931733 learn rate: 1.5625e-05 iteration: 27274
[[ 2.00131546]
 [ 4.04289233]
 [-1.02207686]] loss fxn value:  0.012271885651984548 learn rate: 1.5625e-05 iteration: 27275
[[ 2.00131546]
 [ 4.04289233]
 [-1.02207705]] loss fxn value:  0.01226847711923847 learn rate: 1.5625e-05 iteration: 27276
[[ 2.00131547]
 [ 4.04289234]
 [-1.02207724]] loss fxn value:  0.01226506953319789 learn rate: 1.5625e-05 iteration: 27277
[[ 2.00131547]
 [ 4.04289234]
 [-1.02207743]] loss fxn value:  0.012261662893791877 learn rate: 1.5625e-05 iteration: 27278
[[ 2.00131547]
 [ 4.04289234]
 [-1.02207762]] loss fxn value:  0.012258257200625147 learn rate: 1.5625e-05 iteration: 27279
[[ 2.00131547]
 [ 4.04289234]
 [-1.02207781]] loss fxn value:  0.012254852453666849 learn rate: 1.5625e-05 iteration: 27280
[[ 2.00131548]
 [ 4.04289234]
 [-1.02207801]] loss fxn value:  0.01225144865252631 learn rate: 1.5625e-05 iteration: 27281
[[ 2.00131548]
 [ 4.04289234]
 [-1.0220782 ]] loss fxn value:  0.012248045795204339 learn rate: 1.5625e-05 iteration: 27282
[[ 2.00131548]
 [ 4.04289234]
 [-1.02207839]] loss fxn value:  0.012244643884328364 learn rate: 1.5625e-05 iteration: 27283
[[ 2.00131549]
 [ 4.04289234]
 [-1.02207858]] loss fxn value:  0.012241242917633085 learn rate: 1.5625e-05 iteration: 27284
[[ 2.00131549]
 [ 4.04289234]
 [-1.02207877]] loss fxn value:  0.012237842897393035 learn rate: 1.5625e-05 iteration: 27285
[[ 2.00131549]
 [ 4.04289234]
 [-1.02207896]] loss fxn value:  0.01223444381948181 learn rate: 1.5625e-05 iteration: 27286
[[ 2.0013155 ]
 [ 4.04289235]
 [-1.02207915]] loss fxn value:  0.01223104568620479 learn rate: 1.5625e-05 iteration: 27287
[[ 2.0013155 ]
 [ 4.04289235]
 [-1.02207934]] loss fxn value:  0.012227648496284738 learn rate: 1.5625e-05 iteration: 27288
[[ 2.0013155 ]
 [ 4.04289235]
 [-1.02207954]] loss fxn value:  0.012224252250449359 learn rate: 1.5625e-05 iteration: 27289
[[ 2.00131551]
 [ 4.04289235]
 [-1.02207973]] loss fxn value:  0.012220856948410925 learn rate: 1.5625e-05 iteration: 27290
[[ 2.00131551]
 [ 4.04289235]
 [-1.02207992]] loss fxn value:  0.012217462589088516 learn rate: 1.5625e-05 iteration: 27291
[[ 2.00131551]
 [ 4.04289235]
 [-1.02208011]] loss fxn value:  0.012214069171829966 learn rate: 1.5625e-05 iteration: 27292
[[ 2.00131552]
 [ 4.04289235]
 [-1.0220803 ]] loss fxn value:  0.012210676698592084 learn rate: 1.5625e-05 iteration: 27293
[[ 2.00131552]
 [ 4.04289235]
 [-1.02208049]] loss fxn value:  0.012207285165990019 learn rate: 1.5625e-05 iteration: 27294
[[ 2.00131552]
 [ 4.04289235]
 [-1.02208068]] loss fxn value:  0.012203894576620354 learn rate: 1.5625e-05 iteration: 27295
[[ 2.00131553]
 [ 4.04289235]
 [-1.02208087]] loss fxn value:  0.012200504928293332 learn rate: 1.5625e-05 iteration: 27296
[[ 2.00131553]
 [ 4.04289236]
 [-1.02208106]] loss fxn value:  0.012197116221768363 learn rate: 1.5625e-05 iteration: 27297
[[ 2.00131553]
 [ 4.04289236]
 [-1.02208125]] loss fxn value:  0.01219372845687881 learn rate: 1.5625e-05 iteration: 27298
[[ 2.00131554]
 [ 4.04289236]
 [-1.02208144]] loss fxn value:  0.012190341632284564 learn rate: 1.5625e-05 iteration: 27299
[[ 2.00131554]
 [ 4.04289236]
 [-1.02208163]] loss fxn value:  0.012186955748961297 learn rate: 1.5625e-05 iteration: 27300
[[ 2.00131554]
 [ 4.04289236]
 [-1.02208182]] loss fxn value:  0.012183570805514124 learn rate: 1.5625e-05 iteration: 27301
[[ 2.00131554]
 [ 4.04289236]
 [-1.02208201]] loss fxn value:  0.012180186802243474 learn rate: 1.5625e-05 iteration: 27302
[[ 2.00131555]
 [ 4.04289236]
 [-1.0220822 ]] loss fxn value:  0.012176803739481773 learn rate: 1.5625e-05 iteration: 27303
[[ 2.00131555]
 [ 4.04289236]
 [-1.02208239]] loss fxn value:  0.012173421615480094 learn rate: 1.5625e-05 iteration: 27304
[[ 2.00131555]
 [ 4.04289236]
 [-1.02208258]] loss fxn value:  0.01217004043107108 learn rate: 1.5625e-05 iteration: 27305
[[ 2.00131556]
 [ 4.04289236]
 [-1.02208277]] loss fxn value:  0.012166660186393145 learn rate: 1.5625e-05 iteration: 27306
[[ 2.00131556]
 [ 4.04289236]
 [-1.02208296]] loss fxn value:  0.01216328088074134 learn rate: 1.5625e-05 iteration: 27307
[[ 2.00131556]
 [ 4.04289237]
 [-1.02208315]] loss fxn value:  0.012159902513052058 learn rate: 1.5625e-05 iteration: 27308
[[ 2.00131557]
 [ 4.04289237]
 [-1.02208334]] loss fxn value:  0.012156525083448699 learn rate: 1.5625e-05 iteration: 27309
[[ 2.00131557]
 [ 4.04289237]
 [-1.02208353]] loss fxn value:  0.012153148591900415 learn rate: 1.5625e-05 iteration: 27310
[[ 2.00131557]
 [ 4.04289237]
 [-1.02208372]] loss fxn value:  0.012149773038833342 learn rate: 1.5625e-05 iteration: 27311
[[ 2.00131558]
 [ 4.04289237]
 [-1.02208391]] loss fxn value:  0.012146398423397512 learn rate: 1.5625e-05 iteration: 27312
[[ 2.00131558]
 [ 4.04289237]
 [-1.0220841 ]] loss fxn value:  0.012143024744993233 learn rate: 1.5625e-05 iteration: 27313
[[ 2.00131558]
 [ 4.04289237]
 [-1.02208429]] loss fxn value:  0.012139652002875475 learn rate: 1.5625e-05 iteration: 27314
[[ 2.00131559]
 [ 4.04289237]
 [-1.02208448]] loss fxn value:  0.012136280198848257 learn rate: 1.5625e-05 iteration: 27315
[[ 2.00131559]
 [ 4.04289237]
 [-1.02208467]] loss fxn value:  0.012132909330488552 learn rate: 1.5625e-05 iteration: 27316
[[ 2.00131559]
 [ 4.04289237]
 [-1.02208486]] loss fxn value:  0.012129539398907822 learn rate: 1.5625e-05 iteration: 27317
[[ 2.0013156 ]
 [ 4.04289238]
 [-1.02208505]] loss fxn value:  0.012126170403477824 learn rate: 1.5625e-05 iteration: 27318
[[ 2.0013156 ]
 [ 4.04289238]
 [-1.02208524]] loss fxn value:  0.012122802343363295 learn rate: 1.5625e-05 iteration: 27319
[[ 2.0013156 ]
 [ 4.04289238]
 [-1.02208543]] loss fxn value:  0.012119435218130322 learn rate: 1.5625e-05 iteration: 27320
[[ 2.0013156 ]
 [ 4.04289238]
 [-1.02208562]] loss fxn value:  0.012116069029557539 learn rate: 1.5625e-05 iteration: 27321
[[ 2.00131561]
 [ 4.04289238]
 [-1.02208581]] loss fxn value:  0.012112703774519281 learn rate: 1.5625e-05 iteration: 27322
[[ 2.00131561]
 [ 4.04289238]
 [-1.022086  ]] loss fxn value:  0.012109339455243395 learn rate: 1.5625e-05 iteration: 27323
[[ 2.00131561]
 [ 4.04289238]
 [-1.02208619]] loss fxn value:  0.012105976069380945 learn rate: 1.5625e-05 iteration: 27324
[[ 2.00131562]
 [ 4.04289238]
 [-1.02208638]] loss fxn value:  0.012102613618959666 learn rate: 1.5625e-05 iteration: 27325
[[ 2.00131562]
 [ 4.04289238]
 [-1.02208657]] loss fxn value:  0.012099252101023156 learn rate: 1.5625e-05 iteration: 27326
[[ 2.00131562]
 [ 4.04289238]
 [-1.02208676]] loss fxn value:  0.012095891518444498 learn rate: 1.5625e-05 iteration: 27327
[[ 2.00131563]
 [ 4.04289239]
 [-1.02208694]] loss fxn value:  0.012092531867946092 learn rate: 1.5625e-05 iteration: 27328
[[ 2.00131563]
 [ 4.04289239]
 [-1.02208713]] loss fxn value:  0.012089173151048526 learn rate: 1.5625e-05 iteration: 27329
[[ 2.00131563]
 [ 4.04289239]
 [-1.02208732]] loss fxn value:  0.012085815367575933 learn rate: 1.5625e-05 iteration: 27330
[[ 2.00131564]
 [ 4.04289239]
 [-1.02208751]] loss fxn value:  0.012082458515271927 learn rate: 1.5625e-05 iteration: 27331
[[ 2.00131564]
 [ 4.04289239]
 [-1.0220877 ]] loss fxn value:  0.012079102596575682 learn rate: 1.5625e-05 iteration: 27332
[[ 2.00131564]
 [ 4.04289239]
 [-1.02208789]] loss fxn value:  0.012075747609441006 learn rate: 1.5625e-05 iteration: 27333
[[ 2.00131565]
 [ 4.04289239]
 [-1.02208808]] loss fxn value:  0.012072393554519207 learn rate: 1.5625e-05 iteration: 27334
[[ 2.00131565]
 [ 4.04289239]
 [-1.02208827]] loss fxn value:  0.012069040431760976 learn rate: 1.5625e-05 iteration: 27335
[[ 2.00131565]
 [ 4.04289239]
 [-1.02208845]] loss fxn value:  0.012065688238730901 learn rate: 1.5625e-05 iteration: 27336
[[ 2.00131566]
 [ 4.04289239]
 [-1.02208864]] loss fxn value:  0.012062336978420855 learn rate: 1.5625e-05 iteration: 27337
[[ 2.00131566]
 [ 4.04289239]
 [-1.02208883]] loss fxn value:  0.012058986648348417 learn rate: 1.5625e-05 iteration: 27338
[[ 2.00131566]
 [ 4.0428924 ]
 [-1.02208902]] loss fxn value:  0.012055637248115996 learn rate: 1.5625e-05 iteration: 27339
[[ 2.00131566]
 [ 4.0428924 ]
 [-1.02208921]] loss fxn value:  0.01205228877869003 learn rate: 1.5625e-05 iteration: 27340
[[ 2.00131567]
 [ 4.0428924 ]
 [-1.0220894 ]] loss fxn value:  0.012048941240048905 learn rate: 1.5625e-05 iteration: 27341
[[ 2.00131567]
 [ 4.0428924 ]
 [-1.02208958]] loss fxn value:  0.012045594629828984 learn rate: 1.5625e-05 iteration: 27342
[[ 2.00131567]
 [ 4.0428924 ]
 [-1.02208977]] loss fxn value:  0.012042248949987075 learn rate: 1.5625e-05 iteration: 27343
[[ 2.00131568]
 [ 4.0428924 ]
 [-1.02208996]] loss fxn value:  0.012038904199104368 learn rate: 1.5625e-05 iteration: 27344
[[ 2.00131568]
 [ 4.0428924 ]
 [-1.02209015]] loss fxn value:  0.012035560377530606 learn rate: 1.5625e-05 iteration: 27345
[[ 2.00131568]
 [ 4.0428924 ]
 [-1.02209034]] loss fxn value:  0.012032217484575534 learn rate: 1.5625e-05 iteration: 27346
[[ 2.00131569]
 [ 4.0428924 ]
 [-1.02209052]] loss fxn value:  0.012028875519527598 learn rate: 1.5625e-05 iteration: 27347
[[ 2.00131569]
 [ 4.0428924 ]
 [-1.02209071]] loss fxn value:  0.01202553448261744 learn rate: 1.5625e-05 iteration: 27348
[[ 2.00131569]
 [ 4.04289241]
 [-1.0220909 ]] loss fxn value:  0.012022194374640251 learn rate: 1.5625e-05 iteration: 27349
[[ 2.0013157 ]
 [ 4.04289241]
 [-1.02209109]] loss fxn value:  0.012018855194231995 learn rate: 1.5625e-05 iteration: 27350
[[ 2.0013157 ]
 [ 4.04289241]
 [-1.02209128]] loss fxn value:  0.012015516940935686 learn rate: 1.5625e-05 iteration: 27351
[[ 2.0013157 ]
 [ 4.04289241]
 [-1.02209146]] loss fxn value:  0.012012179615236852 learn rate: 1.5625e-05 iteration: 27352
[[ 2.00131571]
 [ 4.04289241]
 [-1.02209165]] loss fxn value:  0.012008843216219213 learn rate: 1.5625e-05 iteration: 27353
[[ 2.00131571]
 [ 4.04289241]
 [-1.02209184]] loss fxn value:  0.012005507743872688 learn rate: 1.5625e-05 iteration: 27354
[[ 2.00131571]
 [ 4.04289241]
 [-1.02209203]] loss fxn value:  0.012002173199149873 learn rate: 1.5625e-05 iteration: 27355
[[ 2.00131572]
 [ 4.04289241]
 [-1.02209221]] loss fxn value:  0.011998839578725311 learn rate: 1.5625e-05 iteration: 27356
[[ 2.00131572]
 [ 4.04289241]
 [-1.0220924 ]] loss fxn value:  0.011995506884619814 learn rate: 1.5625e-05 iteration: 27357
[[ 2.00131572]
 [ 4.04289241]
 [-1.02209259]] loss fxn value:  0.01199217511714997 learn rate: 1.5625e-05 iteration: 27358
[[ 2.00131572]
 [ 4.04289241]
 [-1.02209278]] loss fxn value:  0.01198884427402392 learn rate: 1.5625e-05 iteration: 27359
[[ 2.00131573]
 [ 4.04289242]
 [-1.02209296]] loss fxn value:  0.01198551435677841 learn rate: 1.5625e-05 iteration: 27360
[[ 2.00131573]
 [ 4.04289242]
 [-1.02209315]] loss fxn value:  0.011982185363400405 learn rate: 1.5625e-05 iteration: 27361
[[ 2.00131573]
 [ 4.04289242]
 [-1.02209334]] loss fxn value:  0.011978857296310614 learn rate: 1.5625e-05 iteration: 27362
[[ 2.00131574]
 [ 4.04289242]
 [-1.02209353]] loss fxn value:  0.0119755301521265 learn rate: 1.5625e-05 iteration: 27363
[[ 2.00131574]
 [ 4.04289242]
 [-1.02209371]] loss fxn value:  0.011972203932475896 learn rate: 1.5625e-05 iteration: 27364
[[ 2.00131574]
 [ 4.04289242]
 [-1.0220939 ]] loss fxn value:  0.01196887863717832 learn rate: 1.5625e-05 iteration: 27365
[[ 2.00131575]
 [ 4.04289242]
 [-1.02209409]] loss fxn value:  0.011965554263998153 learn rate: 1.5625e-05 iteration: 27366
[[ 2.00131575]
 [ 4.04289242]
 [-1.02209427]] loss fxn value:  0.011962230816137455 learn rate: 1.5625e-05 iteration: 27367
[[ 2.00131575]
 [ 4.04289242]
 [-1.02209446]] loss fxn value:  0.011958908290905929 learn rate: 1.5625e-05 iteration: 27368
[[ 2.00131576]
 [ 4.04289242]
 [-1.02209465]] loss fxn value:  0.011955586687209122 learn rate: 1.5625e-05 iteration: 27369
[[ 2.00131576]
 [ 4.04289243]
 [-1.02209483]] loss fxn value:  0.011952266007650538 learn rate: 1.5625e-05 iteration: 27370
[[ 2.00131576]
 [ 4.04289243]
 [-1.02209502]] loss fxn value:  0.011948946249574204 learn rate: 1.5625e-05 iteration: 27371
[[ 2.00131576]
 [ 4.04289243]
 [-1.02209521]] loss fxn value:  0.011945627413781914 learn rate: 1.5625e-05 iteration: 27372
[[ 2.00131577]
 [ 4.04289243]
 [-1.02209539]] loss fxn value:  0.011942309499562116 learn rate: 1.5625e-05 iteration: 27373
[[ 2.00131577]
 [ 4.04289243]
 [-1.02209558]] loss fxn value:  0.011938992507059825 learn rate: 1.5625e-05 iteration: 27374
[[ 2.00131577]
 [ 4.04289243]
 [-1.02209577]] loss fxn value:  0.011935676436213342 learn rate: 1.5625e-05 iteration: 27375
[[ 2.00131578]
 [ 4.04289243]
 [-1.02209595]] loss fxn value:  0.01193236128566556 learn rate: 1.5625e-05 iteration: 27376
[[ 2.00131578]
 [ 4.04289243]
 [-1.02209614]] loss fxn value:  0.011929047057313888 learn rate: 1.5625e-05 iteration: 27377
[[ 2.00131578]
 [ 4.04289243]
 [-1.02209633]] loss fxn value:  0.011925733747804328 learn rate: 1.5625e-05 iteration: 27378
[[ 2.00131579]
 [ 4.04289243]
 [-1.02209651]] loss fxn value:  0.011922421359091382 learn rate: 1.5625e-05 iteration: 27379
[[ 2.00131579]
 [ 4.04289243]
 [-1.0220967 ]] loss fxn value:  0.011919109891255211 learn rate: 1.5625e-05 iteration: 27380
[[ 2.00131579]
 [ 4.04289244]
 [-1.02209688]] loss fxn value:  0.011915799342137755 learn rate: 1.5625e-05 iteration: 27381
[[ 2.0013158 ]
 [ 4.04289244]
 [-1.02209707]] loss fxn value:  0.011912489713092651 learn rate: 1.5625e-05 iteration: 27382
[[ 2.0013158 ]
 [ 4.04289244]
 [-1.02209726]] loss fxn value:  0.011909181002834886 learn rate: 1.5625e-05 iteration: 27383
[[ 2.0013158 ]
 [ 4.04289244]
 [-1.02209744]] loss fxn value:  0.011905873213075612 learn rate: 1.5625e-05 iteration: 27384
[[ 2.00131581]
 [ 4.04289244]
 [-1.02209763]] loss fxn value:  0.011902566339730811 learn rate: 1.5625e-05 iteration: 27385
[[ 2.00131581]
 [ 4.04289244]
 [-1.02209782]] loss fxn value:  0.011899260385972839 learn rate: 1.5625e-05 iteration: 27386
[[ 2.00131581]
 [ 4.04289244]
 [-1.022098  ]] loss fxn value:  0.011895955349699866 learn rate: 1.5625e-05 iteration: 27387
[[ 2.00131581]
 [ 4.04289244]
 [-1.02209819]] loss fxn value:  0.011892651232956635 learn rate: 1.5625e-05 iteration: 27388
[[ 2.00131582]
 [ 4.04289244]
 [-1.02209837]] loss fxn value:  0.011889348033177415 learn rate: 1.5625e-05 iteration: 27389
[[ 2.00131582]
 [ 4.04289244]
 [-1.02209856]] loss fxn value:  0.011886045751106918 learn rate: 1.5625e-05 iteration: 27390
[[ 2.00131582]
 [ 4.04289244]
 [-1.02209874]] loss fxn value:  0.011882744386088363 learn rate: 1.5625e-05 iteration: 27391
[[ 2.00131583]
 [ 4.04289245]
 [-1.02209893]] loss fxn value:  0.011879443937755006 learn rate: 1.5625e-05 iteration: 27392
[[ 2.00131583]
 [ 4.04289245]
 [-1.02209912]] loss fxn value:  0.011876144405625934 learn rate: 1.5625e-05 iteration: 27393
[[ 2.00131583]
 [ 4.04289245]
 [-1.0220993 ]] loss fxn value:  0.011872845790632122 learn rate: 1.5625e-05 iteration: 27394
[[ 2.00131584]
 [ 4.04289245]
 [-1.02209949]] loss fxn value:  0.011869548091897374 learn rate: 1.5625e-05 iteration: 27395
[[ 2.00131584]
 [ 4.04289245]
 [-1.02209967]] loss fxn value:  0.011866251310276266 learn rate: 1.5625e-05 iteration: 27396
[[ 2.00131584]
 [ 4.04289245]
 [-1.02209986]] loss fxn value:  0.01186295544249581 learn rate: 1.5625e-05 iteration: 27397
[[ 2.00131585]
 [ 4.04289245]
 [-1.02210004]] loss fxn value:  0.011859660490605365 learn rate: 1.5625e-05 iteration: 27398
[[ 2.00131585]
 [ 4.04289245]
 [-1.02210023]] loss fxn value:  0.011856366453952764 learn rate: 1.5625e-05 iteration: 27399
[[ 2.00131585]
 [ 4.04289245]
 [-1.02210041]] loss fxn value:  0.011853073332704647 learn rate: 1.5625e-05 iteration: 27400
[[ 2.00131585]
 [ 4.04289245]
 [-1.0221006 ]] loss fxn value:  0.011849781125694774 learn rate: 1.5625e-05 iteration: 27401
[[ 2.00131586]
 [ 4.04289246]
 [-1.02210078]] loss fxn value:  0.011846489832727658 learn rate: 1.5625e-05 iteration: 27402
[[ 2.00131586]
 [ 4.04289246]
 [-1.02210097]] loss fxn value:  0.011843199454141497 learn rate: 1.5625e-05 iteration: 27403
[[ 2.00131586]
 [ 4.04289246]
 [-1.02210115]] loss fxn value:  0.011839909989512466 learn rate: 1.5625e-05 iteration: 27404
[[ 2.00131587]
 [ 4.04289246]
 [-1.02210134]] loss fxn value:  0.011836621439266701 learn rate: 1.5625e-05 iteration: 27405
[[ 2.00131587]
 [ 4.04289246]
 [-1.02210152]] loss fxn value:  0.01183333380158318 learn rate: 1.5625e-05 iteration: 27406
[[ 2.00131587]
 [ 4.04289246]
 [-1.02210171]] loss fxn value:  0.011830047077406723 learn rate: 1.5625e-05 iteration: 27407
[[ 2.00131588]
 [ 4.04289246]
 [-1.02210189]] loss fxn value:  0.011826761264873925 learn rate: 1.5625e-05 iteration: 27408
[[ 2.00131588]
 [ 4.04289246]
 [-1.02210208]] loss fxn value:  0.011823476366790707 learn rate: 1.5625e-05 iteration: 27409
[[ 2.00131588]
 [ 4.04289246]
 [-1.02210226]] loss fxn value:  0.011820192380845904 learn rate: 1.5625e-05 iteration: 27410
[[ 2.00131589]
 [ 4.04289246]
 [-1.02210245]] loss fxn value:  0.01181690930549269 learn rate: 1.5625e-05 iteration: 27411
[[ 2.00131589]
 [ 4.04289246]
 [-1.02210263]] loss fxn value:  0.011813627143850954 learn rate: 1.5625e-05 iteration: 27412
[[ 2.00131589]
 [ 4.04289247]
 [-1.02210282]] loss fxn value:  0.011810345892810038 learn rate: 1.5625e-05 iteration: 27413
[[ 2.00131589]
 [ 4.04289247]
 [-1.022103  ]] loss fxn value:  0.011807065553567028 learn rate: 1.5625e-05 iteration: 27414
[[ 2.0013159 ]
 [ 4.04289247]
 [-1.02210319]] loss fxn value:  0.011803786125465144 learn rate: 1.5625e-05 iteration: 27415
[[ 2.0013159 ]
 [ 4.04289247]
 [-1.02210337]] loss fxn value:  0.011800507608080556 learn rate: 1.5625e-05 iteration: 27416
[[ 2.0013159 ]
 [ 4.04289247]
 [-1.02210355]] loss fxn value:  0.01179723000107045 learn rate: 1.5625e-05 iteration: 27417
[[ 2.00131591]
 [ 4.04289247]
 [-1.02210374]] loss fxn value:  0.011793953304349195 learn rate: 1.5625e-05 iteration: 27418
[[ 2.00131591]
 [ 4.04289247]
 [-1.02210392]] loss fxn value:  0.011790677518373779 learn rate: 1.5625e-05 iteration: 27419
[[ 2.00131591]
 [ 4.04289247]
 [-1.02210411]] loss fxn value:  0.011787402641808711 learn rate: 1.5625e-05 iteration: 27420
[[ 2.00131592]
 [ 4.04289247]
 [-1.02210429]] loss fxn value:  0.011784128674594597 learn rate: 1.5625e-05 iteration: 27421
[[ 2.00131592]
 [ 4.04289247]
 [-1.02210448]] loss fxn value:  0.011780855617333443 learn rate: 1.5625e-05 iteration: 27422
[[ 2.00131592]
 [ 4.04289248]
 [-1.02210466]] loss fxn value:  0.011777583469370774 learn rate: 1.5625e-05 iteration: 27423
[[ 2.00131593]
 [ 4.04289248]
 [-1.02210484]] loss fxn value:  0.011774312229452107 learn rate: 1.5625e-05 iteration: 27424
[[ 2.00131593]
 [ 4.04289248]
 [-1.02210503]] loss fxn value:  0.011771041899029416 learn rate: 1.5625e-05 iteration: 27425
[[ 2.00131593]
 [ 4.04289248]
 [-1.02210521]] loss fxn value:  0.01176777247605334 learn rate: 1.5625e-05 iteration: 27426
[[ 2.00131593]
 [ 4.04289248]
 [-1.02210539]] loss fxn value:  0.011764503961628415 learn rate: 1.5625e-05 iteration: 27427
[[ 2.00131594]
 [ 4.04289248]
 [-1.02210558]] loss fxn value:  0.01176123635428567 learn rate: 1.5625e-05 iteration: 27428
[[ 2.00131594]
 [ 4.04289248]
 [-1.02210576]] loss fxn value:  0.011757969655041703 learn rate: 1.5625e-05 iteration: 27429
[[ 2.00131594]
 [ 4.04289248]
 [-1.02210595]] loss fxn value:  0.011754703863315286 learn rate: 1.5625e-05 iteration: 27430
[[ 2.00131595]
 [ 4.04289248]
 [-1.02210613]] loss fxn value:  0.011751438978285839 learn rate: 1.5625e-05 iteration: 27431
[[ 2.00131595]
 [ 4.04289248]
 [-1.02210631]] loss fxn value:  0.011748175000861873 learn rate: 1.5625e-05 iteration: 27432
[[ 2.00131595]
 [ 4.04289248]
 [-1.0221065 ]] loss fxn value:  0.011744911929109047 learn rate: 1.5625e-05 iteration: 27433
[[ 2.00131596]
 [ 4.04289249]
 [-1.02210668]] loss fxn value:  0.011741649765040406 learn rate: 1.5625e-05 iteration: 27434
[[ 2.00131596]
 [ 4.04289249]
 [-1.02210686]] loss fxn value:  0.011738388506206687 learn rate: 1.5625e-05 iteration: 27435
[[ 2.00131596]
 [ 4.04289249]
 [-1.02210705]] loss fxn value:  0.011735128152231919 learn rate: 1.5625e-05 iteration: 27436
[[ 2.00131597]
 [ 4.04289249]
 [-1.02210723]] loss fxn value:  0.011731868704910886 learn rate: 1.5625e-05 iteration: 27437
[[ 2.00131597]
 [ 4.04289249]
 [-1.02210741]] loss fxn value:  0.011728610162938944 learn rate: 1.5625e-05 iteration: 27438
[[ 2.00131597]
 [ 4.04289249]
 [-1.0221076 ]] loss fxn value:  0.011725352525740326 learn rate: 1.5625e-05 iteration: 27439
[[ 2.00131597]
 [ 4.04289249]
 [-1.02210778]] loss fxn value:  0.011722095792550694 learn rate: 1.5625e-05 iteration: 27440
[[ 2.00131598]
 [ 4.04289249]
 [-1.02210796]] loss fxn value:  0.011718839965614892 learn rate: 1.5625e-05 iteration: 27441
[[ 2.00131598]
 [ 4.04289249]
 [-1.02210815]] loss fxn value:  0.011715585042462048 learn rate: 1.5625e-05 iteration: 27442
[[ 2.00131598]
 [ 4.04289249]
 [-1.02210833]] loss fxn value:  0.011712331022468225 learn rate: 1.5625e-05 iteration: 27443
[[ 2.00131599]
 [ 4.04289249]
 [-1.02210851]] loss fxn value:  0.011709077906823896 learn rate: 1.5625e-05 iteration: 27444
[[ 2.00131599]
 [ 4.0428925 ]
 [-1.0221087 ]] loss fxn value:  0.011705825694226724 learn rate: 1.5625e-05 iteration: 27445
[[ 2.00131599]
 [ 4.0428925 ]
 [-1.02210888]] loss fxn value:  0.011702574386033823 learn rate: 1.5625e-05 iteration: 27446
[[ 2.001316  ]
 [ 4.0428925 ]
 [-1.02210906]] loss fxn value:  0.011699323980828692 learn rate: 1.5625e-05 iteration: 27447
[[ 2.001316  ]
 [ 4.0428925 ]
 [-1.02210924]] loss fxn value:  0.0116960744768497 learn rate: 1.5625e-05 iteration: 27448
[[ 2.001316  ]
 [ 4.0428925 ]
 [-1.02210943]] loss fxn value:  0.011692825876881998 learn rate: 1.5625e-05 iteration: 27449
[[ 2.00131601]
 [ 4.0428925 ]
 [-1.02210961]] loss fxn value:  0.011689578178904774 learn rate: 1.5625e-05 iteration: 27450
[[ 2.00131601]
 [ 4.0428925 ]
 [-1.02210979]] loss fxn value:  0.011686331382693994 learn rate: 1.5625e-05 iteration: 27451
[[ 2.00131601]
 [ 4.0428925 ]
 [-1.02210997]] loss fxn value:  0.011683085489047153 learn rate: 1.5625e-05 iteration: 27452
[[ 2.00131601]
 [ 4.0428925 ]
 [-1.02211016]] loss fxn value:  0.011679840496074607 learn rate: 1.5625e-05 iteration: 27453
[[ 2.00131602]
 [ 4.0428925 ]
 [-1.02211034]] loss fxn value:  0.011676596404870813 learn rate: 1.5625e-05 iteration: 27454
[[ 2.00131602]
 [ 4.0428925 ]
 [-1.02211052]] loss fxn value:  0.011673353214873847 learn rate: 1.5625e-05 iteration: 27455
[[ 2.00131602]
 [ 4.04289251]
 [-1.0221107 ]] loss fxn value:  0.011670110925553482 learn rate: 1.5625e-05 iteration: 27456
[[ 2.00131603]
 [ 4.04289251]
 [-1.02211089]] loss fxn value:  0.011666869536092916 learn rate: 1.5625e-05 iteration: 27457
[[ 2.00131603]
 [ 4.04289251]
 [-1.02211107]] loss fxn value:  0.0116636290484011 learn rate: 1.5625e-05 iteration: 27458
[[ 2.00131603]
 [ 4.04289251]
 [-1.02211125]] loss fxn value:  0.011660389459514706 learn rate: 1.5625e-05 iteration: 27459
[[ 2.00131604]
 [ 4.04289251]
 [-1.02211143]] loss fxn value:  0.011657150770097437 learn rate: 1.5625e-05 iteration: 27460
[[ 2.00131604]
 [ 4.04289251]
 [-1.02211162]] loss fxn value:  0.011653912980996951 learn rate: 1.5625e-05 iteration: 27461
[[ 2.00131604]
 [ 4.04289251]
 [-1.0221118 ]] loss fxn value:  0.011650676090754358 learn rate: 1.5625e-05 iteration: 27462
[[ 2.00131604]
 [ 4.04289251]
 [-1.02211198]] loss fxn value:  0.011647440099528518 learn rate: 1.5625e-05 iteration: 27463
[[ 2.00131605]
 [ 4.04289251]
 [-1.02211216]] loss fxn value:  0.01164420500813393 learn rate: 1.5625e-05 iteration: 27464
[[ 2.00131605]
 [ 4.04289251]
 [-1.02211234]] loss fxn value:  0.011640970814299515 learn rate: 1.5625e-05 iteration: 27465
[[ 2.00131605]
 [ 4.04289251]
 [-1.02211252]] loss fxn value:  0.011637737519380076 learn rate: 1.5625e-05 iteration: 27466
[[ 2.00131606]
 [ 4.04289252]
 [-1.02211271]] loss fxn value:  0.011634505121601595 learn rate: 1.5625e-05 iteration: 27467
[[ 2.00131606]
 [ 4.04289252]
 [-1.02211289]] loss fxn value:  0.011631273622830637 learn rate: 1.5625e-05 iteration: 27468
[[ 2.00131606]
 [ 4.04289252]
 [-1.02211307]] loss fxn value:  0.01162804302101554 learn rate: 1.5625e-05 iteration: 27469
[[ 2.00131607]
 [ 4.04289252]
 [-1.02211325]] loss fxn value:  0.011624813316029431 learn rate: 1.5625e-05 iteration: 27470
[[ 2.00131607]
 [ 4.04289252]
 [-1.02211343]] loss fxn value:  0.011621584509446538 learn rate: 1.5625e-05 iteration: 27471
[[ 2.00131607]
 [ 4.04289252]
 [-1.02211362]] loss fxn value:  0.01161835659763866 learn rate: 1.5625e-05 iteration: 27472
[[ 2.00131608]
 [ 4.04289252]
 [-1.0221138 ]] loss fxn value:  0.011615129584050041 learn rate: 1.5625e-05 iteration: 27473
[[ 2.00131608]
 [ 4.04289252]
 [-1.02211398]] loss fxn value:  0.011611903466027014 learn rate: 1.5625e-05 iteration: 27474
[[ 2.00131608]
 [ 4.04289252]
 [-1.02211416]] loss fxn value:  0.011608678244371375 learn rate: 1.5625e-05 iteration: 27475
[[ 2.00131608]
 [ 4.04289252]
 [-1.02211434]] loss fxn value:  0.011605453918312176 learn rate: 1.5625e-05 iteration: 27476
[[ 2.00131609]
 [ 4.04289253]
 [-1.02211452]] loss fxn value:  0.011602230488146376 learn rate: 1.5625e-05 iteration: 27477
[[ 2.00131609]
 [ 4.04289253]
 [-1.0221147 ]] loss fxn value:  0.011599007952737132 learn rate: 1.5625e-05 iteration: 27478
[[ 2.00131609]
 [ 4.04289253]
 [-1.02211488]] loss fxn value:  0.011595786313104813 learn rate: 1.5625e-05 iteration: 27479
[[ 2.0013161 ]
 [ 4.04289253]
 [-1.02211507]] loss fxn value:  0.011592565568361678 learn rate: 1.5625e-05 iteration: 27480
[[ 2.0013161 ]
 [ 4.04289253]
 [-1.02211525]] loss fxn value:  0.011589345717022605 learn rate: 1.5625e-05 iteration: 27481
[[ 2.0013161 ]
 [ 4.04289253]
 [-1.02211543]] loss fxn value:  0.011586126761062859 learn rate: 1.5625e-05 iteration: 27482
[[ 2.00131611]
 [ 4.04289253]
 [-1.02211561]] loss fxn value:  0.011582908698535717 learn rate: 1.5625e-05 iteration: 27483
[[ 2.00131611]
 [ 4.04289253]
 [-1.02211579]] loss fxn value:  0.01157969152990278 learn rate: 1.5625e-05 iteration: 27484
[[ 2.00131611]
 [ 4.04289253]
 [-1.02211597]] loss fxn value:  0.011576475255363837 learn rate: 1.5625e-05 iteration: 27485
[[ 2.00131611]
 [ 4.04289253]
 [-1.02211615]] loss fxn value:  0.01157325987463578 learn rate: 1.5625e-05 iteration: 27486
[[ 2.00131612]
 [ 4.04289253]
 [-1.02211633]] loss fxn value:  0.011570045385519305 learn rate: 1.5625e-05 iteration: 27487
[[ 2.00131612]
 [ 4.04289254]
 [-1.02211651]] loss fxn value:  0.011566831789541925 learn rate: 1.5625e-05 iteration: 27488
[[ 2.00131612]
 [ 4.04289254]
 [-1.02211669]] loss fxn value:  0.011563619087501987 learn rate: 1.5625e-05 iteration: 27489
[[ 2.00131613]
 [ 4.04289254]
 [-1.02211687]] loss fxn value:  0.011560407276114114 learn rate: 1.5625e-05 iteration: 27490
[[ 2.00131613]
 [ 4.04289254]
 [-1.02211706]] loss fxn value:  0.011557196357860719 learn rate: 1.5625e-05 iteration: 27491
[[ 2.00131613]
 [ 4.04289254]
 [-1.02211724]] loss fxn value:  0.011553986331223523 learn rate: 1.5625e-05 iteration: 27492
[[ 2.00131614]
 [ 4.04289254]
 [-1.02211742]] loss fxn value:  0.011550777195266931 learn rate: 1.5625e-05 iteration: 27493
[[ 2.00131614]
 [ 4.04289254]
 [-1.0221176 ]] loss fxn value:  0.011547568952075768 learn rate: 1.5625e-05 iteration: 27494
[[ 2.00131614]
 [ 4.04289254]
 [-1.02211778]] loss fxn value:  0.011544361598987137 learn rate: 1.5625e-05 iteration: 27495
[[ 2.00131614]
 [ 4.04289254]
 [-1.02211796]] loss fxn value:  0.011541155137176498 learn rate: 1.5625e-05 iteration: 27496
[[ 2.00131615]
 [ 4.04289254]
 [-1.02211814]] loss fxn value:  0.011537949566167556 learn rate: 1.5625e-05 iteration: 27497
[[ 2.00131615]
 [ 4.04289254]
 [-1.02211832]] loss fxn value:  0.011534744885389157 learn rate: 1.5625e-05 iteration: 27498
[[ 2.00131615]
 [ 4.04289255]
 [-1.0221185 ]] loss fxn value:  0.011531541094006035 learn rate: 1.5625e-05 iteration: 27499
[[ 2.00131616]
 [ 4.04289255]
 [-1.02211868]] loss fxn value:  0.011528338193393758 learn rate: 1.5625e-05 iteration: 27500
[[ 2.00131616]
 [ 4.04289255]
 [-1.02211886]] loss fxn value:  0.011525136182216837 learn rate: 1.5625e-05 iteration: 27501
[[ 2.00131616]
 [ 4.04289255]
 [-1.02211904]] loss fxn value:  0.01152193506035418 learn rate: 1.5625e-05 iteration: 27502
[[ 2.00131617]
 [ 4.04289255]
 [-1.02211922]] loss fxn value:  0.011518734827436735 learn rate: 1.5625e-05 iteration: 27503
[[ 2.00131617]
 [ 4.04289255]
 [-1.0221194 ]] loss fxn value:  0.011515535482559762 learn rate: 1.5625e-05 iteration: 27504
[[ 2.00131617]
 [ 4.04289255]
 [-1.02211958]] loss fxn value:  0.011512337027570513 learn rate: 1.5625e-05 iteration: 27505
[[ 2.00131617]
 [ 4.04289255]
 [-1.02211976]] loss fxn value:  0.0115091394605338 learn rate: 1.5625e-05 iteration: 27506
[[ 2.00131618]
 [ 4.04289255]
 [-1.02211994]] loss fxn value:  0.011505942781601566 learn rate: 1.5625e-05 iteration: 27507
[[ 2.00131618]
 [ 4.04289255]
 [-1.02212012]] loss fxn value:  0.011502746990129419 learn rate: 1.5625e-05 iteration: 27508
[[ 2.00131618]
 [ 4.04289255]
 [-1.0221203 ]] loss fxn value:  0.01149955208723343 learn rate: 1.5625e-05 iteration: 27509
[[ 2.00131619]
 [ 4.04289256]
 [-1.02212048]] loss fxn value:  0.011496358070959101 learn rate: 1.5625e-05 iteration: 27510
[[ 2.00131619]
 [ 4.04289256]
 [-1.02212066]] loss fxn value:  0.011493164942758401 learn rate: 1.5625e-05 iteration: 27511
[[ 2.00131619]
 [ 4.04289256]
 [-1.02212084]] loss fxn value:  0.011489972700660675 learn rate: 1.5625e-05 iteration: 27512
[[ 2.0013162 ]
 [ 4.04289256]
 [-1.02212102]] loss fxn value:  0.01148678134532501 learn rate: 1.5625e-05 iteration: 27513
[[ 2.0013162 ]
 [ 4.04289256]
 [-1.0221212 ]] loss fxn value:  0.011483590876154021 learn rate: 1.5625e-05 iteration: 27514
[[ 2.0013162 ]
 [ 4.04289256]
 [-1.02212137]] loss fxn value:  0.011480401293652543 learn rate: 1.5625e-05 iteration: 27515
[[ 2.0013162 ]
 [ 4.04289256]
 [-1.02212155]] loss fxn value:  0.01147721259643031 learn rate: 1.5625e-05 iteration: 27516
[[ 2.00131621]
 [ 4.04289256]
 [-1.02212173]] loss fxn value:  0.011474024785472223 learn rate: 1.5625e-05 iteration: 27517
[[ 2.00131621]
 [ 4.04289256]
 [-1.02212191]] loss fxn value:  0.01147083785920838 learn rate: 1.5625e-05 iteration: 27518
[[ 2.00131621]
 [ 4.04289256]
 [-1.02212209]] loss fxn value:  0.011467651818380338 learn rate: 1.5625e-05 iteration: 27519
[[ 2.00131622]
 [ 4.04289256]
 [-1.02212227]] loss fxn value:  0.011464466664257272 learn rate: 1.5625e-05 iteration: 27520
[[ 2.00131622]
 [ 4.04289257]
 [-1.02212245]] loss fxn value:  0.011461282392514132 learn rate: 1.5625e-05 iteration: 27521
[[ 2.00131622]
 [ 4.04289257]
 [-1.02212263]] loss fxn value:  0.011458099006711629 learn rate: 1.5625e-05 iteration: 27522
[[ 2.00131623]
 [ 4.04289257]
 [-1.02212281]] loss fxn value:  0.011454916503767653 learn rate: 1.5625e-05 iteration: 27523
[[ 2.00131623]
 [ 4.04289257]
 [-1.02212299]] loss fxn value:  0.011451734885345505 learn rate: 1.5625e-05 iteration: 27524
[[ 2.00131623]
 [ 4.04289257]
 [-1.02212317]] loss fxn value:  0.011448554150329115 learn rate: 1.5625e-05 iteration: 27525
[[ 2.00131623]
 [ 4.04289257]
 [-1.02212334]] loss fxn value:  0.011445374299770545 learn rate: 1.5625e-05 iteration: 27526
[[ 2.00131624]
 [ 4.04289257]
 [-1.02212352]] loss fxn value:  0.011442195331256002 learn rate: 1.5625e-05 iteration: 27527
[[ 2.00131624]
 [ 4.04289257]
 [-1.0221237 ]] loss fxn value:  0.01143901724623284 learn rate: 1.5625e-05 iteration: 27528
[[ 2.00131624]
 [ 4.04289257]
 [-1.02212388]] loss fxn value:  0.011435840043727696 learn rate: 1.5625e-05 iteration: 27529
[[ 2.00131625]
 [ 4.04289257]
 [-1.02212406]] loss fxn value:  0.011432663724415811 learn rate: 1.5625e-05 iteration: 27530
[[ 2.00131625]
 [ 4.04289257]
 [-1.02212424]] loss fxn value:  0.011429488286115199 learn rate: 1.5625e-05 iteration: 27531
[[ 2.00131625]
 [ 4.04289258]
 [-1.02212442]] loss fxn value:  0.011426313730486852 learn rate: 1.5625e-05 iteration: 27532
[[ 2.00131626]
 [ 4.04289258]
 [-1.0221246 ]] loss fxn value:  0.011423140056498018 learn rate: 1.5625e-05 iteration: 27533
[[ 2.00131626]
 [ 4.04289258]
 [-1.02212477]] loss fxn value:  0.011419967264157923 learn rate: 1.5625e-05 iteration: 27534
[[ 2.00131626]
 [ 4.04289258]
 [-1.02212495]] loss fxn value:  0.01141679535352596 learn rate: 1.5625e-05 iteration: 27535
[[ 2.00131626]
 [ 4.04289258]
 [-1.02212513]] loss fxn value:  0.01141362432310547 learn rate: 1.5625e-05 iteration: 27536
[[ 2.00131627]
 [ 4.04289258]
 [-1.02212531]] loss fxn value:  0.011410454172998226 learn rate: 1.5625e-05 iteration: 27537
[[ 2.00131627]
 [ 4.04289258]
 [-1.02212549]] loss fxn value:  0.011407284904199214 learn rate: 1.5625e-05 iteration: 27538
[[ 2.00131627]
 [ 4.04289258]
 [-1.02212567]] loss fxn value:  0.011404116516016189 learn rate: 1.5625e-05 iteration: 27539
[[ 2.00131628]
 [ 4.04289258]
 [-1.02212584]] loss fxn value:  0.011400949007751125 learn rate: 1.5625e-05 iteration: 27540
[[ 2.00131628]
 [ 4.04289258]
 [-1.02212602]] loss fxn value:  0.01139778237839981 learn rate: 1.5625e-05 iteration: 27541
[[ 2.00131628]
 [ 4.04289258]
 [-1.0221262 ]] loss fxn value:  0.01139461662932628 learn rate: 1.5625e-05 iteration: 27542
[[ 2.00131629]
 [ 4.04289259]
 [-1.02212638]] loss fxn value:  0.011391451758714128 learn rate: 1.5625e-05 iteration: 27543
[[ 2.00131629]
 [ 4.04289259]
 [-1.02212656]] loss fxn value:  0.01138828776845069 learn rate: 1.5625e-05 iteration: 27544
[[ 2.00131629]
 [ 4.04289259]
 [-1.02212673]] loss fxn value:  0.011385124655277672 learn rate: 1.5625e-05 iteration: 27545
[[ 2.00131629]
 [ 4.04289259]
 [-1.02212691]] loss fxn value:  0.011381962422415596 learn rate: 1.5625e-05 iteration: 27546
[[ 2.0013163 ]
 [ 4.04289259]
 [-1.02212709]] loss fxn value:  0.011378801066620014 learn rate: 1.5625e-05 iteration: 27547
[[ 2.0013163 ]
 [ 4.04289259]
 [-1.02212727]] loss fxn value:  0.01137564059028541 learn rate: 1.5625e-05 iteration: 27548
[[ 2.0013163 ]
 [ 4.04289259]
 [-1.02212744]] loss fxn value:  0.01137248099002001 learn rate: 1.5625e-05 iteration: 27549
[[ 2.00131631]
 [ 4.04289259]
 [-1.02212762]] loss fxn value:  0.01136932226836331 learn rate: 1.5625e-05 iteration: 27550
[[ 2.00131631]
 [ 4.04289259]
 [-1.0221278 ]] loss fxn value:  0.011366164424260944 learn rate: 1.5625e-05 iteration: 27551
[[ 2.00131631]
 [ 4.04289259]
 [-1.02212798]] loss fxn value:  0.01136300745674416 learn rate: 1.5625e-05 iteration: 27552
[[ 2.00131631]
 [ 4.04289259]
 [-1.02212816]] loss fxn value:  0.011359851365927123 learn rate: 1.5625e-05 iteration: 27553
[[ 2.00131632]
 [ 4.0428926 ]
 [-1.02212833]] loss fxn value:  0.011356696151752752 learn rate: 1.5625e-05 iteration: 27554
[[ 2.00131632]
 [ 4.0428926 ]
 [-1.02212851]] loss fxn value:  0.011353541814249591 learn rate: 1.5625e-05 iteration: 27555
[[ 2.00131632]
 [ 4.0428926 ]
 [-1.02212869]] loss fxn value:  0.011350388353479336 learn rate: 1.5625e-05 iteration: 27556
[[ 2.00131633]
 [ 4.0428926 ]
 [-1.02212886]] loss fxn value:  0.011347235767357166 learn rate: 1.5625e-05 iteration: 27557
[[ 2.00131633]
 [ 4.0428926 ]
 [-1.02212904]] loss fxn value:  0.011344084057627393 learn rate: 1.5625e-05 iteration: 27558
[[ 2.00131633]
 [ 4.0428926 ]
 [-1.02212922]] loss fxn value:  0.011340933223573844 learn rate: 1.5625e-05 iteration: 27559
[[ 2.00131634]
 [ 4.0428926 ]
 [-1.0221294 ]] loss fxn value:  0.011337783263370888 learn rate: 1.5625e-05 iteration: 27560
[[ 2.00131634]
 [ 4.0428926 ]
 [-1.02212957]] loss fxn value:  0.01133463417905318 learn rate: 1.5625e-05 iteration: 27561
[[ 2.00131634]
 [ 4.0428926 ]
 [-1.02212975]] loss fxn value:  0.01133148596904997 learn rate: 1.5625e-05 iteration: 27562
[[ 2.00131634]
 [ 4.0428926 ]
 [-1.02212993]] loss fxn value:  0.011328338634353934 learn rate: 1.5625e-05 iteration: 27563
[[ 2.00131635]
 [ 4.0428926 ]
 [-1.0221301 ]] loss fxn value:  0.011325192172687064 learn rate: 1.5625e-05 iteration: 27564
[[ 2.00131635]
 [ 4.04289261]
 [-1.02213028]] loss fxn value:  0.011322046585365543 learn rate: 1.5625e-05 iteration: 27565
[[ 2.00131635]
 [ 4.04289261]
 [-1.02213046]] loss fxn value:  0.011318901871527867 learn rate: 1.5625e-05 iteration: 27566
[[ 2.00131636]
 [ 4.04289261]
 [-1.02213064]] loss fxn value:  0.01131575803118096 learn rate: 1.5625e-05 iteration: 27567
[[ 2.00131636]
 [ 4.04289261]
 [-1.02213081]] loss fxn value:  0.011312615064812655 learn rate: 1.5625e-05 iteration: 27568
[[ 2.00131636]
 [ 4.04289261]
 [-1.02213099]] loss fxn value:  0.01130947297090467 learn rate: 1.5625e-05 iteration: 27569
[[ 2.00131636]
 [ 4.04289261]
 [-1.02213117]] loss fxn value:  0.01130633174917358 learn rate: 1.5625e-05 iteration: 27570
[[ 2.00131637]
 [ 4.04289261]
 [-1.02213134]] loss fxn value:  0.011303191400937874 learn rate: 1.5625e-05 iteration: 27571
[[ 2.00131637]
 [ 4.04289261]
 [-1.02213152]] loss fxn value:  0.011300051923831609 learn rate: 1.5625e-05 iteration: 27572
[[ 2.00131637]
 [ 4.04289261]
 [-1.0221317 ]] loss fxn value:  0.011296913318906856 learn rate: 1.5625e-05 iteration: 27573
[[ 2.00131638]
 [ 4.04289261]
 [-1.02213187]] loss fxn value:  0.011293775586054058 learn rate: 1.5625e-05 iteration: 27574
[[ 2.00131638]
 [ 4.04289261]
 [-1.02213205]] loss fxn value:  0.011290638725349614 learn rate: 1.5625e-05 iteration: 27575
[[ 2.00131638]
 [ 4.04289261]
 [-1.02213222]] loss fxn value:  0.0112875027352937 learn rate: 1.5625e-05 iteration: 27576
[[ 2.00131639]
 [ 4.04289262]
 [-1.0221324 ]] loss fxn value:  0.011284367617019394 learn rate: 1.5625e-05 iteration: 27577
[[ 2.00131639]
 [ 4.04289262]
 [-1.02213258]] loss fxn value:  0.011281233367998736 learn rate: 1.5625e-05 iteration: 27578
[[ 2.00131639]
 [ 4.04289262]
 [-1.02213275]] loss fxn value:  0.011278099990795149 learn rate: 1.5625e-05 iteration: 27579
[[ 2.00131639]
 [ 4.04289262]
 [-1.02213293]] loss fxn value:  0.01127496748375918 learn rate: 1.5625e-05 iteration: 27580
[[ 2.0013164 ]
 [ 4.04289262]
 [-1.02213311]] loss fxn value:  0.01127183584565566 learn rate: 1.5625e-05 iteration: 27581
[[ 2.0013164 ]
 [ 4.04289262]
 [-1.02213328]] loss fxn value:  0.011268705078378844 learn rate: 1.5625e-05 iteration: 27582
[[ 2.0013164 ]
 [ 4.04289262]
 [-1.02213346]] loss fxn value:  0.011265575180434377 learn rate: 1.5625e-05 iteration: 27583
[[ 2.00131641]
 [ 4.04289262]
 [-1.02213363]] loss fxn value:  0.01126244615135058 learn rate: 1.5625e-05 iteration: 27584
[[ 2.00131641]
 [ 4.04289262]
 [-1.02213381]] loss fxn value:  0.011259317992715203 learn rate: 1.5625e-05 iteration: 27585
[[ 2.00131641]
 [ 4.04289262]
 [-1.02213399]] loss fxn value:  0.01125619070100069 learn rate: 1.5625e-05 iteration: 27586
[[ 2.00131641]
 [ 4.04289262]
 [-1.02213416]] loss fxn value:  0.011253064280246364 learn rate: 1.5625e-05 iteration: 27587
[[ 2.00131642]
 [ 4.04289263]
 [-1.02213434]] loss fxn value:  0.011249938725931989 learn rate: 1.5625e-05 iteration: 27588
[[ 2.00131642]
 [ 4.04289263]
 [-1.02213451]] loss fxn value:  0.011246814040218782 learn rate: 1.5625e-05 iteration: 27589
[[ 2.00131642]
 [ 4.04289263]
 [-1.02213469]] loss fxn value:  0.011243690222937797 learn rate: 1.5625e-05 iteration: 27590
[[ 2.00131643]
 [ 4.04289263]
 [-1.02213486]] loss fxn value:  0.011240567272806014 learn rate: 1.5625e-05 iteration: 27591
[[ 2.00131643]
 [ 4.04289263]
 [-1.02213504]] loss fxn value:  0.011237445190168555 learn rate: 1.5625e-05 iteration: 27592
[[ 2.00131643]
 [ 4.04289263]
 [-1.02213522]] loss fxn value:  0.01123432397471576 learn rate: 1.5625e-05 iteration: 27593
[[ 2.00131644]
 [ 4.04289263]
 [-1.02213539]] loss fxn value:  0.011231203625869554 learn rate: 1.5625e-05 iteration: 27594
[[ 2.00131644]
 [ 4.04289263]
 [-1.02213557]] loss fxn value:  0.0112280841436654 learn rate: 1.5625e-05 iteration: 27595
[[ 2.00131644]
 [ 4.04289263]
 [-1.02213574]] loss fxn value:  0.011224965528674453 learn rate: 1.5625e-05 iteration: 27596
[[ 2.00131644]
 [ 4.04289263]
 [-1.02213592]] loss fxn value:  0.011221847779749789 learn rate: 1.5625e-05 iteration: 27597
[[ 2.00131645]
 [ 4.04289263]
 [-1.02213609]] loss fxn value:  0.011218730896638834 learn rate: 1.5625e-05 iteration: 27598
[[ 2.00131645]
 [ 4.04289264]
 [-1.02213627]] loss fxn value:  0.011215614878324983 learn rate: 1.5625e-05 iteration: 27599
[[ 2.00131645]
 [ 4.04289264]
 [-1.02213644]] loss fxn value:  0.011212499726712576 learn rate: 1.5625e-05 iteration: 27600
[[ 2.00131646]
 [ 4.04289264]
 [-1.02213662]] loss fxn value:  0.011209385440373573 learn rate: 1.5625e-05 iteration: 27601
[[ 2.00131646]
 [ 4.04289264]
 [-1.02213679]] loss fxn value:  0.01120627201885791 learn rate: 1.5625e-05 iteration: 27602
[[ 2.00131646]
 [ 4.04289264]
 [-1.02213697]] loss fxn value:  0.011203159461737142 learn rate: 1.5625e-05 iteration: 27603
[[ 2.00131646]
 [ 4.04289264]
 [-1.02213714]] loss fxn value:  0.011200047768975806 learn rate: 1.5625e-05 iteration: 27604
[[ 2.00131647]
 [ 4.04289264]
 [-1.02213732]] loss fxn value:  0.01119693694064483 learn rate: 1.5625e-05 iteration: 27605
[[ 2.00131647]
 [ 4.04289264]
 [-1.02213749]] loss fxn value:  0.011193826976130675 learn rate: 1.5625e-05 iteration: 27606
[[ 2.00131647]
 [ 4.04289264]
 [-1.02213767]] loss fxn value:  0.011190717875680135 learn rate: 1.5625e-05 iteration: 27607
[[ 2.00131648]
 [ 4.04289264]
 [-1.02213784]] loss fxn value:  0.011187609639086495 learn rate: 1.5625e-05 iteration: 27608
[[ 2.00131648]
 [ 4.04289264]
 [-1.02213802]] loss fxn value:  0.01118450226458351 learn rate: 1.5625e-05 iteration: 27609
[[ 2.00131648]
 [ 4.04289265]
 [-1.02213819]] loss fxn value:  0.011181395754925485 learn rate: 1.5625e-05 iteration: 27610
[[ 2.00131649]
 [ 4.04289265]
 [-1.02213837]] loss fxn value:  0.011178290106967444 learn rate: 1.5625e-05 iteration: 27611
[[ 2.00131649]
 [ 4.04289265]
 [-1.02213854]] loss fxn value:  0.011175185322473323 learn rate: 1.5625e-05 iteration: 27612
[[ 2.00131649]
 [ 4.04289265]
 [-1.02213872]] loss fxn value:  0.011172081398610968 learn rate: 1.5625e-05 iteration: 27613
[[ 2.00131649]
 [ 4.04289265]
 [-1.02213889]] loss fxn value:  0.01116897833884077 learn rate: 1.5625e-05 iteration: 27614
[[ 2.0013165 ]
 [ 4.04289265]
 [-1.02213907]] loss fxn value:  0.011165876140166245 learn rate: 1.5625e-05 iteration: 27615
[[ 2.0013165 ]
 [ 4.04289265]
 [-1.02213924]] loss fxn value:  0.011162774803156238 learn rate: 1.5625e-05 iteration: 27616
[[ 2.0013165 ]
 [ 4.04289265]
 [-1.02213941]] loss fxn value:  0.011159674327334456 learn rate: 1.5625e-05 iteration: 27617
[[ 2.00131651]
 [ 4.04289265]
 [-1.02213959]] loss fxn value:  0.011156574712746437 learn rate: 1.5625e-05 iteration: 27618
[[ 2.00131651]
 [ 4.04289265]
 [-1.02213976]] loss fxn value:  0.011153475959375186 learn rate: 1.5625e-05 iteration: 27619
[[ 2.00131651]
 [ 4.04289265]
 [-1.02213994]] loss fxn value:  0.011150378066671164 learn rate: 1.5625e-05 iteration: 27620
[[ 2.00131651]
 [ 4.04289265]
 [-1.02214011]] loss fxn value:  0.011147281034305397 learn rate: 1.5625e-05 iteration: 27621
[[ 2.00131652]
 [ 4.04289266]
 [-1.02214029]] loss fxn value:  0.011144184861728353 learn rate: 1.5625e-05 iteration: 27622
[[ 2.00131652]
 [ 4.04289266]
 [-1.02214046]] loss fxn value:  0.01114108954950888 learn rate: 1.5625e-05 iteration: 27623
[[ 2.00131652]
 [ 4.04289266]
 [-1.02214063]] loss fxn value:  0.011137995097108975 learn rate: 1.5625e-05 iteration: 27624
[[ 2.00131653]
 [ 4.04289266]
 [-1.02214081]] loss fxn value:  0.01113490150356682 learn rate: 1.5625e-05 iteration: 27625
[[ 2.00131653]
 [ 4.04289266]
 [-1.02214098]] loss fxn value:  0.01113180877041539 learn rate: 1.5625e-05 iteration: 27626
[[ 2.00131653]
 [ 4.04289266]
 [-1.02214116]] loss fxn value:  0.01112871689514142 learn rate: 1.5625e-05 iteration: 27627
[[ 2.00131653]
 [ 4.04289266]
 [-1.02214133]] loss fxn value:  0.011125625878927299 learn rate: 1.5625e-05 iteration: 27628
[[ 2.00131654]
 [ 4.04289266]
 [-1.0221415 ]] loss fxn value:  0.011122535721594851 learn rate: 1.5625e-05 iteration: 27629
[[ 2.00131654]
 [ 4.04289266]
 [-1.02214168]] loss fxn value:  0.011119446422722555 learn rate: 1.5625e-05 iteration: 27630
[[ 2.00131654]
 [ 4.04289266]
 [-1.02214185]] loss fxn value:  0.011116357981848813 learn rate: 1.5625e-05 iteration: 27631
[[ 2.00131655]
 [ 4.04289266]
 [-1.02214202]] loss fxn value:  0.011113270398114425 learn rate: 1.5625e-05 iteration: 27632
[[ 2.00131655]
 [ 4.04289267]
 [-1.0221422 ]] loss fxn value:  0.011110183671878365 learn rate: 1.5625e-05 iteration: 27633
[[ 2.00131655]
 [ 4.04289267]
 [-1.02214237]] loss fxn value:  0.011107097803752719 learn rate: 1.5625e-05 iteration: 27634
[[ 2.00131655]
 [ 4.04289267]
 [-1.02214255]] loss fxn value:  0.011104012792666105 learn rate: 1.5625e-05 iteration: 27635
[[ 2.00131656]
 [ 4.04289267]
 [-1.02214272]] loss fxn value:  0.011100928638721154 learn rate: 1.5625e-05 iteration: 27636
[[ 2.00131656]
 [ 4.04289267]
 [-1.02214289]] loss fxn value:  0.01109784534090588 learn rate: 1.5625e-05 iteration: 27637
[[ 2.00131656]
 [ 4.04289267]
 [-1.02214307]] loss fxn value:  0.01109476289893686 learn rate: 1.5625e-05 iteration: 27638
[[ 2.00131657]
 [ 4.04289267]
 [-1.02214324]] loss fxn value:  0.011091681313997641 learn rate: 1.5625e-05 iteration: 27639
[[ 2.00131657]
 [ 4.04289267]
 [-1.02214341]] loss fxn value:  0.01108860058524057 learn rate: 1.5625e-05 iteration: 27640
[[ 2.00131657]
 [ 4.04289267]
 [-1.02214359]] loss fxn value:  0.01108552071044703 learn rate: 1.5625e-05 iteration: 27641
[[ 2.00131658]
 [ 4.04289267]
 [-1.02214376]] loss fxn value:  0.011082441692778153 learn rate: 1.5625e-05 iteration: 27642
[[ 2.00131658]
 [ 4.04289267]
 [-1.02214393]] loss fxn value:  0.011079363529865686 learn rate: 1.5625e-05 iteration: 27643
[[ 2.00131658]
 [ 4.04289268]
 [-1.0221441 ]] loss fxn value:  0.011076286221866186 learn rate: 1.5625e-05 iteration: 27644
[[ 2.00131658]
 [ 4.04289268]
 [-1.02214428]] loss fxn value:  0.01107320976819004 learn rate: 1.5625e-05 iteration: 27645
[[ 2.00131659]
 [ 4.04289268]
 [-1.02214445]] loss fxn value:  0.011070134169848384 learn rate: 1.5625e-05 iteration: 27646
[[ 2.00131659]
 [ 4.04289268]
 [-1.02214462]] loss fxn value:  0.01106705942493457 learn rate: 1.5625e-05 iteration: 27647
[[ 2.00131659]
 [ 4.04289268]
 [-1.0221448 ]] loss fxn value:  0.011063985533927205 learn rate: 1.5625e-05 iteration: 27648
[[ 2.0013166 ]
 [ 4.04289268]
 [-1.02214497]] loss fxn value:  0.01106091249736659 learn rate: 1.5625e-05 iteration: 27649
[[ 2.0013166 ]
 [ 4.04289268]
 [-1.02214514]] loss fxn value:  0.011057840314233819 learn rate: 1.5625e-05 iteration: 27650
[[ 2.0013166 ]
 [ 4.04289268]
 [-1.02214532]] loss fxn value:  0.011054768984557432 learn rate: 1.5625e-05 iteration: 27651
[[ 2.0013166 ]
 [ 4.04289268]
 [-1.02214549]] loss fxn value:  0.011051698507454308 learn rate: 1.5625e-05 iteration: 27652
[[ 2.00131661]
 [ 4.04289268]
 [-1.02214566]] loss fxn value:  0.011048628883341351 learn rate: 1.5625e-05 iteration: 27653
[[ 2.00131661]
 [ 4.04289268]
 [-1.02214583]] loss fxn value:  0.011045560111353903 learn rate: 1.5625e-05 iteration: 27654
[[ 2.00131661]
 [ 4.04289268]
 [-1.02214601]] loss fxn value:  0.011042492192875307 learn rate: 1.5625e-05 iteration: 27655
[[ 2.00131662]
 [ 4.04289269]
 [-1.02214618]] loss fxn value:  0.011039425125527238 learn rate: 1.5625e-05 iteration: 27656
[[ 2.00131662]
 [ 4.04289269]
 [-1.02214635]] loss fxn value:  0.011036358910716965 learn rate: 1.5625e-05 iteration: 27657
[[ 2.00131662]
 [ 4.04289269]
 [-1.02214652]] loss fxn value:  0.01103329354717762 learn rate: 1.5625e-05 iteration: 27658
[[ 2.00131662]
 [ 4.04289269]
 [-1.0221467 ]] loss fxn value:  0.011030229034814345 learn rate: 1.5625e-05 iteration: 27659
[[ 2.00131663]
 [ 4.04289269]
 [-1.02214687]] loss fxn value:  0.011027165373603215 learn rate: 1.5625e-05 iteration: 27660
[[ 2.00131663]
 [ 4.04289269]
 [-1.02214704]] loss fxn value:  0.011024102563632161 learn rate: 1.5625e-05 iteration: 27661
[[ 2.00131663]
 [ 4.04289269]
 [-1.02214721]] loss fxn value:  0.011021040605298781 learn rate: 1.5625e-05 iteration: 27662
[[ 2.00131664]
 [ 4.04289269]
 [-1.02214738]] loss fxn value:  0.011017979496325065 learn rate: 1.5625e-05 iteration: 27663
[[ 2.00131664]
 [ 4.04289269]
 [-1.02214756]] loss fxn value:  0.011014919238079665 learn rate: 1.5625e-05 iteration: 27664
[[ 2.00131664]
 [ 4.04289269]
 [-1.02214773]] loss fxn value:  0.011011859829708 learn rate: 1.5625e-05 iteration: 27665
[[ 2.00131664]
 [ 4.04289269]
 [-1.0221479 ]] loss fxn value:  0.011008801270215089 learn rate: 1.5625e-05 iteration: 27666
[[ 2.00131665]
 [ 4.0428927 ]
 [-1.02214807]] loss fxn value:  0.011005743560624453 learn rate: 1.5625e-05 iteration: 27667
[[ 2.00131665]
 [ 4.0428927 ]
 [-1.02214824]] loss fxn value:  0.011002686701278915 learn rate: 1.5625e-05 iteration: 27668
[[ 2.00131665]
 [ 4.0428927 ]
 [-1.02214842]] loss fxn value:  0.01099963068989585 learn rate: 1.5625e-05 iteration: 27669
[[ 2.00131666]
 [ 4.0428927 ]
 [-1.02214859]] loss fxn value:  0.010996575527965 learn rate: 1.5625e-05 iteration: 27670
[[ 2.00131666]
 [ 4.0428927 ]
 [-1.02214876]] loss fxn value:  0.010993521213939537 learn rate: 1.5625e-05 iteration: 27671
[[ 2.00131666]
 [ 4.0428927 ]
 [-1.02214893]] loss fxn value:  0.010990467748971004 learn rate: 1.5625e-05 iteration: 27672
[[ 2.00131666]
 [ 4.0428927 ]
 [-1.0221491 ]] loss fxn value:  0.010987415132393388 learn rate: 1.5625e-05 iteration: 27673
[[ 2.00131667]
 [ 4.0428927 ]
 [-1.02214928]] loss fxn value:  0.01098436336335903 learn rate: 1.5625e-05 iteration: 27674
[[ 2.00131667]
 [ 4.0428927 ]
 [-1.02214945]] loss fxn value:  0.010981312440958579 learn rate: 1.5625e-05 iteration: 27675
[[ 2.00131667]
 [ 4.0428927 ]
 [-1.02214962]] loss fxn value:  0.01097826236667485 learn rate: 1.5625e-05 iteration: 27676
[[ 2.00131668]
 [ 4.0428927 ]
 [-1.02214979]] loss fxn value:  0.010975213139846446 learn rate: 1.5625e-05 iteration: 27677
[[ 2.00131668]
 [ 4.0428927 ]
 [-1.02214996]] loss fxn value:  0.01097216475876421 learn rate: 1.5625e-05 iteration: 27678
[[ 2.00131668]
 [ 4.04289271]
 [-1.02215013]] loss fxn value:  0.01096911722577246 learn rate: 1.5625e-05 iteration: 27679
[[ 2.00131668]
 [ 4.04289271]
 [-1.0221503 ]] loss fxn value:  0.010966070539328989 learn rate: 1.5625e-05 iteration: 27680
[[ 2.00131669]
 [ 4.04289271]
 [-1.02215048]] loss fxn value:  0.010963024698629377 learn rate: 1.5625e-05 iteration: 27681
[[ 2.00131669]
 [ 4.04289271]
 [-1.02215065]] loss fxn value:  0.010959979703780017 learn rate: 1.5625e-05 iteration: 27682
[[ 2.00131669]
 [ 4.04289271]
 [-1.02215082]] loss fxn value:  0.010956935554500958 learn rate: 1.5625e-05 iteration: 27683
[[ 2.0013167 ]
 [ 4.04289271]
 [-1.02215099]] loss fxn value:  0.01095389225067225 learn rate: 1.5625e-05 iteration: 27684
[[ 2.0013167 ]
 [ 4.04289271]
 [-1.02215116]] loss fxn value:  0.010950849792513314 learn rate: 1.5625e-05 iteration: 27685
[[ 2.0013167 ]
 [ 4.04289271]
 [-1.02215133]] loss fxn value:  0.010947808179617323 learn rate: 1.5625e-05 iteration: 27686
[[ 2.0013167 ]
 [ 4.04289271]
 [-1.0221515 ]] loss fxn value:  0.010944767411598224 learn rate: 1.5625e-05 iteration: 27687
[[ 2.00131671]
 [ 4.04289271]
 [-1.02215167]] loss fxn value:  0.01094172748739241 learn rate: 1.5625e-05 iteration: 27688
[[ 2.00131671]
 [ 4.04289271]
 [-1.02215184]] loss fxn value:  0.010938688407703664 learn rate: 1.5625e-05 iteration: 27689
[[ 2.00131671]
 [ 4.04289272]
 [-1.02215202]] loss fxn value:  0.010935650172761487 learn rate: 1.5625e-05 iteration: 27690
[[ 2.00131672]
 [ 4.04289272]
 [-1.02215219]] loss fxn value:  0.010932612780846639 learn rate: 1.5625e-05 iteration: 27691
[[ 2.00131672]
 [ 4.04289272]
 [-1.02215236]] loss fxn value:  0.010929576232347481 learn rate: 1.5625e-05 iteration: 27692
[[ 2.00131672]
 [ 4.04289272]
 [-1.02215253]] loss fxn value:  0.010926540528329929 learn rate: 1.5625e-05 iteration: 27693
[[ 2.00131672]
 [ 4.04289272]
 [-1.0221527 ]] loss fxn value:  0.010923505666766241 learn rate: 1.5625e-05 iteration: 27694
[[ 2.00131673]
 [ 4.04289272]
 [-1.02215287]] loss fxn value:  0.010920471649194014 learn rate: 1.5625e-05 iteration: 27695
[[ 2.00131673]
 [ 4.04289272]
 [-1.02215304]] loss fxn value:  0.010917438473227997 learn rate: 1.5625e-05 iteration: 27696
[[ 2.00131673]
 [ 4.04289272]
 [-1.02215321]] loss fxn value:  0.010914406139794549 learn rate: 1.5625e-05 iteration: 27697
[[ 2.00131674]
 [ 4.04289272]
 [-1.02215338]] loss fxn value:  0.0109113746489646 learn rate: 1.5625e-05 iteration: 27698
[[ 2.00131674]
 [ 4.04289272]
 [-1.02215355]] loss fxn value:  0.010908344000228698 learn rate: 1.5625e-05 iteration: 27699
[[ 2.00131674]
 [ 4.04289272]
 [-1.02215372]] loss fxn value:  0.0109053141935753 learn rate: 1.5625e-05 iteration: 27700
[[ 2.00131674]
 [ 4.04289272]
 [-1.02215389]] loss fxn value:  0.010902285227642682 learn rate: 1.5625e-05 iteration: 27701
[[ 2.00131675]
 [ 4.04289273]
 [-1.02215406]] loss fxn value:  0.010899257103889734 learn rate: 1.5625e-05 iteration: 27702
[[ 2.00131675]
 [ 4.04289273]
 [-1.02215423]] loss fxn value:  0.010896229819855663 learn rate: 1.5625e-05 iteration: 27703
[[ 2.00131675]
 [ 4.04289273]
 [-1.0221544 ]] loss fxn value:  0.01089320337750881 learn rate: 1.5625e-05 iteration: 27704
[[ 2.00131676]
 [ 4.04289273]
 [-1.02215457]] loss fxn value:  0.010890177775977592 learn rate: 1.5625e-05 iteration: 27705
[[ 2.00131676]
 [ 4.04289273]
 [-1.02215474]] loss fxn value:  0.010887153014596002 learn rate: 1.5625e-05 iteration: 27706
[[ 2.00131676]
 [ 4.04289273]
 [-1.02215491]] loss fxn value:  0.010884129093144616 learn rate: 1.5625e-05 iteration: 27707
[[ 2.00131676]
 [ 4.04289273]
 [-1.02215508]] loss fxn value:  0.010881106011442956 learn rate: 1.5625e-05 iteration: 27708
[[ 2.00131677]
 [ 4.04289273]
 [-1.02215525]] loss fxn value:  0.010878083770102253 learn rate: 1.5625e-05 iteration: 27709
[[ 2.00131677]
 [ 4.04289273]
 [-1.02215542]] loss fxn value:  0.010875062367604226 learn rate: 1.5625e-05 iteration: 27710
[[ 2.00131677]
 [ 4.04289273]
 [-1.02215559]] loss fxn value:  0.010872041804981629 learn rate: 1.5625e-05 iteration: 27711
[[ 2.00131678]
 [ 4.04289273]
 [-1.02215576]] loss fxn value:  0.010869022080349433 learn rate: 1.5625e-05 iteration: 27712
[[ 2.00131678]
 [ 4.04289274]
 [-1.02215593]] loss fxn value:  0.010866003194621611 learn rate: 1.5625e-05 iteration: 27713
[[ 2.00131678]
 [ 4.04289274]
 [-1.0221561 ]] loss fxn value:  0.010862985147829015 learn rate: 1.5625e-05 iteration: 27714
[[ 2.00131678]
 [ 4.04289274]
 [-1.02215627]] loss fxn value:  0.01085996793857445 learn rate: 1.5625e-05 iteration: 27715
[[ 2.00131679]
 [ 4.04289274]
 [-1.02215644]] loss fxn value:  0.010856951568764563 learn rate: 1.5625e-05 iteration: 27716
[[ 2.00131679]
 [ 4.04289274]
 [-1.02215661]] loss fxn value:  0.010853936035954713 learn rate: 1.5625e-05 iteration: 27717
[[ 2.00131679]
 [ 4.04289274]
 [-1.02215678]] loss fxn value:  0.010850921340770828 learn rate: 1.5625e-05 iteration: 27718
[[ 2.0013168 ]
 [ 4.04289274]
 [-1.02215695]] loss fxn value:  0.010847907482129993 learn rate: 1.5625e-05 iteration: 27719
[[ 2.0013168 ]
 [ 4.04289274]
 [-1.02215712]] loss fxn value:  0.010844894462147876 learn rate: 1.5625e-05 iteration: 27720
[[ 2.0013168 ]
 [ 4.04289274]
 [-1.02215729]] loss fxn value:  0.01084188227719053 learn rate: 1.5625e-05 iteration: 27721
[[ 2.0013168 ]
 [ 4.04289274]
 [-1.02215746]] loss fxn value:  0.010838870930011088 learn rate: 1.5625e-05 iteration: 27722
[[ 2.00131681]
 [ 4.04289274]
 [-1.02215763]] loss fxn value:  0.010835860419339231 learn rate: 1.5625e-05 iteration: 27723
[[ 2.00131681]
 [ 4.04289274]
 [-1.0221578 ]] loss fxn value:  0.01083285074493392 learn rate: 1.5625e-05 iteration: 27724
[[ 2.00131681]
 [ 4.04289275]
 [-1.02215797]] loss fxn value:  0.010829841905738474 learn rate: 1.5625e-05 iteration: 27725
[[ 2.00131681]
 [ 4.04289275]
 [-1.02215814]] loss fxn value:  0.010826833902778724 learn rate: 1.5625e-05 iteration: 27726
[[ 2.00131682]
 [ 4.04289275]
 [-1.0221583 ]] loss fxn value:  0.010823826734652865 learn rate: 1.5625e-05 iteration: 27727
[[ 2.00131682]
 [ 4.04289275]
 [-1.02215847]] loss fxn value:  0.010820820402220089 learn rate: 1.5625e-05 iteration: 27728
[[ 2.00131682]
 [ 4.04289275]
 [-1.02215864]] loss fxn value:  0.010817814905111347 learn rate: 1.5625e-05 iteration: 27729
[[ 2.00131683]
 [ 4.04289275]
 [-1.02215881]] loss fxn value:  0.010814810242819491 learn rate: 1.5625e-05 iteration: 27730
[[ 2.00131683]
 [ 4.04289275]
 [-1.02215898]] loss fxn value:  0.010811806414361925 learn rate: 1.5625e-05 iteration: 27731
[[ 2.00131683]
 [ 4.04289275]
 [-1.02215915]] loss fxn value:  0.01080880342041851 learn rate: 1.5625e-05 iteration: 27732
[[ 2.00131683]
 [ 4.04289275]
 [-1.02215932]] loss fxn value:  0.010805801261194814 learn rate: 1.5625e-05 iteration: 27733
[[ 2.00131684]
 [ 4.04289275]
 [-1.02215949]] loss fxn value:  0.010802799935478747 learn rate: 1.5625e-05 iteration: 27734
[[ 2.00131684]
 [ 4.04289275]
 [-1.02215966]] loss fxn value:  0.0107997994436679 learn rate: 1.5625e-05 iteration: 27735
[[ 2.00131684]
 [ 4.04289275]
 [-1.02215983]] loss fxn value:  0.010796799784867615 learn rate: 1.5625e-05 iteration: 27736
[[ 2.00131685]
 [ 4.04289276]
 [-1.02215999]] loss fxn value:  0.010793800959006112 learn rate: 1.5625e-05 iteration: 27737
[[ 2.00131685]
 [ 4.04289276]
 [-1.02216016]] loss fxn value:  0.010790802966287798 learn rate: 1.5625e-05 iteration: 27738
[[ 2.00131685]
 [ 4.04289276]
 [-1.02216033]] loss fxn value:  0.010787805806437338 learn rate: 1.5625e-05 iteration: 27739
[[ 2.00131685]
 [ 4.04289276]
 [-1.0221605 ]] loss fxn value:  0.010784809479275388 learn rate: 1.5625e-05 iteration: 27740
[[ 2.00131686]
 [ 4.04289276]
 [-1.02216067]] loss fxn value:  0.010781813984083472 learn rate: 1.5625e-05 iteration: 27741
[[ 2.00131686]
 [ 4.04289276]
 [-1.02216084]] loss fxn value:  0.01077881932057124 learn rate: 1.5625e-05 iteration: 27742
[[ 2.00131686]
 [ 4.04289276]
 [-1.022161  ]] loss fxn value:  0.01077582548875023 learn rate: 1.5625e-05 iteration: 27743
[[ 2.00131687]
 [ 4.04289276]
 [-1.02216117]] loss fxn value:  0.010772832489475023 learn rate: 1.5625e-05 iteration: 27744
[[ 2.00131687]
 [ 4.04289276]
 [-1.02216134]] loss fxn value:  0.010769840319939696 learn rate: 1.5625e-05 iteration: 27745
[[ 2.00131687]
 [ 4.04289276]
 [-1.02216151]] loss fxn value:  0.010766848982609661 learn rate: 1.5625e-05 iteration: 27746
[[ 2.00131687]
 [ 4.04289276]
 [-1.02216168]] loss fxn value:  0.010763858476425928 learn rate: 1.5625e-05 iteration: 27747
[[ 2.00131688]
 [ 4.04289277]
 [-1.02216185]] loss fxn value:  0.010760868799532013 learn rate: 1.5625e-05 iteration: 27748
[[ 2.00131688]
 [ 4.04289277]
 [-1.02216201]] loss fxn value:  0.010757879953934034 learn rate: 1.5625e-05 iteration: 27749
[[ 2.00131688]
 [ 4.04289277]
 [-1.02216218]] loss fxn value:  0.010754891938118323 learn rate: 1.5625e-05 iteration: 27750
[[ 2.00131689]
 [ 4.04289277]
 [-1.02216235]] loss fxn value:  0.010751904753108403 learn rate: 1.5625e-05 iteration: 27751
[[ 2.00131689]
 [ 4.04289277]
 [-1.02216252]] loss fxn value:  0.010748918396395628 learn rate: 1.5625e-05 iteration: 27752
[[ 2.00131689]
 [ 4.04289277]
 [-1.02216269]] loss fxn value:  0.010745932870607428 learn rate: 1.5625e-05 iteration: 27753
[[ 2.00131689]
 [ 4.04289277]
 [-1.02216285]] loss fxn value:  0.010742948173571049 learn rate: 1.5625e-05 iteration: 27754
[[ 2.0013169 ]
 [ 4.04289277]
 [-1.02216302]] loss fxn value:  0.010739964305521748 learn rate: 1.5625e-05 iteration: 27755
[[ 2.0013169 ]
 [ 4.04289277]
 [-1.02216319]] loss fxn value:  0.010736981265469162 learn rate: 1.5625e-05 iteration: 27756
[[ 2.0013169 ]
 [ 4.04289277]
 [-1.02216336]] loss fxn value:  0.010733999054313414 learn rate: 1.5625e-05 iteration: 27757
[[ 2.0013169 ]
 [ 4.04289277]
 [-1.02216353]] loss fxn value:  0.010731017672118509 learn rate: 1.5625e-05 iteration: 27758
[[ 2.00131691]
 [ 4.04289277]
 [-1.02216369]] loss fxn value:  0.010728037116944648 learn rate: 1.5625e-05 iteration: 27759
[[ 2.00131691]
 [ 4.04289278]
 [-1.02216386]] loss fxn value:  0.010725057391281167 learn rate: 1.5625e-05 iteration: 27760
[[ 2.00131691]
 [ 4.04289278]
 [-1.02216403]] loss fxn value:  0.010722078492060649 learn rate: 1.5625e-05 iteration: 27761
[[ 2.00131692]
 [ 4.04289278]
 [-1.0221642 ]] loss fxn value:  0.010719100420098741 learn rate: 1.5625e-05 iteration: 27762
[[ 2.00131692]
 [ 4.04289278]
 [-1.02216436]] loss fxn value:  0.010716123175129332 learn rate: 1.5625e-05 iteration: 27763
[[ 2.00131692]
 [ 4.04289278]
 [-1.02216453]] loss fxn value:  0.010713146758268495 learn rate: 1.5625e-05 iteration: 27764
[[ 2.00131692]
 [ 4.04289278]
 [-1.0221647 ]] loss fxn value:  0.01071017116749311 learn rate: 1.5625e-05 iteration: 27765
[[ 2.00131693]
 [ 4.04289278]
 [-1.02216486]] loss fxn value:  0.010707196402948193 learn rate: 1.5625e-05 iteration: 27766
[[ 2.00131693]
 [ 4.04289278]
 [-1.02216503]] loss fxn value:  0.010704222464605203 learn rate: 1.5625e-05 iteration: 27767
[[ 2.00131693]
 [ 4.04289278]
 [-1.0221652 ]] loss fxn value:  0.010701249352861732 learn rate: 1.5625e-05 iteration: 27768
[[ 2.00131694]
 [ 4.04289278]
 [-1.02216537]] loss fxn value:  0.01069827706641314 learn rate: 1.5625e-05 iteration: 27769
[[ 2.00131694]
 [ 4.04289278]
 [-1.02216553]] loss fxn value:  0.010695305605700258 learn rate: 1.5625e-05 iteration: 27770
[[ 2.00131694]
 [ 4.04289278]
 [-1.0221657 ]] loss fxn value:  0.010692334969779723 learn rate: 1.5625e-05 iteration: 27771
[[ 2.00131694]
 [ 4.04289279]
 [-1.02216587]] loss fxn value:  0.010689365159204225 learn rate: 1.5625e-05 iteration: 27772
[[ 2.00131695]
 [ 4.04289279]
 [-1.02216603]] loss fxn value:  0.010686396173861907 learn rate: 1.5625e-05 iteration: 27773
[[ 2.00131695]
 [ 4.04289279]
 [-1.0221662 ]] loss fxn value:  0.010683428013357478 learn rate: 1.5625e-05 iteration: 27774
[[ 2.00131695]
 [ 4.04289279]
 [-1.02216637]] loss fxn value:  0.01068046067721003 learn rate: 1.5625e-05 iteration: 27775
[[ 2.00131696]
 [ 4.04289279]
 [-1.02216654]] loss fxn value:  0.010677494164960267 learn rate: 1.5625e-05 iteration: 27776
[[ 2.00131696]
 [ 4.04289279]
 [-1.0221667 ]] loss fxn value:  0.010674528476636734 learn rate: 1.5625e-05 iteration: 27777
[[ 2.00131696]
 [ 4.04289279]
 [-1.02216687]] loss fxn value:  0.010671563611299222 learn rate: 1.5625e-05 iteration: 27778
[[ 2.00131696]
 [ 4.04289279]
 [-1.02216704]] loss fxn value:  0.010668599570832757 learn rate: 1.5625e-05 iteration: 27779
[[ 2.00131697]
 [ 4.04289279]
 [-1.0221672 ]] loss fxn value:  0.010665636352899945 learn rate: 1.5625e-05 iteration: 27780
[[ 2.00131697]
 [ 4.04289279]
 [-1.02216737]] loss fxn value:  0.010662673957929227 learn rate: 1.5625e-05 iteration: 27781
[[ 2.00131697]
 [ 4.04289279]
 [-1.02216754]] loss fxn value:  0.01065971238691328 learn rate: 1.5625e-05 iteration: 27782
[[ 2.00131697]
 [ 4.04289279]
 [-1.0221677 ]] loss fxn value:  0.010656751637036098 learn rate: 1.5625e-05 iteration: 27783
[[ 2.00131698]
 [ 4.0428928 ]
 [-1.02216787]] loss fxn value:  0.010653791709754267 learn rate: 1.5625e-05 iteration: 27784
[[ 2.00131698]
 [ 4.0428928 ]
 [-1.02216804]] loss fxn value:  0.010650832604525175 learn rate: 1.5625e-05 iteration: 27785
[[ 2.00131698]
 [ 4.0428928 ]
 [-1.0221682 ]] loss fxn value:  0.01064787432143214 learn rate: 1.5625e-05 iteration: 27786
[[ 2.00131699]
 [ 4.0428928 ]
 [-1.02216837]] loss fxn value:  0.010644916859965707 learn rate: 1.5625e-05 iteration: 27787
[[ 2.00131699]
 [ 4.0428928 ]
 [-1.02216853]] loss fxn value:  0.01064196022010195 learn rate: 1.5625e-05 iteration: 27788
[[ 2.00131699]
 [ 4.0428928 ]
 [-1.0221687 ]] loss fxn value:  0.010639004401948114 learn rate: 1.5625e-05 iteration: 27789
[[ 2.00131699]
 [ 4.0428928 ]
 [-1.02216887]] loss fxn value:  0.010636049404016764 learn rate: 1.5625e-05 iteration: 27790
[[ 2.001317  ]
 [ 4.0428928 ]
 [-1.02216903]] loss fxn value:  0.010633095227264263 learn rate: 1.5625e-05 iteration: 27791
[[ 2.001317 ]
 [ 4.0428928]
 [-1.0221692]] loss fxn value:  0.010630141870312727 learn rate: 1.5625e-05 iteration: 27792
[[ 2.001317  ]
 [ 4.0428928 ]
 [-1.02216937]] loss fxn value:  0.01062718933469198 learn rate: 1.5625e-05 iteration: 27793
[[ 2.00131701]
 [ 4.0428928 ]
 [-1.02216953]] loss fxn value:  0.010624237618237038 learn rate: 1.5625e-05 iteration: 27794
[[ 2.00131701]
 [ 4.04289281]
 [-1.0221697 ]] loss fxn value:  0.010621286722189682 learn rate: 1.5625e-05 iteration: 27795
[[ 2.00131701]
 [ 4.04289281]
 [-1.02216986]] loss fxn value:  0.010618336645952521 learn rate: 1.5625e-05 iteration: 27796
[[ 2.00131701]
 [ 4.04289281]
 [-1.02217003]] loss fxn value:  0.010615387388033512 learn rate: 1.5625e-05 iteration: 27797
[[ 2.00131702]
 [ 4.04289281]
 [-1.02217019]] loss fxn value:  0.010612438949676737 learn rate: 1.5625e-05 iteration: 27798
[[ 2.00131702]
 [ 4.04289281]
 [-1.02217036]] loss fxn value:  0.010609491331009068 learn rate: 1.5625e-05 iteration: 27799
[[ 2.00131702]
 [ 4.04289281]
 [-1.02217053]] loss fxn value:  0.010606544530416201 learn rate: 1.5625e-05 iteration: 27800
[[ 2.00131702]
 [ 4.04289281]
 [-1.02217069]] loss fxn value:  0.010603598548664784 learn rate: 1.5625e-05 iteration: 27801
[[ 2.00131703]
 [ 4.04289281]
 [-1.02217086]] loss fxn value:  0.010600653384988171 learn rate: 1.5625e-05 iteration: 27802
[[ 2.00131703]
 [ 4.04289281]
 [-1.02217102]] loss fxn value:  0.010597709039205877 learn rate: 1.5625e-05 iteration: 27803
[[ 2.00131703]
 [ 4.04289281]
 [-1.02217119]] loss fxn value:  0.010594765511112329 learn rate: 1.5625e-05 iteration: 27804
[[ 2.00131704]
 [ 4.04289281]
 [-1.02217135]] loss fxn value:  0.010591822801403245 learn rate: 1.5625e-05 iteration: 27805
[[ 2.00131704]
 [ 4.04289281]
 [-1.02217152]] loss fxn value:  0.010588880908307764 learn rate: 1.5625e-05 iteration: 27806
[[ 2.00131704]
 [ 4.04289282]
 [-1.02217169]] loss fxn value:  0.01058593983184204 learn rate: 1.5625e-05 iteration: 27807
[[ 2.00131704]
 [ 4.04289282]
 [-1.02217185]] loss fxn value:  0.010582999573969805 learn rate: 1.5625e-05 iteration: 27808
[[ 2.00131705]
 [ 4.04289282]
 [-1.02217202]] loss fxn value:  0.010580060131178196 learn rate: 1.5625e-05 iteration: 27809
[[ 2.00131705]
 [ 4.04289282]
 [-1.02217218]] loss fxn value:  0.010577121505149821 learn rate: 1.5625e-05 iteration: 27810
[[ 2.00131705]
 [ 4.04289282]
 [-1.02217235]] loss fxn value:  0.01057418369524175 learn rate: 1.5625e-05 iteration: 27811
[[ 2.00131705]
 [ 4.04289282]
 [-1.02217251]] loss fxn value:  0.010571246701613695 learn rate: 1.5625e-05 iteration: 27812
[[ 2.00131706]
 [ 4.04289282]
 [-1.02217268]] loss fxn value:  0.010568310524011087 learn rate: 1.5625e-05 iteration: 27813
[[ 2.00131706]
 [ 4.04289282]
 [-1.02217284]] loss fxn value:  0.010565375161355311 learn rate: 1.5625e-05 iteration: 27814
[[ 2.00131706]
 [ 4.04289282]
 [-1.02217301]] loss fxn value:  0.010562440613903558 learn rate: 1.5625e-05 iteration: 27815
[[ 2.00131707]
 [ 4.04289282]
 [-1.02217317]] loss fxn value:  0.010559506882710202 learn rate: 1.5625e-05 iteration: 27816
[[ 2.00131707]
 [ 4.04289282]
 [-1.02217334]] loss fxn value:  0.010556573964840457 learn rate: 1.5625e-05 iteration: 27817
[[ 2.00131707]
 [ 4.04289282]
 [-1.0221735 ]] loss fxn value:  0.010553641862376837 learn rate: 1.5625e-05 iteration: 27818
[[ 2.00131707]
 [ 4.04289283]
 [-1.02217367]] loss fxn value:  0.010550710574719646 learn rate: 1.5625e-05 iteration: 27819
[[ 2.00131708]
 [ 4.04289283]
 [-1.02217383]] loss fxn value:  0.010547780100390683 learn rate: 1.5625e-05 iteration: 27820
[[ 2.00131708]
 [ 4.04289283]
 [-1.022174  ]] loss fxn value:  0.010544850440125429 learn rate: 1.5625e-05 iteration: 27821
[[ 2.00131708]
 [ 4.04289283]
 [-1.02217416]] loss fxn value:  0.01054192159321925 learn rate: 1.5625e-05 iteration: 27822
[[ 2.00131709]
 [ 4.04289283]
 [-1.02217433]] loss fxn value:  0.010538993561683732 learn rate: 1.5625e-05 iteration: 27823
[[ 2.00131709]
 [ 4.04289283]
 [-1.02217449]] loss fxn value:  0.010536066341657728 learn rate: 1.5625e-05 iteration: 27824
[[ 2.00131709]
 [ 4.04289283]
 [-1.02217466]] loss fxn value:  0.010533139935609807 learn rate: 1.5625e-05 iteration: 27825
[[ 2.00131709]
 [ 4.04289283]
 [-1.02217482]] loss fxn value:  0.010530214341642554 learn rate: 1.5625e-05 iteration: 27826
[[ 2.0013171 ]
 [ 4.04289283]
 [-1.02217498]] loss fxn value:  0.010527289560665324 learn rate: 1.5625e-05 iteration: 27827
[[ 2.0013171 ]
 [ 4.04289283]
 [-1.02217515]] loss fxn value:  0.010524365591814308 learn rate: 1.5625e-05 iteration: 27828
[[ 2.0013171 ]
 [ 4.04289283]
 [-1.02217531]] loss fxn value:  0.010521442435017726 learn rate: 1.5625e-05 iteration: 27829
[[ 2.0013171 ]
 [ 4.04289283]
 [-1.02217548]] loss fxn value:  0.01051852009032343 learn rate: 1.5625e-05 iteration: 27830
[[ 2.00131711]
 [ 4.04289284]
 [-1.02217564]] loss fxn value:  0.010515598556774211 learn rate: 1.5625e-05 iteration: 27831
[[ 2.00131711]
 [ 4.04289284]
 [-1.02217581]] loss fxn value:  0.010512677834925068 learn rate: 1.5625e-05 iteration: 27832
[[ 2.00131711]
 [ 4.04289284]
 [-1.02217597]] loss fxn value:  0.01050975792516121 learn rate: 1.5625e-05 iteration: 27833
[[ 2.00131712]
 [ 4.04289284]
 [-1.02217613]] loss fxn value:  0.01050683882610706 learn rate: 1.5625e-05 iteration: 27834
[[ 2.00131712]
 [ 4.04289284]
 [-1.0221763 ]] loss fxn value:  0.010503920537738694 learn rate: 1.5625e-05 iteration: 27835
[[ 2.00131712]
 [ 4.04289284]
 [-1.02217646]] loss fxn value:  0.010501003059196917 learn rate: 1.5625e-05 iteration: 27836
[[ 2.00131712]
 [ 4.04289284]
 [-1.02217663]] loss fxn value:  0.010498086391404928 learn rate: 1.5625e-05 iteration: 27837
[[ 2.00131713]
 [ 4.04289284]
 [-1.02217679]] loss fxn value:  0.010495170533925055 learn rate: 1.5625e-05 iteration: 27838
[[ 2.00131713]
 [ 4.04289284]
 [-1.02217695]] loss fxn value:  0.010492255486226225 learn rate: 1.5625e-05 iteration: 27839
[[ 2.00131713]
 [ 4.04289284]
 [-1.02217712]] loss fxn value:  0.010489341248353984 learn rate: 1.5625e-05 iteration: 27840
[[ 2.00131713]
 [ 4.04289284]
 [-1.02217728]] loss fxn value:  0.01048642781980349 learn rate: 1.5625e-05 iteration: 27841
[[ 2.00131714]
 [ 4.04289284]
 [-1.02217745]] loss fxn value:  0.010483515201143592 learn rate: 1.5625e-05 iteration: 27842
[[ 2.00131714]
 [ 4.04289285]
 [-1.02217761]] loss fxn value:  0.010480603390379708 learn rate: 1.5625e-05 iteration: 27843
[[ 2.00131714]
 [ 4.04289285]
 [-1.02217777]] loss fxn value:  0.010477692388111536 learn rate: 1.5625e-05 iteration: 27844
[[ 2.00131715]
 [ 4.04289285]
 [-1.02217794]] loss fxn value:  0.01047478219525766 learn rate: 1.5625e-05 iteration: 27845
[[ 2.00131715]
 [ 4.04289285]
 [-1.0221781 ]] loss fxn value:  0.01047187281084241 learn rate: 1.5625e-05 iteration: 27846
[[ 2.00131715]
 [ 4.04289285]
 [-1.02217826]] loss fxn value:  0.010468964233890118 learn rate: 1.5625e-05 iteration: 27847
[[ 2.00131715]
 [ 4.04289285]
 [-1.02217843]] loss fxn value:  0.010466056465014322 learn rate: 1.5625e-05 iteration: 27848
[[ 2.00131716]
 [ 4.04289285]
 [-1.02217859]] loss fxn value:  0.010463149504612617 learn rate: 1.5625e-05 iteration: 27849
[[ 2.00131716]
 [ 4.04289285]
 [-1.02217876]] loss fxn value:  0.010460243349802688 learn rate: 1.5625e-05 iteration: 27850
[[ 2.00131716]
 [ 4.04289285]
 [-1.02217892]] loss fxn value:  0.010457338003631177 learn rate: 1.5625e-05 iteration: 27851
[[ 2.00131716]
 [ 4.04289285]
 [-1.02217908]] loss fxn value:  0.01045443346393687 learn rate: 1.5625e-05 iteration: 27852
[[ 2.00131717]
 [ 4.04289285]
 [-1.02217925]] loss fxn value:  0.01045152973143594 learn rate: 1.5625e-05 iteration: 27853
[[ 2.00131717]
 [ 4.04289285]
 [-1.02217941]] loss fxn value:  0.010448626804586176 learn rate: 1.5625e-05 iteration: 27854
[[ 2.00131717]
 [ 4.04289286]
 [-1.02217957]] loss fxn value:  0.010445724684420331 learn rate: 1.5625e-05 iteration: 27855
[[ 2.00131718]
 [ 4.04289286]
 [-1.02217974]] loss fxn value:  0.010442823370872094 learn rate: 1.5625e-05 iteration: 27856
[[ 2.00131718]
 [ 4.04289286]
 [-1.0221799 ]] loss fxn value:  0.01043992286212967 learn rate: 1.5625e-05 iteration: 27857
[[ 2.00131718]
 [ 4.04289286]
 [-1.02218006]] loss fxn value:  0.010437023160068861 learn rate: 1.5625e-05 iteration: 27858
[[ 2.00131718]
 [ 4.04289286]
 [-1.02218022]] loss fxn value:  0.010434124262714397 learn rate: 1.5625e-05 iteration: 27859
[[ 2.00131719]
 [ 4.04289286]
 [-1.02218039]] loss fxn value:  0.01043122617069913 learn rate: 1.5625e-05 iteration: 27860
[[ 2.00131719]
 [ 4.04289286]
 [-1.02218055]] loss fxn value:  0.0104283288830967 learn rate: 1.5625e-05 iteration: 27861
[[ 2.00131719]
 [ 4.04289286]
 [-1.02218071]] loss fxn value:  0.01042543240115236 learn rate: 1.5625e-05 iteration: 27862
[[ 2.00131719]
 [ 4.04289286]
 [-1.02218088]] loss fxn value:  0.010422536723576159 learn rate: 1.5625e-05 iteration: 27863
[[ 2.0013172 ]
 [ 4.04289286]
 [-1.02218104]] loss fxn value:  0.010419641849472592 learn rate: 1.5625e-05 iteration: 27864
[[ 2.0013172 ]
 [ 4.04289286]
 [-1.0221812 ]] loss fxn value:  0.01041674778065575 learn rate: 1.5625e-05 iteration: 27865
[[ 2.0013172 ]
 [ 4.04289286]
 [-1.02218136]] loss fxn value:  0.010413854515178915 learn rate: 1.5625e-05 iteration: 27866
[[ 2.00131721]
 [ 4.04289287]
 [-1.02218153]] loss fxn value:  0.010410962052355593 learn rate: 1.5625e-05 iteration: 27867
[[ 2.00131721]
 [ 4.04289287]
 [-1.02218169]] loss fxn value:  0.010408070393878794 learn rate: 1.5625e-05 iteration: 27868
[[ 2.00131721]
 [ 4.04289287]
 [-1.02218185]] loss fxn value:  0.010405179538384485 learn rate: 1.5625e-05 iteration: 27869
[[ 2.00131721]
 [ 4.04289287]
 [-1.02218201]] loss fxn value:  0.010402289485898896 learn rate: 1.5625e-05 iteration: 27870
[[ 2.00131722]
 [ 4.04289287]
 [-1.02218218]] loss fxn value:  0.010399400236405025 learn rate: 1.5625e-05 iteration: 27871
[[ 2.00131722]
 [ 4.04289287]
 [-1.02218234]] loss fxn value:  0.010396511788917975 learn rate: 1.5625e-05 iteration: 27872
[[ 2.00131722]
 [ 4.04289287]
 [-1.0221825 ]] loss fxn value:  0.010393624143653687 learn rate: 1.5625e-05 iteration: 27873
[[ 2.00131722]
 [ 4.04289287]
 [-1.02218266]] loss fxn value:  0.010390737300348361 learn rate: 1.5625e-05 iteration: 27874
[[ 2.00131723]
 [ 4.04289287]
 [-1.02218283]] loss fxn value:  0.010387851259718174 learn rate: 1.5625e-05 iteration: 27875
[[ 2.00131723]
 [ 4.04289287]
 [-1.02218299]] loss fxn value:  0.01038496602015921 learn rate: 1.5625e-05 iteration: 27876
[[ 2.00131723]
 [ 4.04289287]
 [-1.02218315]] loss fxn value:  0.01038208158133558 learn rate: 1.5625e-05 iteration: 27877
[[ 2.00131724]
 [ 4.04289287]
 [-1.02218331]] loss fxn value:  0.010379197944196717 learn rate: 1.5625e-05 iteration: 27878
[[ 2.00131724]
 [ 4.04289288]
 [-1.02218348]] loss fxn value:  0.010376315108676306 learn rate: 1.5625e-05 iteration: 27879
[[ 2.00131724]
 [ 4.04289288]
 [-1.02218364]] loss fxn value:  0.010373433072960252 learn rate: 1.5625e-05 iteration: 27880
[[ 2.00131724]
 [ 4.04289288]
 [-1.0221838 ]] loss fxn value:  0.010370551837917831 learn rate: 1.5625e-05 iteration: 27881
[[ 2.00131725]
 [ 4.04289288]
 [-1.02218396]] loss fxn value:  0.010367671403217761 learn rate: 1.5625e-05 iteration: 27882
[[ 2.00131725]
 [ 4.04289288]
 [-1.02218412]] loss fxn value:  0.010364791768319741 learn rate: 1.5625e-05 iteration: 27883
[[ 2.00131725]
 [ 4.04289288]
 [-1.02218429]] loss fxn value:  0.010361912934552337 learn rate: 1.5625e-05 iteration: 27884
[[ 2.00131725]
 [ 4.04289288]
 [-1.02218445]] loss fxn value:  0.01035903489882997 learn rate: 1.5625e-05 iteration: 27885
[[ 2.00131726]
 [ 4.04289288]
 [-1.02218461]] loss fxn value:  0.010356157663304937 learn rate: 1.5625e-05 iteration: 27886
[[ 2.00131726]
 [ 4.04289288]
 [-1.02218477]] loss fxn value:  0.010353281225846556 learn rate: 1.5625e-05 iteration: 27887
[[ 2.00131726]
 [ 4.04289288]
 [-1.02218493]] loss fxn value:  0.010350405588671138 learn rate: 1.5625e-05 iteration: 27888
[[ 2.00131726]
 [ 4.04289288]
 [-1.02218509]] loss fxn value:  0.010347530749398043 learn rate: 1.5625e-05 iteration: 27889
[[ 2.00131727]
 [ 4.04289288]
 [-1.02218526]] loss fxn value:  0.010344656709155735 learn rate: 1.5625e-05 iteration: 27890
[[ 2.00131727]
 [ 4.04289288]
 [-1.02218542]] loss fxn value:  0.01034178346677798 learn rate: 1.5625e-05 iteration: 27891
[[ 2.00131727]
 [ 4.04289289]
 [-1.02218558]] loss fxn value:  0.010338911022954712 learn rate: 1.5625e-05 iteration: 27892
[[ 2.00131728]
 [ 4.04289289]
 [-1.02218574]] loss fxn value:  0.010336039376115184 learn rate: 1.5625e-05 iteration: 27893
[[ 2.00131728]
 [ 4.04289289]
 [-1.0221859 ]] loss fxn value:  0.010333168527375466 learn rate: 1.5625e-05 iteration: 27894
[[ 2.00131728]
 [ 4.04289289]
 [-1.02218606]] loss fxn value:  0.010330298476557385 learn rate: 1.5625e-05 iteration: 27895
[[ 2.00131728]
 [ 4.04289289]
 [-1.02218623]] loss fxn value:  0.010327429221961011 learn rate: 1.5625e-05 iteration: 27896
[[ 2.00131729]
 [ 4.04289289]
 [-1.02218639]] loss fxn value:  0.010324560764867059 learn rate: 1.5625e-05 iteration: 27897
[[ 2.00131729]
 [ 4.04289289]
 [-1.02218655]] loss fxn value:  0.01032169310398789 learn rate: 1.5625e-05 iteration: 27898
[[ 2.00131729]
 [ 4.04289289]
 [-1.02218671]] loss fxn value:  0.010318826240156466 learn rate: 1.5625e-05 iteration: 27899
[[ 2.00131729]
 [ 4.04289289]
 [-1.02218687]] loss fxn value:  0.01031596017209207 learn rate: 1.5625e-05 iteration: 27900
[[ 2.0013173 ]
 [ 4.04289289]
 [-1.02218703]] loss fxn value:  0.01031309490015914 learn rate: 1.5625e-05 iteration: 27901
[[ 2.0013173 ]
 [ 4.04289289]
 [-1.02218719]] loss fxn value:  0.010310230424417068 learn rate: 1.5625e-05 iteration: 27902
[[ 2.0013173 ]
 [ 4.04289289]
 [-1.02218735]] loss fxn value:  0.010307366743468658 learn rate: 1.5625e-05 iteration: 27903
[[ 2.00131731]
 [ 4.0428929 ]
 [-1.02218752]] loss fxn value:  0.010304503859205866 learn rate: 1.5625e-05 iteration: 27904
[[ 2.00131731]
 [ 4.0428929 ]
 [-1.02218768]] loss fxn value:  0.010301641769248903 learn rate: 1.5625e-05 iteration: 27905
[[ 2.00131731]
 [ 4.0428929 ]
 [-1.02218784]] loss fxn value:  0.01029878047458267 learn rate: 1.5625e-05 iteration: 27906
[[ 2.00131731]
 [ 4.0428929 ]
 [-1.022188  ]] loss fxn value:  0.010295919975195631 learn rate: 1.5625e-05 iteration: 27907
[[ 2.00131732]
 [ 4.0428929 ]
 [-1.02218816]] loss fxn value:  0.010293060268731075 learn rate: 1.5625e-05 iteration: 27908
[[ 2.00131732]
 [ 4.0428929 ]
 [-1.02218832]] loss fxn value:  0.010290201358121481 learn rate: 1.5625e-05 iteration: 27909
[[ 2.00131732]
 [ 4.0428929 ]
 [-1.02218848]] loss fxn value:  0.010287343240763342 learn rate: 1.5625e-05 iteration: 27910
[[ 2.00131732]
 [ 4.0428929 ]
 [-1.02218864]] loss fxn value:  0.010284485917048473 learn rate: 1.5625e-05 iteration: 27911
[[ 2.00131733]
 [ 4.0428929 ]
 [-1.0221888 ]] loss fxn value:  0.010281629388048568 learn rate: 1.5625e-05 iteration: 27912
[[ 2.00131733]
 [ 4.0428929 ]
 [-1.02218896]] loss fxn value:  0.010278773650659578 learn rate: 1.5625e-05 iteration: 27913
[[ 2.00131733]
 [ 4.0428929 ]
 [-1.02218912]] loss fxn value:  0.010275918708156804 learn rate: 1.5625e-05 iteration: 27914
[[ 2.00131733]
 [ 4.0428929 ]
 [-1.02218928]] loss fxn value:  0.010273064557700313 learn rate: 1.5625e-05 iteration: 27915
[[ 2.00131734]
 [ 4.04289291]
 [-1.02218944]] loss fxn value:  0.010270211200159383 learn rate: 1.5625e-05 iteration: 27916
[[ 2.00131734]
 [ 4.04289291]
 [-1.0221896 ]] loss fxn value:  0.010267358635785427 learn rate: 1.5625e-05 iteration: 27917
[[ 2.00131734]
 [ 4.04289291]
 [-1.02218976]] loss fxn value:  0.010264506862901295 learn rate: 1.5625e-05 iteration: 27918
[[ 2.00131735]
 [ 4.04289291]
 [-1.02218993]] loss fxn value:  0.010261655882601447 learn rate: 1.5625e-05 iteration: 27919
[[ 2.00131735]
 [ 4.04289291]
 [-1.02219009]] loss fxn value:  0.010258805693888588 learn rate: 1.5625e-05 iteration: 27920
[[ 2.00131735]
 [ 4.04289291]
 [-1.02219025]] loss fxn value:  0.010255956296398283 learn rate: 1.5625e-05 iteration: 27921
[[ 2.00131735]
 [ 4.04289291]
 [-1.02219041]] loss fxn value:  0.010253107691004423 learn rate: 1.5625e-05 iteration: 27922
[[ 2.00131736]
 [ 4.04289291]
 [-1.02219057]] loss fxn value:  0.010250259876776033 learn rate: 1.5625e-05 iteration: 27923
[[ 2.00131736]
 [ 4.04289291]
 [-1.02219073]] loss fxn value:  0.01024741285322297 learn rate: 1.5625e-05 iteration: 27924
[[ 2.00131736]
 [ 4.04289291]
 [-1.02219089]] loss fxn value:  0.010244566620890154 learn rate: 1.5625e-05 iteration: 27925
[[ 2.00131736]
 [ 4.04289291]
 [-1.02219105]] loss fxn value:  0.010241721178354157 learn rate: 1.5625e-05 iteration: 27926
[[ 2.00131737]
 [ 4.04289291]
 [-1.02219121]] loss fxn value:  0.010238876526981322 learn rate: 1.5625e-05 iteration: 27927
[[ 2.00131737]
 [ 4.04289292]
 [-1.02219137]] loss fxn value:  0.010236032665429235 learn rate: 1.5625e-05 iteration: 27928
[[ 2.00131737]
 [ 4.04289292]
 [-1.02219153]] loss fxn value:  0.010233189593676275 learn rate: 1.5625e-05 iteration: 27929
[[ 2.00131737]
 [ 4.04289292]
 [-1.02219169]] loss fxn value:  0.010230347310843936 learn rate: 1.5625e-05 iteration: 27930
[[ 2.00131738]
 [ 4.04289292]
 [-1.02219185]] loss fxn value:  0.010227505818253865 learn rate: 1.5625e-05 iteration: 27931
[[ 2.00131738]
 [ 4.04289292]
 [-1.02219201]] loss fxn value:  0.010224665114619879 learn rate: 1.5625e-05 iteration: 27932
[[ 2.00131738]
 [ 4.04289292]
 [-1.02219217]] loss fxn value:  0.010221825200751863 learn rate: 1.5625e-05 iteration: 27933
[[ 2.00131739]
 [ 4.04289292]
 [-1.02219233]] loss fxn value:  0.010218986074864262 learn rate: 1.5625e-05 iteration: 27934
[[ 2.00131739]
 [ 4.04289292]
 [-1.02219248]] loss fxn value:  0.010216147738345038 learn rate: 1.5625e-05 iteration: 27935
[[ 2.00131739]
 [ 4.04289292]
 [-1.02219264]] loss fxn value:  0.01021331018935155 learn rate: 1.5625e-05 iteration: 27936
[[ 2.00131739]
 [ 4.04289292]
 [-1.0221928 ]] loss fxn value:  0.010210473428360095 learn rate: 1.5625e-05 iteration: 27937
[[ 2.0013174 ]
 [ 4.04289292]
 [-1.02219296]] loss fxn value:  0.010207637455832277 learn rate: 1.5625e-05 iteration: 27938
[[ 2.0013174 ]
 [ 4.04289292]
 [-1.02219312]] loss fxn value:  0.010204802271260945 learn rate: 1.5625e-05 iteration: 27939
[[ 2.0013174 ]
 [ 4.04289292]
 [-1.02219328]] loss fxn value:  0.010201967873358463 learn rate: 1.5625e-05 iteration: 27940
[[ 2.0013174 ]
 [ 4.04289293]
 [-1.02219344]] loss fxn value:  0.01019913426294856 learn rate: 1.5625e-05 iteration: 27941
[[ 2.00131741]
 [ 4.04289293]
 [-1.0221936 ]] loss fxn value:  0.01019630144011917 learn rate: 1.5625e-05 iteration: 27942
[[ 2.00131741]
 [ 4.04289293]
 [-1.02219376]] loss fxn value:  0.010193469403910776 learn rate: 1.5625e-05 iteration: 27943
[[ 2.00131741]
 [ 4.04289293]
 [-1.02219392]] loss fxn value:  0.010190638153824004 learn rate: 1.5625e-05 iteration: 27944
[[ 2.00131741]
 [ 4.04289293]
 [-1.02219408]] loss fxn value:  0.010187807690413001 learn rate: 1.5625e-05 iteration: 27945
[[ 2.00131742]
 [ 4.04289293]
 [-1.02219424]] loss fxn value:  0.010184978013194552 learn rate: 1.5625e-05 iteration: 27946
[[ 2.00131742]
 [ 4.04289293]
 [-1.0221944 ]] loss fxn value:  0.01018214912207149 learn rate: 1.5625e-05 iteration: 27947
[[ 2.00131742]
 [ 4.04289293]
 [-1.02219456]] loss fxn value:  0.010179321016291015 learn rate: 1.5625e-05 iteration: 27948
[[ 2.00131743]
 [ 4.04289293]
 [-1.02219472]] loss fxn value:  0.010176493696632162 learn rate: 1.5625e-05 iteration: 27949
[[ 2.00131743]
 [ 4.04289293]
 [-1.02219487]] loss fxn value:  0.010173667162294276 learn rate: 1.5625e-05 iteration: 27950
[[ 2.00131743]
 [ 4.04289293]
 [-1.02219503]] loss fxn value:  0.010170841411718996 learn rate: 1.5625e-05 iteration: 27951
[[ 2.00131743]
 [ 4.04289293]
 [-1.02219519]] loss fxn value:  0.010168016447476667 learn rate: 1.5625e-05 iteration: 27952
[[ 2.00131744]
 [ 4.04289294]
 [-1.02219535]] loss fxn value:  0.010165192267070184 learn rate: 1.5625e-05 iteration: 27953
[[ 2.00131744]
 [ 4.04289294]
 [-1.02219551]] loss fxn value:  0.010162368871454441 learn rate: 1.5625e-05 iteration: 27954
[[ 2.00131744]
 [ 4.04289294]
 [-1.02219567]] loss fxn value:  0.010159546259786404 learn rate: 1.5625e-05 iteration: 27955
[[ 2.00131744]
 [ 4.04289294]
 [-1.02219583]] loss fxn value:  0.010156724432428198 learn rate: 1.5625e-05 iteration: 27956
[[ 2.00131745]
 [ 4.04289294]
 [-1.02219599]] loss fxn value:  0.010153903388044332 learn rate: 1.5625e-05 iteration: 27957
[[ 2.00131745]
 [ 4.04289294]
 [-1.02219614]] loss fxn value:  0.01015108312808908 learn rate: 1.5625e-05 iteration: 27958
[[ 2.00131745]
 [ 4.04289294]
 [-1.0221963 ]] loss fxn value:  0.010148263651024848 learn rate: 1.5625e-05 iteration: 27959
[[ 2.00131745]
 [ 4.04289294]
 [-1.02219646]] loss fxn value:  0.01014544495705374 learn rate: 1.5625e-05 iteration: 27960
[[ 2.00131746]
 [ 4.04289294]
 [-1.02219662]] loss fxn value:  0.01014262704644995 learn rate: 1.5625e-05 iteration: 27961
[[ 2.00131746]
 [ 4.04289294]
 [-1.02219678]] loss fxn value:  0.010139809918403592 learn rate: 1.5625e-05 iteration: 27962
[[ 2.00131746]
 [ 4.04289294]
 [-1.02219694]] loss fxn value:  0.010136993571969847 learn rate: 1.5625e-05 iteration: 27963
[[ 2.00131746]
 [ 4.04289294]
 [-1.0221971 ]] loss fxn value:  0.010134178008600682 learn rate: 1.5625e-05 iteration: 27964
[[ 2.00131747]
 [ 4.04289294]
 [-1.02219725]] loss fxn value:  0.010131363227691788 learn rate: 1.5625e-05 iteration: 27965
[[ 2.00131747]
 [ 4.04289295]
 [-1.02219741]] loss fxn value:  0.010128549227490765 learn rate: 1.5625e-05 iteration: 27966
[[ 2.00131747]
 [ 4.04289295]
 [-1.02219757]] loss fxn value:  0.010125736009416422 learn rate: 1.5625e-05 iteration: 27967
[[ 2.00131748]
 [ 4.04289295]
 [-1.02219773]] loss fxn value:  0.010122923572950077 learn rate: 1.5625e-05 iteration: 27968
[[ 2.00131748]
 [ 4.04289295]
 [-1.02219789]] loss fxn value:  0.01012011191673231 learn rate: 1.5625e-05 iteration: 27969
[[ 2.00131748]
 [ 4.04289295]
 [-1.02219804]] loss fxn value:  0.010117301042614988 learn rate: 1.5625e-05 iteration: 27970
[[ 2.00131748]
 [ 4.04289295]
 [-1.0221982 ]] loss fxn value:  0.010114490948777097 learn rate: 1.5625e-05 iteration: 27971
[[ 2.00131749]
 [ 4.04289295]
 [-1.02219836]] loss fxn value:  0.010111681635606995 learn rate: 1.5625e-05 iteration: 27972
[[ 2.00131749]
 [ 4.04289295]
 [-1.02219852]] loss fxn value:  0.010108873101811579 learn rate: 1.5625e-05 iteration: 27973
[[ 2.00131749]
 [ 4.04289295]
 [-1.02219868]] loss fxn value:  0.010106065349198026 learn rate: 1.5625e-05 iteration: 27974
[[ 2.00131749]
 [ 4.04289295]
 [-1.02219883]] loss fxn value:  0.010103258375899765 learn rate: 1.5625e-05 iteration: 27975
[[ 2.0013175 ]
 [ 4.04289295]
 [-1.02219899]] loss fxn value:  0.010100452182445565 learn rate: 1.5625e-05 iteration: 27976
[[ 2.0013175 ]
 [ 4.04289295]
 [-1.02219915]] loss fxn value:  0.010097646767880523 learn rate: 1.5625e-05 iteration: 27977
[[ 2.0013175 ]
 [ 4.04289296]
 [-1.02219931]] loss fxn value:  0.010094842133559443 learn rate: 1.5625e-05 iteration: 27978
[[ 2.0013175 ]
 [ 4.04289296]
 [-1.02219947]] loss fxn value:  0.010092038277251324 learn rate: 1.5625e-05 iteration: 27979
[[ 2.00131751]
 [ 4.04289296]
 [-1.02219962]] loss fxn value:  0.010089235200277808 learn rate: 1.5625e-05 iteration: 27980
[[ 2.00131751]
 [ 4.04289296]
 [-1.02219978]] loss fxn value:  0.010086432901760393 learn rate: 1.5625e-05 iteration: 27981
[[ 2.00131751]
 [ 4.04289296]
 [-1.02219994]] loss fxn value:  0.010083631380761179 learn rate: 1.5625e-05 iteration: 27982
[[ 2.00131752]
 [ 4.04289296]
 [-1.0222001 ]] loss fxn value:  0.010080830639626793 learn rate: 1.5625e-05 iteration: 27983
[[ 2.00131752]
 [ 4.04289296]
 [-1.02220025]] loss fxn value:  0.01007803067504186 learn rate: 1.5625e-05 iteration: 27984
[[ 2.00131752]
 [ 4.04289296]
 [-1.02220041]] loss fxn value:  0.010075231488460656 learn rate: 1.5625e-05 iteration: 27985
[[ 2.00131752]
 [ 4.04289296]
 [-1.02220057]] loss fxn value:  0.010072433079454735 learn rate: 1.5625e-05 iteration: 27986
[[ 2.00131753]
 [ 4.04289296]
 [-1.02220073]] loss fxn value:  0.010069635447909932 learn rate: 1.5625e-05 iteration: 27987
[[ 2.00131753]
 [ 4.04289296]
 [-1.02220088]] loss fxn value:  0.010066838593064214 learn rate: 1.5625e-05 iteration: 27988
[[ 2.00131753]
 [ 4.04289296]
 [-1.02220104]] loss fxn value:  0.010064042514774873 learn rate: 1.5625e-05 iteration: 27989
[[ 2.00131753]
 [ 4.04289296]
 [-1.0222012 ]] loss fxn value:  0.010061247214120207 learn rate: 1.5625e-05 iteration: 27990
[[ 2.00131754]
 [ 4.04289297]
 [-1.02220135]] loss fxn value:  0.010058452688596183 learn rate: 1.5625e-05 iteration: 27991
[[ 2.00131754]
 [ 4.04289297]
 [-1.02220151]] loss fxn value:  0.010055658940195073 learn rate: 1.5625e-05 iteration: 27992
[[ 2.00131754]
 [ 4.04289297]
 [-1.02220167]] loss fxn value:  0.01005286596710047 learn rate: 1.5625e-05 iteration: 27993
[[ 2.00131754]
 [ 4.04289297]
 [-1.02220183]] loss fxn value:  0.01005007377016465 learn rate: 1.5625e-05 iteration: 27994
[[ 2.00131755]
 [ 4.04289297]
 [-1.02220198]] loss fxn value:  0.010047282349382998 learn rate: 1.5625e-05 iteration: 27995
[[ 2.00131755]
 [ 4.04289297]
 [-1.02220214]] loss fxn value:  0.010044491703424632 learn rate: 1.5625e-05 iteration: 27996
[[ 2.00131755]
 [ 4.04289297]
 [-1.0222023 ]] loss fxn value:  0.010041701831744637 learn rate: 1.5625e-05 iteration: 27997
[[ 2.00131755]
 [ 4.04289297]
 [-1.02220245]] loss fxn value:  0.010038912735852062 learn rate: 1.5625e-05 iteration: 27998
[[ 2.00131756]
 [ 4.04289297]
 [-1.02220261]] loss fxn value:  0.010036124414273321 learn rate: 1.5625e-05 iteration: 27999
[[ 2.00131756]
 [ 4.04289297]
 [-1.02220277]] loss fxn value:  0.010033336867113352 learn rate: 1.5625e-05 iteration: 28000
[[ 2.00131756]
 [ 4.04289297]
 [-1.02220292]] loss fxn value:  0.010030550094688739 learn rate: 1.5625e-05 iteration: 28001
[[ 2.00131756]
 [ 4.04289297]
 [-1.02220308]] loss fxn value:  0.010027764096147208 learn rate: 1.5625e-05 iteration: 28002
[[ 2.00131757]
 [ 4.04289298]
 [-1.02220324]] loss fxn value:  0.010024978871124322 learn rate: 1.5625e-05 iteration: 28003
[[ 2.00131757]
 [ 4.04289298]
 [-1.02220339]] loss fxn value:  0.010022194419434985 learn rate: 1.5625e-05 iteration: 28004
[[ 2.00131757]
 [ 4.04289298]
 [-1.02220355]] loss fxn value:  0.010019410741723586 learn rate: 1.5625e-05 iteration: 28005
[[ 2.00131758]
 [ 4.04289298]
 [-1.02220371]] loss fxn value:  0.010016627837016763 learn rate: 1.5625e-05 iteration: 28006
[[ 2.00131758]
 [ 4.04289298]
 [-1.02220386]] loss fxn value:  0.01001384570473644 learn rate: 1.5625e-05 iteration: 28007
[[ 2.00131758]
 [ 4.04289298]
 [-1.02220402]] loss fxn value:  0.01001106434557486 learn rate: 1.5625e-05 iteration: 28008
[[ 2.00131758]
 [ 4.04289298]
 [-1.02220418]] loss fxn value:  0.010008283758822775 learn rate: 1.5625e-05 iteration: 28009
[[ 2.00131759]
 [ 4.04289298]
 [-1.02220433]] loss fxn value:  0.010005503945182513 learn rate: 1.5625e-05 iteration: 28010
[[ 2.00131759]
 [ 4.04289298]
 [-1.02220449]] loss fxn value:  0.010002724903551842 learn rate: 1.5625e-05 iteration: 28011
[[ 2.00131759]
 [ 4.04289298]
 [-1.02220465]] loss fxn value:  0.009999946632528959 learn rate: 1.5625e-05 iteration: 28012
