Input:
2 4 -1

Output:

[[ 1.9995739 ]
 [ 4.00912711]
 [-1.07224997]] loss fxn value:  0.21341416831973353 learn rate: 1.5625e-05 iteration: 18421
[[ 1.99957396]
 [ 4.00912713]
 [-1.0722533 ]] loss fxn value:  0.2133548922485705 learn rate: 1.5625e-05 iteration: 18422
[[ 1.99957401]
 [ 4.00912714]
 [-1.07225664]] loss fxn value:  0.21329563264170265 learn rate: 1.5625e-05 iteration: 18423
[[ 1.99957407]
 [ 4.00912716]
 [-1.07225997]] loss fxn value:  0.21323638949434567 learn rate: 1.5625e-05 iteration: 18424
[[ 1.99957412]
 [ 4.00912718]
 [-1.0722633 ]] loss fxn value:  0.21317716280115756 learn rate: 1.5625e-05 iteration: 18425
[[ 1.99957418]
 [ 4.00912719]
 [-1.07226663]] loss fxn value:  0.21311795255899105 learn rate: 1.5625e-05 iteration: 18426
[[ 1.99957424]
 [ 4.00912721]
 [-1.07226996]] loss fxn value:  0.21305875876186903 learn rate: 1.5625e-05 iteration: 18427
[[ 1.99957429]
 [ 4.00912723]
 [-1.07227329]] loss fxn value:  0.2129995814061301 learn rate: 1.5625e-05 iteration: 18428
[[ 1.99957435]
 [ 4.00912725]
 [-1.07227662]] loss fxn value:  0.21294042048731082 learn rate: 1.5625e-05 iteration: 18429
[[ 1.9995744 ]
 [ 4.00912726]
 [-1.07227994]] loss fxn value:  0.21288127600080964 learn rate: 1.5625e-05 iteration: 18430
[[ 1.99957446]
 [ 4.00912728]
 [-1.07228327]] loss fxn value:  0.21282214794113957 learn rate: 1.5625e-05 iteration: 18431
[[ 1.99957451]
 [ 4.0091273 ]
 [-1.07228659]] loss fxn value:  0.21276303630429874 learn rate: 1.5625e-05 iteration: 18432
[[ 1.99957457]
 [ 4.00912731]
 [-1.07228992]] loss fxn value:  0.21270394108571875 learn rate: 1.5625e-05 iteration: 18433
[[ 1.99957462]
 [ 4.00912733]
 [-1.07229324]] loss fxn value:  0.2126448622812011 learn rate: 1.5625e-05 iteration: 18434
[[ 1.99957468]
 [ 4.00912735]
 [-1.07229656]] loss fxn value:  0.21258579988684112 learn rate: 1.5625e-05 iteration: 18435
[[ 1.99957473]
 [ 4.00912736]
 [-1.07229988]] loss fxn value:  0.21252675389603107 learn rate: 1.5625e-05 iteration: 18436
[[ 1.99957479]
 [ 4.00912738]
 [-1.0723032 ]] loss fxn value:  0.21246772430582353 learn rate: 1.5625e-05 iteration: 18437
[[ 1.99957485]
 [ 4.0091274 ]
 [-1.07230652]] loss fxn value:  0.21240871111060028 learn rate: 1.5625e-05 iteration: 18438
[[ 1.9995749 ]
 [ 4.00912741]
 [-1.07230984]] loss fxn value:  0.2123497143059149 learn rate: 1.5625e-05 iteration: 18439
[[ 1.99957496]
 [ 4.00912743]
 [-1.07231316]] loss fxn value:  0.21229073388899145 learn rate: 1.5625e-05 iteration: 18440
[[ 1.99957501]
 [ 4.00912745]
 [-1.07231648]] loss fxn value:  0.2122317698534884 learn rate: 1.5625e-05 iteration: 18441
[[ 1.99957507]
 [ 4.00912746]
 [-1.07231979]] loss fxn value:  0.212172822195678 learn rate: 1.5625e-05 iteration: 18442
[[ 1.99957512]
 [ 4.00912748]
 [-1.07232311]] loss fxn value:  0.21211389090931823 learn rate: 1.5625e-05 iteration: 18443
[[ 1.99957518]
 [ 4.0091275 ]
 [-1.07232642]] loss fxn value:  0.21205497599210485 learn rate: 1.5625e-05 iteration: 18444
[[ 1.99957523]
 [ 4.00912751]
 [-1.07232973]] loss fxn value:  0.21199607743854618 learn rate: 1.5625e-05 iteration: 18445
[[ 1.99957529]
 [ 4.00912753]
 [-1.07233305]] loss fxn value:  0.21193719524364546 learn rate: 1.5625e-05 iteration: 18446
[[ 1.99957534]
 [ 4.00912755]
 [-1.07233636]] loss fxn value:  0.21187832940424844 learn rate: 1.5625e-05 iteration: 18447
[[ 1.9995754 ]
 [ 4.00912757]
 [-1.07233967]] loss fxn value:  0.2118194799148396 learn rate: 1.5625e-05 iteration: 18448
[[ 1.99957545]
 [ 4.00912758]
 [-1.07234298]] loss fxn value:  0.21176064677051 learn rate: 1.5625e-05 iteration: 18449
[[ 1.99957551]
 [ 4.0091276 ]
 [-1.07234628]] loss fxn value:  0.21170182996658954 learn rate: 1.5625e-05 iteration: 18450
[[ 1.99957556]
 [ 4.00912762]
 [-1.07234959]] loss fxn value:  0.2116430295005568 learn rate: 1.5625e-05 iteration: 18451
[[ 1.99957562]
 [ 4.00912763]
 [-1.0723529 ]] loss fxn value:  0.21158424536529927 learn rate: 1.5625e-05 iteration: 18452
[[ 1.99957567]
 [ 4.00912765]
 [-1.0723562 ]] loss fxn value:  0.21152547755786485 learn rate: 1.5625e-05 iteration: 18453
[[ 1.99957573]
 [ 4.00912767]
 [-1.07235951]] loss fxn value:  0.2114667260731734 learn rate: 1.5625e-05 iteration: 18454
[[ 1.99957578]
 [ 4.00912768]
 [-1.07236281]] loss fxn value:  0.21140799090620957 learn rate: 1.5625e-05 iteration: 18455
[[ 1.99957584]
 [ 4.0091277 ]
 [-1.07236611]] loss fxn value:  0.21134927205385928 learn rate: 1.5625e-05 iteration: 18456
[[ 1.99957589]
 [ 4.00912772]
 [-1.07236942]] loss fxn value:  0.21129056951057842 learn rate: 1.5625e-05 iteration: 18457
[[ 1.99957595]
 [ 4.00912773]
 [-1.07237272]] loss fxn value:  0.2112318832723081 learn rate: 1.5625e-05 iteration: 18458
[[ 1.999576  ]
 [ 4.00912775]
 [-1.07237602]] loss fxn value:  0.21117321333406378 learn rate: 1.5625e-05 iteration: 18459
[[ 1.99957606]
 [ 4.00912777]
 [-1.07237932]] loss fxn value:  0.211114559690787 learn rate: 1.5625e-05 iteration: 18460
[[ 1.99957611]
 [ 4.00912778]
 [-1.07238261]] loss fxn value:  0.2110559223399085 learn rate: 1.5625e-05 iteration: 18461
[[ 1.99957617]
 [ 4.0091278 ]
 [-1.07238591]] loss fxn value:  0.21099730127386887 learn rate: 1.5625e-05 iteration: 18462
[[ 1.99957622]
 [ 4.00912782]
 [-1.07238921]] loss fxn value:  0.21093869649116484 learn rate: 1.5625e-05 iteration: 18463
[[ 1.99957628]
 [ 4.00912783]
 [-1.0723925 ]] loss fxn value:  0.2108801079852103 learn rate: 1.5625e-05 iteration: 18464
[[ 1.99957633]
 [ 4.00912785]
 [-1.0723958 ]] loss fxn value:  0.2108215357529151 learn rate: 1.5625e-05 iteration: 18465
[[ 1.99957639]
 [ 4.00912787]
 [-1.07239909]] loss fxn value:  0.2107629797892492 learn rate: 1.5625e-05 iteration: 18466
[[ 1.99957644]
 [ 4.00912788]
 [-1.07240238]] loss fxn value:  0.21070444008969444 learn rate: 1.5625e-05 iteration: 18467
[[ 1.9995765 ]
 [ 4.0091279 ]
 [-1.07240568]] loss fxn value:  0.21064591664919216 learn rate: 1.5625e-05 iteration: 18468
[[ 1.99957655]
 [ 4.00912792]
 [-1.07240897]] loss fxn value:  0.21058740946419988 learn rate: 1.5625e-05 iteration: 18469
[[ 1.99957661]
 [ 4.00912793]
 [-1.07241226]] loss fxn value:  0.21052891852818625 learn rate: 1.5625e-05 iteration: 18470
[[ 1.99957666]
 [ 4.00912795]
 [-1.07241555]] loss fxn value:  0.21047044383961028 learn rate: 1.5625e-05 iteration: 18471
[[ 1.99957672]
 [ 4.00912797]
 [-1.07241883]] loss fxn value:  0.2104119853922333 learn rate: 1.5625e-05 iteration: 18472
[[ 1.99957677]
 [ 4.00912798]
 [-1.07242212]] loss fxn value:  0.21035354318126057 learn rate: 1.5625e-05 iteration: 18473
[[ 1.99957683]
 [ 4.009128  ]
 [-1.07242541]] loss fxn value:  0.21029511720257607 learn rate: 1.5625e-05 iteration: 18474
[[ 1.99957688]
 [ 4.00912802]
 [-1.07242869]] loss fxn value:  0.21023670745207382 learn rate: 1.5625e-05 iteration: 18475
[[ 1.99957694]
 [ 4.00912803]
 [-1.07243198]] loss fxn value:  0.21017831392562084 learn rate: 1.5625e-05 iteration: 18476
[[ 1.99957699]
 [ 4.00912805]
 [-1.07243526]] loss fxn value:  0.210119936617314 learn rate: 1.5625e-05 iteration: 18477
[[ 1.99957705]
 [ 4.00912807]
 [-1.07243854]] loss fxn value:  0.21006157552307977 learn rate: 1.5625e-05 iteration: 18478
[[ 1.9995771 ]
 [ 4.00912808]
 [-1.07244182]] loss fxn value:  0.21000323063936166 learn rate: 1.5625e-05 iteration: 18479
[[ 1.99957716]
 [ 4.0091281 ]
 [-1.07244511]] loss fxn value:  0.2099449019605323 learn rate: 1.5625e-05 iteration: 18480
[[ 1.99957721]
 [ 4.00912812]
 [-1.07244839]] loss fxn value:  0.20988658948308772 learn rate: 1.5625e-05 iteration: 18481
[[ 1.99957727]
 [ 4.00912813]
 [-1.07245166]] loss fxn value:  0.2098282932020118 learn rate: 1.5625e-05 iteration: 18482
[[ 1.99957732]
 [ 4.00912815]
 [-1.07245494]] loss fxn value:  0.2097700131122059 learn rate: 1.5625e-05 iteration: 18483
[[ 1.99957738]
 [ 4.00912817]
 [-1.07245822]] loss fxn value:  0.20971174921014907 learn rate: 1.5625e-05 iteration: 18484
[[ 1.99957743]
 [ 4.00912818]
 [-1.0724615 ]] loss fxn value:  0.20965350149124437 learn rate: 1.5625e-05 iteration: 18485
[[ 1.99957749]
 [ 4.0091282 ]
 [-1.07246477]] loss fxn value:  0.20959526995048572 learn rate: 1.5625e-05 iteration: 18486
[[ 1.99957754]
 [ 4.00912822]
 [-1.07246805]] loss fxn value:  0.20953705458380956 learn rate: 1.5625e-05 iteration: 18487
[[ 1.99957759]
 [ 4.00912823]
 [-1.07247132]] loss fxn value:  0.2094788553856695 learn rate: 1.5625e-05 iteration: 18488
[[ 1.99957765]
 [ 4.00912825]
 [-1.07247459]] loss fxn value:  0.2094206723534825 learn rate: 1.5625e-05 iteration: 18489
[[ 1.9995777 ]
 [ 4.00912827]
 [-1.07247786]] loss fxn value:  0.20936250548126134 learn rate: 1.5625e-05 iteration: 18490
[[ 1.99957776]
 [ 4.00912828]
 [-1.07248113]] loss fxn value:  0.20930435476480752 learn rate: 1.5625e-05 iteration: 18491
[[ 1.99957781]
 [ 4.0091283 ]
 [-1.0724844 ]] loss fxn value:  0.20924622020028036 learn rate: 1.5625e-05 iteration: 18492
[[ 1.99957787]
 [ 4.00912832]
 [-1.07248767]] loss fxn value:  0.2091881017824339 learn rate: 1.5625e-05 iteration: 18493
[[ 1.99957792]
 [ 4.00912833]
 [-1.07249094]] loss fxn value:  0.20912999950684016 learn rate: 1.5625e-05 iteration: 18494
[[ 1.99957798]
 [ 4.00912835]
 [-1.07249421]] loss fxn value:  0.20907191336941394 learn rate: 1.5625e-05 iteration: 18495
[[ 1.99957803]
 [ 4.00912837]
 [-1.07249747]] loss fxn value:  0.20901384336557072 learn rate: 1.5625e-05 iteration: 18496
[[ 1.99957809]
 [ 4.00912838]
 [-1.07250074]] loss fxn value:  0.20895578949025653 learn rate: 1.5625e-05 iteration: 18497
[[ 1.99957814]
 [ 4.0091284 ]
 [-1.072504  ]] loss fxn value:  0.2088977517395482 learn rate: 1.5625e-05 iteration: 18498
[[ 1.99957819]
 [ 4.00912842]
 [-1.07250727]] loss fxn value:  0.20883973010963475 learn rate: 1.5625e-05 iteration: 18499
[[ 1.99957825]
 [ 4.00912843]
 [-1.07251053]] loss fxn value:  0.20878172459469568 learn rate: 1.5625e-05 iteration: 18500
[[ 1.9995783 ]
 [ 4.00912845]
 [-1.07251379]] loss fxn value:  0.20872373519103177 learn rate: 1.5625e-05 iteration: 18501
[[ 1.99957836]
 [ 4.00912847]
 [-1.07251705]] loss fxn value:  0.20866576189421507 learn rate: 1.5625e-05 iteration: 18502
[[ 1.99957841]
 [ 4.00912848]
 [-1.07252031]] loss fxn value:  0.20860780469904427 learn rate: 1.5625e-05 iteration: 18503
[[ 1.99957847]
 [ 4.0091285 ]
 [-1.07252357]] loss fxn value:  0.20854986360258665 learn rate: 1.5625e-05 iteration: 18504
[[ 1.99957852]
 [ 4.00912851]
 [-1.07252683]] loss fxn value:  0.2084919385981936 learn rate: 1.5625e-05 iteration: 18505
[[ 1.99957858]
 [ 4.00912853]
 [-1.07253009]] loss fxn value:  0.20843402968342933 learn rate: 1.5625e-05 iteration: 18506
[[ 1.99957863]
 [ 4.00912855]
 [-1.07253334]] loss fxn value:  0.20837613685262413 learn rate: 1.5625e-05 iteration: 18507
[[ 1.99957868]
 [ 4.00912856]
 [-1.0725366 ]] loss fxn value:  0.2083182601013021 learn rate: 1.5625e-05 iteration: 18508
[[ 1.99957874]
 [ 4.00912858]
 [-1.07253985]] loss fxn value:  0.20826039942584976 learn rate: 1.5625e-05 iteration: 18509
[[ 1.99957879]
 [ 4.0091286 ]
 [-1.07254311]] loss fxn value:  0.20820255482028996 learn rate: 1.5625e-05 iteration: 18510
[[ 1.99957885]
 [ 4.00912861]
 [-1.07254636]] loss fxn value:  0.20814472628200106 learn rate: 1.5625e-05 iteration: 18511
[[ 1.9995789 ]
 [ 4.00912863]
 [-1.07254961]] loss fxn value:  0.2080869138054182 learn rate: 1.5625e-05 iteration: 18512
[[ 1.99957896]
 [ 4.00912865]
 [-1.07255286]] loss fxn value:  0.20802911738697488 learn rate: 1.5625e-05 iteration: 18513
[[ 1.99957901]
 [ 4.00912866]
 [-1.07255611]] loss fxn value:  0.2079713370202154 learn rate: 1.5625e-05 iteration: 18514
[[ 1.99957906]
 [ 4.00912868]
 [-1.07255936]] loss fxn value:  0.20791357270304214 learn rate: 1.5625e-05 iteration: 18515
[[ 1.99957912]
 [ 4.0091287 ]
 [-1.07256261]] loss fxn value:  0.20785582442979697 learn rate: 1.5625e-05 iteration: 18516
[[ 1.99957917]
 [ 4.00912871]
 [-1.07256586]] loss fxn value:  0.20779809219652584 learn rate: 1.5625e-05 iteration: 18517
[[ 1.99957923]
 [ 4.00912873]
 [-1.0725691 ]] loss fxn value:  0.20774037599813935 learn rate: 1.5625e-05 iteration: 18518
[[ 1.99957928]
 [ 4.00912875]
 [-1.07257235]] loss fxn value:  0.20768267583016162 learn rate: 1.5625e-05 iteration: 18519
[[ 1.99957933]
 [ 4.00912876]
 [-1.07257559]] loss fxn value:  0.2076249916889106 learn rate: 1.5625e-05 iteration: 18520
[[ 1.99957939]
 [ 4.00912878]
 [-1.07257884]] loss fxn value:  0.20756732356939858 learn rate: 1.5625e-05 iteration: 18521
[[ 1.99957944]
 [ 4.0091288 ]
 [-1.07258208]] loss fxn value:  0.20750967146751972 learn rate: 1.5625e-05 iteration: 18522
[[ 1.9995795 ]
 [ 4.00912881]
 [-1.07258532]] loss fxn value:  0.2074520353777939 learn rate: 1.5625e-05 iteration: 18523
[[ 1.99957955]
 [ 4.00912883]
 [-1.07258856]] loss fxn value:  0.2073944152980996 learn rate: 1.5625e-05 iteration: 18524
[[ 1.99957961]
 [ 4.00912884]
 [-1.0725918 ]] loss fxn value:  0.20733681122140776 learn rate: 1.5625e-05 iteration: 18525
[[ 1.99957966]
 [ 4.00912886]
 [-1.07259504]] loss fxn value:  0.2072792231432571 learn rate: 1.5625e-05 iteration: 18526
[[ 1.99957971]
 [ 4.00912888]
 [-1.07259828]] loss fxn value:  0.20722165106237161 learn rate: 1.5625e-05 iteration: 18527
[[ 1.99957977]
 [ 4.00912889]
 [-1.07260152]] loss fxn value:  0.20716409497084587 learn rate: 1.5625e-05 iteration: 18528
[[ 1.99957982]
 [ 4.00912891]
 [-1.07260475]] loss fxn value:  0.20710655486655608 learn rate: 1.5625e-05 iteration: 18529
[[ 1.99957988]
 [ 4.00912893]
 [-1.07260799]] loss fxn value:  0.20704903074349892 learn rate: 1.5625e-05 iteration: 18530
[[ 1.99957993]
 [ 4.00912894]
 [-1.07261122]] loss fxn value:  0.2069915225981295 learn rate: 1.5625e-05 iteration: 18531
[[ 1.99957998]
 [ 4.00912896]
 [-1.07261446]] loss fxn value:  0.2069340304253013 learn rate: 1.5625e-05 iteration: 18532
[[ 1.99958004]
 [ 4.00912898]
 [-1.07261769]] loss fxn value:  0.20687655422063425 learn rate: 1.5625e-05 iteration: 18533
[[ 1.99958009]
 [ 4.00912899]
 [-1.07262092]] loss fxn value:  0.20681909398086457 learn rate: 1.5625e-05 iteration: 18534
[[ 1.99958014]
 [ 4.00912901]
 [-1.07262415]] loss fxn value:  0.2067616497009645 learn rate: 1.5625e-05 iteration: 18535
[[ 1.9995802 ]
 [ 4.00912903]
 [-1.07262738]] loss fxn value:  0.20670422137547104 learn rate: 1.5625e-05 iteration: 18536
[[ 1.99958025]
 [ 4.00912904]
 [-1.07263061]] loss fxn value:  0.20664680900134186 learn rate: 1.5625e-05 iteration: 18537
[[ 1.99958031]
 [ 4.00912906]
 [-1.07263384]] loss fxn value:  0.20658941257380412 learn rate: 1.5625e-05 iteration: 18538
[[ 1.99958036]
 [ 4.00912907]
 [-1.07263707]] loss fxn value:  0.20653203208712748 learn rate: 1.5625e-05 iteration: 18539
[[ 1.99958041]
 [ 4.00912909]
 [-1.07264029]] loss fxn value:  0.20647466753851523 learn rate: 1.5625e-05 iteration: 18540
[[ 1.99958047]
 [ 4.00912911]
 [-1.07264352]] loss fxn value:  0.20641731892348236 learn rate: 1.5625e-05 iteration: 18541
[[ 1.99958052]
 [ 4.00912912]
 [-1.07264675]] loss fxn value:  0.2063599862364369 learn rate: 1.5625e-05 iteration: 18542
[[ 1.99958058]
 [ 4.00912914]
 [-1.07264997]] loss fxn value:  0.20630266947384168 learn rate: 1.5625e-05 iteration: 18543
[[ 1.99958063]
 [ 4.00912916]
 [-1.07265319]] loss fxn value:  0.20624536863070692 learn rate: 1.5625e-05 iteration: 18544
[[ 1.99958068]
 [ 4.00912917]
 [-1.07265641]] loss fxn value:  0.20618808370380967 learn rate: 1.5625e-05 iteration: 18545
[[ 1.99958074]
 [ 4.00912919]
 [-1.07265964]] loss fxn value:  0.20613081468725764 learn rate: 1.5625e-05 iteration: 18546
[[ 1.99958079]
 [ 4.00912921]
 [-1.07266286]] loss fxn value:  0.20607356157830195 learn rate: 1.5625e-05 iteration: 18547
[[ 1.99958084]
 [ 4.00912922]
 [-1.07266608]] loss fxn value:  0.20601632437009856 learn rate: 1.5625e-05 iteration: 18548
[[ 1.9995809 ]
 [ 4.00912924]
 [-1.07266929]] loss fxn value:  0.20595910306000959 learn rate: 1.5625e-05 iteration: 18549
[[ 1.99958095]
 [ 4.00912925]
 [-1.07267251]] loss fxn value:  0.2059018976434049 learn rate: 1.5625e-05 iteration: 18550
[[ 1.99958101]
 [ 4.00912927]
 [-1.07267573]] loss fxn value:  0.20584470811534253 learn rate: 1.5625e-05 iteration: 18551
[[ 1.99958106]
 [ 4.00912929]
 [-1.07267894]] loss fxn value:  0.2057875344721141 learn rate: 1.5625e-05 iteration: 18552
[[ 1.99958111]
 [ 4.0091293 ]
 [-1.07268216]] loss fxn value:  0.20573037670875582 learn rate: 1.5625e-05 iteration: 18553
[[ 1.99958117]
 [ 4.00912932]
 [-1.07268537]] loss fxn value:  0.20567323482123048 learn rate: 1.5625e-05 iteration: 18554
[[ 1.99958122]
 [ 4.00912934]
 [-1.07268859]] loss fxn value:  0.2056161088048748 learn rate: 1.5625e-05 iteration: 18555
[[ 1.99958127]
 [ 4.00912935]
 [-1.0726918 ]] loss fxn value:  0.2055589986552036 learn rate: 1.5625e-05 iteration: 18556
[[ 1.99958133]
 [ 4.00912937]
 [-1.07269501]] loss fxn value:  0.205501904367725 learn rate: 1.5625e-05 iteration: 18557
[[ 1.99958138]
 [ 4.00912938]
 [-1.07269822]] loss fxn value:  0.20544482593871588 learn rate: 1.5625e-05 iteration: 18558
[[ 1.99958143]
 [ 4.0091294 ]
 [-1.07270143]] loss fxn value:  0.20538776336320103 learn rate: 1.5625e-05 iteration: 18559
[[ 1.99958149]
 [ 4.00912942]
 [-1.07270464]] loss fxn value:  0.20533071663712152 learn rate: 1.5625e-05 iteration: 18560
[[ 1.99958154]
 [ 4.00912943]
 [-1.07270785]] loss fxn value:  0.20527368575541877 learn rate: 1.5625e-05 iteration: 18561
[[ 1.99958159]
 [ 4.00912945]
 [-1.07271105]] loss fxn value:  0.2052166707139938 learn rate: 1.5625e-05 iteration: 18562
[[ 1.99958165]
 [ 4.00912947]
 [-1.07271426]] loss fxn value:  0.2051596715083923 learn rate: 1.5625e-05 iteration: 18563
[[ 1.9995817 ]
 [ 4.00912948]
 [-1.07271746]] loss fxn value:  0.20510268813543392 learn rate: 1.5625e-05 iteration: 18564
[[ 1.99958176]
 [ 4.0091295 ]
 [-1.07272067]] loss fxn value:  0.20504572058899415 learn rate: 1.5625e-05 iteration: 18565
[[ 1.99958181]
 [ 4.00912951]
 [-1.07272387]] loss fxn value:  0.20498876886569936 learn rate: 1.5625e-05 iteration: 18566
[[ 1.99958186]
 [ 4.00912953]
 [-1.07272707]] loss fxn value:  0.20493183296038148 learn rate: 1.5625e-05 iteration: 18567
[[ 1.99958192]
 [ 4.00912955]
 [-1.07273028]] loss fxn value:  0.2048749128695196 learn rate: 1.5625e-05 iteration: 18568
[[ 1.99958197]
 [ 4.00912956]
 [-1.07273348]] loss fxn value:  0.20481800858794869 learn rate: 1.5625e-05 iteration: 18569
[[ 1.99958202]
 [ 4.00912958]
 [-1.07273668]] loss fxn value:  0.20476112011131864 learn rate: 1.5625e-05 iteration: 18570
[[ 1.99958208]
 [ 4.0091296 ]
 [-1.07273988]] loss fxn value:  0.20470424743632562 learn rate: 1.5625e-05 iteration: 18571
[[ 1.99958213]
 [ 4.00912961]
 [-1.07274307]] loss fxn value:  0.20464739055753278 learn rate: 1.5625e-05 iteration: 18572
[[ 1.99958218]
 [ 4.00912963]
 [-1.07274627]] loss fxn value:  0.2045905494713074 learn rate: 1.5625e-05 iteration: 18573
[[ 1.99958224]
 [ 4.00912964]
 [-1.07274947]] loss fxn value:  0.20453372417267873 learn rate: 1.5625e-05 iteration: 18574
[[ 1.99958229]
 [ 4.00912966]
 [-1.07275266]] loss fxn value:  0.2044769146561005 learn rate: 1.5625e-05 iteration: 18575
[[ 1.99958234]
 [ 4.00912968]
 [-1.07275586]] loss fxn value:  0.20442012091945122 learn rate: 1.5625e-05 iteration: 18576
[[ 1.9995824 ]
 [ 4.00912969]
 [-1.07275905]] loss fxn value:  0.20436334295660638 learn rate: 1.5625e-05 iteration: 18577
[[ 1.99958245]
 [ 4.00912971]
 [-1.07276224]] loss fxn value:  0.20430658076465175 learn rate: 1.5625e-05 iteration: 18578
[[ 1.9995825 ]
 [ 4.00912973]
 [-1.07276543]] loss fxn value:  0.20424983433874355 learn rate: 1.5625e-05 iteration: 18579
[[ 1.99958256]
 [ 4.00912974]
 [-1.07276863]] loss fxn value:  0.20419310367366778 learn rate: 1.5625e-05 iteration: 18580
[[ 1.99958261]
 [ 4.00912976]
 [-1.07277182]] loss fxn value:  0.2041363887652329 learn rate: 1.5625e-05 iteration: 18581
[[ 1.99958266]
 [ 4.00912977]
 [-1.072775  ]] loss fxn value:  0.2040796896097845 learn rate: 1.5625e-05 iteration: 18582
[[ 1.99958272]
 [ 4.00912979]
 [-1.07277819]] loss fxn value:  0.20402300620282596 learn rate: 1.5625e-05 iteration: 18583
[[ 1.99958277]
 [ 4.00912981]
 [-1.07278138]] loss fxn value:  0.20396633854024349 learn rate: 1.5625e-05 iteration: 18584
[[ 1.99958282]
 [ 4.00912982]
 [-1.07278457]] loss fxn value:  0.20390968661606002 learn rate: 1.5625e-05 iteration: 18585
[[ 1.99958287]
 [ 4.00912984]
 [-1.07278775]] loss fxn value:  0.2038530504276971 learn rate: 1.5625e-05 iteration: 18586
[[ 1.99958293]
 [ 4.00912986]
 [-1.07279094]] loss fxn value:  0.20379642996954894 learn rate: 1.5625e-05 iteration: 18587
[[ 1.99958298]
 [ 4.00912987]
 [-1.07279412]] loss fxn value:  0.2037398252375474 learn rate: 1.5625e-05 iteration: 18588
[[ 1.99958303]
 [ 4.00912989]
 [-1.0727973 ]] loss fxn value:  0.2036832362286994 learn rate: 1.5625e-05 iteration: 18589
[[ 1.99958309]
 [ 4.0091299 ]
 [-1.07280049]] loss fxn value:  0.2036266629367664 learn rate: 1.5625e-05 iteration: 18590
[[ 1.99958314]
 [ 4.00912992]
 [-1.07280367]] loss fxn value:  0.20357010535836773 learn rate: 1.5625e-05 iteration: 18591
[[ 1.99958319]
 [ 4.00912994]
 [-1.07280685]] loss fxn value:  0.2035135634893589 learn rate: 1.5625e-05 iteration: 18592
[[ 1.99958325]
 [ 4.00912995]
 [-1.07281003]] loss fxn value:  0.20345703732465742 learn rate: 1.5625e-05 iteration: 18593
[[ 1.9995833 ]
 [ 4.00912997]
 [-1.07281321]] loss fxn value:  0.20340052685976207 learn rate: 1.5625e-05 iteration: 18594
[[ 1.99958335]
 [ 4.00912998]
 [-1.07281638]] loss fxn value:  0.20334403209153012 learn rate: 1.5625e-05 iteration: 18595
[[ 1.99958341]
 [ 4.00913   ]
 [-1.07281956]] loss fxn value:  0.2032875530139799 learn rate: 1.5625e-05 iteration: 18596
[[ 1.99958346]
 [ 4.00913002]
 [-1.07282274]] loss fxn value:  0.20323108962405664 learn rate: 1.5625e-05 iteration: 18597
[[ 1.99958351]
 [ 4.00913003]
 [-1.07282591]] loss fxn value:  0.20317464191602658 learn rate: 1.5625e-05 iteration: 18598
[[ 1.99958356]
 [ 4.00913005]
 [-1.07282908]] loss fxn value:  0.20311820988801502 learn rate: 1.5625e-05 iteration: 18599
[[ 1.99958362]
 [ 4.00913007]
 [-1.07283226]] loss fxn value:  0.2030617935332932 learn rate: 1.5625e-05 iteration: 18600
[[ 1.99958367]
 [ 4.00913008]
 [-1.07283543]] loss fxn value:  0.20300539284794492 learn rate: 1.5625e-05 iteration: 18601
[[ 1.99958372]
 [ 4.0091301 ]
 [-1.0728386 ]] loss fxn value:  0.20294900782791123 learn rate: 1.5625e-05 iteration: 18602
[[ 1.99958378]
 [ 4.00913011]
 [-1.07284177]] loss fxn value:  0.2028926384698975 learn rate: 1.5625e-05 iteration: 18603
[[ 1.99958383]
 [ 4.00913013]
 [-1.07284494]] loss fxn value:  0.20283628476710286 learn rate: 1.5625e-05 iteration: 18604
[[ 1.99958388]
 [ 4.00913015]
 [-1.07284811]] loss fxn value:  0.20277994671737043 learn rate: 1.5625e-05 iteration: 18605
[[ 1.99958393]
 [ 4.00913016]
 [-1.07285128]] loss fxn value:  0.20272362431507512 learn rate: 1.5625e-05 iteration: 18606
[[ 1.99958399]
 [ 4.00913018]
 [-1.07285445]] loss fxn value:  0.20266731755720538 learn rate: 1.5625e-05 iteration: 18607
[[ 1.99958404]
 [ 4.00913019]
 [-1.07285761]] loss fxn value:  0.20261102643861942 learn rate: 1.5625e-05 iteration: 18608
[[ 1.99958409]
 [ 4.00913021]
 [-1.07286078]] loss fxn value:  0.20255475095481595 learn rate: 1.5625e-05 iteration: 18609
[[ 1.99958415]
 [ 4.00913023]
 [-1.07286394]] loss fxn value:  0.202498491101286 learn rate: 1.5625e-05 iteration: 18610
[[ 1.9995842 ]
 [ 4.00913024]
 [-1.07286711]] loss fxn value:  0.20244224687524903 learn rate: 1.5625e-05 iteration: 18611
[[ 1.99958425]
 [ 4.00913026]
 [-1.07287027]] loss fxn value:  0.20238601826895933 learn rate: 1.5625e-05 iteration: 18612
[[ 1.9995843 ]
 [ 4.00913027]
 [-1.07287343]] loss fxn value:  0.20232980528161165 learn rate: 1.5625e-05 iteration: 18613
[[ 1.99958436]
 [ 4.00913029]
 [-1.07287659]] loss fxn value:  0.2022736079067433 learn rate: 1.5625e-05 iteration: 18614
[[ 1.99958441]
 [ 4.00913031]
 [-1.07287975]] loss fxn value:  0.20221742614216656 learn rate: 1.5625e-05 iteration: 18615
[[ 1.99958446]
 [ 4.00913032]
 [-1.07288291]] loss fxn value:  0.20216125998041137 learn rate: 1.5625e-05 iteration: 18616
[[ 1.99958451]
 [ 4.00913034]
 [-1.07288607]] loss fxn value:  0.2021051094199159 learn rate: 1.5625e-05 iteration: 18617
[[ 1.99958457]
 [ 4.00913035]
 [-1.07288923]] loss fxn value:  0.2020489744546174 learn rate: 1.5625e-05 iteration: 18618
[[ 1.99958462]
 [ 4.00913037]
 [-1.07289238]] loss fxn value:  0.20199285508227566 learn rate: 1.5625e-05 iteration: 18619
[[ 1.99958467]
 [ 4.00913039]
 [-1.07289554]] loss fxn value:  0.2019367512956273 learn rate: 1.5625e-05 iteration: 18620
[[ 1.99958473]
 [ 4.0091304 ]
 [-1.07289869]] loss fxn value:  0.20188066309281358 learn rate: 1.5625e-05 iteration: 18621
[[ 1.99958478]
 [ 4.00913042]
 [-1.07290185]] loss fxn value:  0.2018245904679568 learn rate: 1.5625e-05 iteration: 18622
[[ 1.99958483]
 [ 4.00913043]
 [-1.072905  ]] loss fxn value:  0.20176853341792217 learn rate: 1.5625e-05 iteration: 18623
[[ 1.99958488]
 [ 4.00913045]
 [-1.07290815]] loss fxn value:  0.20171249193714155 learn rate: 1.5625e-05 iteration: 18624
[[ 1.99958494]
 [ 4.00913047]
 [-1.0729113 ]] loss fxn value:  0.2016564660225032 learn rate: 1.5625e-05 iteration: 18625
[[ 1.99958499]
 [ 4.00913048]
 [-1.07291445]] loss fxn value:  0.20160045566853713 learn rate: 1.5625e-05 iteration: 18626
[[ 1.99958504]
 [ 4.0091305 ]
 [-1.0729176 ]] loss fxn value:  0.2015444608725484 learn rate: 1.5625e-05 iteration: 18627
[[ 1.99958509]
 [ 4.00913051]
 [-1.07292075]] loss fxn value:  0.20148848162904778 learn rate: 1.5625e-05 iteration: 18628
[[ 1.99958515]
 [ 4.00913053]
 [-1.0729239 ]] loss fxn value:  0.20143251793343825 learn rate: 1.5625e-05 iteration: 18629
[[ 1.9995852 ]
 [ 4.00913055]
 [-1.07292705]] loss fxn value:  0.20137656978170876 learn rate: 1.5625e-05 iteration: 18630
[[ 1.99958525]
 [ 4.00913056]
 [-1.07293019]] loss fxn value:  0.201320637169734 learn rate: 1.5625e-05 iteration: 18631
[[ 1.9995853 ]
 [ 4.00913058]
 [-1.07293334]] loss fxn value:  0.2012647200934335 learn rate: 1.5625e-05 iteration: 18632
[[ 1.99958536]
 [ 4.00913059]
 [-1.07293648]] loss fxn value:  0.201208818547287 learn rate: 1.5625e-05 iteration: 18633
[[ 1.99958541]
 [ 4.00913061]
 [-1.07293963]] loss fxn value:  0.20115293252825225 learn rate: 1.5625e-05 iteration: 18634
[[ 1.99958546]
 [ 4.00913063]
 [-1.07294277]] loss fxn value:  0.2010970620325845 learn rate: 1.5625e-05 iteration: 18635
[[ 1.99958551]
 [ 4.00913064]
 [-1.07294591]] loss fxn value:  0.20104120705384512 learn rate: 1.5625e-05 iteration: 18636
[[ 1.99958557]
 [ 4.00913066]
 [-1.07294905]] loss fxn value:  0.20098536759004518 learn rate: 1.5625e-05 iteration: 18637
[[ 1.99958562]
 [ 4.00913067]
 [-1.07295219]] loss fxn value:  0.20092954363441587 learn rate: 1.5625e-05 iteration: 18638
[[ 1.99958567]
 [ 4.00913069]
 [-1.07295533]] loss fxn value:  0.20087373518411383 learn rate: 1.5625e-05 iteration: 18639
[[ 1.99958572]
 [ 4.00913071]
 [-1.07295847]] loss fxn value:  0.2008179422358375 learn rate: 1.5625e-05 iteration: 18640
[[ 1.99958578]
 [ 4.00913072]
 [-1.0729616 ]] loss fxn value:  0.20076216478311495 learn rate: 1.5625e-05 iteration: 18641
[[ 1.99958583]
 [ 4.00913074]
 [-1.07296474]] loss fxn value:  0.20070640282296476 learn rate: 1.5625e-05 iteration: 18642
[[ 1.99958588]
 [ 4.00913075]
 [-1.07296788]] loss fxn value:  0.20065065635113358 learn rate: 1.5625e-05 iteration: 18643
[[ 1.99958593]
 [ 4.00913077]
 [-1.07297101]] loss fxn value:  0.20059492536222237 learn rate: 1.5625e-05 iteration: 18644
[[ 1.99958598]
 [ 4.00913079]
 [-1.07297415]] loss fxn value:  0.20053920985262694 learn rate: 1.5625e-05 iteration: 18645
[[ 1.99958604]
 [ 4.0091308 ]
 [-1.07297728]] loss fxn value:  0.20048350981865268 learn rate: 1.5625e-05 iteration: 18646
[[ 1.99958609]
 [ 4.00913082]
 [-1.07298041]] loss fxn value:  0.20042782525532446 learn rate: 1.5625e-05 iteration: 18647
[[ 1.99958614]
 [ 4.00913083]
 [-1.07298354]] loss fxn value:  0.2003721561585524 learn rate: 1.5625e-05 iteration: 18648
[[ 1.99958619]
 [ 4.00913085]
 [-1.07298667]] loss fxn value:  0.2003165025238229 learn rate: 1.5625e-05 iteration: 18649
[[ 1.99958625]
 [ 4.00913086]
 [-1.0729898 ]] loss fxn value:  0.2002608643469158 learn rate: 1.5625e-05 iteration: 18650
[[ 1.9995863 ]
 [ 4.00913088]
 [-1.07299293]] loss fxn value:  0.20020524162389336 learn rate: 1.5625e-05 iteration: 18651
[[ 1.99958635]
 [ 4.0091309 ]
 [-1.07299606]] loss fxn value:  0.2001496343506017 learn rate: 1.5625e-05 iteration: 18652
[[ 1.9995864 ]
 [ 4.00913091]
 [-1.07299918]] loss fxn value:  0.2000940425210706 learn rate: 1.5625e-05 iteration: 18653
[[ 1.99958645]
 [ 4.00913093]
 [-1.07300231]] loss fxn value:  0.20003846613269083 learn rate: 1.5625e-05 iteration: 18654
[[ 1.99958651]
 [ 4.00913094]
 [-1.07300544]] loss fxn value:  0.19998290518127998 learn rate: 1.5625e-05 iteration: 18655
[[ 1.99958656]
 [ 4.00913096]
 [-1.07300856]] loss fxn value:  0.19992735966090336 learn rate: 1.5625e-05 iteration: 18656
[[ 1.99958661]
 [ 4.00913098]
 [-1.07301168]] loss fxn value:  0.19987182956897787 learn rate: 1.5625e-05 iteration: 18657
[[ 1.99958666]
 [ 4.00913099]
 [-1.07301481]] loss fxn value:  0.19981631490083337 learn rate: 1.5625e-05 iteration: 18658
[[ 1.99958672]
 [ 4.00913101]
 [-1.07301793]] loss fxn value:  0.19976081565192766 learn rate: 1.5625e-05 iteration: 18659
[[ 1.99958677]
 [ 4.00913102]
 [-1.07302105]] loss fxn value:  0.199705331817714 learn rate: 1.5625e-05 iteration: 18660
[[ 1.99958682]
 [ 4.00913104]
 [-1.07302417]] loss fxn value:  0.19964986339418353 learn rate: 1.5625e-05 iteration: 18661
[[ 1.99958687]
 [ 4.00913105]
 [-1.07302729]] loss fxn value:  0.199594410377137 learn rate: 1.5625e-05 iteration: 18662
[[ 1.99958692]
 [ 4.00913107]
 [-1.07303041]] loss fxn value:  0.19953897276258717 learn rate: 1.5625e-05 iteration: 18663
[[ 1.99958698]
 [ 4.00913109]
 [-1.07303352]] loss fxn value:  0.1994835505463347 learn rate: 1.5625e-05 iteration: 18664
[[ 1.99958703]
 [ 4.0091311 ]
 [-1.07303664]] loss fxn value:  0.19942814372248352 learn rate: 1.5625e-05 iteration: 18665
[[ 1.99958708]
 [ 4.00913112]
 [-1.07303975]] loss fxn value:  0.1993727522888712 learn rate: 1.5625e-05 iteration: 18666
[[ 1.99958713]
 [ 4.00913113]
 [-1.07304287]] loss fxn value:  0.19931737623944507 learn rate: 1.5625e-05 iteration: 18667
[[ 1.99958718]
 [ 4.00913115]
 [-1.07304598]] loss fxn value:  0.19926201557066953 learn rate: 1.5625e-05 iteration: 18668
[[ 1.99958724]
 [ 4.00913117]
 [-1.0730491 ]] loss fxn value:  0.19920667027981873 learn rate: 1.5625e-05 iteration: 18669
[[ 1.99958729]
 [ 4.00913118]
 [-1.07305221]] loss fxn value:  0.19915134036040386 learn rate: 1.5625e-05 iteration: 18670
[[ 1.99958734]
 [ 4.0091312 ]
 [-1.07305532]] loss fxn value:  0.1990960258084469 learn rate: 1.5625e-05 iteration: 18671
[[ 1.99958739]
 [ 4.00913121]
 [-1.07305843]] loss fxn value:  0.1990407266212291 learn rate: 1.5625e-05 iteration: 18672
[[ 1.99958744]
 [ 4.00913123]
 [-1.07306154]] loss fxn value:  0.19898544279274474 learn rate: 1.5625e-05 iteration: 18673
[[ 1.99958749]
 [ 4.00913124]
 [-1.07306465]] loss fxn value:  0.19893017431894958 learn rate: 1.5625e-05 iteration: 18674
[[ 1.99958755]
 [ 4.00913126]
 [-1.07306776]] loss fxn value:  0.19887492119716715 learn rate: 1.5625e-05 iteration: 18675
[[ 1.9995876 ]
 [ 4.00913128]
 [-1.07307086]] loss fxn value:  0.19881968342096568 learn rate: 1.5625e-05 iteration: 18676
[[ 1.99958765]
 [ 4.00913129]
 [-1.07307397]] loss fxn value:  0.198764460987641 learn rate: 1.5625e-05 iteration: 18677
[[ 1.9995877 ]
 [ 4.00913131]
 [-1.07307707]] loss fxn value:  0.19870925389267485 learn rate: 1.5625e-05 iteration: 18678
[[ 1.99958775]
 [ 4.00913132]
 [-1.07308018]] loss fxn value:  0.19865406213140865 learn rate: 1.5625e-05 iteration: 18679
[[ 1.99958781]
 [ 4.00913134]
 [-1.07308328]] loss fxn value:  0.19859888569986442 learn rate: 1.5625e-05 iteration: 18680
[[ 1.99958786]
 [ 4.00913135]
 [-1.07308638]] loss fxn value:  0.19854372459258368 learn rate: 1.5625e-05 iteration: 18681
[[ 1.99958791]
 [ 4.00913137]
 [-1.07308949]] loss fxn value:  0.19848857880769763 learn rate: 1.5625e-05 iteration: 18682
[[ 1.99958796]
 [ 4.00913139]
 [-1.07309259]] loss fxn value:  0.1984334483392816 learn rate: 1.5625e-05 iteration: 18683
[[ 1.99958801]
 [ 4.0091314 ]
 [-1.07309569]] loss fxn value:  0.19837833318331663 learn rate: 1.5625e-05 iteration: 18684
[[ 1.99958806]
 [ 4.00913142]
 [-1.07309879]] loss fxn value:  0.19832323333518742 learn rate: 1.5625e-05 iteration: 18685
[[ 1.99958812]
 [ 4.00913143]
 [-1.07310189]] loss fxn value:  0.19826814879174665 learn rate: 1.5625e-05 iteration: 18686
[[ 1.99958817]
 [ 4.00913145]
 [-1.07310498]] loss fxn value:  0.19821307954798822 learn rate: 1.5625e-05 iteration: 18687
[[ 1.99958822]
 [ 4.00913146]
 [-1.07310808]] loss fxn value:  0.19815802560027476 learn rate: 1.5625e-05 iteration: 18688
[[ 1.99958827]
 [ 4.00913148]
 [-1.07311118]] loss fxn value:  0.19810298694264064 learn rate: 1.5625e-05 iteration: 18689
[[ 1.99958832]
 [ 4.0091315 ]
 [-1.07311427]] loss fxn value:  0.19804796357198182 learn rate: 1.5625e-05 iteration: 18690
[[ 1.99958837]
 [ 4.00913151]
 [-1.07311736]] loss fxn value:  0.1979929554860673 learn rate: 1.5625e-05 iteration: 18691
[[ 1.99958843]
 [ 4.00913153]
 [-1.07312046]] loss fxn value:  0.19793796267646838 learn rate: 1.5625e-05 iteration: 18692
[[ 1.99958848]
 [ 4.00913154]
 [-1.07312355]] loss fxn value:  0.19788298514217503 learn rate: 1.5625e-05 iteration: 18693
[[ 1.99958853]
 [ 4.00913156]
 [-1.07312664]] loss fxn value:  0.19782802287883836 learn rate: 1.5625e-05 iteration: 18694
[[ 1.99958858]
 [ 4.00913157]
 [-1.07312973]] loss fxn value:  0.197773075880593 learn rate: 1.5625e-05 iteration: 18695
[[ 1.99958863]
 [ 4.00913159]
 [-1.07313282]] loss fxn value:  0.1977181441433801 learn rate: 1.5625e-05 iteration: 18696
[[ 1.99958868]
 [ 4.00913161]
 [-1.07313591]] loss fxn value:  0.19766322766456637 learn rate: 1.5625e-05 iteration: 18697
[[ 1.99958874]
 [ 4.00913162]
 [-1.073139  ]] loss fxn value:  0.19760832643797027 learn rate: 1.5625e-05 iteration: 18698
[[ 1.99958879]
 [ 4.00913164]
 [-1.07314209]] loss fxn value:  0.19755344046070375 learn rate: 1.5625e-05 iteration: 18699
[[ 1.99958884]
 [ 4.00913165]
 [-1.07314517]] loss fxn value:  0.1974985697280773 learn rate: 1.5625e-05 iteration: 18700
[[ 1.99958889]
 [ 4.00913167]
 [-1.07314826]] loss fxn value:  0.1974437142350517 learn rate: 1.5625e-05 iteration: 18701
[[ 1.99958894]
 [ 4.00913168]
 [-1.07315134]] loss fxn value:  0.1973888739795101 learn rate: 1.5625e-05 iteration: 18702
[[ 1.99958899]
 [ 4.0091317 ]
 [-1.07315443]] loss fxn value:  0.19733404895581352 learn rate: 1.5625e-05 iteration: 18703
[[ 1.99958904]
 [ 4.00913172]
 [-1.07315751]] loss fxn value:  0.19727923915950552 learn rate: 1.5625e-05 iteration: 18704
[[ 1.9995891 ]
 [ 4.00913173]
 [-1.07316059]] loss fxn value:  0.19722444458649163 learn rate: 1.5625e-05 iteration: 18705
[[ 1.99958915]
 [ 4.00913175]
 [-1.07316367]] loss fxn value:  0.19716966523268664 learn rate: 1.5625e-05 iteration: 18706
[[ 1.9995892 ]
 [ 4.00913176]
 [-1.07316675]] loss fxn value:  0.19711490109447943 learn rate: 1.5625e-05 iteration: 18707
[[ 1.99958925]
 [ 4.00913178]
 [-1.07316983]] loss fxn value:  0.19706015216671655 learn rate: 1.5625e-05 iteration: 18708
[[ 1.9995893 ]
 [ 4.00913179]
 [-1.07317291]] loss fxn value:  0.19700541844460098 learn rate: 1.5625e-05 iteration: 18709
[[ 1.99958935]
 [ 4.00913181]
 [-1.07317599]] loss fxn value:  0.19695069992668765 learn rate: 1.5625e-05 iteration: 18710
[[ 1.9995894 ]
 [ 4.00913183]
 [-1.07317906]] loss fxn value:  0.19689599660560916 learn rate: 1.5625e-05 iteration: 18711
[[ 1.99958945]
 [ 4.00913184]
 [-1.07318214]] loss fxn value:  0.1968413084787493 learn rate: 1.5625e-05 iteration: 18712
[[ 1.99958951]
 [ 4.00913186]
 [-1.07318522]] loss fxn value:  0.19678663554205378 learn rate: 1.5625e-05 iteration: 18713
[[ 1.99958956]
 [ 4.00913187]
 [-1.07318829]] loss fxn value:  0.19673197779034754 learn rate: 1.5625e-05 iteration: 18714
[[ 1.99958961]
 [ 4.00913189]
 [-1.07319136]] loss fxn value:  0.19667733522019523 learn rate: 1.5625e-05 iteration: 18715
[[ 1.99958966]
 [ 4.0091319 ]
 [-1.07319444]] loss fxn value:  0.19662270782683877 learn rate: 1.5625e-05 iteration: 18716
[[ 1.99958971]
 [ 4.00913192]
 [-1.07319751]] loss fxn value:  0.19656809560639513 learn rate: 1.5625e-05 iteration: 18717
[[ 1.99958976]
 [ 4.00913193]
 [-1.07320058]] loss fxn value:  0.19651349855414388 learn rate: 1.5625e-05 iteration: 18718
[[ 1.99958981]
 [ 4.00913195]
 [-1.07320365]] loss fxn value:  0.19645891666753054 learn rate: 1.5625e-05 iteration: 18719
[[ 1.99958987]
 [ 4.00913197]
 [-1.07320672]] loss fxn value:  0.19640434993952594 learn rate: 1.5625e-05 iteration: 18720
[[ 1.99958992]
 [ 4.00913198]
 [-1.07320979]] loss fxn value:  0.1963497983694606 learn rate: 1.5625e-05 iteration: 18721
[[ 1.99958997]
 [ 4.009132  ]
 [-1.07321285]] loss fxn value:  0.19629526194930566 learn rate: 1.5625e-05 iteration: 18722
[[ 1.99959002]
 [ 4.00913201]
 [-1.07321592]] loss fxn value:  0.19624074067760805 learn rate: 1.5625e-05 iteration: 18723
[[ 1.99959007]
 [ 4.00913203]
 [-1.07321899]] loss fxn value:  0.19618623454854373 learn rate: 1.5625e-05 iteration: 18724
[[ 1.99959012]
 [ 4.00913204]
 [-1.07322205]] loss fxn value:  0.19613174355919835 learn rate: 1.5625e-05 iteration: 18725
[[ 1.99959017]
 [ 4.00913206]
 [-1.07322512]] loss fxn value:  0.1960772677044586 learn rate: 1.5625e-05 iteration: 18726
[[ 1.99959022]
 [ 4.00913207]
 [-1.07322818]] loss fxn value:  0.19602280698117028 learn rate: 1.5625e-05 iteration: 18727
[[ 1.99959027]
 [ 4.00913209]
 [-1.07323124]] loss fxn value:  0.19596836138335166 learn rate: 1.5625e-05 iteration: 18728
[[ 1.99959033]
 [ 4.00913211]
 [-1.0732343 ]] loss fxn value:  0.19591393090934747 learn rate: 1.5625e-05 iteration: 18729
[[ 1.99959038]
 [ 4.00913212]
 [-1.07323736]] loss fxn value:  0.19585951555209075 learn rate: 1.5625e-05 iteration: 18730
[[ 1.99959043]
 [ 4.00913214]
 [-1.07324042]] loss fxn value:  0.19580511531006436 learn rate: 1.5625e-05 iteration: 18731
[[ 1.99959048]
 [ 4.00913215]
 [-1.07324348]] loss fxn value:  0.19575073017612035 learn rate: 1.5625e-05 iteration: 18732
[[ 1.99959053]
 [ 4.00913217]
 [-1.07324654]] loss fxn value:  0.19569636014921324 learn rate: 1.5625e-05 iteration: 18733
[[ 1.99959058]
 [ 4.00913218]
 [-1.0732496 ]] loss fxn value:  0.195642005223173 learn rate: 1.5625e-05 iteration: 18734
[[ 1.99959063]
 [ 4.0091322 ]
 [-1.07325265]] loss fxn value:  0.1955876653940595 learn rate: 1.5625e-05 iteration: 18735
[[ 1.99959068]
 [ 4.00913221]
 [-1.07325571]] loss fxn value:  0.1955333406586476 learn rate: 1.5625e-05 iteration: 18736
[[ 1.99959073]
 [ 4.00913223]
 [-1.07325876]] loss fxn value:  0.19547903101101177 learn rate: 1.5625e-05 iteration: 18737
[[ 1.99959078]
 [ 4.00913225]
 [-1.07326182]] loss fxn value:  0.19542473644840783 learn rate: 1.5625e-05 iteration: 18738
[[ 1.99959084]
 [ 4.00913226]
 [-1.07326487]] loss fxn value:  0.19537045696587438 learn rate: 1.5625e-05 iteration: 18739
[[ 1.99959089]
 [ 4.00913228]
 [-1.07326792]] loss fxn value:  0.19531619256031885 learn rate: 1.5625e-05 iteration: 18740
[[ 1.99959094]
 [ 4.00913229]
 [-1.07327097]] loss fxn value:  0.19526194322601448 learn rate: 1.5625e-05 iteration: 18741
[[ 1.99959099]
 [ 4.00913231]
 [-1.07327403]] loss fxn value:  0.1952077089595922 learn rate: 1.5625e-05 iteration: 18742
[[ 1.99959104]
 [ 4.00913232]
 [-1.07327707]] loss fxn value:  0.19515348975686275 learn rate: 1.5625e-05 iteration: 18743
[[ 1.99959109]
 [ 4.00913234]
 [-1.07328012]] loss fxn value:  0.19509928561413853 learn rate: 1.5625e-05 iteration: 18744
[[ 1.99959114]
 [ 4.00913235]
 [-1.07328317]] loss fxn value:  0.19504509652601823 learn rate: 1.5625e-05 iteration: 18745
[[ 1.99959119]
 [ 4.00913237]
 [-1.07328622]] loss fxn value:  0.19499092248935684 learn rate: 1.5625e-05 iteration: 18746
[[ 1.99959124]
 [ 4.00913238]
 [-1.07328927]] loss fxn value:  0.19493676349900094 learn rate: 1.5625e-05 iteration: 18747
[[ 1.99959129]
 [ 4.0091324 ]
 [-1.07329231]] loss fxn value:  0.19488261955199612 learn rate: 1.5625e-05 iteration: 18748
[[ 1.99959134]
 [ 4.00913242]
 [-1.07329536]] loss fxn value:  0.19482849064362212 learn rate: 1.5625e-05 iteration: 18749
[[ 1.99959139]
 [ 4.00913243]
 [-1.0732984 ]] loss fxn value:  0.19477437676888432 learn rate: 1.5625e-05 iteration: 18750
[[ 1.99959145]
 [ 4.00913245]
 [-1.07330144]] loss fxn value:  0.19472027792519042 learn rate: 1.5625e-05 iteration: 18751
[[ 1.9995915 ]
 [ 4.00913246]
 [-1.07330448]] loss fxn value:  0.19466619410734384 learn rate: 1.5625e-05 iteration: 18752
[[ 1.99959155]
 [ 4.00913248]
 [-1.07330752]] loss fxn value:  0.1946121253114214 learn rate: 1.5625e-05 iteration: 18753
[[ 1.9995916 ]
 [ 4.00913249]
 [-1.07331057]] loss fxn value:  0.19455807153327392 learn rate: 1.5625e-05 iteration: 18754
[[ 1.99959165]
 [ 4.00913251]
 [-1.0733136 ]] loss fxn value:  0.1945040327677811 learn rate: 1.5625e-05 iteration: 18755
[[ 1.9995917 ]
 [ 4.00913252]
 [-1.07331664]] loss fxn value:  0.19445000901245485 learn rate: 1.5625e-05 iteration: 18756
[[ 1.99959175]
 [ 4.00913254]
 [-1.07331968]] loss fxn value:  0.19439600026208692 learn rate: 1.5625e-05 iteration: 18757
[[ 1.9995918 ]
 [ 4.00913255]
 [-1.07332272]] loss fxn value:  0.19434200651266623 learn rate: 1.5625e-05 iteration: 18758
[[ 1.99959185]
 [ 4.00913257]
 [-1.07332575]] loss fxn value:  0.19428802776010298 learn rate: 1.5625e-05 iteration: 18759
[[ 1.9995919 ]
 [ 4.00913259]
 [-1.07332879]] loss fxn value:  0.194234064000312 learn rate: 1.5625e-05 iteration: 18760
[[ 1.99959195]
 [ 4.0091326 ]
 [-1.07333182]] loss fxn value:  0.1941801152286848 learn rate: 1.5625e-05 iteration: 18761
[[ 1.999592  ]
 [ 4.00913262]
 [-1.07333486]] loss fxn value:  0.1941261814416673 learn rate: 1.5625e-05 iteration: 18762
[[ 1.99959205]
 [ 4.00913263]
 [-1.07333789]] loss fxn value:  0.19407226263559577 learn rate: 1.5625e-05 iteration: 18763
[[ 1.9995921 ]
 [ 4.00913265]
 [-1.07334092]] loss fxn value:  0.19401835880447615 learn rate: 1.5625e-05 iteration: 18764
[[ 1.99959215]
 [ 4.00913266]
 [-1.07334395]] loss fxn value:  0.19396446994525454 learn rate: 1.5625e-05 iteration: 18765
[[ 1.99959221]
 [ 4.00913268]
 [-1.07334698]] loss fxn value:  0.19391059605331695 learn rate: 1.5625e-05 iteration: 18766
[[ 1.99959226]
 [ 4.00913269]
 [-1.07335001]] loss fxn value:  0.1938567371259593 learn rate: 1.5625e-05 iteration: 18767
[[ 1.99959231]
 [ 4.00913271]
 [-1.07335304]] loss fxn value:  0.19380289315768762 learn rate: 1.5625e-05 iteration: 18768
[[ 1.99959236]
 [ 4.00913272]
 [-1.07335607]] loss fxn value:  0.19374906414444992 learn rate: 1.5625e-05 iteration: 18769
[[ 1.99959241]
 [ 4.00913274]
 [-1.0733591 ]] loss fxn value:  0.1936952500825733 learn rate: 1.5625e-05 iteration: 18770
[[ 1.99959246]
 [ 4.00913275]
 [-1.07336212]] loss fxn value:  0.19364145096753724 learn rate: 1.5625e-05 iteration: 18771
[[ 1.99959251]
 [ 4.00913277]
 [-1.07336515]] loss fxn value:  0.19358766679522335 learn rate: 1.5625e-05 iteration: 18772
[[ 1.99959256]
 [ 4.00913278]
 [-1.07336817]] loss fxn value:  0.19353389756108488 learn rate: 1.5625e-05 iteration: 18773
[[ 1.99959261]
 [ 4.0091328 ]
 [-1.0733712 ]] loss fxn value:  0.1934801432624863 learn rate: 1.5625e-05 iteration: 18774
[[ 1.99959266]
 [ 4.00913282]
 [-1.07337422]] loss fxn value:  0.19342640389290788 learn rate: 1.5625e-05 iteration: 18775
[[ 1.99959271]
 [ 4.00913283]
 [-1.07337724]] loss fxn value:  0.19337267945068284 learn rate: 1.5625e-05 iteration: 18776
[[ 1.99959276]
 [ 4.00913285]
 [-1.07338026]] loss fxn value:  0.1933189699292914 learn rate: 1.5625e-05 iteration: 18777
[[ 1.99959281]
 [ 4.00913286]
 [-1.07338328]] loss fxn value:  0.1932652753270715 learn rate: 1.5625e-05 iteration: 18778
[[ 1.99959286]
 [ 4.00913288]
 [-1.0733863 ]] loss fxn value:  0.19321159563841497 learn rate: 1.5625e-05 iteration: 18779
[[ 1.99959291]
 [ 4.00913289]
 [-1.07338932]] loss fxn value:  0.19315793085843683 learn rate: 1.5625e-05 iteration: 18780
[[ 1.99959296]
 [ 4.00913291]
 [-1.07339234]] loss fxn value:  0.193104280984352 learn rate: 1.5625e-05 iteration: 18781
[[ 1.99959301]
 [ 4.00913292]
 [-1.07339535]] loss fxn value:  0.19305064601118288 learn rate: 1.5625e-05 iteration: 18782
[[ 1.99959306]
 [ 4.00913294]
 [-1.07339837]] loss fxn value:  0.19299702593575827 learn rate: 1.5625e-05 iteration: 18783
[[ 1.99959311]
 [ 4.00913295]
 [-1.07340138]] loss fxn value:  0.19294342075346047 learn rate: 1.5625e-05 iteration: 18784
[[ 1.99959316]
 [ 4.00913297]
 [-1.0734044 ]] loss fxn value:  0.19288983046078007 learn rate: 1.5625e-05 iteration: 18785
[[ 1.99959321]
 [ 4.00913298]
 [-1.07340741]] loss fxn value:  0.19283625505119503 learn rate: 1.5625e-05 iteration: 18786
[[ 1.99959326]
 [ 4.009133  ]
 [-1.07341042]] loss fxn value:  0.19278269452346236 learn rate: 1.5625e-05 iteration: 18787
[[ 1.99959331]
 [ 4.00913301]
 [-1.07341344]] loss fxn value:  0.19272914887158335 learn rate: 1.5625e-05 iteration: 18788
[[ 1.99959336]
 [ 4.00913303]
 [-1.07341645]] loss fxn value:  0.19267561809252257 learn rate: 1.5625e-05 iteration: 18789
[[ 1.99959341]
 [ 4.00913305]
 [-1.07341946]] loss fxn value:  0.19262210218104792 learn rate: 1.5625e-05 iteration: 18790
[[ 1.99959346]
 [ 4.00913306]
 [-1.07342247]] loss fxn value:  0.19256860113510738 learn rate: 1.5625e-05 iteration: 18791
[[ 1.99959352]
 [ 4.00913308]
 [-1.07342548]] loss fxn value:  0.19251511494771423 learn rate: 1.5625e-05 iteration: 18792
[[ 1.99959357]
 [ 4.00913309]
 [-1.07342848]] loss fxn value:  0.19246164361671378 learn rate: 1.5625e-05 iteration: 18793
[[ 1.99959362]
 [ 4.00913311]
 [-1.07343149]] loss fxn value:  0.19240818713801164 learn rate: 1.5625e-05 iteration: 18794
[[ 1.99959367]
 [ 4.00913312]
 [-1.0734345 ]] loss fxn value:  0.1923547455064259 learn rate: 1.5625e-05 iteration: 18795
[[ 1.99959372]
 [ 4.00913314]
 [-1.0734375 ]] loss fxn value:  0.1923013187176473 learn rate: 1.5625e-05 iteration: 18796
[[ 1.99959377]
 [ 4.00913315]
 [-1.0734405 ]] loss fxn value:  0.19224790676931916 learn rate: 1.5625e-05 iteration: 18797
[[ 1.99959382]
 [ 4.00913317]
 [-1.07344351]] loss fxn value:  0.19219450965589047 learn rate: 1.5625e-05 iteration: 18798
[[ 1.99959387]
 [ 4.00913318]
 [-1.07344651]] loss fxn value:  0.19214112737293554 learn rate: 1.5625e-05 iteration: 18799
[[ 1.99959392]
 [ 4.0091332 ]
 [-1.07344951]] loss fxn value:  0.19208775991675292 learn rate: 1.5625e-05 iteration: 18800
[[ 1.99959397]
 [ 4.00913321]
 [-1.07345251]] loss fxn value:  0.1920344072851402 learn rate: 1.5625e-05 iteration: 18801
[[ 1.99959402]
 [ 4.00913323]
 [-1.07345551]] loss fxn value:  0.19198106947021817 learn rate: 1.5625e-05 iteration: 18802
[[ 1.99959407]
 [ 4.00913324]
 [-1.07345851]] loss fxn value:  0.19192774647174898 learn rate: 1.5625e-05 iteration: 18803
[[ 1.99959412]
 [ 4.00913326]
 [-1.07346151]] loss fxn value:  0.19187443828269335 learn rate: 1.5625e-05 iteration: 18804
[[ 1.99959417]
 [ 4.00913327]
 [-1.07346451]] loss fxn value:  0.19182114490140376 learn rate: 1.5625e-05 iteration: 18805
[[ 1.99959422]
 [ 4.00913329]
 [-1.07346751]] loss fxn value:  0.19176786632088424 learn rate: 1.5625e-05 iteration: 18806
[[ 1.99959427]
 [ 4.0091333 ]
 [-1.0734705 ]] loss fxn value:  0.19171460254001293 learn rate: 1.5625e-05 iteration: 18807
[[ 1.99959432]
 [ 4.00913332]
 [-1.0734735 ]] loss fxn value:  0.19166135355214667 learn rate: 1.5625e-05 iteration: 18808
[[ 1.99959437]
 [ 4.00913333]
 [-1.07347649]] loss fxn value:  0.19160811935434718 learn rate: 1.5625e-05 iteration: 18809
[[ 1.99959442]
 [ 4.00913335]
 [-1.07347948]] loss fxn value:  0.19155489994188724 learn rate: 1.5625e-05 iteration: 18810
[[ 1.99959447]
 [ 4.00913336]
 [-1.07348248]] loss fxn value:  0.19150169531264308 learn rate: 1.5625e-05 iteration: 18811
[[ 1.99959452]
 [ 4.00913338]
 [-1.07348547]] loss fxn value:  0.19144850546058967 learn rate: 1.5625e-05 iteration: 18812
[[ 1.99959457]
 [ 4.0091334 ]
 [-1.07348846]] loss fxn value:  0.1913953303816234 learn rate: 1.5625e-05 iteration: 18813
[[ 1.99959462]
 [ 4.00913341]
 [-1.07349145]] loss fxn value:  0.19134217007222798 learn rate: 1.5625e-05 iteration: 18814
[[ 1.99959467]
 [ 4.00913343]
 [-1.07349444]] loss fxn value:  0.19128902452822794 learn rate: 1.5625e-05 iteration: 18815
[[ 1.99959472]
 [ 4.00913344]
 [-1.07349743]] loss fxn value:  0.19123589374550723 learn rate: 1.5625e-05 iteration: 18816
[[ 1.99959477]
 [ 4.00913346]
 [-1.07350041]] loss fxn value:  0.19118277771956235 learn rate: 1.5625e-05 iteration: 18817
[[ 1.99959482]
 [ 4.00913347]
 [-1.0735034 ]] loss fxn value:  0.1911296764477053 learn rate: 1.5625e-05 iteration: 18818
[[ 1.99959487]
 [ 4.00913349]
 [-1.07350639]] loss fxn value:  0.19107658992344947 learn rate: 1.5625e-05 iteration: 18819
[[ 1.99959491]
 [ 4.0091335 ]
 [-1.07350937]] loss fxn value:  0.1910235181446665 learn rate: 1.5625e-05 iteration: 18820
[[ 1.99959496]
 [ 4.00913352]
 [-1.07351236]] loss fxn value:  0.19097046110666463 learn rate: 1.5625e-05 iteration: 18821
[[ 1.99959501]
 [ 4.00913353]
 [-1.07351534]] loss fxn value:  0.1909174188059537 learn rate: 1.5625e-05 iteration: 18822
[[ 1.99959506]
 [ 4.00913355]
 [-1.07351832]] loss fxn value:  0.1908643912364779 learn rate: 1.5625e-05 iteration: 18823
[[ 1.99959511]
 [ 4.00913356]
 [-1.0735213 ]] loss fxn value:  0.19081137839604484 learn rate: 1.5625e-05 iteration: 18824
[[ 1.99959516]
 [ 4.00913358]
 [-1.07352429]] loss fxn value:  0.1907583802811212 learn rate: 1.5625e-05 iteration: 18825
[[ 1.99959521]
 [ 4.00913359]
 [-1.07352727]] loss fxn value:  0.1907053968849929 learn rate: 1.5625e-05 iteration: 18826
[[ 1.99959526]
 [ 4.00913361]
 [-1.07353025]] loss fxn value:  0.19065242820587322 learn rate: 1.5625e-05 iteration: 18827
[[ 1.99959531]
 [ 4.00913362]
 [-1.07353322]] loss fxn value:  0.1905994742382925 learn rate: 1.5625e-05 iteration: 18828
[[ 1.99959536]
 [ 4.00913364]
 [-1.0735362 ]] loss fxn value:  0.19054653497895813 learn rate: 1.5625e-05 iteration: 18829
[[ 1.99959541]
 [ 4.00913365]
 [-1.07353918]] loss fxn value:  0.19049361042454688 learn rate: 1.5625e-05 iteration: 18830
[[ 1.99959546]
 [ 4.00913367]
 [-1.07354215]] loss fxn value:  0.19044070056817236 learn rate: 1.5625e-05 iteration: 18831
[[ 1.99959551]
 [ 4.00913368]
 [-1.07354513]] loss fxn value:  0.190387805409044 learn rate: 1.5625e-05 iteration: 18832
[[ 1.99959556]
 [ 4.0091337 ]
 [-1.0735481 ]] loss fxn value:  0.1903349249407677 learn rate: 1.5625e-05 iteration: 18833
[[ 1.99959561]
 [ 4.00913371]
 [-1.07355108]] loss fxn value:  0.19028205916058918 learn rate: 1.5625e-05 iteration: 18834
[[ 1.99959566]
 [ 4.00913373]
 [-1.07355405]] loss fxn value:  0.19022920806396165 learn rate: 1.5625e-05 iteration: 18835
[[ 1.99959571]
 [ 4.00913374]
 [-1.07355702]] loss fxn value:  0.1901763716467861 learn rate: 1.5625e-05 iteration: 18836
[[ 1.99959576]
 [ 4.00913376]
 [-1.07355999]] loss fxn value:  0.19012354990458671 learn rate: 1.5625e-05 iteration: 18837
[[ 1.99959581]
 [ 4.00913377]
 [-1.07356296]] loss fxn value:  0.19007074283408582 learn rate: 1.5625e-05 iteration: 18838
[[ 1.99959586]
 [ 4.00913379]
 [-1.07356593]] loss fxn value:  0.19001795043075825 learn rate: 1.5625e-05 iteration: 18839
[[ 1.99959591]
 [ 4.0091338 ]
 [-1.0735689 ]] loss fxn value:  0.18996517269060914 learn rate: 1.5625e-05 iteration: 18840
[[ 1.99959596]
 [ 4.00913382]
 [-1.07357187]] loss fxn value:  0.18991240960937047 learn rate: 1.5625e-05 iteration: 18841
[[ 1.99959601]
 [ 4.00913383]
 [-1.07357484]] loss fxn value:  0.18985966118315223 learn rate: 1.5625e-05 iteration: 18842
[[ 1.99959606]
 [ 4.00913385]
 [-1.0735778 ]] loss fxn value:  0.18980692740762706 learn rate: 1.5625e-05 iteration: 18843
[[ 1.99959611]
 [ 4.00913386]
 [-1.07358077]] loss fxn value:  0.18975420827942135 learn rate: 1.5625e-05 iteration: 18844
[[ 1.99959616]
 [ 4.00913388]
 [-1.07358373]] loss fxn value:  0.18970150379469095 learn rate: 1.5625e-05 iteration: 18845
[[ 1.99959621]
 [ 4.00913389]
 [-1.0735867 ]] loss fxn value:  0.18964881394759367 learn rate: 1.5625e-05 iteration: 18846
[[ 1.99959625]
 [ 4.00913391]
 [-1.07358966]] loss fxn value:  0.18959613873587083 learn rate: 1.5625e-05 iteration: 18847
[[ 1.9995963 ]
 [ 4.00913392]
 [-1.07359262]] loss fxn value:  0.18954347815452555 learn rate: 1.5625e-05 iteration: 18848
[[ 1.99959635]
 [ 4.00913394]
 [-1.07359558]] loss fxn value:  0.18949083219989188 learn rate: 1.5625e-05 iteration: 18849
[[ 1.9995964 ]
 [ 4.00913395]
 [-1.07359854]] loss fxn value:  0.1894382008664566 learn rate: 1.5625e-05 iteration: 18850
[[ 1.99959645]
 [ 4.00913397]
 [-1.0736015 ]] loss fxn value:  0.18938558415261464 learn rate: 1.5625e-05 iteration: 18851
[[ 1.9995965 ]
 [ 4.00913398]
 [-1.07360446]] loss fxn value:  0.1893329820526368 learn rate: 1.5625e-05 iteration: 18852
[[ 1.99959655]
 [ 4.009134  ]
 [-1.07360742]] loss fxn value:  0.18928039456355952 learn rate: 1.5625e-05 iteration: 18853
[[ 1.9995966 ]
 [ 4.00913401]
 [-1.07361037]] loss fxn value:  0.18922782168072091 learn rate: 1.5625e-05 iteration: 18854
[[ 1.99959665]
 [ 4.00913403]
 [-1.07361333]] loss fxn value:  0.18917526339955112 learn rate: 1.5625e-05 iteration: 18855
[[ 1.9995967 ]
 [ 4.00913404]
 [-1.07361629]] loss fxn value:  0.1891227197169623 learn rate: 1.5625e-05 iteration: 18856
[[ 1.99959675]
 [ 4.00913406]
 [-1.07361924]] loss fxn value:  0.1890701906283151 learn rate: 1.5625e-05 iteration: 18857
[[ 1.9995968 ]
 [ 4.00913407]
 [-1.07362219]] loss fxn value:  0.18901767612912676 learn rate: 1.5625e-05 iteration: 18858
[[ 1.99959685]
 [ 4.00913409]
 [-1.07362515]] loss fxn value:  0.18896517621670464 learn rate: 1.5625e-05 iteration: 18859
[[ 1.9995969]
 [ 4.0091341]
 [-1.0736281]] loss fxn value:  0.1889126908854554 learn rate: 1.5625e-05 iteration: 18860
[[ 1.99959695]
 [ 4.00913412]
 [-1.07363105]] loss fxn value:  0.1888602201332475 learn rate: 1.5625e-05 iteration: 18861
[[ 1.99959699]
 [ 4.00913413]
 [-1.073634  ]] loss fxn value:  0.18880776395497303 learn rate: 1.5625e-05 iteration: 18862
[[ 1.99959704]
 [ 4.00913415]
 [-1.07363695]] loss fxn value:  0.188755322344759 learn rate: 1.5625e-05 iteration: 18863
[[ 1.99959709]
 [ 4.00913416]
 [-1.0736399 ]] loss fxn value:  0.18870289530129386 learn rate: 1.5625e-05 iteration: 18864
[[ 1.99959714]
 [ 4.00913418]
 [-1.07364285]] loss fxn value:  0.18865048281955218 learn rate: 1.5625e-05 iteration: 18865
[[ 1.99959719]
 [ 4.00913419]
 [-1.0736458 ]] loss fxn value:  0.1885980848944091 learn rate: 1.5625e-05 iteration: 18866
[[ 1.99959724]
 [ 4.00913421]
 [-1.07364874]] loss fxn value:  0.18854570152471659 learn rate: 1.5625e-05 iteration: 18867
[[ 1.99959729]
 [ 4.00913422]
 [-1.07365169]] loss fxn value:  0.188493332703924 learn rate: 1.5625e-05 iteration: 18868
[[ 1.99959734]
 [ 4.00913424]
 [-1.07365463]] loss fxn value:  0.1884409784279963 learn rate: 1.5625e-05 iteration: 18869
[[ 1.99959739]
 [ 4.00913425]
 [-1.07365758]] loss fxn value:  0.1883886386938102 learn rate: 1.5625e-05 iteration: 18870
[[ 1.99959744]
 [ 4.00913427]
 [-1.07366052]] loss fxn value:  0.18833631349676408 learn rate: 1.5625e-05 iteration: 18871
[[ 1.99959749]
 [ 4.00913428]
 [-1.07366346]] loss fxn value:  0.18828400283462005 learn rate: 1.5625e-05 iteration: 18872
[[ 1.99959753]
 [ 4.0091343 ]
 [-1.0736664 ]] loss fxn value:  0.18823170669997288 learn rate: 1.5625e-05 iteration: 18873
[[ 1.99959758]
 [ 4.00913431]
 [-1.07366934]] loss fxn value:  0.188179425091213 learn rate: 1.5625e-05 iteration: 18874
[[ 1.99959763]
 [ 4.00913433]
 [-1.07367228]] loss fxn value:  0.1881271580036554 learn rate: 1.5625e-05 iteration: 18875
[[ 1.99959768]
 [ 4.00913434]
 [-1.07367522]] loss fxn value:  0.18807490543364655 learn rate: 1.5625e-05 iteration: 18876
[[ 1.99959773]
 [ 4.00913436]
 [-1.07367816]] loss fxn value:  0.18802266737725096 learn rate: 1.5625e-05 iteration: 18877
[[ 1.99959778]
 [ 4.00913437]
 [-1.0736811 ]] loss fxn value:  0.18797044382875325 learn rate: 1.5625e-05 iteration: 18878
[[ 1.99959783]
 [ 4.00913439]
 [-1.07368403]] loss fxn value:  0.18791823478664632 learn rate: 1.5625e-05 iteration: 18879
[[ 1.99959788]
 [ 4.0091344 ]
 [-1.07368697]] loss fxn value:  0.18786604024567655 learn rate: 1.5625e-05 iteration: 18880
[[ 1.99959793]
 [ 4.00913442]
 [-1.07368991]] loss fxn value:  0.1878138602008856 learn rate: 1.5625e-05 iteration: 18881
[[ 1.99959798]
 [ 4.00913443]
 [-1.07369284]] loss fxn value:  0.18776169464972603 learn rate: 1.5625e-05 iteration: 18882
[[ 1.99959802]
 [ 4.00913445]
 [-1.07369577]] loss fxn value:  0.18770954358785336 learn rate: 1.5625e-05 iteration: 18883
[[ 1.99959807]
 [ 4.00913446]
 [-1.07369871]] loss fxn value:  0.18765740701043276 learn rate: 1.5625e-05 iteration: 18884
[[ 1.99959812]
 [ 4.00913448]
 [-1.07370164]] loss fxn value:  0.18760528491513384 learn rate: 1.5625e-05 iteration: 18885
[[ 1.99959817]
 [ 4.00913449]
 [-1.07370457]] loss fxn value:  0.18755317729464852 learn rate: 1.5625e-05 iteration: 18886
[[ 1.99959822]
 [ 4.00913451]
 [-1.0737075 ]] loss fxn value:  0.18750108414958347 learn rate: 1.5625e-05 iteration: 18887
[[ 1.99959827]
 [ 4.00913452]
 [-1.07371043]] loss fxn value:  0.18744900547197152 learn rate: 1.5625e-05 iteration: 18888
[[ 1.99959832]
 [ 4.00913454]
 [-1.07371336]] loss fxn value:  0.18739694126026704 learn rate: 1.5625e-05 iteration: 18889
[[ 1.99959837]
 [ 4.00913455]
 [-1.07371628]] loss fxn value:  0.18734489150776057 learn rate: 1.5625e-05 iteration: 18890
[[ 1.99959842]
 [ 4.00913457]
 [-1.07371921]] loss fxn value:  0.18729285621393923 learn rate: 1.5625e-05 iteration: 18891
[[ 1.99959846]
 [ 4.00913458]
 [-1.07372214]] loss fxn value:  0.18724083537209033 learn rate: 1.5625e-05 iteration: 18892
[[ 1.99959851]
 [ 4.0091346 ]
 [-1.07372506]] loss fxn value:  0.18718882897927877 learn rate: 1.5625e-05 iteration: 18893
[[ 1.99959856]
 [ 4.00913461]
 [-1.07372799]] loss fxn value:  0.1871368370312196 learn rate: 1.5625e-05 iteration: 18894
[[ 1.99959861]
 [ 4.00913463]
 [-1.07373091]] loss fxn value:  0.1870848595239943 learn rate: 1.5625e-05 iteration: 18895
[[ 1.99959866]
 [ 4.00913464]
 [-1.07373383]] loss fxn value:  0.18703289645339197 learn rate: 1.5625e-05 iteration: 18896
[[ 1.99959871]
 [ 4.00913466]
 [-1.07373675]] loss fxn value:  0.18698094781628694 learn rate: 1.5625e-05 iteration: 18897
[[ 1.99959876]
 [ 4.00913467]
 [-1.07373968]] loss fxn value:  0.18692901360855854 learn rate: 1.5625e-05 iteration: 18898
[[ 1.99959881]
 [ 4.00913469]
 [-1.0737426 ]] loss fxn value:  0.18687709382332723 learn rate: 1.5625e-05 iteration: 18899
[[ 1.99959885]
 [ 4.0091347 ]
 [-1.07374552]] loss fxn value:  0.18682518846079743 learn rate: 1.5625e-05 iteration: 18900
[[ 1.9995989 ]
 [ 4.00913471]
 [-1.07374843]] loss fxn value:  0.18677329751434674 learn rate: 1.5625e-05 iteration: 18901
[[ 1.99959895]
 [ 4.00913473]
 [-1.07375135]] loss fxn value:  0.18672142098144226 learn rate: 1.5625e-05 iteration: 18902
[[ 1.999599  ]
 [ 4.00913474]
 [-1.07375427]] loss fxn value:  0.18666955885603054 learn rate: 1.5625e-05 iteration: 18903
[[ 1.99959905]
 [ 4.00913476]
 [-1.07375719]] loss fxn value:  0.1866177111364185 learn rate: 1.5625e-05 iteration: 18904
[[ 1.9995991 ]
 [ 4.00913477]
 [-1.0737601 ]] loss fxn value:  0.18656587781704823 learn rate: 1.5625e-05 iteration: 18905
[[ 1.99959915]
 [ 4.00913479]
 [-1.07376302]] loss fxn value:  0.18651405889388933 learn rate: 1.5625e-05 iteration: 18906
[[ 1.9995992 ]
 [ 4.0091348 ]
 [-1.07376593]] loss fxn value:  0.18646225436467304 learn rate: 1.5625e-05 iteration: 18907
[[ 1.99959924]
 [ 4.00913482]
 [-1.07376884]] loss fxn value:  0.1864104642243408 learn rate: 1.5625e-05 iteration: 18908
[[ 1.99959929]
 [ 4.00913483]
 [-1.07377175]] loss fxn value:  0.186358688468396 learn rate: 1.5625e-05 iteration: 18909
[[ 1.99959934]
 [ 4.00913485]
 [-1.07377467]] loss fxn value:  0.18630692709266322 learn rate: 1.5625e-05 iteration: 18910
[[ 1.99959939]
 [ 4.00913486]
 [-1.07377758]] loss fxn value:  0.18625518009459258 learn rate: 1.5625e-05 iteration: 18911
[[ 1.99959944]
 [ 4.00913488]
 [-1.07378049]] loss fxn value:  0.18620344746900439 learn rate: 1.5625e-05 iteration: 18912
[[ 1.99959949]
 [ 4.00913489]
 [-1.0737834 ]] loss fxn value:  0.18615172921140438 learn rate: 1.5625e-05 iteration: 18913
[[ 1.99959954]
 [ 4.00913491]
 [-1.0737863 ]] loss fxn value:  0.18610002531955921 learn rate: 1.5625e-05 iteration: 18914
[[ 1.99959958]
 [ 4.00913492]
 [-1.07378921]] loss fxn value:  0.186048335787975 learn rate: 1.5625e-05 iteration: 18915
[[ 1.99959963]
 [ 4.00913494]
 [-1.07379212]] loss fxn value:  0.18599666061395914 learn rate: 1.5625e-05 iteration: 18916
[[ 1.99959968]
 [ 4.00913495]
 [-1.07379502]] loss fxn value:  0.18594499979196064 learn rate: 1.5625e-05 iteration: 18917
[[ 1.99959973]
 [ 4.00913497]
 [-1.07379793]] loss fxn value:  0.18589335331986265 learn rate: 1.5625e-05 iteration: 18918
[[ 1.99959978]
 [ 4.00913498]
 [-1.07380083]] loss fxn value:  0.18584172119162864 learn rate: 1.5625e-05 iteration: 18919
[[ 1.99959983]
 [ 4.009135  ]
 [-1.07380374]] loss fxn value:  0.1857901034050184 learn rate: 1.5625e-05 iteration: 18920
[[ 1.99959987]
 [ 4.00913501]
 [-1.07380664]] loss fxn value:  0.18573849995457575 learn rate: 1.5625e-05 iteration: 18921
[[ 1.99959992]
 [ 4.00913502]
 [-1.07380954]] loss fxn value:  0.18568691083804897 learn rate: 1.5625e-05 iteration: 18922
[[ 1.99959997]
 [ 4.00913504]
 [-1.07381244]] loss fxn value:  0.18563533604947477 learn rate: 1.5625e-05 iteration: 18923
[[ 1.99960002]
 [ 4.00913505]
 [-1.07381534]] loss fxn value:  0.18558377558621295 learn rate: 1.5625e-05 iteration: 18924
[[ 1.99960007]
 [ 4.00913507]
 [-1.07381824]] loss fxn value:  0.18553222944408124 learn rate: 1.5625e-05 iteration: 18925
[[ 1.99960012]
 [ 4.00913508]
 [-1.07382114]] loss fxn value:  0.1854806976190469 learn rate: 1.5625e-05 iteration: 18926
[[ 1.99960017]
 [ 4.0091351 ]
 [-1.07382404]] loss fxn value:  0.1854291801064798 learn rate: 1.5625e-05 iteration: 18927
[[ 1.99960021]
 [ 4.00913511]
 [-1.07382693]] loss fxn value:  0.18537767690332843 learn rate: 1.5625e-05 iteration: 18928
[[ 1.99960026]
 [ 4.00913513]
 [-1.07382983]] loss fxn value:  0.18532618800537407 learn rate: 1.5625e-05 iteration: 18929
[[ 1.99960031]
 [ 4.00913514]
 [-1.07383272]] loss fxn value:  0.18527471340914595 learn rate: 1.5625e-05 iteration: 18930
[[ 1.99960036]
 [ 4.00913516]
 [-1.07383562]] loss fxn value:  0.1852232531084386 learn rate: 1.5625e-05 iteration: 18931
[[ 1.99960041]
 [ 4.00913517]
 [-1.07383851]] loss fxn value:  0.18517180710223743 learn rate: 1.5625e-05 iteration: 18932
[[ 1.99960045]
 [ 4.00913519]
 [-1.07384141]] loss fxn value:  0.1851203753848363 learn rate: 1.5625e-05 iteration: 18933
[[ 1.9996005]
 [ 4.0091352]
 [-1.0738443]] loss fxn value:  0.18506895795315287 learn rate: 1.5625e-05 iteration: 18934
[[ 1.99960055]
 [ 4.00913522]
 [-1.07384719]] loss fxn value:  0.18501755480219254 learn rate: 1.5625e-05 iteration: 18935
[[ 1.9996006 ]
 [ 4.00913523]
 [-1.07385008]] loss fxn value:  0.18496616592823226 learn rate: 1.5625e-05 iteration: 18936
[[ 1.99960065]
 [ 4.00913525]
 [-1.07385297]] loss fxn value:  0.18491479132726096 learn rate: 1.5625e-05 iteration: 18937
[[ 1.9996007 ]
 [ 4.00913526]
 [-1.07385586]] loss fxn value:  0.1848634309970738 learn rate: 1.5625e-05 iteration: 18938
[[ 1.99960074]
 [ 4.00913527]
 [-1.07385875]] loss fxn value:  0.18481208493108947 learn rate: 1.5625e-05 iteration: 18939
[[ 1.99960079]
 [ 4.00913529]
 [-1.07386163]] loss fxn value:  0.18476075312678883 learn rate: 1.5625e-05 iteration: 18940
[[ 1.99960084]
 [ 4.0091353 ]
 [-1.07386452]] loss fxn value:  0.1847094355804488 learn rate: 1.5625e-05 iteration: 18941
[[ 1.99960089]
 [ 4.00913532]
 [-1.07386741]] loss fxn value:  0.184658132287461 learn rate: 1.5625e-05 iteration: 18942
[[ 1.99960094]
 [ 4.00913533]
 [-1.07387029]] loss fxn value:  0.18460684324388751 learn rate: 1.5625e-05 iteration: 18943
[[ 1.99960098]
 [ 4.00913535]
 [-1.07387317]] loss fxn value:  0.18455556844592974 learn rate: 1.5625e-05 iteration: 18944
[[ 1.99960103]
 [ 4.00913536]
 [-1.07387606]] loss fxn value:  0.18450430788959046 learn rate: 1.5625e-05 iteration: 18945
[[ 1.99960108]
 [ 4.00913538]
 [-1.07387894]] loss fxn value:  0.18445306157120367 learn rate: 1.5625e-05 iteration: 18946
[[ 1.99960113]
 [ 4.00913539]
 [-1.07388182]] loss fxn value:  0.1844018294852824 learn rate: 1.5625e-05 iteration: 18947
[[ 1.99960118]
 [ 4.00913541]
 [-1.0738847 ]] loss fxn value:  0.1843506116306192 learn rate: 1.5625e-05 iteration: 18948
[[ 1.99960123]
 [ 4.00913542]
 [-1.07388758]] loss fxn value:  0.18429940800151107 learn rate: 1.5625e-05 iteration: 18949
[[ 1.99960127]
 [ 4.00913544]
 [-1.07389046]] loss fxn value:  0.184248218594011 learn rate: 1.5625e-05 iteration: 18950
[[ 1.99960132]
 [ 4.00913545]
 [-1.07389334]] loss fxn value:  0.18419704340500712 learn rate: 1.5625e-05 iteration: 18951
[[ 1.99960137]
 [ 4.00913546]
 [-1.07389622]] loss fxn value:  0.18414588242931287 learn rate: 1.5625e-05 iteration: 18952
[[ 1.99960142]
 [ 4.00913548]
 [-1.07389909]] loss fxn value:  0.18409473566389514 learn rate: 1.5625e-05 iteration: 18953
[[ 1.99960147]
 [ 4.00913549]
 [-1.07390197]] loss fxn value:  0.18404360310499315 learn rate: 1.5625e-05 iteration: 18954
[[ 1.99960151]
 [ 4.00913551]
 [-1.07390485]] loss fxn value:  0.18399248474723864 learn rate: 1.5625e-05 iteration: 18955
[[ 1.99960156]
 [ 4.00913552]
 [-1.07390772]] loss fxn value:  0.18394138058840065 learn rate: 1.5625e-05 iteration: 18956
[[ 1.99960161]
 [ 4.00913554]
 [-1.07391059]] loss fxn value:  0.18389029062379972 learn rate: 1.5625e-05 iteration: 18957
[[ 1.99960166]
 [ 4.00913555]
 [-1.07391347]] loss fxn value:  0.18383921484944324 learn rate: 1.5625e-05 iteration: 18958
[[ 1.99960171]
 [ 4.00913557]
 [-1.07391634]] loss fxn value:  0.18378815326120138 learn rate: 1.5625e-05 iteration: 18959
[[ 1.99960175]
 [ 4.00913558]
 [-1.07391921]] loss fxn value:  0.18373710585498657 learn rate: 1.5625e-05 iteration: 18960
[[ 1.9996018 ]
 [ 4.0091356 ]
 [-1.07392208]] loss fxn value:  0.18368607262760459 learn rate: 1.5625e-05 iteration: 18961
[[ 1.99960185]
 [ 4.00913561]
 [-1.07392495]] loss fxn value:  0.1836350535754673 learn rate: 1.5625e-05 iteration: 18962
[[ 1.9996019 ]
 [ 4.00913563]
 [-1.07392782]] loss fxn value:  0.18358404869305225 learn rate: 1.5625e-05 iteration: 18963
[[ 1.99960194]
 [ 4.00913564]
 [-1.07393069]] loss fxn value:  0.18353305797771233 learn rate: 1.5625e-05 iteration: 18964
[[ 1.99960199]
 [ 4.00913565]
 [-1.07393355]] loss fxn value:  0.18348208142567213 learn rate: 1.5625e-05 iteration: 18965
[[ 1.99960204]
 [ 4.00913567]
 [-1.07393642]] loss fxn value:  0.18343111903115653 learn rate: 1.5625e-05 iteration: 18966
[[ 1.99960209]
 [ 4.00913568]
 [-1.07393929]] loss fxn value:  0.18338017079229668 learn rate: 1.5625e-05 iteration: 18967
[[ 1.99960214]
 [ 4.0091357 ]
 [-1.07394215]] loss fxn value:  0.18332923670457202 learn rate: 1.5625e-05 iteration: 18968
[[ 1.99960218]
 [ 4.00913571]
 [-1.07394502]] loss fxn value:  0.1832783167628955 learn rate: 1.5625e-05 iteration: 18969
[[ 1.99960223]
 [ 4.00913573]
 [-1.07394788]] loss fxn value:  0.1832274109646578 learn rate: 1.5625e-05 iteration: 18970
[[ 1.99960228]
 [ 4.00913574]
 [-1.07395074]] loss fxn value:  0.18317651930658366 learn rate: 1.5625e-05 iteration: 18971
[[ 1.99960233]
 [ 4.00913576]
 [-1.0739536 ]] loss fxn value:  0.183125641782817 learn rate: 1.5625e-05 iteration: 18972
[[ 1.99960237]
 [ 4.00913577]
 [-1.07395646]] loss fxn value:  0.18307477839060818 learn rate: 1.5625e-05 iteration: 18973
[[ 1.99960242]
 [ 4.00913579]
 [-1.07395932]] loss fxn value:  0.18302392912580104 learn rate: 1.5625e-05 iteration: 18974
[[ 1.99960247]
 [ 4.0091358 ]
 [-1.07396218]] loss fxn value:  0.18297309398448625 learn rate: 1.5625e-05 iteration: 18975
[[ 1.99960252]
 [ 4.00913581]
 [-1.07396504]] loss fxn value:  0.1829222729628174 learn rate: 1.5625e-05 iteration: 18976
[[ 1.99960257]
 [ 4.00913583]
 [-1.0739679 ]] loss fxn value:  0.18287146605632415 learn rate: 1.5625e-05 iteration: 18977
[[ 1.99960261]
 [ 4.00913584]
 [-1.07397076]] loss fxn value:  0.18282067326144683 learn rate: 1.5625e-05 iteration: 18978
[[ 1.99960266]
 [ 4.00913586]
 [-1.07397361]] loss fxn value:  0.18276989457490328 learn rate: 1.5625e-05 iteration: 18979
[[ 1.99960271]
 [ 4.00913587]
 [-1.07397647]] loss fxn value:  0.18271912999123735 learn rate: 1.5625e-05 iteration: 18980
[[ 1.99960276]
 [ 4.00913589]
 [-1.07397932]] loss fxn value:  0.18266837950875373 learn rate: 1.5625e-05 iteration: 18981
[[ 1.9996028 ]
 [ 4.0091359 ]
 [-1.07398218]] loss fxn value:  0.1826176431218466 learn rate: 1.5625e-05 iteration: 18982
[[ 1.99960285]
 [ 4.00913592]
 [-1.07398503]] loss fxn value:  0.18256692082696654 learn rate: 1.5625e-05 iteration: 18983
[[ 1.9996029 ]
 [ 4.00913593]
 [-1.07398788]] loss fxn value:  0.18251621261993117 learn rate: 1.5625e-05 iteration: 18984
[[ 1.99960295]
 [ 4.00913594]
 [-1.07399073]] loss fxn value:  0.18246551849770506 learn rate: 1.5625e-05 iteration: 18985
[[ 1.99960299]
 [ 4.00913596]
 [-1.07399358]] loss fxn value:  0.18241483845511092 learn rate: 1.5625e-05 iteration: 18986
[[ 1.99960304]
 [ 4.00913597]
 [-1.07399643]] loss fxn value:  0.1823641724886848 learn rate: 1.5625e-05 iteration: 18987
[[ 1.99960309]
 [ 4.00913599]
 [-1.07399928]] loss fxn value:  0.18231352059698178 learn rate: 1.5625e-05 iteration: 18988
[[ 1.99960314]
 [ 4.009136  ]
 [-1.07400213]] loss fxn value:  0.18226288277266753 learn rate: 1.5625e-05 iteration: 18989
[[ 1.99960318]
 [ 4.00913602]
 [-1.07400498]] loss fxn value:  0.18221225901215016 learn rate: 1.5625e-05 iteration: 18990
[[ 1.99960323]
 [ 4.00913603]
 [-1.07400782]] loss fxn value:  0.18216164931273712 learn rate: 1.5625e-05 iteration: 18991
[[ 1.99960328]
 [ 4.00913605]
 [-1.07401067]] loss fxn value:  0.1821110536708002 learn rate: 1.5625e-05 iteration: 18992
[[ 1.99960333]
 [ 4.00913606]
 [-1.07401352]] loss fxn value:  0.18206047208172857 learn rate: 1.5625e-05 iteration: 18993
[[ 1.99960337]
 [ 4.00913607]
 [-1.07401636]] loss fxn value:  0.1820099045419088 learn rate: 1.5625e-05 iteration: 18994
[[ 1.99960342]
 [ 4.00913609]
 [-1.0740192 ]] loss fxn value:  0.18195935104680558 learn rate: 1.5625e-05 iteration: 18995
[[ 1.99960347]
 [ 4.0091361 ]
 [-1.07402205]] loss fxn value:  0.1819088115937056 learn rate: 1.5625e-05 iteration: 18996
[[ 1.99960352]
 [ 4.00913612]
 [-1.07402489]] loss fxn value:  0.1818582861775286 learn rate: 1.5625e-05 iteration: 18997
[[ 1.99960356]
 [ 4.00913613]
 [-1.07402773]] loss fxn value:  0.18180777479572477 learn rate: 1.5625e-05 iteration: 18998
[[ 1.99960361]
 [ 4.00913615]
 [-1.07403057]] loss fxn value:  0.1817572774425364 learn rate: 1.5625e-05 iteration: 18999
[[ 1.99960366]
 [ 4.00913616]
 [-1.07403341]] loss fxn value:  0.1817067941146446 learn rate: 1.5625e-05 iteration: 19000
[[ 1.99960371]
 [ 4.00913618]
 [-1.07403625]] loss fxn value:  0.1816563248101041 learn rate: 1.5625e-05 iteration: 19001
[[ 1.99960375]
 [ 4.00913619]
 [-1.07403909]] loss fxn value:  0.18160586952192667 learn rate: 1.5625e-05 iteration: 19002
[[ 1.9996038 ]
 [ 4.0091362 ]
 [-1.07404192]] loss fxn value:  0.18155542824914242 learn rate: 1.5625e-05 iteration: 19003
[[ 1.99960385]
 [ 4.00913622]
 [-1.07404476]] loss fxn value:  0.18150500098537223 learn rate: 1.5625e-05 iteration: 19004
[[ 1.9996039 ]
 [ 4.00913623]
 [-1.07404759]] loss fxn value:  0.1814545877282545 learn rate: 1.5625e-05 iteration: 19005
[[ 1.99960394]
 [ 4.00913625]
 [-1.07405043]] loss fxn value:  0.18140418847353745 learn rate: 1.5625e-05 iteration: 19006
[[ 1.99960399]
 [ 4.00913626]
 [-1.07405326]] loss fxn value:  0.18135380321756978 learn rate: 1.5625e-05 iteration: 19007
[[ 1.99960404]
 [ 4.00913628]
 [-1.0740561 ]] loss fxn value:  0.18130343195587564 learn rate: 1.5625e-05 iteration: 19008
[[ 1.99960408]
 [ 4.00913629]
 [-1.07405893]] loss fxn value:  0.1812530746842943 learn rate: 1.5625e-05 iteration: 19009
[[ 1.99960413]
 [ 4.0091363 ]
 [-1.07406176]] loss fxn value:  0.18120273140064497 learn rate: 1.5625e-05 iteration: 19010
[[ 1.99960418]
 [ 4.00913632]
 [-1.07406459]] loss fxn value:  0.18115240209890254 learn rate: 1.5625e-05 iteration: 19011
[[ 1.99960423]
 [ 4.00913633]
 [-1.07406742]] loss fxn value:  0.18110208677687475 learn rate: 1.5625e-05 iteration: 19012
[[ 1.99960427]
 [ 4.00913635]
 [-1.07407025]] loss fxn value:  0.18105178542950068 learn rate: 1.5625e-05 iteration: 19013
[[ 1.99960432]
 [ 4.00913636]
 [-1.07407308]] loss fxn value:  0.1810014980536948 learn rate: 1.5625e-05 iteration: 19014
[[ 1.99960437]
 [ 4.00913638]
 [-1.07407591]] loss fxn value:  0.18095122464475605 learn rate: 1.5625e-05 iteration: 19015
[[ 1.99960441]
 [ 4.00913639]
 [-1.07407873]] loss fxn value:  0.18090096520016538 learn rate: 1.5625e-05 iteration: 19016
[[ 1.99960446]
 [ 4.00913641]
 [-1.07408156]] loss fxn value:  0.1808507197151647 learn rate: 1.5625e-05 iteration: 19017
[[ 1.99960451]
 [ 4.00913642]
 [-1.07408439]] loss fxn value:  0.18080048818529743 learn rate: 1.5625e-05 iteration: 19018
[[ 1.99960456]
 [ 4.00913643]
 [-1.07408721]] loss fxn value:  0.18075027060741863 learn rate: 1.5625e-05 iteration: 19019
[[ 1.9996046 ]
 [ 4.00913645]
 [-1.07409003]] loss fxn value:  0.18070006697833862 learn rate: 1.5625e-05 iteration: 19020
[[ 1.99960465]
 [ 4.00913646]
 [-1.07409286]] loss fxn value:  0.18064987729247556 learn rate: 1.5625e-05 iteration: 19021
[[ 1.9996047 ]
 [ 4.00913648]
 [-1.07409568]] loss fxn value:  0.18059970154634622 learn rate: 1.5625e-05 iteration: 19022
[[ 1.99960474]
 [ 4.00913649]
 [-1.0740985 ]] loss fxn value:  0.18054953973814122 learn rate: 1.5625e-05 iteration: 19023
[[ 1.99960479]
 [ 4.00913651]
 [-1.07410132]] loss fxn value:  0.18049939186175765 learn rate: 1.5625e-05 iteration: 19024
[[ 1.99960484]
 [ 4.00913652]
 [-1.07410414]] loss fxn value:  0.18044925791371924 learn rate: 1.5625e-05 iteration: 19025
[[ 1.99960489]
 [ 4.00913653]
 [-1.07410696]] loss fxn value:  0.18039913789085799 learn rate: 1.5625e-05 iteration: 19026
[[ 1.99960493]
 [ 4.00913655]
 [-1.07410978]] loss fxn value:  0.18034903178851525 learn rate: 1.5625e-05 iteration: 19027
[[ 1.99960498]
 [ 4.00913656]
 [-1.0741126 ]] loss fxn value:  0.1802989396036008 learn rate: 1.5625e-05 iteration: 19028
[[ 1.99960503]
 [ 4.00913658]
 [-1.07411541]] loss fxn value:  0.18024886133105378 learn rate: 1.5625e-05 iteration: 19029
[[ 1.99960507]
 [ 4.00913659]
 [-1.07411823]] loss fxn value:  0.18019879696868646 learn rate: 1.5625e-05 iteration: 19030
[[ 1.99960512]
 [ 4.00913661]
 [-1.07412104]] loss fxn value:  0.18014874651183554 learn rate: 1.5625e-05 iteration: 19031
[[ 1.99960517]
 [ 4.00913662]
 [-1.07412386]] loss fxn value:  0.18009870995600674 learn rate: 1.5625e-05 iteration: 19032
[[ 1.99960521]
 [ 4.00913663]
 [-1.07412667]] loss fxn value:  0.18004868729802423 learn rate: 1.5625e-05 iteration: 19033
[[ 1.99960526]
 [ 4.00913665]
 [-1.07412948]] loss fxn value:  0.17999867853476004 learn rate: 1.5625e-05 iteration: 19034
[[ 1.99960531]
 [ 4.00913666]
 [-1.0741323 ]] loss fxn value:  0.17994868366016295 learn rate: 1.5625e-05 iteration: 19035
[[ 1.99960536]
 [ 4.00913668]
 [-1.07413511]] loss fxn value:  0.179898702672093 learn rate: 1.5625e-05 iteration: 19036
[[ 1.9996054 ]
 [ 4.00913669]
 [-1.07413792]] loss fxn value:  0.1798487355659248 learn rate: 1.5625e-05 iteration: 19037
[[ 1.99960545]
 [ 4.00913671]
 [-1.07414073]] loss fxn value:  0.1797987823389919 learn rate: 1.5625e-05 iteration: 19038
[[ 1.9996055 ]
 [ 4.00913672]
 [-1.07414354]] loss fxn value:  0.1797488429862312 learn rate: 1.5625e-05 iteration: 19039
[[ 1.99960554]
 [ 4.00913673]
 [-1.07414635]] loss fxn value:  0.17969891750496936 learn rate: 1.5625e-05 iteration: 19040
[[ 1.99960559]
 [ 4.00913675]
 [-1.07414915]] loss fxn value:  0.1796490058906048 learn rate: 1.5625e-05 iteration: 19041
[[ 1.99960564]
 [ 4.00913676]
 [-1.07415196]] loss fxn value:  0.17959910813768146 learn rate: 1.5625e-05 iteration: 19042
[[ 1.99960568]
 [ 4.00913678]
 [-1.07415476]] loss fxn value:  0.17954922424488773 learn rate: 1.5625e-05 iteration: 19043
[[ 1.99960573]
 [ 4.00913679]
 [-1.07415757]] loss fxn value:  0.17949935420814306 learn rate: 1.5625e-05 iteration: 19044
[[ 1.99960578]
 [ 4.00913681]
 [-1.07416037]] loss fxn value:  0.17944949802094698 learn rate: 1.5625e-05 iteration: 19045
[[ 1.99960582]
 [ 4.00913682]
 [-1.07416318]] loss fxn value:  0.1793996556835293 learn rate: 1.5625e-05 iteration: 19046
[[ 1.99960587]
 [ 4.00913683]
 [-1.07416598]] loss fxn value:  0.17934982718792614 learn rate: 1.5625e-05 iteration: 19047
[[ 1.99960592]
 [ 4.00913685]
 [-1.07416878]] loss fxn value:  0.17930001253381767 learn rate: 1.5625e-05 iteration: 19048
[[ 1.99960596]
 [ 4.00913686]
 [-1.07417158]] loss fxn value:  0.17925021171526456 learn rate: 1.5625e-05 iteration: 19049
[[ 1.99960601]
 [ 4.00913688]
 [-1.07417438]] loss fxn value:  0.17920042472905326 learn rate: 1.5625e-05 iteration: 19050
[[ 1.99960606]
 [ 4.00913689]
 [-1.07417718]] loss fxn value:  0.17915065157160107 learn rate: 1.5625e-05 iteration: 19051
[[ 1.9996061 ]
 [ 4.0091369 ]
 [-1.07417998]] loss fxn value:  0.1791008922373593 learn rate: 1.5625e-05 iteration: 19052
[[ 1.99960615]
 [ 4.00913692]
 [-1.07418278]] loss fxn value:  0.17905114672561068 learn rate: 1.5625e-05 iteration: 19053
[[ 1.9996062 ]
 [ 4.00913693]
 [-1.07418558]] loss fxn value:  0.17900141502925038 learn rate: 1.5625e-05 iteration: 19054
[[ 1.99960624]
 [ 4.00913695]
 [-1.07418837]] loss fxn value:  0.1789516971462233 learn rate: 1.5625e-05 iteration: 19055
[[ 1.99960629]
 [ 4.00913696]
 [-1.07419117]] loss fxn value:  0.17890199307243734 learn rate: 1.5625e-05 iteration: 19056
[[ 1.99960634]
 [ 4.00913698]
 [-1.07419396]] loss fxn value:  0.17885230280455783 learn rate: 1.5625e-05 iteration: 19057
[[ 1.99960638]
 [ 4.00913699]
 [-1.07419676]] loss fxn value:  0.17880262633863994 learn rate: 1.5625e-05 iteration: 19058
[[ 1.99960643]
 [ 4.009137  ]
 [-1.07419955]] loss fxn value:  0.17875296366908716 learn rate: 1.5625e-05 iteration: 19059
[[ 1.99960648]
 [ 4.00913702]
 [-1.07420234]] loss fxn value:  0.17870331479424054 learn rate: 1.5625e-05 iteration: 19060
[[ 1.99960652]
 [ 4.00913703]
 [-1.07420514]] loss fxn value:  0.17865367970900514 learn rate: 1.5625e-05 iteration: 19061
[[ 1.99960657]
 [ 4.00913705]
 [-1.07420793]] loss fxn value:  0.17860405841018212 learn rate: 1.5625e-05 iteration: 19062
[[ 1.99960662]
 [ 4.00913706]
 [-1.07421072]] loss fxn value:  0.17855445089371014 learn rate: 1.5625e-05 iteration: 19063
[[ 1.99960666]
 [ 4.00913708]
 [-1.07421351]] loss fxn value:  0.17850485715598272 learn rate: 1.5625e-05 iteration: 19064
[[ 1.99960671]
 [ 4.00913709]
 [-1.0742163 ]] loss fxn value:  0.17845527719287688 learn rate: 1.5625e-05 iteration: 19065
[[ 1.99960676]
 [ 4.0091371 ]
 [-1.07421908]] loss fxn value:  0.1784057109997339 learn rate: 1.5625e-05 iteration: 19066
[[ 1.9996068 ]
 [ 4.00913712]
 [-1.07422187]] loss fxn value:  0.178356158575473 learn rate: 1.5625e-05 iteration: 19067
[[ 1.99960685]
 [ 4.00913713]
 [-1.07422466]] loss fxn value:  0.17830661991299537 learn rate: 1.5625e-05 iteration: 19068
[[ 1.9996069 ]
 [ 4.00913715]
 [-1.07422744]] loss fxn value:  0.1782570950110991 learn rate: 1.5625e-05 iteration: 19069
[[ 1.99960694]
 [ 4.00913716]
 [-1.07423023]] loss fxn value:  0.178207583863726 learn rate: 1.5625e-05 iteration: 19070
[[ 1.99960699]
 [ 4.00913717]
 [-1.07423301]] loss fxn value:  0.17815808646876155 learn rate: 1.5625e-05 iteration: 19071
[[ 1.99960704]
 [ 4.00913719]
 [-1.0742358 ]] loss fxn value:  0.17810860282159036 learn rate: 1.5625e-05 iteration: 19072
[[ 1.99960708]
 [ 4.0091372 ]
 [-1.07423858]] loss fxn value:  0.17805913291906744 learn rate: 1.5625e-05 iteration: 19073
[[ 1.99960713]
 [ 4.00913722]
 [-1.07424136]] loss fxn value:  0.1780096767560039 learn rate: 1.5625e-05 iteration: 19074
[[ 1.99960717]
 [ 4.00913723]
 [-1.07424414]] loss fxn value:  0.17796023432997096 learn rate: 1.5625e-05 iteration: 19075
[[ 1.99960722]
 [ 4.00913724]
 [-1.07424692]] loss fxn value:  0.17791080563715767 learn rate: 1.5625e-05 iteration: 19076
[[ 1.99960727]
 [ 4.00913726]
 [-1.0742497 ]] loss fxn value:  0.1778613906720199 learn rate: 1.5625e-05 iteration: 19077
[[ 1.99960731]
 [ 4.00913727]
 [-1.07425248]] loss fxn value:  0.17781198943299353 learn rate: 1.5625e-05 iteration: 19078
[[ 1.99960736]
 [ 4.00913729]
 [-1.07425526]] loss fxn value:  0.17776260191437246 learn rate: 1.5625e-05 iteration: 19079
[[ 1.99960741]
 [ 4.0091373 ]
 [-1.07425803]] loss fxn value:  0.17771322811410933 learn rate: 1.5625e-05 iteration: 19080
[[ 1.99960745]
 [ 4.00913732]
 [-1.07426081]] loss fxn value:  0.17766386802644646 learn rate: 1.5625e-05 iteration: 19081
[[ 1.9996075 ]
 [ 4.00913733]
 [-1.07426359]] loss fxn value:  0.1776145216489951 learn rate: 1.5625e-05 iteration: 19082
[[ 1.99960755]
 [ 4.00913734]
 [-1.07426636]] loss fxn value:  0.17756518897790186 learn rate: 1.5625e-05 iteration: 19083
[[ 1.99960759]
 [ 4.00913736]
 [-1.07426913]] loss fxn value:  0.17751587000910782 learn rate: 1.5625e-05 iteration: 19084
[[ 1.99960764]
 [ 4.00913737]
 [-1.07427191]] loss fxn value:  0.17746656473906117 learn rate: 1.5625e-05 iteration: 19085
[[ 1.99960768]
 [ 4.00913739]
 [-1.07427468]] loss fxn value:  0.17741727316264397 learn rate: 1.5625e-05 iteration: 19086
[[ 1.99960773]
 [ 4.0091374 ]
 [-1.07427745]] loss fxn value:  0.17736799527764224 learn rate: 1.5625e-05 iteration: 19087
[[ 1.99960778]
 [ 4.00913741]
 [-1.07428022]] loss fxn value:  0.1773187310785952 learn rate: 1.5625e-05 iteration: 19088
[[ 1.99960782]
 [ 4.00913743]
 [-1.07428299]] loss fxn value:  0.17726948056417657 learn rate: 1.5625e-05 iteration: 19089
[[ 1.99960787]
 [ 4.00913744]
 [-1.07428576]] loss fxn value:  0.17722024372886166 learn rate: 1.5625e-05 iteration: 19090
[[ 1.99960792]
 [ 4.00913746]
 [-1.07428853]] loss fxn value:  0.17717102056808431 learn rate: 1.5625e-05 iteration: 19091
[[ 1.99960796]
 [ 4.00913747]
 [-1.0742913 ]] loss fxn value:  0.17712181108019018 learn rate: 1.5625e-05 iteration: 19092
[[ 1.99960801]
 [ 4.00913748]
 [-1.07429407]] loss fxn value:  0.17707261525995405 learn rate: 1.5625e-05 iteration: 19093
[[ 1.99960805]
 [ 4.0091375 ]
 [-1.07429683]] loss fxn value:  0.17702343310342888 learn rate: 1.5625e-05 iteration: 19094
[[ 1.9996081 ]
 [ 4.00913751]
 [-1.0742996 ]] loss fxn value:  0.17697426460836285 learn rate: 1.5625e-05 iteration: 19095
[[ 1.99960815]
 [ 4.00913753]
 [-1.07430236]] loss fxn value:  0.17692510976961875 learn rate: 1.5625e-05 iteration: 19096
[[ 1.99960819]
 [ 4.00913754]
 [-1.07430513]] loss fxn value:  0.17687596858317395 learn rate: 1.5625e-05 iteration: 19097
[[ 1.99960824]
 [ 4.00913755]
 [-1.07430789]] loss fxn value:  0.17682684104592353 learn rate: 1.5625e-05 iteration: 19098
[[ 1.99960828]
 [ 4.00913757]
 [-1.07431065]] loss fxn value:  0.17677772715410664 learn rate: 1.5625e-05 iteration: 19099
[[ 1.99960833]
 [ 4.00913758]
 [-1.07431341]] loss fxn value:  0.17672862690320046 learn rate: 1.5625e-05 iteration: 19100
[[ 1.99960838]
 [ 4.0091376 ]
 [-1.07431618]] loss fxn value:  0.17667954029105504 learn rate: 1.5625e-05 iteration: 19101
[[ 1.99960842]
 [ 4.00913761]
 [-1.07431894]] loss fxn value:  0.17663046731155044 learn rate: 1.5625e-05 iteration: 19102
[[ 1.99960847]
 [ 4.00913762]
 [-1.0743217 ]] loss fxn value:  0.17658140796258923 learn rate: 1.5625e-05 iteration: 19103
[[ 1.99960851]
 [ 4.00913764]
 [-1.07432445]] loss fxn value:  0.17653236224005533 learn rate: 1.5625e-05 iteration: 19104
[[ 1.99960856]
 [ 4.00913765]
 [-1.07432721]] loss fxn value:  0.17648333014019255 learn rate: 1.5625e-05 iteration: 19105
[[ 1.99960861]
 [ 4.00913767]
 [-1.07432997]] loss fxn value:  0.1764343116585922 learn rate: 1.5625e-05 iteration: 19106
[[ 1.99960865]
 [ 4.00913768]
 [-1.07433273]] loss fxn value:  0.17638530679287362 learn rate: 1.5625e-05 iteration: 19107
[[ 1.9996087 ]
 [ 4.00913769]
 [-1.07433548]] loss fxn value:  0.17633631553769488 learn rate: 1.5625e-05 iteration: 19108
[[ 1.99960874]
 [ 4.00913771]
 [-1.07433824]] loss fxn value:  0.17628733788972126 learn rate: 1.5625e-05 iteration: 19109
[[ 1.99960879]
 [ 4.00913772]
 [-1.07434099]] loss fxn value:  0.17623837384546726 learn rate: 1.5625e-05 iteration: 19110
[[ 1.99960884]
 [ 4.00913774]
 [-1.07434374]] loss fxn value:  0.17618942340074828 learn rate: 1.5625e-05 iteration: 19111
[[ 1.99960888]
 [ 4.00913775]
 [-1.0743465 ]] loss fxn value:  0.17614048655287168 learn rate: 1.5625e-05 iteration: 19112
[[ 1.99960893]
 [ 4.00913776]
 [-1.07434925]] loss fxn value:  0.1760915632973192 learn rate: 1.5625e-05 iteration: 19113
[[ 1.99960897]
 [ 4.00913778]
 [-1.074352  ]] loss fxn value:  0.1760426536293899 learn rate: 1.5625e-05 iteration: 19114
[[ 1.99960902]
 [ 4.00913779]
 [-1.07435475]] loss fxn value:  0.17599375754617394 learn rate: 1.5625e-05 iteration: 19115
[[ 1.99960907]
 [ 4.00913781]
 [-1.0743575 ]] loss fxn value:  0.17594487504464176 learn rate: 1.5625e-05 iteration: 19116
[[ 1.99960911]
 [ 4.00913782]
 [-1.07436025]] loss fxn value:  0.17589600611954856 learn rate: 1.5625e-05 iteration: 19117
[[ 1.99960916]
 [ 4.00913783]
 [-1.07436299]] loss fxn value:  0.17584715076809757 learn rate: 1.5625e-05 iteration: 19118
[[ 1.9996092 ]
 [ 4.00913785]
 [-1.07436574]] loss fxn value:  0.1757983089871246 learn rate: 1.5625e-05 iteration: 19119
[[ 1.99960925]
 [ 4.00913786]
 [-1.07436849]] loss fxn value:  0.17574948077112873 learn rate: 1.5625e-05 iteration: 19120
[[ 1.9996093 ]
 [ 4.00913788]
 [-1.07437123]] loss fxn value:  0.17570066611784355 learn rate: 1.5625e-05 iteration: 19121
[[ 1.99960934]
 [ 4.00913789]
 [-1.07437398]] loss fxn value:  0.17565186502186536 learn rate: 1.5625e-05 iteration: 19122
[[ 1.99960939]
 [ 4.0091379 ]
 [-1.07437672]] loss fxn value:  0.1756030774818348 learn rate: 1.5625e-05 iteration: 19123
[[ 1.99960943]
 [ 4.00913792]
 [-1.07437947]] loss fxn value:  0.17555430349123666 learn rate: 1.5625e-05 iteration: 19124
[[ 1.99960948]
 [ 4.00913793]
 [-1.07438221]] loss fxn value:  0.1755055430484921 learn rate: 1.5625e-05 iteration: 19125
[[ 1.99960952]
 [ 4.00913795]
 [-1.07438495]] loss fxn value:  0.17545679614881457 learn rate: 1.5625e-05 iteration: 19126
[[ 1.99960957]
 [ 4.00913796]
 [-1.07438769]] loss fxn value:  0.17540806278922563 learn rate: 1.5625e-05 iteration: 19127
[[ 1.99960962]
 [ 4.00913797]
 [-1.07439043]] loss fxn value:  0.17535934296457883 learn rate: 1.5625e-05 iteration: 19128
[[ 1.99960966]
 [ 4.00913799]
 [-1.07439317]] loss fxn value:  0.17531063667217928 learn rate: 1.5625e-05 iteration: 19129
[[ 1.99960971]
 [ 4.009138  ]
 [-1.07439591]] loss fxn value:  0.1752619439084705 learn rate: 1.5625e-05 iteration: 19130
[[ 1.99960975]
 [ 4.00913801]
 [-1.07439865]] loss fxn value:  0.17521326466833928 learn rate: 1.5625e-05 iteration: 19131
[[ 1.9996098 ]
 [ 4.00913803]
 [-1.07440139]] loss fxn value:  0.1751645989495692 learn rate: 1.5625e-05 iteration: 19132
[[ 1.99960984]
 [ 4.00913804]
 [-1.07440412]] loss fxn value:  0.17511594674763978 learn rate: 1.5625e-05 iteration: 19133
[[ 1.99960989]
 [ 4.00913806]
 [-1.07440686]] loss fxn value:  0.17506730805886112 learn rate: 1.5625e-05 iteration: 19134
[[ 1.99960994]
 [ 4.00913807]
 [-1.07440959]] loss fxn value:  0.175018682879558 learn rate: 1.5625e-05 iteration: 19135
[[ 1.99960998]
 [ 4.00913808]
 [-1.07441233]] loss fxn value:  0.17497007120578795 learn rate: 1.5625e-05 iteration: 19136
[[ 1.99961003]
 [ 4.0091381 ]
 [-1.07441506]] loss fxn value:  0.17492147303465164 learn rate: 1.5625e-05 iteration: 19137
[[ 1.99961007]
 [ 4.00913811]
 [-1.07441779]] loss fxn value:  0.17487288836080714 learn rate: 1.5625e-05 iteration: 19138
[[ 1.99961012]
 [ 4.00913813]
 [-1.07442053]] loss fxn value:  0.17482431718191704 learn rate: 1.5625e-05 iteration: 19139
[[ 1.99961016]
 [ 4.00913814]
 [-1.07442326]] loss fxn value:  0.17477575949395552 learn rate: 1.5625e-05 iteration: 19140
[[ 1.99961021]
 [ 4.00913815]
 [-1.07442599]] loss fxn value:  0.17472721529234958 learn rate: 1.5625e-05 iteration: 19141
[[ 1.99961025]
 [ 4.00913817]
 [-1.07442872]] loss fxn value:  0.17467868457472638 learn rate: 1.5625e-05 iteration: 19142
[[ 1.9996103 ]
 [ 4.00913818]
 [-1.07443145]] loss fxn value:  0.17463016733577474 learn rate: 1.5625e-05 iteration: 19143
[[ 1.99961035]
 [ 4.0091382 ]
 [-1.07443417]] loss fxn value:  0.1745816635726949 learn rate: 1.5625e-05 iteration: 19144
[[ 1.99961039]
 [ 4.00913821]
 [-1.0744369 ]] loss fxn value:  0.174533173282321 learn rate: 1.5625e-05 iteration: 19145
[[ 1.99961044]
 [ 4.00913822]
 [-1.07443963]] loss fxn value:  0.17448469645868295 learn rate: 1.5625e-05 iteration: 19146
[[ 1.99961048]
 [ 4.00913824]
 [-1.07444235]] loss fxn value:  0.17443623310199663 learn rate: 1.5625e-05 iteration: 19147
[[ 1.99961053]
 [ 4.00913825]
 [-1.07444508]] loss fxn value:  0.17438778320371226 learn rate: 1.5625e-05 iteration: 19148
[[ 1.99961057]
 [ 4.00913826]
 [-1.0744478 ]] loss fxn value:  0.1743393467637053 learn rate: 1.5625e-05 iteration: 19149
[[ 1.99961062]
 [ 4.00913828]
 [-1.07445053]] loss fxn value:  0.17429092377679148 learn rate: 1.5625e-05 iteration: 19150
[[ 1.99961066]
 [ 4.00913829]
 [-1.07445325]] loss fxn value:  0.17424251423898046 learn rate: 1.5625e-05 iteration: 19151
[[ 1.99961071]
 [ 4.00913831]
 [-1.07445597]] loss fxn value:  0.17419411814744012 learn rate: 1.5625e-05 iteration: 19152
[[ 1.99961075]
 [ 4.00913832]
 [-1.07445869]] loss fxn value:  0.17414573549817783 learn rate: 1.5625e-05 iteration: 19153
[[ 1.9996108 ]
 [ 4.00913833]
 [-1.07446141]] loss fxn value:  0.1740973662865565 learn rate: 1.5625e-05 iteration: 19154
[[ 1.99961085]
 [ 4.00913835]
 [-1.07446413]] loss fxn value:  0.17404901050999086 learn rate: 1.5625e-05 iteration: 19155
[[ 1.99961089]
 [ 4.00913836]
 [-1.07446685]] loss fxn value:  0.1740006681641797 learn rate: 1.5625e-05 iteration: 19156
[[ 1.99961094]
 [ 4.00913837]
 [-1.07446957]] loss fxn value:  0.17395233924521838 learn rate: 1.5625e-05 iteration: 19157
[[ 1.99961098]
 [ 4.00913839]
 [-1.07447229]] loss fxn value:  0.17390402375079572 learn rate: 1.5625e-05 iteration: 19158
[[ 1.99961103]
 [ 4.0091384 ]
 [-1.07447501]] loss fxn value:  0.17385572167433488 learn rate: 1.5625e-05 iteration: 19159
[[ 1.99961107]
 [ 4.00913842]
 [-1.07447772]] loss fxn value:  0.17380743301626547 learn rate: 1.5625e-05 iteration: 19160
[[ 1.99961112]
 [ 4.00913843]
 [-1.07448044]] loss fxn value:  0.17375915776834505 learn rate: 1.5625e-05 iteration: 19161
[[ 1.99961116]
 [ 4.00913844]
 [-1.07448315]] loss fxn value:  0.17371089592917063 learn rate: 1.5625e-05 iteration: 19162
[[ 1.99961121]
 [ 4.00913846]
 [-1.07448587]] loss fxn value:  0.17366264749540983 learn rate: 1.5625e-05 iteration: 19163
[[ 1.99961125]
 [ 4.00913847]
 [-1.07448858]] loss fxn value:  0.17361441246288725 learn rate: 1.5625e-05 iteration: 19164
[[ 1.9996113 ]
 [ 4.00913848]
 [-1.07449129]] loss fxn value:  0.17356619082716335 learn rate: 1.5625e-05 iteration: 19165
[[ 1.99961134]
 [ 4.0091385 ]
 [-1.074494  ]] loss fxn value:  0.1735179825845505 learn rate: 1.5625e-05 iteration: 19166
[[ 1.99961139]
 [ 4.00913851]
 [-1.07449671]] loss fxn value:  0.17346978773279928 learn rate: 1.5625e-05 iteration: 19167
[[ 1.99961143]
 [ 4.00913853]
 [-1.07449942]] loss fxn value:  0.17342160626697226 learn rate: 1.5625e-05 iteration: 19168
[[ 1.99961148]
 [ 4.00913854]
 [-1.07450213]] loss fxn value:  0.17337343818322523 learn rate: 1.5625e-05 iteration: 19169
[[ 1.99961152]
 [ 4.00913855]
 [-1.07450484]] loss fxn value:  0.17332528347912252 learn rate: 1.5625e-05 iteration: 19170
[[ 1.99961157]
 [ 4.00913857]
 [-1.07450755]] loss fxn value:  0.17327714214981804 learn rate: 1.5625e-05 iteration: 19171
[[ 1.99961161]
 [ 4.00913858]
 [-1.07451026]] loss fxn value:  0.17322901419097866 learn rate: 1.5625e-05 iteration: 19172
[[ 1.99961166]
 [ 4.00913859]
 [-1.07451296]] loss fxn value:  0.17318089960069086 learn rate: 1.5625e-05 iteration: 19173
[[ 1.99961171]
 [ 4.00913861]
 [-1.07451567]] loss fxn value:  0.1731327983735362 learn rate: 1.5625e-05 iteration: 19174
[[ 1.99961175]
 [ 4.00913862]
 [-1.07451837]] loss fxn value:  0.17308471050720586 learn rate: 1.5625e-05 iteration: 19175
[[ 1.9996118 ]
 [ 4.00913864]
 [-1.07452108]] loss fxn value:  0.17303663599678631 learn rate: 1.5625e-05 iteration: 19176
[[ 1.99961184]
 [ 4.00913865]
 [-1.07452378]] loss fxn value:  0.17298857483937594 learn rate: 1.5625e-05 iteration: 19177
[[ 1.99961189]
 [ 4.00913866]
 [-1.07452648]] loss fxn value:  0.17294052703062773 learn rate: 1.5625e-05 iteration: 19178
[[ 1.99961193]
 [ 4.00913868]
 [-1.07452918]] loss fxn value:  0.17289249256809933 learn rate: 1.5625e-05 iteration: 19179
[[ 1.99961198]
 [ 4.00913869]
 [-1.07453189]] loss fxn value:  0.17284447144645113 learn rate: 1.5625e-05 iteration: 19180
[[ 1.99961202]
 [ 4.0091387 ]
 [-1.07453459]] loss fxn value:  0.17279646366291956 learn rate: 1.5625e-05 iteration: 19181
[[ 1.99961207]
 [ 4.00913872]
 [-1.07453729]] loss fxn value:  0.172748469213841 learn rate: 1.5625e-05 iteration: 19182
[[ 1.99961211]
 [ 4.00913873]
 [-1.07453998]] loss fxn value:  0.1727004880951279 learn rate: 1.5625e-05 iteration: 19183
[[ 1.99961216]
 [ 4.00913875]
 [-1.07454268]] loss fxn value:  0.17265252030319533 learn rate: 1.5625e-05 iteration: 19184
[[ 1.9996122 ]
 [ 4.00913876]
 [-1.07454538]] loss fxn value:  0.17260456583483436 learn rate: 1.5625e-05 iteration: 19185
[[ 1.99961225]
 [ 4.00913877]
 [-1.07454808]] loss fxn value:  0.17255662468541016 learn rate: 1.5625e-05 iteration: 19186
[[ 1.99961229]
 [ 4.00913879]
 [-1.07455077]] loss fxn value:  0.1725086968518805 learn rate: 1.5625e-05 iteration: 19187
[[ 1.99961234]
 [ 4.0091388 ]
 [-1.07455347]] loss fxn value:  0.17246078233052686 learn rate: 1.5625e-05 iteration: 19188
[[ 1.99961238]
 [ 4.00913881]
 [-1.07455616]] loss fxn value:  0.17241288111724798 learn rate: 1.5625e-05 iteration: 19189
[[ 1.99961243]
 [ 4.00913883]
 [-1.07455885]] loss fxn value:  0.17236499320844645 learn rate: 1.5625e-05 iteration: 19190
[[ 1.99961247]
 [ 4.00913884]
 [-1.07456155]] loss fxn value:  0.17231711860048027 learn rate: 1.5625e-05 iteration: 19191
[[ 1.99961252]
 [ 4.00913886]
 [-1.07456424]] loss fxn value:  0.17226925729064987 learn rate: 1.5625e-05 iteration: 19192
[[ 1.99961256]
 [ 4.00913887]
 [-1.07456693]] loss fxn value:  0.17222140927335874 learn rate: 1.5625e-05 iteration: 19193
[[ 1.99961261]
 [ 4.00913888]
 [-1.07456962]] loss fxn value:  0.17217357454604548 learn rate: 1.5625e-05 iteration: 19194
[[ 1.99961265]
 [ 4.0091389 ]
 [-1.07457231]] loss fxn value:  0.17212575310550104 learn rate: 1.5625e-05 iteration: 19195
[[ 1.9996127 ]
 [ 4.00913891]
 [-1.074575  ]] loss fxn value:  0.17207794494655276 learn rate: 1.5625e-05 iteration: 19196
[[ 1.99961274]
 [ 4.00913892]
 [-1.07457769]] loss fxn value:  0.17203015006675795 learn rate: 1.5625e-05 iteration: 19197
[[ 1.99961278]
 [ 4.00913894]
 [-1.07458038]] loss fxn value:  0.17198236846270554 learn rate: 1.5625e-05 iteration: 19198
[[ 1.99961283]
 [ 4.00913895]
 [-1.07458306]] loss fxn value:  0.17193460012942036 learn rate: 1.5625e-05 iteration: 19199
[[ 1.99961287]
 [ 4.00913896]
 [-1.07458575]] loss fxn value:  0.1718868450638692 learn rate: 1.5625e-05 iteration: 19200
[[ 1.99961292]
 [ 4.00913898]
 [-1.07458843]] loss fxn value:  0.1718391032626912 learn rate: 1.5625e-05 iteration: 19201
[[ 1.99961296]
 [ 4.00913899]
 [-1.07459112]] loss fxn value:  0.1717913747219107 learn rate: 1.5625e-05 iteration: 19202
[[ 1.99961301]
 [ 4.00913901]
 [-1.0745938 ]] loss fxn value:  0.17174365943734307 learn rate: 1.5625e-05 iteration: 19203
[[ 1.99961305]
 [ 4.00913902]
 [-1.07459649]] loss fxn value:  0.1716959574058958 learn rate: 1.5625e-05 iteration: 19204
[[ 1.9996131 ]
 [ 4.00913903]
 [-1.07459917]] loss fxn value:  0.17164826862345056 learn rate: 1.5625e-05 iteration: 19205
[[ 1.99961314]
 [ 4.00913905]
 [-1.07460185]] loss fxn value:  0.17160059308679834 learn rate: 1.5625e-05 iteration: 19206
[[ 1.99961319]
 [ 4.00913906]
 [-1.07460453]] loss fxn value:  0.1715529307922948 learn rate: 1.5625e-05 iteration: 19207
[[ 1.99961323]
 [ 4.00913907]
 [-1.07460721]] loss fxn value:  0.17150528173636195 learn rate: 1.5625e-05 iteration: 19208
[[ 1.99961328]
 [ 4.00913909]
 [-1.07460989]] loss fxn value:  0.17145764591482893 learn rate: 1.5625e-05 iteration: 19209
[[ 1.99961332]
 [ 4.0091391 ]
 [-1.07461257]] loss fxn value:  0.17141002332410157 learn rate: 1.5625e-05 iteration: 19210
[[ 1.99961337]
 [ 4.00913911]
 [-1.07461525]] loss fxn value:  0.17136241396009466 learn rate: 1.5625e-05 iteration: 19211
[[ 1.99961341]
 [ 4.00913913]
 [-1.07461792]] loss fxn value:  0.17131481782009172 learn rate: 1.5625e-05 iteration: 19212
[[ 1.99961346]
 [ 4.00913914]
 [-1.0746206 ]] loss fxn value:  0.17126723490086068 learn rate: 1.5625e-05 iteration: 19213
[[ 1.9996135 ]
 [ 4.00913915]
 [-1.07462328]] loss fxn value:  0.1712196651960167 learn rate: 1.5625e-05 iteration: 19214
[[ 1.99961355]
 [ 4.00913917]
 [-1.07462595]] loss fxn value:  0.17117210870525248 learn rate: 1.5625e-05 iteration: 19215
[[ 1.99961359]
 [ 4.00913918]
 [-1.07462862]] loss fxn value:  0.1711245654224458 learn rate: 1.5625e-05 iteration: 19216
[[ 1.99961363]
 [ 4.0091392 ]
 [-1.0746313 ]] loss fxn value:  0.17107703534553467 learn rate: 1.5625e-05 iteration: 19217
[[ 1.99961368]
 [ 4.00913921]
 [-1.07463397]] loss fxn value:  0.17102951846979642 learn rate: 1.5625e-05 iteration: 19218
[[ 1.99961372]
 [ 4.00913922]
 [-1.07463664]] loss fxn value:  0.17098201479170547 learn rate: 1.5625e-05 iteration: 19219
[[ 1.99961377]
 [ 4.00913924]
 [-1.07463931]] loss fxn value:  0.1709345243079672 learn rate: 1.5625e-05 iteration: 19220
[[ 1.99961381]
 [ 4.00913925]
 [-1.07464198]] loss fxn value:  0.17088704701514634 learn rate: 1.5625e-05 iteration: 19221
[[ 1.99961386]
 [ 4.00913926]
 [-1.07464465]] loss fxn value:  0.17083958290888693 learn rate: 1.5625e-05 iteration: 19222
[[ 1.9996139 ]
 [ 4.00913928]
 [-1.07464732]] loss fxn value:  0.17079213198627696 learn rate: 1.5625e-05 iteration: 19223
[[ 1.99961395]
 [ 4.00913929]
 [-1.07464999]] loss fxn value:  0.17074469424298216 learn rate: 1.5625e-05 iteration: 19224
[[ 1.99961399]
 [ 4.0091393 ]
 [-1.07465266]] loss fxn value:  0.17069726967595558 learn rate: 1.5625e-05 iteration: 19225
[[ 1.99961404]
 [ 4.00913932]
 [-1.07465533]] loss fxn value:  0.17064985827967155 learn rate: 1.5625e-05 iteration: 19226
[[ 1.99961408]
 [ 4.00913933]
 [-1.07465799]] loss fxn value:  0.17060246005381355 learn rate: 1.5625e-05 iteration: 19227
[[ 1.99961412]
 [ 4.00913934]
 [-1.07466066]] loss fxn value:  0.17055507499133074 learn rate: 1.5625e-05 iteration: 19228
[[ 1.99961417]
 [ 4.00913936]
 [-1.07466332]] loss fxn value:  0.1705077030906659 learn rate: 1.5625e-05 iteration: 19229
[[ 1.99961421]
 [ 4.00913937]
 [-1.07466599]] loss fxn value:  0.1704603443483987 learn rate: 1.5625e-05 iteration: 19230
[[ 1.99961426]
 [ 4.00913939]
 [-1.07466865]] loss fxn value:  0.17041299875925353 learn rate: 1.5625e-05 iteration: 19231
[[ 1.9996143 ]
 [ 4.0091394 ]
 [-1.07467131]] loss fxn value:  0.17036566632038577 learn rate: 1.5625e-05 iteration: 19232
[[ 1.99961435]
 [ 4.00913941]
 [-1.07467397]] loss fxn value:  0.17031834702869147 learn rate: 1.5625e-05 iteration: 19233
[[ 1.99961439]
 [ 4.00913943]
 [-1.07467663]] loss fxn value:  0.17027104088002828 learn rate: 1.5625e-05 iteration: 19234
[[ 1.99961444]
 [ 4.00913944]
 [-1.07467929]] loss fxn value:  0.17022374786978317 learn rate: 1.5625e-05 iteration: 19235
[[ 1.99961448]
 [ 4.00913945]
 [-1.07468195]] loss fxn value:  0.17017646799635563 learn rate: 1.5625e-05 iteration: 19236
[[ 1.99961452]
 [ 4.00913947]
 [-1.07468461]] loss fxn value:  0.17012920125450204 learn rate: 1.5625e-05 iteration: 19237
[[ 1.99961457]
 [ 4.00913948]
 [-1.07468727]] loss fxn value:  0.17008194764117773 learn rate: 1.5625e-05 iteration: 19238
[[ 1.99961461]
 [ 4.00913949]
 [-1.07468993]] loss fxn value:  0.17003470715179506 learn rate: 1.5625e-05 iteration: 19239
[[ 1.99961466]
 [ 4.00913951]
 [-1.07469258]] loss fxn value:  0.16998747978409753 learn rate: 1.5625e-05 iteration: 19240
[[ 1.9996147 ]
 [ 4.00913952]
 [-1.07469524]] loss fxn value:  0.1699402655344501 learn rate: 1.5625e-05 iteration: 19241
[[ 1.99961475]
 [ 4.00913953]
 [-1.07469789]] loss fxn value:  0.1698930643977919 learn rate: 1.5625e-05 iteration: 19242
[[ 1.99961479]
 [ 4.00913955]
 [-1.07470055]] loss fxn value:  0.16984587637145424 learn rate: 1.5625e-05 iteration: 19243
[[ 1.99961483]
 [ 4.00913956]
 [-1.0747032 ]] loss fxn value:  0.16979870145183057 learn rate: 1.5625e-05 iteration: 19244
[[ 1.99961488]
 [ 4.00913957]
 [-1.07470585]] loss fxn value:  0.16975153963519318 learn rate: 1.5625e-05 iteration: 19245
[[ 1.99961492]
 [ 4.00913959]
 [-1.07470851]] loss fxn value:  0.16970439091795947 learn rate: 1.5625e-05 iteration: 19246
[[ 1.99961497]
 [ 4.0091396 ]
 [-1.07471116]] loss fxn value:  0.169657255295561 learn rate: 1.5625e-05 iteration: 19247
[[ 1.99961501]
 [ 4.00913961]
 [-1.07471381]] loss fxn value:  0.16961013276575063 learn rate: 1.5625e-05 iteration: 19248
[[ 1.99961506]
 [ 4.00913963]
 [-1.07471646]] loss fxn value:  0.16956302332488402 learn rate: 1.5625e-05 iteration: 19249
[[ 1.9996151 ]
 [ 4.00913964]
 [-1.07471911]] loss fxn value:  0.1695159269683688 learn rate: 1.5625e-05 iteration: 19250
[[ 1.99961514]
 [ 4.00913965]
 [-1.07472175]] loss fxn value:  0.16946884369170614 learn rate: 1.5625e-05 iteration: 19251
[[ 1.99961519]
 [ 4.00913967]
 [-1.0747244 ]] loss fxn value:  0.16942177349356274 learn rate: 1.5625e-05 iteration: 19252
[[ 1.99961523]
 [ 4.00913968]
 [-1.07472705]] loss fxn value:  0.16937471636976092 learn rate: 1.5625e-05 iteration: 19253
[[ 1.99961528]
 [ 4.00913969]
 [-1.07472969]] loss fxn value:  0.16932767231490625 learn rate: 1.5625e-05 iteration: 19254
[[ 1.99961532]
 [ 4.00913971]
 [-1.07473234]] loss fxn value:  0.16928064132760615 learn rate: 1.5625e-05 iteration: 19255
[[ 1.99961536]
 [ 4.00913972]
 [-1.07473498]] loss fxn value:  0.1692336234019668 learn rate: 1.5625e-05 iteration: 19256
[[ 1.99961541]
 [ 4.00913974]
 [-1.07473763]] loss fxn value:  0.16918661853663336 learn rate: 1.5625e-05 iteration: 19257
[[ 1.99961545]
 [ 4.00913975]
 [-1.07474027]] loss fxn value:  0.16913962672700206 learn rate: 1.5625e-05 iteration: 19258
[[ 1.9996155 ]
 [ 4.00913976]
 [-1.07474291]] loss fxn value:  0.1690926479690617 learn rate: 1.5625e-05 iteration: 19259
[[ 1.99961554]
 [ 4.00913978]
 [-1.07474556]] loss fxn value:  0.16904568225952005 learn rate: 1.5625e-05 iteration: 19260
[[ 1.99961558]
 [ 4.00913979]
 [-1.0747482 ]] loss fxn value:  0.1689987295949371 learn rate: 1.5625e-05 iteration: 19261
[[ 1.99961563]
 [ 4.0091398 ]
 [-1.07475084]] loss fxn value:  0.16895178997187332 learn rate: 1.5625e-05 iteration: 19262
[[ 1.99961567]
 [ 4.00913982]
 [-1.07475348]] loss fxn value:  0.16890486338501523 learn rate: 1.5625e-05 iteration: 19263
[[ 1.99961572]
 [ 4.00913983]
 [-1.07475611]] loss fxn value:  0.16885794983357225 learn rate: 1.5625e-05 iteration: 19264
[[ 1.99961576]
 [ 4.00913984]
 [-1.07475875]] loss fxn value:  0.16881104931225058 learn rate: 1.5625e-05 iteration: 19265
[[ 1.9996158 ]
 [ 4.00913986]
 [-1.07476139]] loss fxn value:  0.16876416181718418 learn rate: 1.5625e-05 iteration: 19266
[[ 1.99961585]
 [ 4.00913987]
 [-1.07476403]] loss fxn value:  0.16871728734413358 learn rate: 1.5625e-05 iteration: 19267
[[ 1.99961589]
 [ 4.00913988]
 [-1.07476666]] loss fxn value:  0.16867042589198844 learn rate: 1.5625e-05 iteration: 19268
[[ 1.99961594]
 [ 4.0091399 ]
 [-1.0747693 ]] loss fxn value:  0.16862357745635284 learn rate: 1.5625e-05 iteration: 19269
[[ 1.99961598]
 [ 4.00913991]
 [-1.07477193]] loss fxn value:  0.1685767420314232 learn rate: 1.5625e-05 iteration: 19270
[[ 1.99961602]
 [ 4.00913992]
 [-1.07477457]] loss fxn value:  0.16852991961550418 learn rate: 1.5625e-05 iteration: 19271
[[ 1.99961607]
 [ 4.00913994]
 [-1.0747772 ]] loss fxn value:  0.16848311020476547 learn rate: 1.5625e-05 iteration: 19272
[[ 1.99961611]
 [ 4.00913995]
 [-1.07477983]] loss fxn value:  0.1684363137947537 learn rate: 1.5625e-05 iteration: 19273
[[ 1.99961616]
 [ 4.00913996]
 [-1.07478246]] loss fxn value:  0.16838953038279245 learn rate: 1.5625e-05 iteration: 19274
[[ 1.9996162 ]
 [ 4.00913998]
 [-1.07478509]] loss fxn value:  0.16834275996519957 learn rate: 1.5625e-05 iteration: 19275
[[ 1.99961624]
 [ 4.00913999]
 [-1.07478772]] loss fxn value:  0.16829600253829208 learn rate: 1.5625e-05 iteration: 19276
[[ 1.99961629]
 [ 4.00914   ]
 [-1.07479035]] loss fxn value:  0.16824925809890656 learn rate: 1.5625e-05 iteration: 19277
[[ 1.99961633]
 [ 4.00914002]
 [-1.07479298]] loss fxn value:  0.16820252664162236 learn rate: 1.5625e-05 iteration: 19278
[[ 1.99961638]
 [ 4.00914003]
 [-1.07479561]] loss fxn value:  0.16815580816506848 learn rate: 1.5625e-05 iteration: 19279
[[ 1.99961642]
 [ 4.00914004]
 [-1.07479824]] loss fxn value:  0.16810910266324386 learn rate: 1.5625e-05 iteration: 19280
[[ 1.99961646]
 [ 4.00914006]
 [-1.07480086]] loss fxn value:  0.16806241013594528 learn rate: 1.5625e-05 iteration: 19281
[[ 1.99961651]
 [ 4.00914007]
 [-1.07480349]] loss fxn value:  0.1680157305759777 learn rate: 1.5625e-05 iteration: 19282
[[ 1.99961655]
 [ 4.00914008]
 [-1.07480611]] loss fxn value:  0.16796906398134312 learn rate: 1.5625e-05 iteration: 19283
[[ 1.99961659]
 [ 4.0091401 ]
 [-1.07480874]] loss fxn value:  0.1679224103488302 learn rate: 1.5625e-05 iteration: 19284
[[ 1.99961664]
 [ 4.00914011]
 [-1.07481136]] loss fxn value:  0.16787576967471826 learn rate: 1.5625e-05 iteration: 19285
[[ 1.99961668]
 [ 4.00914012]
 [-1.07481398]] loss fxn value:  0.1678291419544821 learn rate: 1.5625e-05 iteration: 19286
[[ 1.99961673]
 [ 4.00914014]
 [-1.0748166 ]] loss fxn value:  0.16778252718636005 learn rate: 1.5625e-05 iteration: 19287
[[ 1.99961677]
 [ 4.00914015]
 [-1.07481923]] loss fxn value:  0.1677359253643341 learn rate: 1.5625e-05 iteration: 19288
[[ 1.99961681]
 [ 4.00914016]
 [-1.07482185]] loss fxn value:  0.16768933648624273 learn rate: 1.5625e-05 iteration: 19289
[[ 1.99961686]
 [ 4.00914018]
 [-1.07482447]] loss fxn value:  0.16764276054886768 learn rate: 1.5625e-05 iteration: 19290
[[ 1.9996169 ]
 [ 4.00914019]
 [-1.07482708]] loss fxn value:  0.16759619754760513 learn rate: 1.5625e-05 iteration: 19291
[[ 1.99961694]
 [ 4.0091402 ]
 [-1.0748297 ]] loss fxn value:  0.1675496474789125 learn rate: 1.5625e-05 iteration: 19292
[[ 1.99961699]
 [ 4.00914022]
 [-1.07483232]] loss fxn value:  0.16750311033997145 learn rate: 1.5625e-05 iteration: 19293
[[ 1.99961703]
 [ 4.00914023]
 [-1.07483494]] loss fxn value:  0.16745658612671382 learn rate: 1.5625e-05 iteration: 19294
[[ 1.99961708]
 [ 4.00914024]
 [-1.07483755]] loss fxn value:  0.16741007483601858 learn rate: 1.5625e-05 iteration: 19295
[[ 1.99961712]
 [ 4.00914026]
 [-1.07484017]] loss fxn value:  0.16736357646370567 learn rate: 1.5625e-05 iteration: 19296
[[ 1.99961716]
 [ 4.00914027]
 [-1.07484278]] loss fxn value:  0.16731709100670883 learn rate: 1.5625e-05 iteration: 19297
[[ 1.99961721]
 [ 4.00914028]
 [-1.0748454 ]] loss fxn value:  0.1672706184598245 learn rate: 1.5625e-05 iteration: 19298
[[ 1.99961725]
 [ 4.0091403 ]
 [-1.07484801]] loss fxn value:  0.16722415882146688 learn rate: 1.5625e-05 iteration: 19299
[[ 1.99961729]
 [ 4.00914031]
 [-1.07485062]] loss fxn value:  0.1671777120873943 learn rate: 1.5625e-05 iteration: 19300
[[ 1.99961734]
 [ 4.00914032]
 [-1.07485323]] loss fxn value:  0.16713127825403098 learn rate: 1.5625e-05 iteration: 19301
[[ 1.99961738]
 [ 4.00914034]
 [-1.07485585]] loss fxn value:  0.16708485731770867 learn rate: 1.5625e-05 iteration: 19302
[[ 1.99961742]
 [ 4.00914035]
 [-1.07485846]] loss fxn value:  0.16703844927478764 learn rate: 1.5625e-05 iteration: 19303
[[ 1.99961747]
 [ 4.00914036]
 [-1.07486107]] loss fxn value:  0.1669920541216613 learn rate: 1.5625e-05 iteration: 19304
[[ 1.99961751]
 [ 4.00914037]
 [-1.07486367]] loss fxn value:  0.1669456718556062 learn rate: 1.5625e-05 iteration: 19305
[[ 1.99961756]
 [ 4.00914039]
 [-1.07486628]] loss fxn value:  0.1668993024711068 learn rate: 1.5625e-05 iteration: 19306
[[ 1.9996176 ]
 [ 4.0091404 ]
 [-1.07486889]] loss fxn value:  0.16685294596639916 learn rate: 1.5625e-05 iteration: 19307
[[ 1.99961764]
 [ 4.00914041]
 [-1.0748715 ]] loss fxn value:  0.16680660233735806 learn rate: 1.5625e-05 iteration: 19308
[[ 1.99961769]
 [ 4.00914043]
 [-1.0748741 ]] loss fxn value:  0.1667602715799245 learn rate: 1.5625e-05 iteration: 19309
[[ 1.99961773]
 [ 4.00914044]
 [-1.07487671]] loss fxn value:  0.16671395369089187 learn rate: 1.5625e-05 iteration: 19310
[[ 1.99961777]
 [ 4.00914045]
 [-1.07487931]] loss fxn value:  0.1666676486675845 learn rate: 1.5625e-05 iteration: 19311
[[ 1.99961782]
 [ 4.00914047]
 [-1.07488192]] loss fxn value:  0.16662135650437274 learn rate: 1.5625e-05 iteration: 19312
[[ 1.99961786]
 [ 4.00914048]
 [-1.07488452]] loss fxn value:  0.1665750771997279 learn rate: 1.5625e-05 iteration: 19313
[[ 1.9996179 ]
 [ 4.00914049]
 [-1.07488712]] loss fxn value:  0.16652881074929404 learn rate: 1.5625e-05 iteration: 19314
[[ 1.99961795]
 [ 4.00914051]
 [-1.07488972]] loss fxn value:  0.16648255714813143 learn rate: 1.5625e-05 iteration: 19315
[[ 1.99961799]
 [ 4.00914052]
 [-1.07489232]] loss fxn value:  0.16643631639502107 learn rate: 1.5625e-05 iteration: 19316
[[ 1.99961803]
 [ 4.00914053]
 [-1.07489492]] loss fxn value:  0.16639008848572584 learn rate: 1.5625e-05 iteration: 19317
[[ 1.99961808]
 [ 4.00914055]
 [-1.07489752]] loss fxn value:  0.1663438734152396 learn rate: 1.5625e-05 iteration: 19318
[[ 1.99961812]
 [ 4.00914056]
 [-1.07490012]] loss fxn value:  0.16629767118228403 learn rate: 1.5625e-05 iteration: 19319
[[ 1.99961816]
 [ 4.00914057]
 [-1.07490272]] loss fxn value:  0.1662514817818383 learn rate: 1.5625e-05 iteration: 19320
[[ 1.99961821]
 [ 4.00914059]
 [-1.07490532]] loss fxn value:  0.1662053052101462 learn rate: 1.5625e-05 iteration: 19321
[[ 1.99961825]
 [ 4.0091406 ]
 [-1.07490791]] loss fxn value:  0.1661591414632846 learn rate: 1.5625e-05 iteration: 19322
[[ 1.99961829]
 [ 4.00914061]
 [-1.07491051]] loss fxn value:  0.1661129905388613 learn rate: 1.5625e-05 iteration: 19323
[[ 1.99961834]
 [ 4.00914063]
 [-1.07491311]] loss fxn value:  0.16606685243385244 learn rate: 1.5625e-05 iteration: 19324
[[ 1.99961838]
 [ 4.00914064]
 [-1.0749157 ]] loss fxn value:  0.1660207271439237 learn rate: 1.5625e-05 iteration: 19325
[[ 1.99961842]
 [ 4.00914065]
 [-1.07491829]] loss fxn value:  0.1659746146632739 learn rate: 1.5625e-05 iteration: 19326
[[ 1.99961847]
 [ 4.00914067]
 [-1.07492089]] loss fxn value:  0.16592851499299968 learn rate: 1.5625e-05 iteration: 19327
[[ 1.99961851]
 [ 4.00914068]
 [-1.07492348]] loss fxn value:  0.1658824281254699 learn rate: 1.5625e-05 iteration: 19328
[[ 1.99961855]
 [ 4.00914069]
 [-1.07492607]] loss fxn value:  0.16583635405821803 learn rate: 1.5625e-05 iteration: 19329
[[ 1.9996186 ]
 [ 4.0091407 ]
 [-1.07492866]] loss fxn value:  0.16579029278933965 learn rate: 1.5625e-05 iteration: 19330
[[ 1.99961864]
 [ 4.00914072]
 [-1.07493125]] loss fxn value:  0.16574424431344037 learn rate: 1.5625e-05 iteration: 19331
[[ 1.99961868]
 [ 4.00914073]
 [-1.07493384]] loss fxn value:  0.165698208627671 learn rate: 1.5625e-05 iteration: 19332
[[ 1.99961873]
 [ 4.00914074]
 [-1.07493643]] loss fxn value:  0.1656521857280251 learn rate: 1.5625e-05 iteration: 19333
[[ 1.99961877]
 [ 4.00914076]
 [-1.07493902]] loss fxn value:  0.16560617561226929 learn rate: 1.5625e-05 iteration: 19334
[[ 1.99961881]
 [ 4.00914077]
 [-1.0749416 ]] loss fxn value:  0.1655601782742962 learn rate: 1.5625e-05 iteration: 19335
[[ 1.99961886]
 [ 4.00914078]
 [-1.07494419]] loss fxn value:  0.165514193713024 learn rate: 1.5625e-05 iteration: 19336
[[ 1.9996189 ]
 [ 4.0091408 ]
 [-1.07494678]] loss fxn value:  0.1654682219246325 learn rate: 1.5625e-05 iteration: 19337
[[ 1.99961894]
 [ 4.00914081]
 [-1.07494936]] loss fxn value:  0.16542226290457723 learn rate: 1.5625e-05 iteration: 19338
[[ 1.99961898]
 [ 4.00914082]
 [-1.07495195]] loss fxn value:  0.16537631664927785 learn rate: 1.5625e-05 iteration: 19339
[[ 1.99961903]
 [ 4.00914084]
 [-1.07495453]] loss fxn value:  0.16533038315600626 learn rate: 1.5625e-05 iteration: 19340
[[ 1.99961907]
 [ 4.00914085]
 [-1.07495711]] loss fxn value:  0.16528446242064185 learn rate: 1.5625e-05 iteration: 19341
[[ 1.99961911]
 [ 4.00914086]
 [-1.07495969]] loss fxn value:  0.16523855443902846 learn rate: 1.5625e-05 iteration: 19342
[[ 1.99961916]
 [ 4.00914088]
 [-1.07496228]] loss fxn value:  0.16519265920956572 learn rate: 1.5625e-05 iteration: 19343
[[ 1.9996192 ]
 [ 4.00914089]
 [-1.07496486]] loss fxn value:  0.16514677672745764 learn rate: 1.5625e-05 iteration: 19344
[[ 1.99961924]
 [ 4.0091409 ]
 [-1.07496744]] loss fxn value:  0.16510090698870702 learn rate: 1.5625e-05 iteration: 19345
[[ 1.99961929]
 [ 4.00914091]
 [-1.07497002]] loss fxn value:  0.1650550499915762 learn rate: 1.5625e-05 iteration: 19346
[[ 1.99961933]
 [ 4.00914093]
 [-1.07497259]] loss fxn value:  0.16500920572950442 learn rate: 1.5625e-05 iteration: 19347
[[ 1.99961937]
 [ 4.00914094]
 [-1.07497517]] loss fxn value:  0.16496337420142004 learn rate: 1.5625e-05 iteration: 19348
[[ 1.99961941]
 [ 4.00914095]
 [-1.07497775]] loss fxn value:  0.1649175554043243 learn rate: 1.5625e-05 iteration: 19349
[[ 1.99961946]
 [ 4.00914097]
 [-1.07498033]] loss fxn value:  0.16487174933188248 learn rate: 1.5625e-05 iteration: 19350
[[ 1.9996195 ]
 [ 4.00914098]
 [-1.0749829 ]] loss fxn value:  0.16482595598199248 learn rate: 1.5625e-05 iteration: 19351
[[ 1.99961954]
 [ 4.00914099]
 [-1.07498548]] loss fxn value:  0.16478017535272835 learn rate: 1.5625e-05 iteration: 19352
[[ 1.99961959]
 [ 4.00914101]
 [-1.07498805]] loss fxn value:  0.16473440743856993 learn rate: 1.5625e-05 iteration: 19353
[[ 1.99961963]
 [ 4.00914102]
 [-1.07499062]] loss fxn value:  0.164688652236491 learn rate: 1.5625e-05 iteration: 19354
[[ 1.99961967]
 [ 4.00914103]
 [-1.0749932 ]] loss fxn value:  0.16464290974220058 learn rate: 1.5625e-05 iteration: 19355
[[ 1.99961972]
 [ 4.00914105]
 [-1.07499577]] loss fxn value:  0.16459717995365272 learn rate: 1.5625e-05 iteration: 19356
[[ 1.99961976]
 [ 4.00914106]
 [-1.07499834]] loss fxn value:  0.164551462866087 learn rate: 1.5625e-05 iteration: 19357
[[ 1.9996198 ]
 [ 4.00914107]
 [-1.07500091]] loss fxn value:  0.1645057584769466 learn rate: 1.5625e-05 iteration: 19358
[[ 1.99961984]
 [ 4.00914108]
 [-1.07500348]] loss fxn value:  0.16446006678245143 learn rate: 1.5625e-05 iteration: 19359
[[ 1.99961989]
 [ 4.0091411 ]
 [-1.07500605]] loss fxn value:  0.16441438777865894 learn rate: 1.5625e-05 iteration: 19360
[[ 1.99961993]
 [ 4.00914111]
 [-1.07500862]] loss fxn value:  0.16436872146220827 learn rate: 1.5625e-05 iteration: 19361
[[ 1.99961997]
 [ 4.00914112]
 [-1.07501119]] loss fxn value:  0.16432306783012568 learn rate: 1.5625e-05 iteration: 19362
[[ 1.99962002]
 [ 4.00914114]
 [-1.07501375]] loss fxn value:  0.16427742687807684 learn rate: 1.5625e-05 iteration: 19363
[[ 1.99962006]
 [ 4.00914115]
 [-1.07501632]] loss fxn value:  0.1642317986026242 learn rate: 1.5625e-05 iteration: 19364
[[ 1.9996201 ]
 [ 4.00914116]
 [-1.07501889]] loss fxn value:  0.16418618300051782 learn rate: 1.5625e-05 iteration: 19365
[[ 1.99962014]
 [ 4.00914118]
 [-1.07502145]] loss fxn value:  0.16414058006807322 learn rate: 1.5625e-05 iteration: 19366
[[ 1.99962019]
 [ 4.00914119]
 [-1.07502402]] loss fxn value:  0.16409498980174558 learn rate: 1.5625e-05 iteration: 19367
[[ 1.99962023]
 [ 4.0091412 ]
 [-1.07502658]] loss fxn value:  0.1640494121987235 learn rate: 1.5625e-05 iteration: 19368
[[ 1.99962027]
 [ 4.00914121]
 [-1.07502914]] loss fxn value:  0.1640038472549673 learn rate: 1.5625e-05 iteration: 19369
[[ 1.99962032]
 [ 4.00914123]
 [-1.0750317 ]] loss fxn value:  0.1639582949663495 learn rate: 1.5625e-05 iteration: 19370
[[ 1.99962036]
 [ 4.00914124]
 [-1.07503427]] loss fxn value:  0.1639127553301535 learn rate: 1.5625e-05 iteration: 19371
[[ 1.9996204 ]
 [ 4.00914125]
 [-1.07503683]] loss fxn value:  0.1638672283436821 learn rate: 1.5625e-05 iteration: 19372
[[ 1.99962044]
 [ 4.00914127]
 [-1.07503939]] loss fxn value:  0.16382171400192921 learn rate: 1.5625e-05 iteration: 19373
[[ 1.99962049]
 [ 4.00914128]
 [-1.07504195]] loss fxn value:  0.1637762123011032 learn rate: 1.5625e-05 iteration: 19374
[[ 1.99962053]
 [ 4.00914129]
 [-1.0750445 ]] loss fxn value:  0.16373072323874896 learn rate: 1.5625e-05 iteration: 19375
[[ 1.99962057]
 [ 4.00914131]
 [-1.07504706]] loss fxn value:  0.1636852468105392 learn rate: 1.5625e-05 iteration: 19376
[[ 1.99962061]
 [ 4.00914132]
 [-1.07504962]] loss fxn value:  0.1636397830144003 learn rate: 1.5625e-05 iteration: 19377
[[ 1.99962066]
 [ 4.00914133]
 [-1.07505218]] loss fxn value:  0.16359433184604033 learn rate: 1.5625e-05 iteration: 19378
[[ 1.9996207 ]
 [ 4.00914134]
 [-1.07505473]] loss fxn value:  0.16354889330056974 learn rate: 1.5625e-05 iteration: 19379
[[ 1.99962074]
 [ 4.00914136]
 [-1.07505729]] loss fxn value:  0.16350346737662674 learn rate: 1.5625e-05 iteration: 19380
[[ 1.99962078]
 [ 4.00914137]
 [-1.07505984]] loss fxn value:  0.1634580540696098 learn rate: 1.5625e-05 iteration: 19381
[[ 1.99962083]
 [ 4.00914138]
 [-1.0750624 ]] loss fxn value:  0.1634126533759101 learn rate: 1.5625e-05 iteration: 19382
[[ 1.99962087]
 [ 4.0091414 ]
 [-1.07506495]] loss fxn value:  0.16336726529236642 learn rate: 1.5625e-05 iteration: 19383
[[ 1.99962091]
 [ 4.00914141]
 [-1.0750675 ]] loss fxn value:  0.16332188981586007 learn rate: 1.5625e-05 iteration: 19384
[[ 1.99962096]
 [ 4.00914142]
 [-1.07507005]] loss fxn value:  0.16327652694206599 learn rate: 1.5625e-05 iteration: 19385
[[ 1.999621  ]
 [ 4.00914144]
 [-1.0750726 ]] loss fxn value:  0.16323117666806058 learn rate: 1.5625e-05 iteration: 19386
[[ 1.99962104]
 [ 4.00914145]
 [-1.07507515]] loss fxn value:  0.1631858389909731 learn rate: 1.5625e-05 iteration: 19387
[[ 1.99962108]
 [ 4.00914146]
 [-1.0750777 ]] loss fxn value:  0.16314051390489273 learn rate: 1.5625e-05 iteration: 19388
[[ 1.99962113]
 [ 4.00914147]
 [-1.07508025]] loss fxn value:  0.1630952014095075 learn rate: 1.5625e-05 iteration: 19389
[[ 1.99962117]
 [ 4.00914149]
 [-1.0750828 ]] loss fxn value:  0.16304990149863816 learn rate: 1.5625e-05 iteration: 19390
[[ 1.99962121]
 [ 4.0091415 ]
 [-1.07508535]] loss fxn value:  0.16300461416980347 learn rate: 1.5625e-05 iteration: 19391
[[ 1.99962125]
 [ 4.00914151]
 [-1.07508789]] loss fxn value:  0.16295933942024216 learn rate: 1.5625e-05 iteration: 19392
[[ 1.9996213 ]
 [ 4.00914153]
 [-1.07509044]] loss fxn value:  0.16291407724477464 learn rate: 1.5625e-05 iteration: 19393
[[ 1.99962134]
 [ 4.00914154]
 [-1.07509298]] loss fxn value:  0.1628688276418128 learn rate: 1.5625e-05 iteration: 19394
[[ 1.99962138]
 [ 4.00914155]
 [-1.07509553]] loss fxn value:  0.16282359060712648 learn rate: 1.5625e-05 iteration: 19395
[[ 1.99962142]
 [ 4.00914156]
 [-1.07509807]] loss fxn value:  0.16277836613707358 learn rate: 1.5625e-05 iteration: 19396
[[ 1.99962146]
 [ 4.00914158]
 [-1.07510062]] loss fxn value:  0.1627331542271336 learn rate: 1.5625e-05 iteration: 19397
[[ 1.99962151]
 [ 4.00914159]
 [-1.07510316]] loss fxn value:  0.1626879548765183 learn rate: 1.5625e-05 iteration: 19398
[[ 1.99962155]
 [ 4.0091416 ]
 [-1.0751057 ]] loss fxn value:  0.162642768078596 learn rate: 1.5625e-05 iteration: 19399
[[ 1.99962159]
 [ 4.00914162]
 [-1.07510824]] loss fxn value:  0.16259759383181419 learn rate: 1.5625e-05 iteration: 19400
[[ 1.99962163]
 [ 4.00914163]
 [-1.07511078]] loss fxn value:  0.16255243213190482 learn rate: 1.5625e-05 iteration: 19401
[[ 1.99962168]
 [ 4.00914164]
 [-1.07511332]] loss fxn value:  0.1625072829767133 learn rate: 1.5625e-05 iteration: 19402
[[ 1.99962172]
 [ 4.00914165]
 [-1.07511586]] loss fxn value:  0.16246214636162887 learn rate: 1.5625e-05 iteration: 19403
[[ 1.99962176]
 [ 4.00914167]
 [-1.0751184 ]] loss fxn value:  0.16241702228201677 learn rate: 1.5625e-05 iteration: 19404
[[ 1.9996218 ]
 [ 4.00914168]
 [-1.07512093]] loss fxn value:  0.1623719107367529 learn rate: 1.5625e-05 iteration: 19405
[[ 1.99962185]
 [ 4.00914169]
 [-1.07512347]] loss fxn value:  0.1623268117210266 learn rate: 1.5625e-05 iteration: 19406
[[ 1.99962189]
 [ 4.00914171]
 [-1.07512601]] loss fxn value:  0.16228172523230505 learn rate: 1.5625e-05 iteration: 19407
[[ 1.99962193]
 [ 4.00914172]
 [-1.07512854]] loss fxn value:  0.16223665126593187 learn rate: 1.5625e-05 iteration: 19408
[[ 1.99962197]
 [ 4.00914173]
 [-1.07513108]] loss fxn value:  0.16219158981875748 learn rate: 1.5625e-05 iteration: 19409
[[ 1.99962202]
 [ 4.00914174]
 [-1.07513361]] loss fxn value:  0.16214654088762076 learn rate: 1.5625e-05 iteration: 19410
[[ 1.99962206]
 [ 4.00914176]
 [-1.07513614]] loss fxn value:  0.16210150446788701 learn rate: 1.5625e-05 iteration: 19411
[[ 1.9996221 ]
 [ 4.00914177]
 [-1.07513868]] loss fxn value:  0.16205648055837496 learn rate: 1.5625e-05 iteration: 19412
[[ 1.99962214]
 [ 4.00914178]
 [-1.07514121]] loss fxn value:  0.16201146915386722 learn rate: 1.5625e-05 iteration: 19413
[[ 1.99962218]
 [ 4.0091418 ]
 [-1.07514374]] loss fxn value:  0.1619664702513113 learn rate: 1.5625e-05 iteration: 19414
[[ 1.99962223]
 [ 4.00914181]
 [-1.07514627]] loss fxn value:  0.16192148384705835 learn rate: 1.5625e-05 iteration: 19415
[[ 1.99962227]
 [ 4.00914182]
 [-1.0751488 ]] loss fxn value:  0.1618765099383208 learn rate: 1.5625e-05 iteration: 19416
[[ 1.99962231]
 [ 4.00914183]
 [-1.07515133]] loss fxn value:  0.1618315485206275 learn rate: 1.5625e-05 iteration: 19417
[[ 1.99962235]
 [ 4.00914185]
 [-1.07515386]] loss fxn value:  0.161786599591658 learn rate: 1.5625e-05 iteration: 19418
[[ 1.9996224 ]
 [ 4.00914186]
 [-1.07515638]] loss fxn value:  0.16174166314687016 learn rate: 1.5625e-05 iteration: 19419
[[ 1.99962244]
 [ 4.00914187]
 [-1.07515891]] loss fxn value:  0.16169673918308353 learn rate: 1.5625e-05 iteration: 19420
[[ 1.99962248]
 [ 4.00914189]
 [-1.07516144]] loss fxn value:  0.1616518276975392 learn rate: 1.5625e-05 iteration: 19421
[[ 1.99962252]
 [ 4.0091419 ]
 [-1.07516396]] loss fxn value:  0.16160692868486431 learn rate: 1.5625e-05 iteration: 19422
[[ 1.99962256]
 [ 4.00914191]
 [-1.07516649]] loss fxn value:  0.16156204214503728 learn rate: 1.5625e-05 iteration: 19423
[[ 1.99962261]
 [ 4.00914192]
 [-1.07516901]] loss fxn value:  0.16151716807114308 learn rate: 1.5625e-05 iteration: 19424
[[ 1.99962265]
 [ 4.00914194]
 [-1.07517153]] loss fxn value:  0.16147230646191024 learn rate: 1.5625e-05 iteration: 19425
[[ 1.99962269]
 [ 4.00914195]
 [-1.07517406]] loss fxn value:  0.16142745731228017 learn rate: 1.5625e-05 iteration: 19426
[[ 1.99962273]
 [ 4.00914196]
 [-1.07517658]] loss fxn value:  0.16138262061961045 learn rate: 1.5625e-05 iteration: 19427
[[ 1.99962277]
 [ 4.00914198]
 [-1.0751791 ]] loss fxn value:  0.1613377963801734 learn rate: 1.5625e-05 iteration: 19428
[[ 1.99962282]
 [ 4.00914199]
 [-1.07518162]] loss fxn value:  0.1612929845913073 learn rate: 1.5625e-05 iteration: 19429
[[ 1.99962286]
 [ 4.009142  ]
 [-1.07518414]] loss fxn value:  0.16124818524975382 learn rate: 1.5625e-05 iteration: 19430
[[ 1.9996229 ]
 [ 4.00914201]
 [-1.07518666]] loss fxn value:  0.16120339834967543 learn rate: 1.5625e-05 iteration: 19431
[[ 1.99962294]
 [ 4.00914203]
 [-1.07518918]] loss fxn value:  0.16115862388965094 learn rate: 1.5625e-05 iteration: 19432
[[ 1.99962298]
 [ 4.00914204]
 [-1.0751917 ]] loss fxn value:  0.1611138618661502 learn rate: 1.5625e-05 iteration: 19433
[[ 1.99962303]
 [ 4.00914205]
 [-1.07519421]] loss fxn value:  0.16106911227530746 learn rate: 1.5625e-05 iteration: 19434
[[ 1.99962307]
 [ 4.00914207]
 [-1.07519673]] loss fxn value:  0.1610243751133446 learn rate: 1.5625e-05 iteration: 19435
[[ 1.99962311]
 [ 4.00914208]
 [-1.07519924]] loss fxn value:  0.16097965037773823 learn rate: 1.5625e-05 iteration: 19436
[[ 1.99962315]
 [ 4.00914209]
 [-1.07520176]] loss fxn value:  0.1609349380644418 learn rate: 1.5625e-05 iteration: 19437
[[ 1.99962319]
 [ 4.0091421 ]
 [-1.07520427]] loss fxn value:  0.16089023816994594 learn rate: 1.5625e-05 iteration: 19438
[[ 1.99962324]
 [ 4.00914212]
 [-1.07520679]] loss fxn value:  0.16084555069088044 learn rate: 1.5625e-05 iteration: 19439
[[ 1.99962328]
 [ 4.00914213]
 [-1.0752093 ]] loss fxn value:  0.16080087562382847 learn rate: 1.5625e-05 iteration: 19440
[[ 1.99962332]
 [ 4.00914214]
 [-1.07521181]] loss fxn value:  0.16075621296490344 learn rate: 1.5625e-05 iteration: 19441
[[ 1.99962336]
 [ 4.00914215]
 [-1.07521432]] loss fxn value:  0.16071156271158873 learn rate: 1.5625e-05 iteration: 19442
[[ 1.9996234 ]
 [ 4.00914217]
 [-1.07521683]] loss fxn value:  0.1606669248597019 learn rate: 1.5625e-05 iteration: 19443
[[ 1.99962345]
 [ 4.00914218]
 [-1.07521934]] loss fxn value:  0.16062229940642467 learn rate: 1.5625e-05 iteration: 19444
[[ 1.99962349]
 [ 4.00914219]
 [-1.07522185]] loss fxn value:  0.16057768634739306 learn rate: 1.5625e-05 iteration: 19445
[[ 1.99962353]
 [ 4.00914221]
 [-1.07522436]] loss fxn value:  0.16053308568027427 learn rate: 1.5625e-05 iteration: 19446
[[ 1.99962357]
 [ 4.00914222]
 [-1.07522687]] loss fxn value:  0.16048849740084586 learn rate: 1.5625e-05 iteration: 19447
[[ 1.99962361]
 [ 4.00914223]
 [-1.07522938]] loss fxn value:  0.16044392150563622 learn rate: 1.5625e-05 iteration: 19448
[[ 1.99962366]
 [ 4.00914224]
 [-1.07523188]] loss fxn value:  0.16039935799138705 learn rate: 1.5625e-05 iteration: 19449
[[ 1.9996237 ]
 [ 4.00914226]
 [-1.07523439]] loss fxn value:  0.16035480685489858 learn rate: 1.5625e-05 iteration: 19450
[[ 1.99962374]
 [ 4.00914227]
 [-1.07523689]] loss fxn value:  0.16031026809261442 learn rate: 1.5625e-05 iteration: 19451
[[ 1.99962378]
 [ 4.00914228]
 [-1.0752394 ]] loss fxn value:  0.1602657417008115 learn rate: 1.5625e-05 iteration: 19452
[[ 1.99962382]
 [ 4.00914229]
 [-1.0752419 ]] loss fxn value:  0.16022122767681887 learn rate: 1.5625e-05 iteration: 19453
[[ 1.99962386]
 [ 4.00914231]
 [-1.07524441]] loss fxn value:  0.16017672601597785 learn rate: 1.5625e-05 iteration: 19454
[[ 1.99962391]
 [ 4.00914232]
 [-1.07524691]] loss fxn value:  0.1601322367152677 learn rate: 1.5625e-05 iteration: 19455
[[ 1.99962395]
 [ 4.00914233]
 [-1.07524941]] loss fxn value:  0.16008775977234097 learn rate: 1.5625e-05 iteration: 19456
[[ 1.99962399]
 [ 4.00914235]
 [-1.07525191]] loss fxn value:  0.16004329518309865 learn rate: 1.5625e-05 iteration: 19457
[[ 1.99962403]
 [ 4.00914236]
 [-1.07525441]] loss fxn value:  0.15999884294342928 learn rate: 1.5625e-05 iteration: 19458
[[ 1.99962407]
 [ 4.00914237]
 [-1.07525691]] loss fxn value:  0.15995440305107422 learn rate: 1.5625e-05 iteration: 19459
[[ 1.99962411]
 [ 4.00914238]
 [-1.07525941]] loss fxn value:  0.1599099755005842 learn rate: 1.5625e-05 iteration: 19460
[[ 1.99962416]
 [ 4.0091424 ]
 [-1.07526191]] loss fxn value:  0.1598655602906523 learn rate: 1.5625e-05 iteration: 19461
[[ 1.9996242 ]
 [ 4.00914241]
 [-1.07526441]] loss fxn value:  0.15982115741755545 learn rate: 1.5625e-05 iteration: 19462
[[ 1.99962424]
 [ 4.00914242]
 [-1.0752669 ]] loss fxn value:  0.1597767668767492 learn rate: 1.5625e-05 iteration: 19463
[[ 1.99962428]
 [ 4.00914243]
 [-1.0752694 ]] loss fxn value:  0.15973238866604345 learn rate: 1.5625e-05 iteration: 19464
[[ 1.99962432]
 [ 4.00914245]
 [-1.07527189]] loss fxn value:  0.15968802278073488 learn rate: 1.5625e-05 iteration: 19465
[[ 1.99962436]
 [ 4.00914246]
 [-1.07527439]] loss fxn value:  0.1596436692187753 learn rate: 1.5625e-05 iteration: 19466
[[ 1.99962441]
 [ 4.00914247]
 [-1.07527688]] loss fxn value:  0.15959932797588514 learn rate: 1.5625e-05 iteration: 19467
[[ 1.99962445]
 [ 4.00914248]
 [-1.07527938]] loss fxn value:  0.15955499904846016 learn rate: 1.5625e-05 iteration: 19468
[[ 1.99962449]
 [ 4.0091425 ]
 [-1.07528187]] loss fxn value:  0.15951068243385333 learn rate: 1.5625e-05 iteration: 19469
[[ 1.99962453]
 [ 4.00914251]
 [-1.07528436]] loss fxn value:  0.15946637812837702 learn rate: 1.5625e-05 iteration: 19470
[[ 1.99962457]
 [ 4.00914252]
 [-1.07528685]] loss fxn value:  0.15942208612836528 learn rate: 1.5625e-05 iteration: 19471
[[ 1.99962461]
 [ 4.00914254]
 [-1.07528934]] loss fxn value:  0.1593778064306547 learn rate: 1.5625e-05 iteration: 19472
[[ 1.99962466]
 [ 4.00914255]
 [-1.07529183]] loss fxn value:  0.15933353903163866 learn rate: 1.5625e-05 iteration: 19473
[[ 1.9996247 ]
 [ 4.00914256]
 [-1.07529432]] loss fxn value:  0.1592892839266917 learn rate: 1.5625e-05 iteration: 19474
[[ 1.99962474]
 [ 4.00914257]
 [-1.07529681]] loss fxn value:  0.1592450411155281 learn rate: 1.5625e-05 iteration: 19475
[[ 1.99962478]
 [ 4.00914259]
 [-1.0752993 ]] loss fxn value:  0.15920081059248956 learn rate: 1.5625e-05 iteration: 19476
[[ 1.99962482]
 [ 4.0091426 ]
 [-1.07530179]] loss fxn value:  0.1591565923535319 learn rate: 1.5625e-05 iteration: 19477
[[ 1.99962486]
 [ 4.00914261]
 [-1.07530427]] loss fxn value:  0.15911238639651892 learn rate: 1.5625e-05 iteration: 19478
[[ 1.9996249 ]
 [ 4.00914262]
 [-1.07530676]] loss fxn value:  0.15906819271904465 learn rate: 1.5625e-05 iteration: 19479
[[ 1.99962495]
 [ 4.00914264]
 [-1.07530924]] loss fxn value:  0.15902401131522909 learn rate: 1.5625e-05 iteration: 19480
[[ 1.99962499]
 [ 4.00914265]
 [-1.07531173]] loss fxn value:  0.1589798421827726 learn rate: 1.5625e-05 iteration: 19481
[[ 1.99962503]
 [ 4.00914266]
 [-1.07531421]] loss fxn value:  0.15893568531948746 learn rate: 1.5625e-05 iteration: 19482
[[ 1.99962507]
 [ 4.00914267]
 [-1.07531669]] loss fxn value:  0.15889154071883688 learn rate: 1.5625e-05 iteration: 19483
[[ 1.99962511]
 [ 4.00914269]
 [-1.07531918]] loss fxn value:  0.15884740838065395 learn rate: 1.5625e-05 iteration: 19484
[[ 1.99962515]
 [ 4.0091427 ]
 [-1.07532166]] loss fxn value:  0.15880328830100884 learn rate: 1.5625e-05 iteration: 19485
[[ 1.99962519]
 [ 4.00914271]
 [-1.07532414]] loss fxn value:  0.1587591804745928 learn rate: 1.5625e-05 iteration: 19486
[[ 1.99962524]
 [ 4.00914272]
 [-1.07532662]] loss fxn value:  0.15871508490001787 learn rate: 1.5625e-05 iteration: 19487
[[ 1.99962528]
 [ 4.00914274]
 [-1.0753291 ]] loss fxn value:  0.15867100157224015 learn rate: 1.5625e-05 iteration: 19488
[[ 1.99962532]
 [ 4.00914275]
 [-1.07533158]] loss fxn value:  0.1586269304891166 learn rate: 1.5625e-05 iteration: 19489
[[ 1.99962536]
 [ 4.00914276]
 [-1.07533406]] loss fxn value:  0.15858287164679385 learn rate: 1.5625e-05 iteration: 19490
[[ 1.9996254 ]
 [ 4.00914277]
 [-1.07533653]] loss fxn value:  0.158538825041855 learn rate: 1.5625e-05 iteration: 19491
[[ 1.99962544]
 [ 4.00914279]
 [-1.07533901]] loss fxn value:  0.1584947906710156 learn rate: 1.5625e-05 iteration: 19492
[[ 1.99962548]
 [ 4.0091428 ]
 [-1.07534149]] loss fxn value:  0.15845076853009785 learn rate: 1.5625e-05 iteration: 19493
[[ 1.99962553]
 [ 4.00914281]
 [-1.07534396]] loss fxn value:  0.15840675861651643 learn rate: 1.5625e-05 iteration: 19494
[[ 1.99962557]
 [ 4.00914282]
 [-1.07534644]] loss fxn value:  0.1583627609280334 learn rate: 1.5625e-05 iteration: 19495
[[ 1.99962561]
 [ 4.00914284]
 [-1.07534891]] loss fxn value:  0.158318775459412 learn rate: 1.5625e-05 iteration: 19496
[[ 1.99962565]
 [ 4.00914285]
 [-1.07535138]] loss fxn value:  0.15827480220722162 learn rate: 1.5625e-05 iteration: 19497
[[ 1.99962569]
 [ 4.00914286]
 [-1.07535386]] loss fxn value:  0.15823084116915329 learn rate: 1.5625e-05 iteration: 19498
[[ 1.99962573]
 [ 4.00914288]
 [-1.07535633]] loss fxn value:  0.1581868923405747 learn rate: 1.5625e-05 iteration: 19499
[[ 1.99962577]
 [ 4.00914289]
 [-1.0753588 ]] loss fxn value:  0.15814295571930956 learn rate: 1.5625e-05 iteration: 19500
[[ 1.99962581]
 [ 4.0091429 ]
 [-1.07536127]] loss fxn value:  0.1580990313021636 learn rate: 1.5625e-05 iteration: 19501
[[ 1.99962586]
 [ 4.00914291]
 [-1.07536374]] loss fxn value:  0.15805511908453526 learn rate: 1.5625e-05 iteration: 19502
[[ 1.9996259 ]
 [ 4.00914293]
 [-1.07536621]] loss fxn value:  0.1580112190627825 learn rate: 1.5625e-05 iteration: 19503
[[ 1.99962594]
 [ 4.00914294]
 [-1.07536868]] loss fxn value:  0.15796733123566703 learn rate: 1.5625e-05 iteration: 19504
[[ 1.99962598]
 [ 4.00914295]
 [-1.07537115]] loss fxn value:  0.15792345559706664 learn rate: 1.5625e-05 iteration: 19505
[[ 1.99962602]
 [ 4.00914296]
 [-1.07537361]] loss fxn value:  0.15787959214627872 learn rate: 1.5625e-05 iteration: 19506
[[ 1.99962606]
 [ 4.00914298]
 [-1.07537608]] loss fxn value:  0.15783574087870175 learn rate: 1.5625e-05 iteration: 19507
[[ 1.9996261 ]
 [ 4.00914299]
 [-1.07537854]] loss fxn value:  0.15779190178960376 learn rate: 1.5625e-05 iteration: 19508
[[ 1.99962614]
 [ 4.009143  ]
 [-1.07538101]] loss fxn value:  0.15774807487740367 learn rate: 1.5625e-05 iteration: 19509
[[ 1.99962618]
 [ 4.00914301]
 [-1.07538347]] loss fxn value:  0.15770426013841388 learn rate: 1.5625e-05 iteration: 19510
[[ 1.99962623]
 [ 4.00914303]
 [-1.07538594]] loss fxn value:  0.15766045756892602 learn rate: 1.5625e-05 iteration: 19511
[[ 1.99962627]
 [ 4.00914304]
 [-1.0753884 ]] loss fxn value:  0.15761666716579284 learn rate: 1.5625e-05 iteration: 19512
[[ 1.99962631]
 [ 4.00914305]
 [-1.07539086]] loss fxn value:  0.15757288892488905 learn rate: 1.5625e-05 iteration: 19513
[[ 1.99962635]
 [ 4.00914306]
 [-1.07539333]] loss fxn value:  0.15752912284494777 learn rate: 1.5625e-05 iteration: 19514
[[ 1.99962639]
 [ 4.00914308]
 [-1.07539579]] loss fxn value:  0.15748536891993942 learn rate: 1.5625e-05 iteration: 19515
[[ 1.99962643]
 [ 4.00914309]
 [-1.07539825]] loss fxn value:  0.15744162714766471 learn rate: 1.5625e-05 iteration: 19516
[[ 1.99962647]
 [ 4.0091431 ]
 [-1.07540071]] loss fxn value:  0.1573978975249478 learn rate: 1.5625e-05 iteration: 19517
[[ 1.99962651]
 [ 4.00914311]
 [-1.07540317]] loss fxn value:  0.1573541800484987 learn rate: 1.5625e-05 iteration: 19518
[[ 1.99962655]
 [ 4.00914313]
 [-1.07540562]] loss fxn value:  0.15731047471390178 learn rate: 1.5625e-05 iteration: 19519
[[ 1.9996266 ]
 [ 4.00914314]
 [-1.07540808]] loss fxn value:  0.1572667815188381 learn rate: 1.5625e-05 iteration: 19520
[[ 1.99962664]
 [ 4.00914315]
 [-1.07541054]] loss fxn value:  0.1572231004596325 learn rate: 1.5625e-05 iteration: 19521
[[ 1.99962668]
 [ 4.00914316]
 [-1.07541299]] loss fxn value:  0.15717943153270925 learn rate: 1.5625e-05 iteration: 19522
[[ 1.99962672]
 [ 4.00914318]
 [-1.07541545]] loss fxn value:  0.15713577473482385 learn rate: 1.5625e-05 iteration: 19523
[[ 1.99962676]
 [ 4.00914319]
 [-1.0754179 ]] loss fxn value:  0.15709213006334086 learn rate: 1.5625e-05 iteration: 19524
[[ 1.9996268 ]
 [ 4.0091432 ]
 [-1.07542036]] loss fxn value:  0.15704849751401848 learn rate: 1.5625e-05 iteration: 19525
[[ 1.99962684]
 [ 4.00914321]
 [-1.07542281]] loss fxn value:  0.15700487708336894 learn rate: 1.5625e-05 iteration: 19526
[[ 1.99962688]
 [ 4.00914322]
 [-1.07542527]] loss fxn value:  0.15696126876854077 learn rate: 1.5625e-05 iteration: 19527
[[ 1.99962692]
 [ 4.00914324]
 [-1.07542772]] loss fxn value:  0.15691767256601763 learn rate: 1.5625e-05 iteration: 19528
[[ 1.99962696]
 [ 4.00914325]
 [-1.07543017]] loss fxn value:  0.1568740884720788 learn rate: 1.5625e-05 iteration: 19529
[[ 1.999627  ]
 [ 4.00914326]
 [-1.07543262]] loss fxn value:  0.15683051648403942 learn rate: 1.5625e-05 iteration: 19530
[[ 1.99962705]
 [ 4.00914327]
 [-1.07543507]] loss fxn value:  0.1567869565981903 learn rate: 1.5625e-05 iteration: 19531
[[ 1.99962709]
 [ 4.00914329]
 [-1.07543752]] loss fxn value:  0.15674340881055118 learn rate: 1.5625e-05 iteration: 19532
[[ 1.99962713]
 [ 4.0091433 ]
 [-1.07543997]] loss fxn value:  0.15669987311918457 learn rate: 1.5625e-05 iteration: 19533
[[ 1.99962717]
 [ 4.00914331]
 [-1.07544242]] loss fxn value:  0.15665634951960541 learn rate: 1.5625e-05 iteration: 19534
[[ 1.99962721]
 [ 4.00914332]
 [-1.07544486]] loss fxn value:  0.15661283800870962 learn rate: 1.5625e-05 iteration: 19535
[[ 1.99962725]
 [ 4.00914334]
 [-1.07544731]] loss fxn value:  0.156569338583117 learn rate: 1.5625e-05 iteration: 19536
[[ 1.99962729]
 [ 4.00914335]
 [-1.07544976]] loss fxn value:  0.15652585123981602 learn rate: 1.5625e-05 iteration: 19537
[[ 1.99962733]
 [ 4.00914336]
 [-1.0754522 ]] loss fxn value:  0.15648237597466907 learn rate: 1.5625e-05 iteration: 19538
[[ 1.99962737]
 [ 4.00914337]
 [-1.07545465]] loss fxn value:  0.1564389127853511 learn rate: 1.5625e-05 iteration: 19539
[[ 1.99962741]
 [ 4.00914339]
 [-1.07545709]] loss fxn value:  0.15639546166830257 learn rate: 1.5625e-05 iteration: 19540
[[ 1.99962745]
 [ 4.0091434 ]
 [-1.07545953]] loss fxn value:  0.15635202261838707 learn rate: 1.5625e-05 iteration: 19541
[[ 1.99962749]
 [ 4.00914341]
 [-1.07546198]] loss fxn value:  0.1563085956349582 learn rate: 1.5625e-05 iteration: 19542
[[ 1.99962754]
 [ 4.00914342]
 [-1.07546442]] loss fxn value:  0.1562651807136655 learn rate: 1.5625e-05 iteration: 19543
[[ 1.99962758]
 [ 4.00914344]
 [-1.07546686]] loss fxn value:  0.15622177784999997 learn rate: 1.5625e-05 iteration: 19544
[[ 1.99962762]
 [ 4.00914345]
 [-1.0754693 ]] loss fxn value:  0.15617838704185485 learn rate: 1.5625e-05 iteration: 19545
[[ 1.99962766]
 [ 4.00914346]
 [-1.07547174]] loss fxn value:  0.15613500828630925 learn rate: 1.5625e-05 iteration: 19546
[[ 1.9996277 ]
 [ 4.00914347]
 [-1.07547418]] loss fxn value:  0.15609164157846886 learn rate: 1.5625e-05 iteration: 19547
[[ 1.99962774]
 [ 4.00914349]
 [-1.07547662]] loss fxn value:  0.1560482869160056 learn rate: 1.5625e-05 iteration: 19548
[[ 1.99962778]
 [ 4.0091435 ]
 [-1.07547906]] loss fxn value:  0.15600494429582695 learn rate: 1.5625e-05 iteration: 19549
[[ 1.99962782]
 [ 4.00914351]
 [-1.07548149]] loss fxn value:  0.15596161371275322 learn rate: 1.5625e-05 iteration: 19550
[[ 1.99962786]
 [ 4.00914352]
 [-1.07548393]] loss fxn value:  0.15591829516662212 learn rate: 1.5625e-05 iteration: 19551
[[ 1.9996279 ]
 [ 4.00914354]
 [-1.07548636]] loss fxn value:  0.1558749886511734 learn rate: 1.5625e-05 iteration: 19552
[[ 1.99962794]
 [ 4.00914355]
 [-1.0754888 ]] loss fxn value:  0.15583169416390966 learn rate: 1.5625e-05 iteration: 19553
[[ 1.99962798]
 [ 4.00914356]
 [-1.07549123]] loss fxn value:  0.1557884117015864 learn rate: 1.5625e-05 iteration: 19554
[[ 1.99962802]
 [ 4.00914357]
 [-1.07549367]] loss fxn value:  0.15574514126194408 learn rate: 1.5625e-05 iteration: 19555
[[ 1.99962806]
 [ 4.00914358]
 [-1.0754961 ]] loss fxn value:  0.15570188284044836 learn rate: 1.5625e-05 iteration: 19556
[[ 1.9996281 ]
 [ 4.0091436 ]
 [-1.07549853]] loss fxn value:  0.15565863643384004 learn rate: 1.5625e-05 iteration: 19557
[[ 1.99962814]
 [ 4.00914361]
 [-1.07550097]] loss fxn value:  0.15561540203944585 learn rate: 1.5625e-05 iteration: 19558
[[ 1.99962819]
 [ 4.00914362]
 [-1.0755034 ]] loss fxn value:  0.15557217965277378 learn rate: 1.5625e-05 iteration: 19559
[[ 1.99962823]
 [ 4.00914363]
 [-1.07550583]] loss fxn value:  0.1555289692718979 learn rate: 1.5625e-05 iteration: 19560
[[ 1.99962827]
 [ 4.00914365]
 [-1.07550826]] loss fxn value:  0.1554857708918314 learn rate: 1.5625e-05 iteration: 19561
[[ 1.99962831]
 [ 4.00914366]
 [-1.07551069]] loss fxn value:  0.15544258451130744 learn rate: 1.5625e-05 iteration: 19562
[[ 1.99962835]
 [ 4.00914367]
 [-1.07551311]] loss fxn value:  0.15539941012524355 learn rate: 1.5625e-05 iteration: 19563
[[ 1.99962839]
 [ 4.00914368]
 [-1.07551554]] loss fxn value:  0.1553562477308978 learn rate: 1.5625e-05 iteration: 19564
[[ 1.99962843]
 [ 4.0091437 ]
 [-1.07551797]] loss fxn value:  0.15531309732518228 learn rate: 1.5625e-05 iteration: 19565
[[ 1.99962847]
 [ 4.00914371]
 [-1.0755204 ]] loss fxn value:  0.15526995890388845 learn rate: 1.5625e-05 iteration: 19566
[[ 1.99962851]
 [ 4.00914372]
 [-1.07552282]] loss fxn value:  0.155226832465274 learn rate: 1.5625e-05 iteration: 19567
[[ 1.99962855]
 [ 4.00914373]
 [-1.07552525]] loss fxn value:  0.15518371800475347 learn rate: 1.5625e-05 iteration: 19568
[[ 1.99962859]
 [ 4.00914374]
 [-1.07552767]] loss fxn value:  0.1551406155186996 learn rate: 1.5625e-05 iteration: 19569
[[ 1.99962863]
 [ 4.00914376]
 [-1.07553009]] loss fxn value:  0.1550975250053005 learn rate: 1.5625e-05 iteration: 19570
[[ 1.99962867]
 [ 4.00914377]
 [-1.07553252]] loss fxn value:  0.15505444645955477 learn rate: 1.5625e-05 iteration: 19571
[[ 1.99962871]
 [ 4.00914378]
 [-1.07553494]] loss fxn value:  0.15501137987968608 learn rate: 1.5625e-05 iteration: 19572
[[ 1.99962875]
 [ 4.00914379]
 [-1.07553736]] loss fxn value:  0.1549683252614936 learn rate: 1.5625e-05 iteration: 19573
[[ 1.99962879]
 [ 4.00914381]
 [-1.07553978]] loss fxn value:  0.15492528260186553 learn rate: 1.5625e-05 iteration: 19574
[[ 1.99962883]
 [ 4.00914382]
 [-1.0755422 ]] loss fxn value:  0.15488225189718607 learn rate: 1.5625e-05 iteration: 19575
[[ 1.99962887]
 [ 4.00914383]
 [-1.07554462]] loss fxn value:  0.15483923314370132 learn rate: 1.5625e-05 iteration: 19576
[[ 1.99962891]
 [ 4.00914384]
 [-1.07554704]] loss fxn value:  0.15479622633983933 learn rate: 1.5625e-05 iteration: 19577
[[ 1.99962895]
 [ 4.00914386]
 [-1.07554946]] loss fxn value:  0.1547532314802902 learn rate: 1.5625e-05 iteration: 19578
[[ 1.99962899]
 [ 4.00914387]
 [-1.07555188]] loss fxn value:  0.15471024856302037 learn rate: 1.5625e-05 iteration: 19579
[[ 1.99962903]
 [ 4.00914388]
 [-1.07555429]] loss fxn value:  0.1546672775842474 learn rate: 1.5625e-05 iteration: 19580
[[ 1.99962908]
 [ 4.00914389]
 [-1.07555671]] loss fxn value:  0.15462431854087186 learn rate: 1.5625e-05 iteration: 19581
[[ 1.99962912]
 [ 4.0091439 ]
 [-1.07555913]] loss fxn value:  0.15458137142917766 learn rate: 1.5625e-05 iteration: 19582
[[ 1.99962916]
 [ 4.00914392]
 [-1.07556154]] loss fxn value:  0.15453843624608463 learn rate: 1.5625e-05 iteration: 19583
[[ 1.9996292 ]
 [ 4.00914393]
 [-1.07556396]] loss fxn value:  0.15449551298833827 learn rate: 1.5625e-05 iteration: 19584
[[ 1.99962924]
 [ 4.00914394]
 [-1.07556637]] loss fxn value:  0.15445260165277053 learn rate: 1.5625e-05 iteration: 19585
[[ 1.99962928]
 [ 4.00914395]
 [-1.07556878]] loss fxn value:  0.15440970223621017 learn rate: 1.5625e-05 iteration: 19586
[[ 1.99962932]
 [ 4.00914397]
 [-1.07557119]] loss fxn value:  0.15436681473498665 learn rate: 1.5625e-05 iteration: 19587
[[ 1.99962936]
 [ 4.00914398]
 [-1.07557361]] loss fxn value:  0.15432393914454626 learn rate: 1.5625e-05 iteration: 19588
[[ 1.9996294 ]
 [ 4.00914399]
 [-1.07557602]] loss fxn value:  0.1542810754645623 learn rate: 1.5625e-05 iteration: 19589
[[ 1.99962944]
 [ 4.009144  ]
 [-1.07557843]] loss fxn value:  0.15423822368893658 learn rate: 1.5625e-05 iteration: 19590
[[ 1.99962948]
 [ 4.00914401]
 [-1.07558084]] loss fxn value:  0.15419538381549977 learn rate: 1.5625e-05 iteration: 19591
[[ 1.99962952]
 [ 4.00914403]
 [-1.07558325]] loss fxn value:  0.1541525558411124 learn rate: 1.5625e-05 iteration: 19592
[[ 1.99962956]
 [ 4.00914404]
 [-1.07558565]] loss fxn value:  0.15410973976199432 learn rate: 1.5625e-05 iteration: 19593
[[ 1.9996296 ]
 [ 4.00914405]
 [-1.07558806]] loss fxn value:  0.1540669355765358 learn rate: 1.5625e-05 iteration: 19594
[[ 1.99962964]
 [ 4.00914406]
 [-1.07559047]] loss fxn value:  0.15402414327807676 learn rate: 1.5625e-05 iteration: 19595
[[ 1.99962968]
 [ 4.00914408]
 [-1.07559288]] loss fxn value:  0.1539813628659978 learn rate: 1.5625e-05 iteration: 19596
[[ 1.99962972]
 [ 4.00914409]
 [-1.07559528]] loss fxn value:  0.15393859433651888 learn rate: 1.5625e-05 iteration: 19597
[[ 1.99962976]
 [ 4.0091441 ]
 [-1.07559769]] loss fxn value:  0.15389583768553858 learn rate: 1.5625e-05 iteration: 19598
[[ 1.9996298 ]
 [ 4.00914411]
 [-1.07560009]] loss fxn value:  0.15385309291040214 learn rate: 1.5625e-05 iteration: 19599
[[ 1.99962984]
 [ 4.00914412]
 [-1.07560249]] loss fxn value:  0.1538103600083128 learn rate: 1.5625e-05 iteration: 19600
[[ 1.99962988]
 [ 4.00914414]
 [-1.0756049 ]] loss fxn value:  0.15376763897424062 learn rate: 1.5625e-05 iteration: 19601
[[ 1.99962992]
 [ 4.00914415]
 [-1.0756073 ]] loss fxn value:  0.15372492980699737 learn rate: 1.5625e-05 iteration: 19602
[[ 1.99962996]
 [ 4.00914416]
 [-1.0756097 ]] loss fxn value:  0.15368223250180796 learn rate: 1.5625e-05 iteration: 19603
[[ 1.99963   ]
 [ 4.00914417]
 [-1.0756121 ]] loss fxn value:  0.1536395470556563 learn rate: 1.5625e-05 iteration: 19604
[[ 1.99963004]
 [ 4.00914419]
 [-1.0756145 ]] loss fxn value:  0.1535968734657333 learn rate: 1.5625e-05 iteration: 19605
[[ 1.99963008]
 [ 4.0091442 ]
 [-1.0756169 ]] loss fxn value:  0.15355421172839462 learn rate: 1.5625e-05 iteration: 19606
[[ 1.99963012]
 [ 4.00914421]
 [-1.0756193 ]] loss fxn value:  0.15351156184007142 learn rate: 1.5625e-05 iteration: 19607
[[ 1.99963016]
 [ 4.00914422]
 [-1.0756217 ]] loss fxn value:  0.1534689237989381 learn rate: 1.5625e-05 iteration: 19608
[[ 1.9996302 ]
 [ 4.00914423]
 [-1.0756241 ]] loss fxn value:  0.1534262975998744 learn rate: 1.5625e-05 iteration: 19609
[[ 1.99963024]
 [ 4.00914425]
 [-1.07562649]] loss fxn value:  0.15338368323981633 learn rate: 1.5625e-05 iteration: 19610
[[ 1.99963028]
 [ 4.00914426]
 [-1.07562889]] loss fxn value:  0.1533410807164358 learn rate: 1.5625e-05 iteration: 19611
[[ 1.99963032]
 [ 4.00914427]
 [-1.07563128]] loss fxn value:  0.1532984900266572 learn rate: 1.5625e-05 iteration: 19612
[[ 1.99963036]
 [ 4.00914428]
 [-1.07563368]] loss fxn value:  0.1532559111657456 learn rate: 1.5625e-05 iteration: 19613
[[ 1.9996304 ]
 [ 4.00914429]
 [-1.07563607]] loss fxn value:  0.15321334413110865 learn rate: 1.5625e-05 iteration: 19614
[[ 1.99963044]
 [ 4.00914431]
 [-1.07563847]] loss fxn value:  0.1531707889190357 learn rate: 1.5625e-05 iteration: 19615
[[ 1.99963048]
 [ 4.00914432]
 [-1.07564086]] loss fxn value:  0.153128245526912 learn rate: 1.5625e-05 iteration: 19616
[[ 1.99963052]
 [ 4.00914433]
 [-1.07564325]] loss fxn value:  0.1530857139518792 learn rate: 1.5625e-05 iteration: 19617
[[ 1.99963056]
 [ 4.00914434]
 [-1.07564564]] loss fxn value:  0.15304319418993537 learn rate: 1.5625e-05 iteration: 19618
[[ 1.9996306 ]
 [ 4.00914436]
 [-1.07564804]] loss fxn value:  0.15300068623778362 learn rate: 1.5625e-05 iteration: 19619
[[ 1.99963064]
 [ 4.00914437]
 [-1.07565043]] loss fxn value:  0.15295819009244102 learn rate: 1.5625e-05 iteration: 19620
[[ 1.99963068]
 [ 4.00914438]
 [-1.07565282]] loss fxn value:  0.1529157057495825 learn rate: 1.5625e-05 iteration: 19621
[[ 1.99963072]
 [ 4.00914439]
 [-1.0756552 ]] loss fxn value:  0.15287323320802218 learn rate: 1.5625e-05 iteration: 19622
[[ 1.99963076]
 [ 4.0091444 ]
 [-1.07565759]] loss fxn value:  0.1528307724626969 learn rate: 1.5625e-05 iteration: 19623
[[ 1.9996308 ]
 [ 4.00914442]
 [-1.07565998]] loss fxn value:  0.15278832351128085 learn rate: 1.5625e-05 iteration: 19624
[[ 1.99963084]
 [ 4.00914443]
 [-1.07566237]] loss fxn value:  0.15274588634972744 learn rate: 1.5625e-05 iteration: 19625
[[ 1.99963088]
 [ 4.00914444]
 [-1.07566475]] loss fxn value:  0.15270346097488938 learn rate: 1.5625e-05 iteration: 19626
[[ 1.99963092]
 [ 4.00914445]
 [-1.07566714]] loss fxn value:  0.15266104738492633 learn rate: 1.5625e-05 iteration: 19627
[[ 1.99963096]
 [ 4.00914446]
 [-1.07566952]] loss fxn value:  0.15261864557337795 learn rate: 1.5625e-05 iteration: 19628
[[ 1.999631  ]
 [ 4.00914448]
 [-1.07567191]] loss fxn value:  0.15257625554087714 learn rate: 1.5625e-05 iteration: 19629
[[ 1.99963104]
 [ 4.00914449]
 [-1.07567429]] loss fxn value:  0.15253387728184425 learn rate: 1.5625e-05 iteration: 19630
[[ 1.99963108]
 [ 4.0091445 ]
 [-1.07567667]] loss fxn value:  0.15249151079258721 learn rate: 1.5625e-05 iteration: 19631
[[ 1.99963112]
 [ 4.00914451]
 [-1.07567906]] loss fxn value:  0.1524491560705298 learn rate: 1.5625e-05 iteration: 19632
[[ 1.99963116]
 [ 4.00914453]
 [-1.07568144]] loss fxn value:  0.15240681311433424 learn rate: 1.5625e-05 iteration: 19633
[[ 1.9996312 ]
 [ 4.00914454]
 [-1.07568382]] loss fxn value:  0.15236448191729804 learn rate: 1.5625e-05 iteration: 19634
[[ 1.99963124]
 [ 4.00914455]
 [-1.0756862 ]] loss fxn value:  0.15232216247897454 learn rate: 1.5625e-05 iteration: 19635
[[ 1.99963128]
 [ 4.00914456]
 [-1.07568858]] loss fxn value:  0.1522798547939944 learn rate: 1.5625e-05 iteration: 19636
[[ 1.99963131]
 [ 4.00914457]
 [-1.07569096]] loss fxn value:  0.15223755886029786 learn rate: 1.5625e-05 iteration: 19637
[[ 1.99963135]
 [ 4.00914459]
 [-1.07569334]] loss fxn value:  0.15219527467463817 learn rate: 1.5625e-05 iteration: 19638
[[ 1.99963139]
 [ 4.0091446 ]
 [-1.07569571]] loss fxn value:  0.15215300223332084 learn rate: 1.5625e-05 iteration: 19639
[[ 1.99963143]
 [ 4.00914461]
 [-1.07569809]] loss fxn value:  0.15211074153325108 learn rate: 1.5625e-05 iteration: 19640
[[ 1.99963147]
 [ 4.00914462]
 [-1.07570047]] loss fxn value:  0.15206849257125069 learn rate: 1.5625e-05 iteration: 19641
[[ 1.99963151]
 [ 4.00914463]
 [-1.07570284]] loss fxn value:  0.152026255343985 learn rate: 1.5625e-05 iteration: 19642
[[ 1.99963155]
 [ 4.00914465]
 [-1.07570522]] loss fxn value:  0.15198402984756637 learn rate: 1.5625e-05 iteration: 19643
[[ 1.99963159]
 [ 4.00914466]
 [-1.07570759]] loss fxn value:  0.15194181608003332 learn rate: 1.5625e-05 iteration: 19644
[[ 1.99963163]
 [ 4.00914467]
 [-1.07570997]] loss fxn value:  0.15189961403692473 learn rate: 1.5625e-05 iteration: 19645
[[ 1.99963167]
 [ 4.00914468]
 [-1.07571234]] loss fxn value:  0.15185742371590547 learn rate: 1.5625e-05 iteration: 19646
[[ 1.99963171]
 [ 4.00914469]
 [-1.07571471]] loss fxn value:  0.1518152451119718 learn rate: 1.5625e-05 iteration: 19647
[[ 1.99963175]
 [ 4.00914471]
 [-1.07571708]] loss fxn value:  0.1517730782252278 learn rate: 1.5625e-05 iteration: 19648
[[ 1.99963179]
 [ 4.00914472]
 [-1.07571946]] loss fxn value:  0.15173092304960148 learn rate: 1.5625e-05 iteration: 19649
[[ 1.99963183]
 [ 4.00914473]
 [-1.07572183]] loss fxn value:  0.15168877958248356 learn rate: 1.5625e-05 iteration: 19650
[[ 1.99963187]
 [ 4.00914474]
 [-1.0757242 ]] loss fxn value:  0.1516466478201795 learn rate: 1.5625e-05 iteration: 19651
[[ 1.99963191]
 [ 4.00914475]
 [-1.07572656]] loss fxn value:  0.1516045277605016 learn rate: 1.5625e-05 iteration: 19652
[[ 1.99963195]
 [ 4.00914477]
 [-1.07572893]] loss fxn value:  0.15156241940015522 learn rate: 1.5625e-05 iteration: 19653
[[ 1.99963199]
 [ 4.00914478]
 [-1.0757313 ]] loss fxn value:  0.15152032273506985 learn rate: 1.5625e-05 iteration: 19654
[[ 1.99963203]
 [ 4.00914479]
 [-1.07573367]] loss fxn value:  0.15147823776258376 learn rate: 1.5625e-05 iteration: 19655
[[ 1.99963207]
 [ 4.0091448 ]
 [-1.07573603]] loss fxn value:  0.1514361644790001 learn rate: 1.5625e-05 iteration: 19656
[[ 1.99963211]
 [ 4.00914481]
 [-1.0757384 ]] loss fxn value:  0.15139410288206948 learn rate: 1.5625e-05 iteration: 19657
[[ 1.99963215]
 [ 4.00914483]
 [-1.07574077]] loss fxn value:  0.15135205296724735 learn rate: 1.5625e-05 iteration: 19658
[[ 1.99963219]
 [ 4.00914484]
 [-1.07574313]] loss fxn value:  0.1513100147317532 learn rate: 1.5625e-05 iteration: 19659
[[ 1.99963222]
 [ 4.00914485]
 [-1.07574549]] loss fxn value:  0.15126798817251616 learn rate: 1.5625e-05 iteration: 19660
[[ 1.99963226]
 [ 4.00914486]
 [-1.07574786]] loss fxn value:  0.15122597328622775 learn rate: 1.5625e-05 iteration: 19661
[[ 1.9996323 ]
 [ 4.00914487]
 [-1.07575022]] loss fxn value:  0.1511839700688668 learn rate: 1.5625e-05 iteration: 19662
[[ 1.99963234]
 [ 4.00914489]
 [-1.07575258]] loss fxn value:  0.15114197851909783 learn rate: 1.5625e-05 iteration: 19663
[[ 1.99963238]
 [ 4.0091449 ]
 [-1.07575494]] loss fxn value:  0.1510999986327624 learn rate: 1.5625e-05 iteration: 19664
[[ 1.99963242]
 [ 4.00914491]
 [-1.0757573 ]] loss fxn value:  0.15105803040482826 learn rate: 1.5625e-05 iteration: 19665
[[ 1.99963246]
 [ 4.00914492]
 [-1.07575966]] loss fxn value:  0.15101607383542565 learn rate: 1.5625e-05 iteration: 19666
[[ 1.9996325 ]
 [ 4.00914493]
 [-1.07576202]] loss fxn value:  0.15097412891854664 learn rate: 1.5625e-05 iteration: 19667
[[ 1.99963254]
 [ 4.00914495]
 [-1.07576438]] loss fxn value:  0.15093219565142996 learn rate: 1.5625e-05 iteration: 19668
[[ 1.99963258]
 [ 4.00914496]
 [-1.07576674]] loss fxn value:  0.15089027403237804 learn rate: 1.5625e-05 iteration: 19669
[[ 1.99963262]
 [ 4.00914497]
 [-1.0757691 ]] loss fxn value:  0.15084836405724628 learn rate: 1.5625e-05 iteration: 19670
[[ 1.99963266]
 [ 4.00914498]
 [-1.07577145]] loss fxn value:  0.15080646572184772 learn rate: 1.5625e-05 iteration: 19671
[[ 1.9996327 ]
 [ 4.00914499]
 [-1.07577381]] loss fxn value:  0.1507645790235708 learn rate: 1.5625e-05 iteration: 19672
[[ 1.99963274]
 [ 4.00914501]
 [-1.07577616]] loss fxn value:  0.15072270395965653 learn rate: 1.5625e-05 iteration: 19673
[[ 1.99963278]
 [ 4.00914502]
 [-1.07577852]] loss fxn value:  0.15068084052693376 learn rate: 1.5625e-05 iteration: 19674
[[ 1.99963282]
 [ 4.00914503]
 [-1.07578087]] loss fxn value:  0.1506389887217296 learn rate: 1.5625e-05 iteration: 19675
[[ 1.99963285]
 [ 4.00914504]
 [-1.07578323]] loss fxn value:  0.15059714854130668 learn rate: 1.5625e-05 iteration: 19676
[[ 1.99963289]
 [ 4.00914505]
 [-1.07578558]] loss fxn value:  0.15055531998164162 learn rate: 1.5625e-05 iteration: 19677
[[ 1.99963293]
 [ 4.00914507]
 [-1.07578793]] loss fxn value:  0.1505135030394899 learn rate: 1.5625e-05 iteration: 19678
[[ 1.99963297]
 [ 4.00914508]
 [-1.07579028]] loss fxn value:  0.15047169771263985 learn rate: 1.5625e-05 iteration: 19679
[[ 1.99963301]
 [ 4.00914509]
 [-1.07579263]] loss fxn value:  0.15042990399639045 learn rate: 1.5625e-05 iteration: 19680
[[ 1.99963305]
 [ 4.0091451 ]
 [-1.07579498]] loss fxn value:  0.15038812189010306 learn rate: 1.5625e-05 iteration: 19681
[[ 1.99963309]
 [ 4.00914511]
 [-1.07579733]] loss fxn value:  0.15034635138756988 learn rate: 1.5625e-05 iteration: 19682
[[ 1.99963313]
 [ 4.00914513]
 [-1.07579968]] loss fxn value:  0.15030459248715505 learn rate: 1.5625e-05 iteration: 19683
[[ 1.99963317]
 [ 4.00914514]
 [-1.07580203]] loss fxn value:  0.15026284518520724 learn rate: 1.5625e-05 iteration: 19684
[[ 1.99963321]
 [ 4.00914515]
 [-1.07580438]] loss fxn value:  0.150221109478922 learn rate: 1.5625e-05 iteration: 19685
[[ 1.99963325]
 [ 4.00914516]
 [-1.07580672]] loss fxn value:  0.15017938536474754 learn rate: 1.5625e-05 iteration: 19686
[[ 1.99963329]
 [ 4.00914517]
 [-1.07580907]] loss fxn value:  0.15013767283941087 learn rate: 1.5625e-05 iteration: 19687
[[ 1.99963332]
 [ 4.00914518]
 [-1.07581142]] loss fxn value:  0.15009597189887236 learn rate: 1.5625e-05 iteration: 19688
[[ 1.99963336]
 [ 4.0091452 ]
 [-1.07581376]] loss fxn value:  0.1500542825423267 learn rate: 1.5625e-05 iteration: 19689
[[ 1.9996334 ]
 [ 4.00914521]
 [-1.07581611]] loss fxn value:  0.15001260476453263 learn rate: 1.5625e-05 iteration: 19690
[[ 1.99963344]
 [ 4.00914522]
 [-1.07581845]] loss fxn value:  0.14997093856247165 learn rate: 1.5625e-05 iteration: 19691
[[ 1.99963348]
 [ 4.00914523]
 [-1.07582079]] loss fxn value:  0.14992928393297028 learn rate: 1.5625e-05 iteration: 19692
[[ 1.99963352]
 [ 4.00914524]
 [-1.07582313]] loss fxn value:  0.14988764087369347 learn rate: 1.5625e-05 iteration: 19693
[[ 1.99963356]
 [ 4.00914526]
 [-1.07582548]] loss fxn value:  0.14984600938054904 learn rate: 1.5625e-05 iteration: 19694
[[ 1.9996336 ]
 [ 4.00914527]
 [-1.07582782]] loss fxn value:  0.14980438945132768 learn rate: 1.5625e-05 iteration: 19695
[[ 1.99963364]
 [ 4.00914528]
 [-1.07583016]] loss fxn value:  0.14976278108135224 learn rate: 1.5625e-05 iteration: 19696
[[ 1.99963368]
 [ 4.00914529]
 [-1.0758325 ]] loss fxn value:  0.1497211842680558 learn rate: 1.5625e-05 iteration: 19697
[[ 1.99963372]
 [ 4.0091453 ]
 [-1.07583484]] loss fxn value:  0.1496795990086178 learn rate: 1.5625e-05 iteration: 19698
[[ 1.99963375]
 [ 4.00914532]
 [-1.07583717]] loss fxn value:  0.14963802529893458 learn rate: 1.5625e-05 iteration: 19699
[[ 1.99963379]
 [ 4.00914533]
 [-1.07583951]] loss fxn value:  0.1495964631372961 learn rate: 1.5625e-05 iteration: 19700
[[ 1.99963383]
 [ 4.00914534]
 [-1.07584185]] loss fxn value:  0.14955491251942288 learn rate: 1.5625e-05 iteration: 19701
[[ 1.99963387]
 [ 4.00914535]
 [-1.07584419]] loss fxn value:  0.14951337344230572 learn rate: 1.5625e-05 iteration: 19702
[[ 1.99963391]
 [ 4.00914536]
 [-1.07584652]] loss fxn value:  0.1494718459026408 learn rate: 1.5625e-05 iteration: 19703
[[ 1.99963395]
 [ 4.00914537]
 [-1.07584886]] loss fxn value:  0.1494303298978612 learn rate: 1.5625e-05 iteration: 19704
[[ 1.99963399]
 [ 4.00914539]
 [-1.07585119]] loss fxn value:  0.14938882542318027 learn rate: 1.5625e-05 iteration: 19705
[[ 1.99963403]
 [ 4.0091454 ]
 [-1.07585352]] loss fxn value:  0.14934733247701223 learn rate: 1.5625e-05 iteration: 19706
[[ 1.99963407]
 [ 4.00914541]
 [-1.07585586]] loss fxn value:  0.14930585105556315 learn rate: 1.5625e-05 iteration: 19707
[[ 1.99963411]
 [ 4.00914542]
 [-1.07585819]] loss fxn value:  0.1492643811557235 learn rate: 1.5625e-05 iteration: 19708
[[ 1.99963414]
 [ 4.00914543]
 [-1.07586052]] loss fxn value:  0.14922292277384658 learn rate: 1.5625e-05 iteration: 19709
[[ 1.99963418]
 [ 4.00914545]
 [-1.07586285]] loss fxn value:  0.1491814759071758 learn rate: 1.5625e-05 iteration: 19710
[[ 1.99963422]
 [ 4.00914546]
 [-1.07586518]] loss fxn value:  0.14914004055207608 learn rate: 1.5625e-05 iteration: 19711
[[ 1.99963426]
 [ 4.00914547]
 [-1.07586751]] loss fxn value:  0.14909861670636423 learn rate: 1.5625e-05 iteration: 19712
[[ 1.9996343 ]
 [ 4.00914548]
 [-1.07586984]] loss fxn value:  0.1490572043653153 learn rate: 1.5625e-05 iteration: 19713
[[ 1.99963434]
 [ 4.00914549]
 [-1.07587217]] loss fxn value:  0.14901580352780053 learn rate: 1.5625e-05 iteration: 19714
[[ 1.99963438]
 [ 4.0091455 ]
 [-1.0758745 ]] loss fxn value:  0.14897441418900473 learn rate: 1.5625e-05 iteration: 19715
[[ 1.99963442]
 [ 4.00914552]
 [-1.07587683]] loss fxn value:  0.14893303634552107 learn rate: 1.5625e-05 iteration: 19716
[[ 1.99963446]
 [ 4.00914553]
 [-1.07587915]] loss fxn value:  0.14889166999497588 learn rate: 1.5625e-05 iteration: 19717
[[ 1.99963449]
 [ 4.00914554]
 [-1.07588148]] loss fxn value:  0.14885031513411315 learn rate: 1.5625e-05 iteration: 19718
[[ 1.99963453]
 [ 4.00914555]
 [-1.07588381]] loss fxn value:  0.14880897175993527 learn rate: 1.5625e-05 iteration: 19719
[[ 1.99963457]
 [ 4.00914556]
 [-1.07588613]] loss fxn value:  0.1487676398691314 learn rate: 1.5625e-05 iteration: 19720
[[ 1.99963461]
 [ 4.00914558]
 [-1.07588845]] loss fxn value:  0.14872631945707385 learn rate: 1.5625e-05 iteration: 19721
[[ 1.99963465]
 [ 4.00914559]
 [-1.07589078]] loss fxn value:  0.14868501052263378 learn rate: 1.5625e-05 iteration: 19722
[[ 1.99963469]
 [ 4.0091456 ]
 [-1.0758931 ]] loss fxn value:  0.14864371306199328 learn rate: 1.5625e-05 iteration: 19723
[[ 1.99963473]
 [ 4.00914561]
 [-1.07589542]] loss fxn value:  0.14860242707157895 learn rate: 1.5625e-05 iteration: 19724
[[ 1.99963477]
 [ 4.00914562]
 [-1.07589774]] loss fxn value:  0.1485611525485964 learn rate: 1.5625e-05 iteration: 19725
[[ 1.9996348 ]
 [ 4.00914563]
 [-1.07590007]] loss fxn value:  0.14851988948950076 learn rate: 1.5625e-05 iteration: 19726
[[ 1.99963484]
 [ 4.00914565]
 [-1.07590239]] loss fxn value:  0.148478637891997 learn rate: 1.5625e-05 iteration: 19727
[[ 1.99963488]
 [ 4.00914566]
 [-1.07590471]] loss fxn value:  0.14843739775143888 learn rate: 1.5625e-05 iteration: 19728
[[ 1.99963492]
 [ 4.00914567]
 [-1.07590702]] loss fxn value:  0.14839616906527653 learn rate: 1.5625e-05 iteration: 19729
[[ 1.99963496]
 [ 4.00914568]
 [-1.07590934]] loss fxn value:  0.1483549518306106 learn rate: 1.5625e-05 iteration: 19730
[[ 1.999635  ]
 [ 4.00914569]
 [-1.07591166]] loss fxn value:  0.14831374604388697 learn rate: 1.5625e-05 iteration: 19731
[[ 1.99963504]
 [ 4.00914571]
 [-1.07591398]] loss fxn value:  0.14827255170237527 learn rate: 1.5625e-05 iteration: 19732
[[ 1.99963507]
 [ 4.00914572]
 [-1.07591629]] loss fxn value:  0.14823136880292134 learn rate: 1.5625e-05 iteration: 19733
[[ 1.99963511]
 [ 4.00914573]
 [-1.07591861]] loss fxn value:  0.14819019734178276 learn rate: 1.5625e-05 iteration: 19734
[[ 1.99963515]
 [ 4.00914574]
 [-1.07592092]] loss fxn value:  0.1481490373153916 learn rate: 1.5625e-05 iteration: 19735
[[ 1.99963519]
 [ 4.00914575]
 [-1.07592324]] loss fxn value:  0.14810788872197847 learn rate: 1.5625e-05 iteration: 19736
[[ 1.99963523]
 [ 4.00914576]
 [-1.07592555]] loss fxn value:  0.148066751557378 learn rate: 1.5625e-05 iteration: 19737
[[ 1.99963527]
 [ 4.00914578]
 [-1.07592787]] loss fxn value:  0.14802562581886908 learn rate: 1.5625e-05 iteration: 19738
[[ 1.99963531]
 [ 4.00914579]
 [-1.07593018]] loss fxn value:  0.14798451150377376 learn rate: 1.5625e-05 iteration: 19739
[[ 1.99963534]
 [ 4.0091458 ]
 [-1.07593249]] loss fxn value:  0.14794340860695712 learn rate: 1.5625e-05 iteration: 19740
[[ 1.99963538]
 [ 4.00914581]
 [-1.0759348 ]] loss fxn value:  0.14790231712679333 learn rate: 1.5625e-05 iteration: 19741
[[ 1.99963542]
 [ 4.00914582]
 [-1.07593711]] loss fxn value:  0.14786123705949994 learn rate: 1.5625e-05 iteration: 19742
[[ 1.99963546]
 [ 4.00914583]
 [-1.07593942]] loss fxn value:  0.1478201684038363 learn rate: 1.5625e-05 iteration: 19743
[[ 1.9996355 ]
 [ 4.00914585]
 [-1.07594173]] loss fxn value:  0.14777911115372266 learn rate: 1.5625e-05 iteration: 19744
[[ 1.99963554]
 [ 4.00914586]
 [-1.07594404]] loss fxn value:  0.1477380653079524 learn rate: 1.5625e-05 iteration: 19745
[[ 1.99963558]
 [ 4.00914587]
 [-1.07594635]] loss fxn value:  0.14769703086232155 learn rate: 1.5625e-05 iteration: 19746
[[ 1.99963561]
 [ 4.00914588]
 [-1.07594866]] loss fxn value:  0.14765600781464924 learn rate: 1.5625e-05 iteration: 19747
[[ 1.99963565]
 [ 4.00914589]
 [-1.07595096]] loss fxn value:  0.14761499615981297 learn rate: 1.5625e-05 iteration: 19748
[[ 1.99963569]
 [ 4.0091459 ]
 [-1.07595327]] loss fxn value:  0.14757399589799086 learn rate: 1.5625e-05 iteration: 19749
[[ 1.99963573]
 [ 4.00914592]
 [-1.07595557]] loss fxn value:  0.14753300702261304 learn rate: 1.5625e-05 iteration: 19750
[[ 1.99963577]
 [ 4.00914593]
 [-1.07595788]] loss fxn value:  0.14749202953251758 learn rate: 1.5625e-05 iteration: 19751
[[ 1.99963581]
 [ 4.00914594]
 [-1.07596018]] loss fxn value:  0.14745106342344344 learn rate: 1.5625e-05 iteration: 19752
[[ 1.99963585]
 [ 4.00914595]
 [-1.07596249]] loss fxn value:  0.1474101086927435 learn rate: 1.5625e-05 iteration: 19753
[[ 1.99963588]
 [ 4.00914596]
 [-1.07596479]] loss fxn value:  0.14736916533817532 learn rate: 1.5625e-05 iteration: 19754
[[ 1.99963592]
 [ 4.00914597]
 [-1.07596709]] loss fxn value:  0.14732823335510867 learn rate: 1.5625e-05 iteration: 19755
[[ 1.99963596]
 [ 4.00914599]
 [-1.07596939]] loss fxn value:  0.1472873127408303 learn rate: 1.5625e-05 iteration: 19756
[[ 1.999636 ]
 [ 4.009146 ]
 [-1.0759717]] loss fxn value:  0.14724640349223064 learn rate: 1.5625e-05 iteration: 19757
[[ 1.99963604]
 [ 4.00914601]
 [-1.075974  ]] loss fxn value:  0.14720550560697 learn rate: 1.5625e-05 iteration: 19758
[[ 1.99963608]
 [ 4.00914602]
 [-1.0759763 ]] loss fxn value:  0.14716461908053471 learn rate: 1.5625e-05 iteration: 19759
[[ 1.99963611]
 [ 4.00914603]
 [-1.07597859]] loss fxn value:  0.14712374391013275 learn rate: 1.5625e-05 iteration: 19760
[[ 1.99963615]
 [ 4.00914604]
 [-1.07598089]] loss fxn value:  0.1470828800936095 learn rate: 1.5625e-05 iteration: 19761
[[ 1.99963619]
 [ 4.00914606]
 [-1.07598319]] loss fxn value:  0.14704202762670623 learn rate: 1.5625e-05 iteration: 19762
[[ 1.99963623]
 [ 4.00914607]
 [-1.07598549]] loss fxn value:  0.14700118650595212 learn rate: 1.5625e-05 iteration: 19763
[[ 1.99963627]
 [ 4.00914608]
 [-1.07598778]] loss fxn value:  0.14696035672989521 learn rate: 1.5625e-05 iteration: 19764
[[ 1.99963631]
 [ 4.00914609]
 [-1.07599008]] loss fxn value:  0.14691953829451204 learn rate: 1.5625e-05 iteration: 19765
[[ 1.99963634]
 [ 4.0091461 ]
 [-1.07599238]] loss fxn value:  0.14687873119552308 learn rate: 1.5625e-05 iteration: 19766
[[ 1.99963638]
 [ 4.00914611]
 [-1.07599467]] loss fxn value:  0.14683793543095422 learn rate: 1.5625e-05 iteration: 19767
[[ 1.99963642]
 [ 4.00914613]
 [-1.07599696]] loss fxn value:  0.1467971509977758 learn rate: 1.5625e-05 iteration: 19768
[[ 1.99963646]
 [ 4.00914614]
 [-1.07599926]] loss fxn value:  0.14675637789213097 learn rate: 1.5625e-05 iteration: 19769
[[ 1.9996365 ]
 [ 4.00914615]
 [-1.07600155]] loss fxn value:  0.14671561611252454 learn rate: 1.5625e-05 iteration: 19770
[[ 1.99963654]
 [ 4.00914616]
 [-1.07600384]] loss fxn value:  0.14667486565348423 learn rate: 1.5625e-05 iteration: 19771
[[ 1.99963657]
 [ 4.00914617]
 [-1.07600613]] loss fxn value:  0.14663412651192673 learn rate: 1.5625e-05 iteration: 19772
[[ 1.99963661]
 [ 4.00914618]
 [-1.07600842]] loss fxn value:  0.14659339868832144 learn rate: 1.5625e-05 iteration: 19773
[[ 1.99963665]
 [ 4.0091462 ]
 [-1.07601071]] loss fxn value:  0.1465526821747128 learn rate: 1.5625e-05 iteration: 19774
[[ 1.99963669]
 [ 4.00914621]
 [-1.076013  ]] loss fxn value:  0.14651197697139312 learn rate: 1.5625e-05 iteration: 19775
[[ 1.99963673]
 [ 4.00914622]
 [-1.07601529]] loss fxn value:  0.1464712830731612 learn rate: 1.5625e-05 iteration: 19776
[[ 1.99963676]
 [ 4.00914623]
 [-1.07601758]] loss fxn value:  0.14643060047831016 learn rate: 1.5625e-05 iteration: 19777
[[ 1.9996368 ]
 [ 4.00914624]
 [-1.07601987]] loss fxn value:  0.1463899291831432 learn rate: 1.5625e-05 iteration: 19778
[[ 1.99963684]
 [ 4.00914625]
 [-1.07602216]] loss fxn value:  0.1463492691839943 learn rate: 1.5625e-05 iteration: 19779
[[ 1.99963688]
 [ 4.00914627]
 [-1.07602444]] loss fxn value:  0.1463086204787066 learn rate: 1.5625e-05 iteration: 19780
[[ 1.99963692]
 [ 4.00914628]
 [-1.07602673]] loss fxn value:  0.14626798306352617 learn rate: 1.5625e-05 iteration: 19781
[[ 1.99963696]
 [ 4.00914629]
 [-1.07602901]] loss fxn value:  0.14622735693530112 learn rate: 1.5625e-05 iteration: 19782
[[ 1.99963699]
 [ 4.0091463 ]
 [-1.0760313 ]] loss fxn value:  0.14618674209090582 learn rate: 1.5625e-05 iteration: 19783
[[ 1.99963703]
 [ 4.00914631]
 [-1.07603358]] loss fxn value:  0.14614613852748873 learn rate: 1.5625e-05 iteration: 19784
[[ 1.99963707]
 [ 4.00914632]
 [-1.07603586]] loss fxn value:  0.14610554624159758 learn rate: 1.5625e-05 iteration: 19785
[[ 1.99963711]
 [ 4.00914634]
 [-1.07603815]] loss fxn value:  0.14606496523078308 learn rate: 1.5625e-05 iteration: 19786
[[ 1.99963715]
 [ 4.00914635]
 [-1.07604043]] loss fxn value:  0.1460243954910342 learn rate: 1.5625e-05 iteration: 19787
[[ 1.99963718]
 [ 4.00914636]
 [-1.07604271]] loss fxn value:  0.14598383701959422 learn rate: 1.5625e-05 iteration: 19788
[[ 1.99963722]
 [ 4.00914637]
 [-1.07604499]] loss fxn value:  0.14594328981286356 learn rate: 1.5625e-05 iteration: 19789
[[ 1.99963726]
 [ 4.00914638]
 [-1.07604727]] loss fxn value:  0.14590275386994986 learn rate: 1.5625e-05 iteration: 19790
[[ 1.9996373 ]
 [ 4.00914639]
 [-1.07604955]] loss fxn value:  0.14586222918386862 learn rate: 1.5625e-05 iteration: 19791
[[ 1.99963734]
 [ 4.0091464 ]
 [-1.07605183]] loss fxn value:  0.14582171575396505 learn rate: 1.5625e-05 iteration: 19792
[[ 1.99963737]
 [ 4.00914642]
 [-1.07605411]] loss fxn value:  0.14578121357730664 learn rate: 1.5625e-05 iteration: 19793
[[ 1.99963741]
 [ 4.00914643]
 [-1.07605638]] loss fxn value:  0.14574072264996019 learn rate: 1.5625e-05 iteration: 19794
[[ 1.99963745]
 [ 4.00914644]
 [-1.07605866]] loss fxn value:  0.14570024297039358 learn rate: 1.5625e-05 iteration: 19795
[[ 1.99963749]
 [ 4.00914645]
 [-1.07606094]] loss fxn value:  0.1456597745313812 learn rate: 1.5625e-05 iteration: 19796
[[ 1.99963753]
 [ 4.00914646]
 [-1.07606321]] loss fxn value:  0.1456193173349085 learn rate: 1.5625e-05 iteration: 19797
[[ 1.99963756]
 [ 4.00914647]
 [-1.07606549]] loss fxn value:  0.14557887137385594 learn rate: 1.5625e-05 iteration: 19798
[[ 1.9996376 ]
 [ 4.00914649]
 [-1.07606776]] loss fxn value:  0.1455384366471966 learn rate: 1.5625e-05 iteration: 19799
[[ 1.99963764]
 [ 4.0091465 ]
 [-1.07607004]] loss fxn value:  0.14549801315192243 learn rate: 1.5625e-05 iteration: 19800
[[ 1.99963768]
 [ 4.00914651]
 [-1.07607231]] loss fxn value:  0.14545760088365012 learn rate: 1.5625e-05 iteration: 19801
[[ 1.99963772]
 [ 4.00914652]
 [-1.07607458]] loss fxn value:  0.14541719984000911 learn rate: 1.5625e-05 iteration: 19802
[[ 1.99963775]
 [ 4.00914653]
 [-1.07607685]] loss fxn value:  0.14537681001835465 learn rate: 1.5625e-05 iteration: 19803
[[ 1.99963779]
 [ 4.00914654]
 [-1.07607913]] loss fxn value:  0.14533643141448513 learn rate: 1.5625e-05 iteration: 19804
[[ 1.99963783]
 [ 4.00914655]
 [-1.0760814 ]] loss fxn value:  0.14529606402584597 learn rate: 1.5625e-05 iteration: 19805
[[ 1.99963787]
 [ 4.00914657]
 [-1.07608367]] loss fxn value:  0.14525570784950012 learn rate: 1.5625e-05 iteration: 19806
[[ 1.99963791]
 [ 4.00914658]
 [-1.07608593]] loss fxn value:  0.1452153628824476 learn rate: 1.5625e-05 iteration: 19807
[[ 1.99963794]
 [ 4.00914659]
 [-1.0760882 ]] loss fxn value:  0.1451750291204444 learn rate: 1.5625e-05 iteration: 19808
[[ 1.99963798]
 [ 4.0091466 ]
 [-1.07609047]] loss fxn value:  0.1451347065622784 learn rate: 1.5625e-05 iteration: 19809
[[ 1.99963802]
 [ 4.00914661]
 [-1.07609274]] loss fxn value:  0.14509439520279155 learn rate: 1.5625e-05 iteration: 19810
[[ 1.99963806]
 [ 4.00914662]
 [-1.07609501]] loss fxn value:  0.14505409504074326 learn rate: 1.5625e-05 iteration: 19811
[[ 1.99963809]
 [ 4.00914664]
 [-1.07609727]] loss fxn value:  0.1450138060715343 learn rate: 1.5625e-05 iteration: 19812
[[ 1.99963813]
 [ 4.00914665]
 [-1.07609954]] loss fxn value:  0.14497352829242502 learn rate: 1.5625e-05 iteration: 19813
[[ 1.99963817]
 [ 4.00914666]
 [-1.0761018 ]] loss fxn value:  0.14493326170026583 learn rate: 1.5625e-05 iteration: 19814
[[ 1.99963821]
 [ 4.00914667]
 [-1.07610407]] loss fxn value:  0.14489300629369503 learn rate: 1.5625e-05 iteration: 19815
[[ 1.99963825]
 [ 4.00914668]
 [-1.07610633]] loss fxn value:  0.14485276206671382 learn rate: 1.5625e-05 iteration: 19816
[[ 1.99963828]
 [ 4.00914669]
 [-1.07610859]] loss fxn value:  0.1448125290181318 learn rate: 1.5625e-05 iteration: 19817
[[ 1.99963832]
 [ 4.0091467 ]
 [-1.07611086]] loss fxn value:  0.14477230714410247 learn rate: 1.5625e-05 iteration: 19818
[[ 1.99963836]
 [ 4.00914672]
 [-1.07611312]] loss fxn value:  0.1447320964415711 learn rate: 1.5625e-05 iteration: 19819
[[ 1.9996384 ]
 [ 4.00914673]
 [-1.07611538]] loss fxn value:  0.1446918969087977 learn rate: 1.5625e-05 iteration: 19820
[[ 1.99963843]
 [ 4.00914674]
 [-1.07611764]] loss fxn value:  0.14465170853961223 learn rate: 1.5625e-05 iteration: 19821
[[ 1.99963847]
 [ 4.00914675]
 [-1.0761199 ]] loss fxn value:  0.14461153133476176 learn rate: 1.5625e-05 iteration: 19822
[[ 1.99963851]
 [ 4.00914676]
 [-1.07612216]] loss fxn value:  0.14457136528764086 learn rate: 1.5625e-05 iteration: 19823
[[ 1.99963855]
 [ 4.00914677]
 [-1.07612442]] loss fxn value:  0.14453121039794686 learn rate: 1.5625e-05 iteration: 19824
[[ 1.99963858]
 [ 4.00914678]
 [-1.07612667]] loss fxn value:  0.14449106666019274 learn rate: 1.5625e-05 iteration: 19825
[[ 1.99963862]
 [ 4.0091468 ]
 [-1.07612893]] loss fxn value:  0.1444509340724672 learn rate: 1.5625e-05 iteration: 19826
[[ 1.99963866]
 [ 4.00914681]
 [-1.07613119]] loss fxn value:  0.14441081263223426 learn rate: 1.5625e-05 iteration: 19827
[[ 1.9996387 ]
 [ 4.00914682]
 [-1.07613344]] loss fxn value:  0.14437070233608365 learn rate: 1.5625e-05 iteration: 19828
[[ 1.99963874]
 [ 4.00914683]
 [-1.0761357 ]] loss fxn value:  0.14433060318008675 learn rate: 1.5625e-05 iteration: 19829
[[ 1.99963877]
 [ 4.00914684]
 [-1.07613795]] loss fxn value:  0.1442905151614492 learn rate: 1.5625e-05 iteration: 19830
[[ 1.99963881]
 [ 4.00914685]
 [-1.07614021]] loss fxn value:  0.14425043827747375 learn rate: 1.5625e-05 iteration: 19831
[[ 1.99963885]
 [ 4.00914686]
 [-1.07614246]] loss fxn value:  0.14421037252585384 learn rate: 1.5625e-05 iteration: 19832
[[ 1.99963889]
 [ 4.00914688]
 [-1.07614472]] loss fxn value:  0.14417031790159726 learn rate: 1.5625e-05 iteration: 19833
[[ 1.99963892]
 [ 4.00914689]
 [-1.07614697]] loss fxn value:  0.1441302744029046 learn rate: 1.5625e-05 iteration: 19834
[[ 1.99963896]
 [ 4.0091469 ]
 [-1.07614922]] loss fxn value:  0.1440902420256267 learn rate: 1.5625e-05 iteration: 19835
[[ 1.999639  ]
 [ 4.00914691]
 [-1.07615147]] loss fxn value:  0.14405022076803736 learn rate: 1.5625e-05 iteration: 19836
[[ 1.99963904]
 [ 4.00914692]
 [-1.07615372]] loss fxn value:  0.14401021062553276 learn rate: 1.5625e-05 iteration: 19837
[[ 1.99963907]
 [ 4.00914693]
 [-1.07615597]] loss fxn value:  0.14397021159722048 learn rate: 1.5625e-05 iteration: 19838
[[ 1.99963911]
 [ 4.00914694]
 [-1.07615822]] loss fxn value:  0.14393022367802505 learn rate: 1.5625e-05 iteration: 19839
[[ 1.99963915]
 [ 4.00914696]
 [-1.07616047]] loss fxn value:  0.14389024686581342 learn rate: 1.5625e-05 iteration: 19840
[[ 1.99963919]
 [ 4.00914697]
 [-1.07616272]] loss fxn value:  0.14385028115725554 learn rate: 1.5625e-05 iteration: 19841
[[ 1.99963922]
 [ 4.00914698]
 [-1.07616496]] loss fxn value:  0.143810326548859 learn rate: 1.5625e-05 iteration: 19842
[[ 1.99963926]
 [ 4.00914699]
 [-1.07616721]] loss fxn value:  0.1437703830382123 learn rate: 1.5625e-05 iteration: 19843
[[ 1.9996393 ]
 [ 4.009147  ]
 [-1.07616946]] loss fxn value:  0.14373045062084508 learn rate: 1.5625e-05 iteration: 19844
[[ 1.99963934]
 [ 4.00914701]
 [-1.0761717 ]] loss fxn value:  0.14369052929727832 learn rate: 1.5625e-05 iteration: 19845
[[ 1.99963937]
 [ 4.00914702]
 [-1.07617395]] loss fxn value:  0.14365061905954724 learn rate: 1.5625e-05 iteration: 19846
[[ 1.99963941]
 [ 4.00914704]
 [-1.07617619]] loss fxn value:  0.14361071990748717 learn rate: 1.5625e-05 iteration: 19847
[[ 1.99963945]
 [ 4.00914705]
 [-1.07617843]] loss fxn value:  0.14357083183773722 learn rate: 1.5625e-05 iteration: 19848
[[ 1.99963949]
 [ 4.00914706]
 [-1.07618068]] loss fxn value:  0.14353095484760478 learn rate: 1.5625e-05 iteration: 19849
[[ 1.99963952]
 [ 4.00914707]
 [-1.07618292]] loss fxn value:  0.1434910889325716 learn rate: 1.5625e-05 iteration: 19850
[[ 1.99963956]
 [ 4.00914708]
 [-1.07618516]] loss fxn value:  0.14345123409027172 learn rate: 1.5625e-05 iteration: 19851
[[ 1.9996396 ]
 [ 4.00914709]
 [-1.0761874 ]] loss fxn value:  0.14341139031815991 learn rate: 1.5625e-05 iteration: 19852
[[ 1.99963964]
 [ 4.0091471 ]
 [-1.07618964]] loss fxn value:  0.14337155761193499 learn rate: 1.5625e-05 iteration: 19853
[[ 1.99963967]
 [ 4.00914712]
 [-1.07619188]] loss fxn value:  0.14333173596994495 learn rate: 1.5625e-05 iteration: 19854
[[ 1.99963971]
 [ 4.00914713]
 [-1.07619412]] loss fxn value:  0.14329192538844734 learn rate: 1.5625e-05 iteration: 19855
[[ 1.99963975]
 [ 4.00914714]
 [-1.07619636]] loss fxn value:  0.1432521258642834 learn rate: 1.5625e-05 iteration: 19856
[[ 1.99963978]
 [ 4.00914715]
 [-1.0761986 ]] loss fxn value:  0.14321233739478675 learn rate: 1.5625e-05 iteration: 19857
[[ 1.99963982]
 [ 4.00914716]
 [-1.07620084]] loss fxn value:  0.14317255997572026 learn rate: 1.5625e-05 iteration: 19858
[[ 1.99963986]
 [ 4.00914717]
 [-1.07620307]] loss fxn value:  0.14313279360500802 learn rate: 1.5625e-05 iteration: 19859
[[ 1.9996399 ]
 [ 4.00914718]
 [-1.07620531]] loss fxn value:  0.14309303828068862 learn rate: 1.5625e-05 iteration: 19860
[[ 1.99963993]
 [ 4.0091472 ]
 [-1.07620754]] loss fxn value:  0.14305329399779607 learn rate: 1.5625e-05 iteration: 19861
[[ 1.99963997]
 [ 4.00914721]
 [-1.07620978]] loss fxn value:  0.14301356075407395 learn rate: 1.5625e-05 iteration: 19862
[[ 1.99964001]
 [ 4.00914722]
 [-1.07621201]] loss fxn value:  0.1429738385453515 learn rate: 1.5625e-05 iteration: 19863
[[ 1.99964005]
 [ 4.00914723]
 [-1.07621425]] loss fxn value:  0.14293412737043823 learn rate: 1.5625e-05 iteration: 19864
[[ 1.99964008]
 [ 4.00914724]
 [-1.07621648]] loss fxn value:  0.14289442722458293 learn rate: 1.5625e-05 iteration: 19865
[[ 1.99964012]
 [ 4.00914725]
 [-1.07621871]] loss fxn value:  0.14285473810662366 learn rate: 1.5625e-05 iteration: 19866
[[ 1.99964016]
 [ 4.00914726]
 [-1.07622094]] loss fxn value:  0.14281506001177838 learn rate: 1.5625e-05 iteration: 19867
[[ 1.9996402 ]
 [ 4.00914727]
 [-1.07622318]] loss fxn value:  0.1427753929375281 learn rate: 1.5625e-05 iteration: 19868
[[ 1.99964023]
 [ 4.00914729]
 [-1.07622541]] loss fxn value:  0.14273573688059518 learn rate: 1.5625e-05 iteration: 19869
[[ 1.99964027]
 [ 4.0091473 ]
 [-1.07622764]] loss fxn value:  0.14269609183871312 learn rate: 1.5625e-05 iteration: 19870
[[ 1.99964031]
 [ 4.00914731]
 [-1.07622986]] loss fxn value:  0.14265645780873237 learn rate: 1.5625e-05 iteration: 19871
[[ 1.99964034]
 [ 4.00914732]
 [-1.07623209]] loss fxn value:  0.14261683478554738 learn rate: 1.5625e-05 iteration: 19872
[[ 1.99964038]
 [ 4.00914733]
 [-1.07623432]] loss fxn value:  0.1425772227688623 learn rate: 1.5625e-05 iteration: 19873
[[ 1.99964042]
 [ 4.00914734]
 [-1.07623655]] loss fxn value:  0.14253762175449947 learn rate: 1.5625e-05 iteration: 19874
[[ 1.99964046]
 [ 4.00914735]
 [-1.07623878]] loss fxn value:  0.14249803173921435 learn rate: 1.5625e-05 iteration: 19875
[[ 1.99964049]
 [ 4.00914736]
 [-1.076241  ]] loss fxn value:  0.14245845271999552 learn rate: 1.5625e-05 iteration: 19876
[[ 1.99964053]
 [ 4.00914738]
 [-1.07624323]] loss fxn value:  0.14241888469391278 learn rate: 1.5625e-05 iteration: 19877
[[ 1.99964057]
 [ 4.00914739]
 [-1.07624545]] loss fxn value:  0.1423793276579215 learn rate: 1.5625e-05 iteration: 19878
[[ 1.9996406 ]
 [ 4.0091474 ]
 [-1.07624768]] loss fxn value:  0.14233978160922411 learn rate: 1.5625e-05 iteration: 19879
[[ 1.99964064]
 [ 4.00914741]
 [-1.0762499 ]] loss fxn value:  0.1423002465437694 learn rate: 1.5625e-05 iteration: 19880
[[ 1.99964068]
 [ 4.00914742]
 [-1.07625212]] loss fxn value:  0.14226072246023813 learn rate: 1.5625e-05 iteration: 19881
[[ 1.99964072]
 [ 4.00914743]
 [-1.07625435]] loss fxn value:  0.1422212093539269 learn rate: 1.5625e-05 iteration: 19882
[[ 1.99964075]
 [ 4.00914744]
 [-1.07625657]] loss fxn value:  0.14218170722273818 learn rate: 1.5625e-05 iteration: 19883
[[ 1.99964079]
 [ 4.00914746]
 [-1.07625879]] loss fxn value:  0.14214221606288263 learn rate: 1.5625e-05 iteration: 19884
[[ 1.99964083]
 [ 4.00914747]
 [-1.07626101]] loss fxn value:  0.14210273587179564 learn rate: 1.5625e-05 iteration: 19885
[[ 1.99964086]
 [ 4.00914748]
 [-1.07626323]] loss fxn value:  0.14206326664704036 learn rate: 1.5625e-05 iteration: 19886
[[ 1.9996409 ]
 [ 4.00914749]
 [-1.07626545]] loss fxn value:  0.14202380838371018 learn rate: 1.5625e-05 iteration: 19887
[[ 1.99964094]
 [ 4.0091475 ]
 [-1.07626767]] loss fxn value:  0.14198436108138585 learn rate: 1.5625e-05 iteration: 19888
[[ 1.99964097]
 [ 4.00914751]
 [-1.07626989]] loss fxn value:  0.14194492473490478 learn rate: 1.5625e-05 iteration: 19889
[[ 1.99964101]
 [ 4.00914752]
 [-1.0762721 ]] loss fxn value:  0.14190549934215244 learn rate: 1.5625e-05 iteration: 19890
[[ 1.99964105]
 [ 4.00914753]
 [-1.07627432]] loss fxn value:  0.14186608489945823 learn rate: 1.5625e-05 iteration: 19891
[[ 1.99964109]
 [ 4.00914755]
 [-1.07627654]] loss fxn value:  0.1418266814040278 learn rate: 1.5625e-05 iteration: 19892
[[ 1.99964112]
 [ 4.00914756]
 [-1.07627875]] loss fxn value:  0.14178728885366093 learn rate: 1.5625e-05 iteration: 19893
[[ 1.99964116]
 [ 4.00914757]
 [-1.07628097]] loss fxn value:  0.14174790724422554 learn rate: 1.5625e-05 iteration: 19894
[[ 1.9996412 ]
 [ 4.00914758]
 [-1.07628318]] loss fxn value:  0.14170853657299573 learn rate: 1.5625e-05 iteration: 19895
[[ 1.99964123]
 [ 4.00914759]
 [-1.0762854 ]] loss fxn value:  0.1416691768377291 learn rate: 1.5625e-05 iteration: 19896
[[ 1.99964127]
 [ 4.0091476 ]
 [-1.07628761]] loss fxn value:  0.14162982803387875 learn rate: 1.5625e-05 iteration: 19897
[[ 1.99964131]
 [ 4.00914761]
 [-1.07628982]] loss fxn value:  0.14159049015904798 learn rate: 1.5625e-05 iteration: 19898
[[ 1.99964134]
 [ 4.00914762]
 [-1.07629203]] loss fxn value:  0.14155116321163397 learn rate: 1.5625e-05 iteration: 19899
[[ 1.99964138]
 [ 4.00914764]
 [-1.07629425]] loss fxn value:  0.14151184718599552 learn rate: 1.5625e-05 iteration: 19900
[[ 1.99964142]
 [ 4.00914765]
 [-1.07629646]] loss fxn value:  0.14147254208040874 learn rate: 1.5625e-05 iteration: 19901
[[ 1.99964145]
 [ 4.00914766]
 [-1.07629867]] loss fxn value:  0.14143324789301717 learn rate: 1.5625e-05 iteration: 19902
[[ 1.99964149]
 [ 4.00914767]
 [-1.07630088]] loss fxn value:  0.14139396461885478 learn rate: 1.5625e-05 iteration: 19903
[[ 1.99964153]
 [ 4.00914768]
 [-1.07630309]] loss fxn value:  0.14135469225556027 learn rate: 1.5625e-05 iteration: 19904
[[ 1.99964157]
 [ 4.00914769]
 [-1.07630529]] loss fxn value:  0.14131543080106237 learn rate: 1.5625e-05 iteration: 19905
[[ 1.9996416]
 [ 4.0091477]
 [-1.0763075]] loss fxn value:  0.14127618025049338 learn rate: 1.5625e-05 iteration: 19906
[[ 1.99964164]
 [ 4.00914771]
 [-1.07630971]] loss fxn value:  0.14123694060238634 learn rate: 1.5625e-05 iteration: 19907
[[ 1.99964168]
 [ 4.00914772]
 [-1.07631191]] loss fxn value:  0.1411977118523522 learn rate: 1.5625e-05 iteration: 19908
[[ 1.99964171]
 [ 4.00914774]
 [-1.07631412]] loss fxn value:  0.1411584939992359 learn rate: 1.5625e-05 iteration: 19909
[[ 1.99964175]
 [ 4.00914775]
 [-1.07631633]] loss fxn value:  0.14111928703834106 learn rate: 1.5625e-05 iteration: 19910
[[ 1.99964179]
 [ 4.00914776]
 [-1.07631853]] loss fxn value:  0.14108009096751772 learn rate: 1.5625e-05 iteration: 19911
[[ 1.99964182]
 [ 4.00914777]
 [-1.07632073]] loss fxn value:  0.1410409057835499 learn rate: 1.5625e-05 iteration: 19912
[[ 1.99964186]
 [ 4.00914778]
 [-1.07632294]] loss fxn value:  0.14100173148268838 learn rate: 1.5625e-05 iteration: 19913
[[ 1.9996419 ]
 [ 4.00914779]
 [-1.07632514]] loss fxn value:  0.1409625680628264 learn rate: 1.5625e-05 iteration: 19914
[[ 1.99964193]
 [ 4.0091478 ]
 [-1.07632734]] loss fxn value:  0.14092341552112164 learn rate: 1.5625e-05 iteration: 19915
[[ 1.99964197]
 [ 4.00914781]
 [-1.07632954]] loss fxn value:  0.1408842738535392 learn rate: 1.5625e-05 iteration: 19916
[[ 1.99964201]
 [ 4.00914783]
 [-1.07633175]] loss fxn value:  0.14084514305823634 learn rate: 1.5625e-05 iteration: 19917
[[ 1.99964204]
 [ 4.00914784]
 [-1.07633395]] loss fxn value:  0.1408060231311095 learn rate: 1.5625e-05 iteration: 19918
[[ 1.99964208]
 [ 4.00914785]
 [-1.07633615]] loss fxn value:  0.1407669140694444 learn rate: 1.5625e-05 iteration: 19919
[[ 1.99964212]
 [ 4.00914786]
 [-1.07633834]] loss fxn value:  0.14072781587050606 learn rate: 1.5625e-05 iteration: 19920
[[ 1.99964215]
 [ 4.00914787]
 [-1.07634054]] loss fxn value:  0.1406887285306879 learn rate: 1.5625e-05 iteration: 19921
[[ 1.99964219]
 [ 4.00914788]
 [-1.07634274]] loss fxn value:  0.14064965204768343 learn rate: 1.5625e-05 iteration: 19922
[[ 1.99964223]
 [ 4.00914789]
 [-1.07634494]] loss fxn value:  0.1406105864192546 learn rate: 1.5625e-05 iteration: 19923
[[ 1.99964226]
 [ 4.0091479 ]
 [-1.07634714]] loss fxn value:  0.14057153164034067 learn rate: 1.5625e-05 iteration: 19924
[[ 1.9996423 ]
 [ 4.00914791]
 [-1.07634933]] loss fxn value:  0.14053248770868984 learn rate: 1.5625e-05 iteration: 19925
[[ 1.99964234]
 [ 4.00914793]
 [-1.07635153]] loss fxn value:  0.14049345462299978 learn rate: 1.5625e-05 iteration: 19926
[[ 1.99964237]
 [ 4.00914794]
 [-1.07635372]] loss fxn value:  0.14045443237772867 learn rate: 1.5625e-05 iteration: 19927
[[ 1.99964241]
 [ 4.00914795]
 [-1.07635592]] loss fxn value:  0.1404154209706078 learn rate: 1.5625e-05 iteration: 19928
[[ 1.99964245]
 [ 4.00914796]
 [-1.07635811]] loss fxn value:  0.14037642039895462 learn rate: 1.5625e-05 iteration: 19929
[[ 1.99964248]
 [ 4.00914797]
 [-1.0763603 ]] loss fxn value:  0.14033743066057128 learn rate: 1.5625e-05 iteration: 19930
[[ 1.99964252]
 [ 4.00914798]
 [-1.0763625 ]] loss fxn value:  0.14029845175208996 learn rate: 1.5625e-05 iteration: 19931
[[ 1.99964256]
 [ 4.00914799]
 [-1.07636469]] loss fxn value:  0.14025948366813548 learn rate: 1.5625e-05 iteration: 19932
[[ 1.99964259]
 [ 4.009148  ]
 [-1.07636688]] loss fxn value:  0.1402205264087742 learn rate: 1.5625e-05 iteration: 19933
[[ 1.99964263]
 [ 4.00914801]
 [-1.07636907]] loss fxn value:  0.1401815799707686 learn rate: 1.5625e-05 iteration: 19934
[[ 1.99964267]
 [ 4.00914803]
 [-1.07637126]] loss fxn value:  0.14014264434910798 learn rate: 1.5625e-05 iteration: 19935
[[ 1.9996427 ]
 [ 4.00914804]
 [-1.07637345]] loss fxn value:  0.14010371954146414 learn rate: 1.5625e-05 iteration: 19936
[[ 1.99964274]
 [ 4.00914805]
 [-1.07637564]] loss fxn value:  0.14006480554619657 learn rate: 1.5625e-05 iteration: 19937
[[ 1.99964278]
 [ 4.00914806]
 [-1.07637783]] loss fxn value:  0.1400259023580994 learn rate: 1.5625e-05 iteration: 19938
[[ 1.99964281]
 [ 4.00914807]
 [-1.07638001]] loss fxn value:  0.1399870099768915 learn rate: 1.5625e-05 iteration: 19939
[[ 1.99964285]
 [ 4.00914808]
 [-1.0763822 ]] loss fxn value:  0.1399481283964816 learn rate: 1.5625e-05 iteration: 19940
[[ 1.99964288]
 [ 4.00914809]
 [-1.07638439]] loss fxn value:  0.13990925761659778 learn rate: 1.5625e-05 iteration: 19941
[[ 1.99964292]
 [ 4.0091481 ]
 [-1.07638657]] loss fxn value:  0.13987039763302225 learn rate: 1.5625e-05 iteration: 19942
[[ 1.99964296]
 [ 4.00914811]
 [-1.07638876]] loss fxn value:  0.1398315484430739 learn rate: 1.5625e-05 iteration: 19943
[[ 1.99964299]
 [ 4.00914813]
 [-1.07639094]] loss fxn value:  0.13979271004312085 learn rate: 1.5625e-05 iteration: 19944
[[ 1.99964303]
 [ 4.00914814]
 [-1.07639313]] loss fxn value:  0.13975388243081327 learn rate: 1.5625e-05 iteration: 19945
[[ 1.99964307]
 [ 4.00914815]
 [-1.07639531]] loss fxn value:  0.13971506560272043 learn rate: 1.5625e-05 iteration: 19946
[[ 1.9996431 ]
 [ 4.00914816]
 [-1.07639749]] loss fxn value:  0.1396762595552724 learn rate: 1.5625e-05 iteration: 19947
[[ 1.99964314]
 [ 4.00914817]
 [-1.07639967]] loss fxn value:  0.13963746428809437 learn rate: 1.5625e-05 iteration: 19948
[[ 1.99964318]
 [ 4.00914818]
 [-1.07640186]] loss fxn value:  0.1395986797947741 learn rate: 1.5625e-05 iteration: 19949
[[ 1.99964321]
 [ 4.00914819]
 [-1.07640404]] loss fxn value:  0.13955990607469465 learn rate: 1.5625e-05 iteration: 19950
[[ 1.99964325]
 [ 4.0091482 ]
 [-1.07640622]] loss fxn value:  0.13952114312367594 learn rate: 1.5625e-05 iteration: 19951
[[ 1.99964329]
 [ 4.00914821]
 [-1.0764084 ]] loss fxn value:  0.13948239093990158 learn rate: 1.5625e-05 iteration: 19952
[[ 1.99964332]
 [ 4.00914823]
 [-1.07641058]] loss fxn value:  0.13944364951875843 learn rate: 1.5625e-05 iteration: 19953
[[ 1.99964336]
 [ 4.00914824]
 [-1.07641275]] loss fxn value:  0.13940491885815598 learn rate: 1.5625e-05 iteration: 19954
[[ 1.99964339]
 [ 4.00914825]
 [-1.07641493]] loss fxn value:  0.13936619895568494 learn rate: 1.5625e-05 iteration: 19955
[[ 1.99964343]
 [ 4.00914826]
 [-1.07641711]] loss fxn value:  0.1393274898076872 learn rate: 1.5625e-05 iteration: 19956
[[ 1.99964347]
 [ 4.00914827]
 [-1.07641929]] loss fxn value:  0.13928879140959202 learn rate: 1.5625e-05 iteration: 19957
[[ 1.9996435 ]
 [ 4.00914828]
 [-1.07642146]] loss fxn value:  0.1392501037621248 learn rate: 1.5625e-05 iteration: 19958
[[ 1.99964354]
 [ 4.00914829]
 [-1.07642364]] loss fxn value:  0.139211426858502 learn rate: 1.5625e-05 iteration: 19959
[[ 1.99964358]
 [ 4.0091483 ]
 [-1.07642581]] loss fxn value:  0.1391727606986299 learn rate: 1.5625e-05 iteration: 19960
[[ 1.99964361]
 [ 4.00914831]
 [-1.07642799]] loss fxn value:  0.13913410527775502 learn rate: 1.5625e-05 iteration: 19961
[[ 1.99964365]
 [ 4.00914833]
 [-1.07643016]] loss fxn value:  0.13909546059316397 learn rate: 1.5625e-05 iteration: 19962
[[ 1.99964368]
 [ 4.00914834]
 [-1.07643233]] loss fxn value:  0.1390568266436562 learn rate: 1.5625e-05 iteration: 19963
[[ 1.99964372]
 [ 4.00914835]
 [-1.07643451]] loss fxn value:  0.13901820342308102 learn rate: 1.5625e-05 iteration: 19964
[[ 1.99964376]
 [ 4.00914836]
 [-1.07643668]] loss fxn value:  0.13897959093212375 learn rate: 1.5625e-05 iteration: 19965
[[ 1.99964379]
 [ 4.00914837]
 [-1.07643885]] loss fxn value:  0.1389409891641574 learn rate: 1.5625e-05 iteration: 19966
[[ 1.99964383]
 [ 4.00914838]
 [-1.07644102]] loss fxn value:  0.13890239811860042 learn rate: 1.5625e-05 iteration: 19967
[[ 1.99964387]
 [ 4.00914839]
 [-1.07644319]] loss fxn value:  0.13886381779151152 learn rate: 1.5625e-05 iteration: 19968
[[ 1.9996439 ]
 [ 4.0091484 ]
 [-1.07644536]] loss fxn value:  0.13882524817892197 learn rate: 1.5625e-05 iteration: 19969
[[ 1.99964394]
 [ 4.00914841]
 [-1.07644753]] loss fxn value:  0.1387866892814361 learn rate: 1.5625e-05 iteration: 19970
[[ 1.99964397]
 [ 4.00914842]
 [-1.0764497 ]] loss fxn value:  0.13874814109235367 learn rate: 1.5625e-05 iteration: 19971
[[ 1.99964401]
 [ 4.00914844]
 [-1.07645186]] loss fxn value:  0.1387096036101907 learn rate: 1.5625e-05 iteration: 19972
[[ 1.99964405]
 [ 4.00914845]
 [-1.07645403]] loss fxn value:  0.13867107683243624 learn rate: 1.5625e-05 iteration: 19973
[[ 1.99964408]
 [ 4.00914846]
 [-1.0764562 ]] loss fxn value:  0.13863256075465769 learn rate: 1.5625e-05 iteration: 19974
[[ 1.99964412]
 [ 4.00914847]
 [-1.07645836]] loss fxn value:  0.13859405537552644 learn rate: 1.5625e-05 iteration: 19975
[[ 1.99964416]
 [ 4.00914848]
 [-1.07646053]] loss fxn value:  0.138555560690763 learn rate: 1.5625e-05 iteration: 19976
[[ 1.99964419]
 [ 4.00914849]
 [-1.07646269]] loss fxn value:  0.13851707669882402 learn rate: 1.5625e-05 iteration: 19977
[[ 1.99964423]
 [ 4.0091485 ]
 [-1.07646486]] loss fxn value:  0.13847860339440876 learn rate: 1.5625e-05 iteration: 19978
[[ 1.99964426]
 [ 4.00914851]
 [-1.07646702]] loss fxn value:  0.13844014077780953 learn rate: 1.5625e-05 iteration: 19979
[[ 1.9996443 ]
 [ 4.00914852]
 [-1.07646918]] loss fxn value:  0.1384016888428872 learn rate: 1.5625e-05 iteration: 19980
[[ 1.99964434]
 [ 4.00914853]
 [-1.07647134]] loss fxn value:  0.13836324758842047 learn rate: 1.5625e-05 iteration: 19981
[[ 1.99964437]
 [ 4.00914854]
 [-1.07647351]] loss fxn value:  0.1383248170111078 learn rate: 1.5625e-05 iteration: 19982
[[ 1.99964441]
 [ 4.00914856]
 [-1.07647567]] loss fxn value:  0.1382863971078829 learn rate: 1.5625e-05 iteration: 19983
[[ 1.99964444]
 [ 4.00914857]
 [-1.07647783]] loss fxn value:  0.1382479878759367 learn rate: 1.5625e-05 iteration: 19984
[[ 1.99964448]
 [ 4.00914858]
 [-1.07647999]] loss fxn value:  0.1382095893116819 learn rate: 1.5625e-05 iteration: 19985
[[ 1.99964452]
 [ 4.00914859]
 [-1.07648215]] loss fxn value:  0.1381712014137306 learn rate: 1.5625e-05 iteration: 19986
[[ 1.99964455]
 [ 4.0091486 ]
 [-1.0764843 ]] loss fxn value:  0.13813282417705508 learn rate: 1.5625e-05 iteration: 19987
[[ 1.99964459]
 [ 4.00914861]
 [-1.07648646]] loss fxn value:  0.13809445760036304 learn rate: 1.5625e-05 iteration: 19988
[[ 1.99964462]
 [ 4.00914862]
 [-1.07648862]] loss fxn value:  0.13805610167942667 learn rate: 1.5625e-05 iteration: 19989
[[ 1.99964466]
 [ 4.00914863]
 [-1.07649078]] loss fxn value:  0.1380177564126694 learn rate: 1.5625e-05 iteration: 19990
[[ 1.9996447 ]
 [ 4.00914864]
 [-1.07649293]] loss fxn value:  0.137979421795669 learn rate: 1.5625e-05 iteration: 19991
[[ 1.99964473]
 [ 4.00914865]
 [-1.07649509]] loss fxn value:  0.13794109782695158 learn rate: 1.5625e-05 iteration: 19992
[[ 1.99964477]
 [ 4.00914867]
 [-1.07649724]] loss fxn value:  0.13790278450262747 learn rate: 1.5625e-05 iteration: 19993
[[ 1.9996448 ]
 [ 4.00914868]
 [-1.0764994 ]] loss fxn value:  0.13786448181956404 learn rate: 1.5625e-05 iteration: 19994
[[ 1.99964484]
 [ 4.00914869]
 [-1.07650155]] loss fxn value:  0.13782618977421413 learn rate: 1.5625e-05 iteration: 19995
[[ 1.99964488]
 [ 4.0091487 ]
 [-1.07650371]] loss fxn value:  0.1377879083656136 learn rate: 1.5625e-05 iteration: 19996
[[ 1.99964491]
 [ 4.00914871]
 [-1.07650586]] loss fxn value:  0.13774963758924194 learn rate: 1.5625e-05 iteration: 19997
[[ 1.99964495]
 [ 4.00914872]
 [-1.07650801]] loss fxn value:  0.1377113774436232 learn rate: 1.5625e-05 iteration: 19998
[[ 1.99964498]
 [ 4.00914873]
 [-1.07651016]] loss fxn value:  0.1376731279234656 learn rate: 1.5625e-05 iteration: 19999
[[ 1.99964502]
 [ 4.00914874]
 [-1.07651231]] loss fxn value:  0.13763488902869275 learn rate: 1.5625e-05 iteration: 20000
[[ 1.99964506]
 [ 4.00914875]
 [-1.07651446]] loss fxn value:  0.13759666075283733 learn rate: 1.5625e-05 iteration: 20001
[[ 1.99964509]
 [ 4.00914876]
 [-1.07651661]] loss fxn value:  0.13755844309705786 learn rate: 1.5625e-05 iteration: 20002
[[ 1.99964513]
 [ 4.00914877]
 [-1.07651876]] loss fxn value:  0.13752023605465183 learn rate: 1.5625e-05 iteration: 20003
[[ 1.99964516]
 [ 4.00914879]
 [-1.07652091]] loss fxn value:  0.13748203962555858 learn rate: 1.5625e-05 iteration: 20004
[[ 1.9996452 ]
 [ 4.0091488 ]
 [-1.07652306]] loss fxn value:  0.1374438538048465 learn rate: 1.5625e-05 iteration: 20005
[[ 1.99964523]
 [ 4.00914881]
 [-1.0765252 ]] loss fxn value:  0.137405678590049 learn rate: 1.5625e-05 iteration: 20006
[[ 1.99964527]
 [ 4.00914882]
 [-1.07652735]] loss fxn value:  0.13736751397831926 learn rate: 1.5625e-05 iteration: 20007
[[ 1.99964531]
 [ 4.00914883]
 [-1.0765295 ]] loss fxn value:  0.13732935996796425 learn rate: 1.5625e-05 iteration: 20008
[[ 1.99964534]
 [ 4.00914884]
 [-1.07653164]] loss fxn value:  0.1372912165537357 learn rate: 1.5625e-05 iteration: 20009
[[ 1.99964538]
 [ 4.00914885]
 [-1.07653379]] loss fxn value:  0.1372530837350613 learn rate: 1.5625e-05 iteration: 20010
[[ 1.99964541]
 [ 4.00914886]
 [-1.07653593]] loss fxn value:  0.1372149615065694 learn rate: 1.5625e-05 iteration: 20011
[[ 1.99964545]
 [ 4.00914887]
 [-1.07653808]] loss fxn value:  0.1371768498677185 learn rate: 1.5625e-05 iteration: 20012
[[ 1.99964548]
 [ 4.00914888]
 [-1.07654022]] loss fxn value:  0.1371387488135963 learn rate: 1.5625e-05 iteration: 20013
[[ 1.99964552]
 [ 4.00914889]
 [-1.07654236]] loss fxn value:  0.1371006583431997 learn rate: 1.5625e-05 iteration: 20014
[[ 1.99964556]
 [ 4.00914891]
 [-1.0765445 ]] loss fxn value:  0.13706257845120634 learn rate: 1.5625e-05 iteration: 20015
[[ 1.99964559]
 [ 4.00914892]
 [-1.07654664]] loss fxn value:  0.1370245091364782 learn rate: 1.5625e-05 iteration: 20016
[[ 1.99964563]
 [ 4.00914893]
 [-1.07654878]] loss fxn value:  0.13698645039620627 learn rate: 1.5625e-05 iteration: 20017
[[ 1.99964566]
 [ 4.00914894]
 [-1.07655092]] loss fxn value:  0.13694840222581744 learn rate: 1.5625e-05 iteration: 20018
[[ 1.9996457 ]
 [ 4.00914895]
 [-1.07655306]] loss fxn value:  0.13691036462257222 learn rate: 1.5625e-05 iteration: 20019
[[ 1.99964573]
 [ 4.00914896]
 [-1.0765552 ]] loss fxn value:  0.13687233758616774 learn rate: 1.5625e-05 iteration: 20020
[[ 1.99964577]
 [ 4.00914897]
 [-1.07655734]] loss fxn value:  0.13683432111140054 learn rate: 1.5625e-05 iteration: 20021
[[ 1.99964581]
 [ 4.00914898]
 [-1.07655948]] loss fxn value:  0.13679631519514257 learn rate: 1.5625e-05 iteration: 20022
[[ 1.99964584]
 [ 4.00914899]
 [-1.07656162]] loss fxn value:  0.13675831983523928 learn rate: 1.5625e-05 iteration: 20023
[[ 1.99964588]
 [ 4.009149  ]
 [-1.07656375]] loss fxn value:  0.13672033502835368 learn rate: 1.5625e-05 iteration: 20024
[[ 1.99964591]
 [ 4.00914901]
 [-1.07656589]] loss fxn value:  0.13668236077328516 learn rate: 1.5625e-05 iteration: 20025
[[ 1.99964595]
 [ 4.00914902]
 [-1.07656802]] loss fxn value:  0.13664439706433082 learn rate: 1.5625e-05 iteration: 20026
[[ 1.99964598]
 [ 4.00914904]
 [-1.07657016]] loss fxn value:  0.13660644389993576 learn rate: 1.5625e-05 iteration: 20027
[[ 1.99964602]
 [ 4.00914905]
 [-1.07657229]] loss fxn value:  0.13656850127722917 learn rate: 1.5625e-05 iteration: 20028
[[ 1.99964606]
 [ 4.00914906]
 [-1.07657443]] loss fxn value:  0.13653056919302373 learn rate: 1.5625e-05 iteration: 20029
[[ 1.99964609]
 [ 4.00914907]
 [-1.07657656]] loss fxn value:  0.1364926476442338 learn rate: 1.5625e-05 iteration: 20030
[[ 1.99964613]
 [ 4.00914908]
 [-1.07657869]] loss fxn value:  0.136454736628915 learn rate: 1.5625e-05 iteration: 20031
[[ 1.99964616]
 [ 4.00914909]
 [-1.07658082]] loss fxn value:  0.13641683614312253 learn rate: 1.5625e-05 iteration: 20032
[[ 1.9996462 ]
 [ 4.0091491 ]
 [-1.07658295]] loss fxn value:  0.13637894618392854 learn rate: 1.5625e-05 iteration: 20033
[[ 1.99964623]
 [ 4.00914911]
 [-1.07658509]] loss fxn value:  0.13634106674928567 learn rate: 1.5625e-05 iteration: 20034
[[ 1.99964627]
 [ 4.00914912]
 [-1.07658722]] loss fxn value:  0.13630319783538522 learn rate: 1.5625e-05 iteration: 20035
[[ 1.9996463 ]
 [ 4.00914913]
 [-1.07658934]] loss fxn value:  0.13626533943949454 learn rate: 1.5625e-05 iteration: 20036
[[ 1.99964634]
 [ 4.00914914]
 [-1.07659147]] loss fxn value:  0.13622749155955846 learn rate: 1.5625e-05 iteration: 20037
[[ 1.99964638]
 [ 4.00914915]
 [-1.0765936 ]] loss fxn value:  0.13618965419071943 learn rate: 1.5625e-05 iteration: 20038
[[ 1.99964641]
 [ 4.00914917]
 [-1.07659573]] loss fxn value:  0.1361518273323434 learn rate: 1.5625e-05 iteration: 20039
[[ 1.99964645]
 [ 4.00914918]
 [-1.07659786]] loss fxn value:  0.13611401098016243 learn rate: 1.5625e-05 iteration: 20040
[[ 1.99964648]
 [ 4.00914919]
 [-1.07659998]] loss fxn value:  0.13607620513053212 learn rate: 1.5625e-05 iteration: 20041
[[ 1.99964652]
 [ 4.0091492 ]
 [-1.07660211]] loss fxn value:  0.1360384097822975 learn rate: 1.5625e-05 iteration: 20042
[[ 1.99964655]
 [ 4.00914921]
 [-1.07660423]] loss fxn value:  0.13600062493201434 learn rate: 1.5625e-05 iteration: 20043
[[ 1.99964659]
 [ 4.00914922]
 [-1.07660636]] loss fxn value:  0.13596285057622107 learn rate: 1.5625e-05 iteration: 20044
[[ 1.99964662]
 [ 4.00914923]
 [-1.07660848]] loss fxn value:  0.13592508671254713 learn rate: 1.5625e-05 iteration: 20045
[[ 1.99964666]
 [ 4.00914924]
 [-1.07661061]] loss fxn value:  0.13588733333787606 learn rate: 1.5625e-05 iteration: 20046
[[ 1.99964669]
 [ 4.00914925]
 [-1.07661273]] loss fxn value:  0.13584959044848022 learn rate: 1.5625e-05 iteration: 20047
[[ 1.99964673]
 [ 4.00914926]
 [-1.07661485]] loss fxn value:  0.1358118580436261 learn rate: 1.5625e-05 iteration: 20048
[[ 1.99964677]
 [ 4.00914927]
 [-1.07661697]] loss fxn value:  0.135774136117627 learn rate: 1.5625e-05 iteration: 20049
[[ 1.9996468 ]
 [ 4.00914928]
 [-1.07661909]] loss fxn value:  0.13573642466968303 learn rate: 1.5625e-05 iteration: 20050
[[ 1.99964684]
 [ 4.00914929]
 [-1.07662122]] loss fxn value:  0.13569872369579464 learn rate: 1.5625e-05 iteration: 20051
[[ 1.99964687]
 [ 4.00914931]
 [-1.07662334]] loss fxn value:  0.13566103319308645 learn rate: 1.5625e-05 iteration: 20052
[[ 1.99964691]
 [ 4.00914932]
 [-1.07662545]] loss fxn value:  0.13562335315983232 learn rate: 1.5625e-05 iteration: 20053
[[ 1.99964694]
 [ 4.00914933]
 [-1.07662757]] loss fxn value:  0.13558568359142606 learn rate: 1.5625e-05 iteration: 20054
[[ 1.99964698]
 [ 4.00914934]
 [-1.07662969]] loss fxn value:  0.13554802448652062 learn rate: 1.5625e-05 iteration: 20055
[[ 1.99964701]
 [ 4.00914935]
 [-1.07663181]] loss fxn value:  0.1355103758419996 learn rate: 1.5625e-05 iteration: 20056
[[ 1.99964705]
 [ 4.00914936]
 [-1.07663393]] loss fxn value:  0.13547273765317577 learn rate: 1.5625e-05 iteration: 20057
[[ 1.99964708]
 [ 4.00914937]
 [-1.07663604]] loss fxn value:  0.1354351099187924 learn rate: 1.5625e-05 iteration: 20058
[[ 1.99964712]
 [ 4.00914938]
 [-1.07663816]] loss fxn value:  0.13539749263522355 learn rate: 1.5625e-05 iteration: 20059
[[ 1.99964715]
 [ 4.00914939]
 [-1.07664027]] loss fxn value:  0.13535988580060584 learn rate: 1.5625e-05 iteration: 20060
[[ 1.99964719]
 [ 4.0091494 ]
 [-1.07664239]] loss fxn value:  0.1353222894107993 learn rate: 1.5625e-05 iteration: 20061
[[ 1.99964722]
 [ 4.00914941]
 [-1.0766445 ]] loss fxn value:  0.13528470346368018 learn rate: 1.5625e-05 iteration: 20062
[[ 1.99964726]
 [ 4.00914942]
 [-1.07664662]] loss fxn value:  0.13524712795587834 learn rate: 1.5625e-05 iteration: 20063
[[ 1.9996473 ]
 [ 4.00914943]
 [-1.07664873]] loss fxn value:  0.13520956288572697 learn rate: 1.5625e-05 iteration: 20064
[[ 1.99964733]
 [ 4.00914945]
 [-1.07665084]] loss fxn value:  0.13517200824814363 learn rate: 1.5625e-05 iteration: 20065
[[ 1.99964737]
 [ 4.00914946]
 [-1.07665295]] loss fxn value:  0.1351344640422668 learn rate: 1.5625e-05 iteration: 20066
[[ 1.9996474 ]
 [ 4.00914947]
 [-1.07665506]] loss fxn value:  0.13509693026346642 learn rate: 1.5625e-05 iteration: 20067
[[ 1.99964744]
 [ 4.00914948]
 [-1.07665717]] loss fxn value:  0.13505940691052112 learn rate: 1.5625e-05 iteration: 20068
[[ 1.99964747]
 [ 4.00914949]
 [-1.07665928]] loss fxn value:  0.135021893979139 learn rate: 1.5625e-05 iteration: 20069
[[ 1.99964751]
 [ 4.0091495 ]
 [-1.07666139]] loss fxn value:  0.1349843914667941 learn rate: 1.5625e-05 iteration: 20070
[[ 1.99964754]
 [ 4.00914951]
 [-1.0766635 ]] loss fxn value:  0.1349468993715775 learn rate: 1.5625e-05 iteration: 20071
[[ 1.99964758]
 [ 4.00914952]
 [-1.07666561]] loss fxn value:  0.1349094176893469 learn rate: 1.5625e-05 iteration: 20072
[[ 1.99964761]
 [ 4.00914953]
 [-1.07666772]] loss fxn value:  0.13487194641888095 learn rate: 1.5625e-05 iteration: 20073
[[ 1.99964765]
 [ 4.00914954]
 [-1.07666983]] loss fxn value:  0.13483448555451458 learn rate: 1.5625e-05 iteration: 20074
[[ 1.99964768]
 [ 4.00914955]
 [-1.07667193]] loss fxn value:  0.13479703509554275 learn rate: 1.5625e-05 iteration: 20075
[[ 1.99964772]
 [ 4.00914956]
 [-1.07667404]] loss fxn value:  0.13475959503769752 learn rate: 1.5625e-05 iteration: 20076
[[ 1.99964775]
 [ 4.00914957]
 [-1.07667614]] loss fxn value:  0.13472216538079035 learn rate: 1.5625e-05 iteration: 20077
[[ 1.99964779]
 [ 4.00914958]
 [-1.07667825]] loss fxn value:  0.1346847461185393 learn rate: 1.5625e-05 iteration: 20078
[[ 1.99964782]
 [ 4.00914959]
 [-1.07668035]] loss fxn value:  0.13464733724984737 learn rate: 1.5625e-05 iteration: 20079
[[ 1.99964786]
 [ 4.00914961]
 [-1.07668246]] loss fxn value:  0.13460993877240945 learn rate: 1.5625e-05 iteration: 20080
[[ 1.99964789]
 [ 4.00914962]
 [-1.07668456]] loss fxn value:  0.13457255068109145 learn rate: 1.5625e-05 iteration: 20081
[[ 1.99964793]
 [ 4.00914963]
 [-1.07668666]] loss fxn value:  0.13453517297516449 learn rate: 1.5625e-05 iteration: 20082
[[ 1.99964796]
 [ 4.00914964]
 [-1.07668876]] loss fxn value:  0.13449780565038913 learn rate: 1.5625e-05 iteration: 20083
[[ 1.999648  ]
 [ 4.00914965]
 [-1.07669086]] loss fxn value:  0.13446044870461077 learn rate: 1.5625e-05 iteration: 20084
[[ 1.99964803]
 [ 4.00914966]
 [-1.07669296]] loss fxn value:  0.134423102134954 learn rate: 1.5625e-05 iteration: 20085
[[ 1.99964807]
 [ 4.00914967]
 [-1.07669506]] loss fxn value:  0.13438576593837884 learn rate: 1.5625e-05 iteration: 20086
[[ 1.9996481 ]
 [ 4.00914968]
 [-1.07669716]] loss fxn value:  0.1343484401116215 learn rate: 1.5625e-05 iteration: 20087
[[ 1.99964814]
 [ 4.00914969]
 [-1.07669926]] loss fxn value:  0.13431112465295117 learn rate: 1.5625e-05 iteration: 20088
[[ 1.99964817]
 [ 4.0091497 ]
 [-1.07670136]] loss fxn value:  0.13427381955762907 learn rate: 1.5625e-05 iteration: 20089
[[ 1.99964821]
 [ 4.00914971]
 [-1.07670346]] loss fxn value:  0.1342365248250327 learn rate: 1.5625e-05 iteration: 20090
[[ 1.99964824]
 [ 4.00914972]
 [-1.07670556]] loss fxn value:  0.13419924044985215 learn rate: 1.5625e-05 iteration: 20091
[[ 1.99964828]
 [ 4.00914973]
 [-1.07670765]] loss fxn value:  0.13416196643189884 learn rate: 1.5625e-05 iteration: 20092
[[ 1.99964831]
 [ 4.00914974]
 [-1.07670975]] loss fxn value:  0.1341247027659738 learn rate: 1.5625e-05 iteration: 20093
[[ 1.99964835]
 [ 4.00914975]
 [-1.07671184]] loss fxn value:  0.13408744944941844 learn rate: 1.5625e-05 iteration: 20094
[[ 1.99964838]
 [ 4.00914977]
 [-1.07671394]] loss fxn value:  0.1340502064814367 learn rate: 1.5625e-05 iteration: 20095
[[ 1.99964842]
 [ 4.00914978]
 [-1.07671603]] loss fxn value:  0.13401297385683283 learn rate: 1.5625e-05 iteration: 20096
[[ 1.99964845]
 [ 4.00914979]
 [-1.07671813]] loss fxn value:  0.13397575157343058 learn rate: 1.5625e-05 iteration: 20097
[[ 1.99964849]
 [ 4.0091498 ]
 [-1.07672022]] loss fxn value:  0.13393853962994925 learn rate: 1.5625e-05 iteration: 20098
[[ 1.99964852]
 [ 4.00914981]
 [-1.07672231]] loss fxn value:  0.13390133802069745 learn rate: 1.5625e-05 iteration: 20099
[[ 1.99964856]
 [ 4.00914982]
 [-1.0767244 ]] loss fxn value:  0.13386414674457953 learn rate: 1.5625e-05 iteration: 20100
[[ 1.99964859]
 [ 4.00914983]
 [-1.0767265 ]] loss fxn value:  0.13382696579823228 learn rate: 1.5625e-05 iteration: 20101
[[ 1.99964863]
 [ 4.00914984]
 [-1.07672859]] loss fxn value:  0.1337897951799249 learn rate: 1.5625e-05 iteration: 20102
[[ 1.99964866]
 [ 4.00914985]
 [-1.07673068]] loss fxn value:  0.13375263488505126 learn rate: 1.5625e-05 iteration: 20103
[[ 1.9996487 ]
 [ 4.00914986]
 [-1.07673277]] loss fxn value:  0.133715484911852 learn rate: 1.5625e-05 iteration: 20104
[[ 1.99964873]
 [ 4.00914987]
 [-1.07673486]] loss fxn value:  0.1336783452570896 learn rate: 1.5625e-05 iteration: 20105
[[ 1.99964877]
 [ 4.00914988]
 [-1.07673694]] loss fxn value:  0.13364121591757902 learn rate: 1.5625e-05 iteration: 20106
[[ 1.9996488 ]
 [ 4.00914989]
 [-1.07673903]] loss fxn value:  0.13360409688970676 learn rate: 1.5625e-05 iteration: 20107
[[ 1.99964884]
 [ 4.0091499 ]
 [-1.07674112]] loss fxn value:  0.1335669881735962 learn rate: 1.5625e-05 iteration: 20108
[[ 1.99964887]
 [ 4.00914991]
 [-1.07674321]] loss fxn value:  0.13352988976353203 learn rate: 1.5625e-05 iteration: 20109
[[ 1.99964891]
 [ 4.00914992]
 [-1.07674529]] loss fxn value:  0.1334928016578884 learn rate: 1.5625e-05 iteration: 20110
[[ 1.99964894]
 [ 4.00914993]
 [-1.07674738]] loss fxn value:  0.1334557238538848 learn rate: 1.5625e-05 iteration: 20111
[[ 1.99964898]
 [ 4.00914995]
 [-1.07674946]] loss fxn value:  0.1334186563478552 learn rate: 1.5625e-05 iteration: 20112
[[ 1.99964901]
 [ 4.00914996]
 [-1.07675155]] loss fxn value:  0.1333815991366501 learn rate: 1.5625e-05 iteration: 20113
[[ 1.99964905]
 [ 4.00914997]
 [-1.07675363]] loss fxn value:  0.13334455221895092 learn rate: 1.5625e-05 iteration: 20114
[[ 1.99964908]
 [ 4.00914998]
 [-1.07675571]] loss fxn value:  0.13330751559095827 learn rate: 1.5625e-05 iteration: 20115
[[ 1.99964912]
 [ 4.00914999]
 [-1.0767578 ]] loss fxn value:  0.1332704892501678 learn rate: 1.5625e-05 iteration: 20116
[[ 1.99964915]
 [ 4.00915   ]
 [-1.07675988]] loss fxn value:  0.13323347319368015 learn rate: 1.5625e-05 iteration: 20117
[[ 1.99964918]
 [ 4.00915001]
 [-1.07676196]] loss fxn value:  0.1331964674174341 learn rate: 1.5625e-05 iteration: 20118
[[ 1.99964922]
 [ 4.00915002]
 [-1.07676404]] loss fxn value:  0.1331594719201204 learn rate: 1.5625e-05 iteration: 20119
[[ 1.99964925]
 [ 4.00915003]
 [-1.07676612]] loss fxn value:  0.13312248669947022 learn rate: 1.5625e-05 iteration: 20120
[[ 1.99964929]
 [ 4.00915004]
 [-1.0767682 ]] loss fxn value:  0.13308551175036337 learn rate: 1.5625e-05 iteration: 20121
[[ 1.99964932]
 [ 4.00915005]
 [-1.07677028]] loss fxn value:  0.13304854707067146 learn rate: 1.5625e-05 iteration: 20122
[[ 1.99964936]
 [ 4.00915006]
 [-1.07677236]] loss fxn value:  0.13301159265896875 learn rate: 1.5625e-05 iteration: 20123
[[ 1.99964939]
 [ 4.00915007]
 [-1.07677444]] loss fxn value:  0.13297464851065602 learn rate: 1.5625e-05 iteration: 20124
[[ 1.99964943]
 [ 4.00915008]
 [-1.07677651]] loss fxn value:  0.13293771462354084 learn rate: 1.5625e-05 iteration: 20125
[[ 1.99964946]
 [ 4.00915009]
 [-1.07677859]] loss fxn value:  0.13290079099535676 learn rate: 1.5625e-05 iteration: 20126
[[ 1.9996495 ]
 [ 4.0091501 ]
 [-1.07678067]] loss fxn value:  0.1328638776228285 learn rate: 1.5625e-05 iteration: 20127
[[ 1.99964953]
 [ 4.00915011]
 [-1.07678274]] loss fxn value:  0.1328269745028967 learn rate: 1.5625e-05 iteration: 20128
[[ 1.99964957]
 [ 4.00915012]
 [-1.07678482]] loss fxn value:  0.13279008163316228 learn rate: 1.5625e-05 iteration: 20129
[[ 1.9996496 ]
 [ 4.00915014]
 [-1.07678689]] loss fxn value:  0.13275319900960172 learn rate: 1.5625e-05 iteration: 20130
[[ 1.99964964]
 [ 4.00915015]
 [-1.07678897]] loss fxn value:  0.13271632663132038 learn rate: 1.5625e-05 iteration: 20131
[[ 1.99964967]
 [ 4.00915016]
 [-1.07679104]] loss fxn value:  0.13267946449420687 learn rate: 1.5625e-05 iteration: 20132
[[ 1.9996497 ]
 [ 4.00915017]
 [-1.07679311]] loss fxn value:  0.13264261259453577 learn rate: 1.5625e-05 iteration: 20133
[[ 1.99964974]
 [ 4.00915018]
 [-1.07679518]] loss fxn value:  0.1326057709315976 learn rate: 1.5625e-05 iteration: 20134
[[ 1.99964977]
 [ 4.00915019]
 [-1.07679726]] loss fxn value:  0.13256893950110268 learn rate: 1.5625e-05 iteration: 20135
[[ 1.99964981]
 [ 4.0091502 ]
 [-1.07679933]] loss fxn value:  0.13253211830043718 learn rate: 1.5625e-05 iteration: 20136
[[ 1.99964984]
 [ 4.00915021]
 [-1.0768014 ]] loss fxn value:  0.13249530732681591 learn rate: 1.5625e-05 iteration: 20137
[[ 1.99964988]
 [ 4.00915022]
 [-1.07680347]] loss fxn value:  0.1324585065780419 learn rate: 1.5625e-05 iteration: 20138
[[ 1.99964991]
 [ 4.00915023]
 [-1.07680554]] loss fxn value:  0.1324217160507989 learn rate: 1.5625e-05 iteration: 20139
[[ 1.99964995]
 [ 4.00915024]
 [-1.07680761]] loss fxn value:  0.13238493574106888 learn rate: 1.5625e-05 iteration: 20140
[[ 1.99964998]
 [ 4.00915025]
 [-1.07680967]] loss fxn value:  0.1323481656480512 learn rate: 1.5625e-05 iteration: 20141
[[ 1.99965002]
 [ 4.00915026]
 [-1.07681174]] loss fxn value:  0.1323114057683997 learn rate: 1.5625e-05 iteration: 20142
[[ 1.99965005]
 [ 4.00915027]
 [-1.07681381]] loss fxn value:  0.1322746560980337 learn rate: 1.5625e-05 iteration: 20143
[[ 1.99965008]
 [ 4.00915028]
 [-1.07681587]] loss fxn value:  0.1322379166347756 learn rate: 1.5625e-05 iteration: 20144
[[ 1.99965012]
 [ 4.00915029]
 [-1.07681794]] loss fxn value:  0.13220118737632025 learn rate: 1.5625e-05 iteration: 20145
[[ 1.99965015]
 [ 4.0091503 ]
 [-1.07682001]] loss fxn value:  0.13216446831989262 learn rate: 1.5625e-05 iteration: 20146
[[ 1.99965019]
 [ 4.00915031]
 [-1.07682207]] loss fxn value:  0.13212775946143837 learn rate: 1.5625e-05 iteration: 20147
[[ 1.99965022]
 [ 4.00915032]
 [-1.07682413]] loss fxn value:  0.13209106079913419 learn rate: 1.5625e-05 iteration: 20148
[[ 1.99965026]
 [ 4.00915033]
 [-1.0768262 ]] loss fxn value:  0.1320543723307444 learn rate: 1.5625e-05 iteration: 20149
[[ 1.99965029]
 [ 4.00915035]
 [-1.07682826]] loss fxn value:  0.13201769405158967 learn rate: 1.5625e-05 iteration: 20150
[[ 1.99965033]
 [ 4.00915036]
 [-1.07683032]] loss fxn value:  0.13198102596000777 learn rate: 1.5625e-05 iteration: 20151
[[ 1.99965036]
 [ 4.00915037]
 [-1.07683239]] loss fxn value:  0.13194436805366364 learn rate: 1.5625e-05 iteration: 20152
[[ 1.99965039]
 [ 4.00915038]
 [-1.07683445]] loss fxn value:  0.13190772032841042 learn rate: 1.5625e-05 iteration: 20153
[[ 1.99965043]
 [ 4.00915039]
 [-1.07683651]] loss fxn value:  0.13187108278254353 learn rate: 1.5625e-05 iteration: 20154
[[ 1.99965046]
 [ 4.0091504 ]
 [-1.07683857]] loss fxn value:  0.13183445541279 learn rate: 1.5625e-05 iteration: 20155
[[ 1.9996505 ]
 [ 4.00915041]
 [-1.07684063]] loss fxn value:  0.13179783821642407 learn rate: 1.5625e-05 iteration: 20156
[[ 1.99965053]
 [ 4.00915042]
 [-1.07684269]] loss fxn value:  0.13176123119032931 learn rate: 1.5625e-05 iteration: 20157
[[ 1.99965057]
 [ 4.00915043]
 [-1.07684475]] loss fxn value:  0.1317246343317044 learn rate: 1.5625e-05 iteration: 20158
[[ 1.9996506 ]
 [ 4.00915044]
 [-1.0768468 ]] loss fxn value:  0.131688047638316 learn rate: 1.5625e-05 iteration: 20159
[[ 1.99965063]
 [ 4.00915045]
 [-1.07684886]] loss fxn value:  0.13165147110651987 learn rate: 1.5625e-05 iteration: 20160
[[ 1.99965067]
 [ 4.00915046]
 [-1.07685092]] loss fxn value:  0.1316149047345018 learn rate: 1.5625e-05 iteration: 20161
[[ 1.9996507 ]
 [ 4.00915047]
 [-1.07685297]] loss fxn value:  0.13157834851861747 learn rate: 1.5625e-05 iteration: 20162
[[ 1.99965074]
 [ 4.00915048]
 [-1.07685503]] loss fxn value:  0.13154180245612182 learn rate: 1.5625e-05 iteration: 20163
[[ 1.99965077]
 [ 4.00915049]
 [-1.07685708]] loss fxn value:  0.1315052665433659 learn rate: 1.5625e-05 iteration: 20164
[[ 1.99965081]
 [ 4.0091505 ]
 [-1.07685914]] loss fxn value:  0.1314687407800207 learn rate: 1.5625e-05 iteration: 20165
[[ 1.99965084]
 [ 4.00915051]
 [-1.07686119]] loss fxn value:  0.13143222516086422 learn rate: 1.5625e-05 iteration: 20166
[[ 1.99965087]
 [ 4.00915052]
 [-1.07686325]] loss fxn value:  0.13139571968524544 learn rate: 1.5625e-05 iteration: 20167
[[ 1.99965091]
 [ 4.00915053]
 [-1.0768653 ]] loss fxn value:  0.13135922434700445 learn rate: 1.5625e-05 iteration: 20168
[[ 1.99965094]
 [ 4.00915054]
 [-1.07686735]] loss fxn value:  0.13132273914721723 learn rate: 1.5625e-05 iteration: 20169
[[ 1.99965098]
 [ 4.00915055]
 [-1.0768694 ]] loss fxn value:  0.13128626408033192 learn rate: 1.5625e-05 iteration: 20170
[[ 1.99965101]
 [ 4.00915056]
 [-1.07687145]] loss fxn value:  0.13124979914418008 learn rate: 1.5625e-05 iteration: 20171
[[ 1.99965105]
 [ 4.00915058]
 [-1.0768735 ]] loss fxn value:  0.1312133443373028 learn rate: 1.5625e-05 iteration: 20172
[[ 1.99965108]
 [ 4.00915059]
 [-1.07687555]] loss fxn value:  0.13117689965516488 learn rate: 1.5625e-05 iteration: 20173
[[ 1.99965111]
 [ 4.0091506 ]
 [-1.0768776 ]] loss fxn value:  0.13114046509551913 learn rate: 1.5625e-05 iteration: 20174
[[ 1.99965115]
 [ 4.00915061]
 [-1.07687965]] loss fxn value:  0.1311040406556352 learn rate: 1.5625e-05 iteration: 20175
[[ 1.99965118]
 [ 4.00915062]
 [-1.0768817 ]] loss fxn value:  0.13106762633236807 learn rate: 1.5625e-05 iteration: 20176
[[ 1.99965122]
 [ 4.00915063]
 [-1.07688375]] loss fxn value:  0.13103122212380192 learn rate: 1.5625e-05 iteration: 20177
[[ 1.99965125]
 [ 4.00915064]
 [-1.07688579]] loss fxn value:  0.1309948280263918 learn rate: 1.5625e-05 iteration: 20178
[[ 1.99965129]
 [ 4.00915065]
 [-1.07688784]] loss fxn value:  0.13095844403779577 learn rate: 1.5625e-05 iteration: 20179
[[ 1.99965132]
 [ 4.00915066]
 [-1.07688989]] loss fxn value:  0.13092207015393093 learn rate: 1.5625e-05 iteration: 20180
[[ 1.99965135]
 [ 4.00915067]
 [-1.07689193]] loss fxn value:  0.13088570637400437 learn rate: 1.5625e-05 iteration: 20181
[[ 1.99965139]
 [ 4.00915068]
 [-1.07689398]] loss fxn value:  0.13084935269375048 learn rate: 1.5625e-05 iteration: 20182
[[ 1.99965142]
 [ 4.00915069]
 [-1.07689602]] loss fxn value:  0.13081300911052446 learn rate: 1.5625e-05 iteration: 20183
[[ 1.99965146]
 [ 4.0091507 ]
 [-1.07689806]] loss fxn value:  0.13077667562299314 learn rate: 1.5625e-05 iteration: 20184
[[ 1.99965149]
 [ 4.00915071]
 [-1.07690011]] loss fxn value:  0.13074035222561015 learn rate: 1.5625e-05 iteration: 20185
[[ 1.99965152]
 [ 4.00915072]
 [-1.07690215]] loss fxn value:  0.13070403891758495 learn rate: 1.5625e-05 iteration: 20186
[[ 1.99965156]
 [ 4.00915073]
 [-1.07690419]] loss fxn value:  0.1306677356956136 learn rate: 1.5625e-05 iteration: 20187
[[ 1.99965159]
 [ 4.00915074]
 [-1.07690623]] loss fxn value:  0.1306314425570699 learn rate: 1.5625e-05 iteration: 20188
[[ 1.99965163]
 [ 4.00915075]
 [-1.07690827]] loss fxn value:  0.13059515949867162 learn rate: 1.5625e-05 iteration: 20189
[[ 1.99965166]
 [ 4.00915076]
 [-1.07691031]] loss fxn value:  0.1305588865187119 learn rate: 1.5625e-05 iteration: 20190
[[ 1.99965169]
 [ 4.00915077]
 [-1.07691235]] loss fxn value:  0.13052262361345066 learn rate: 1.5625e-05 iteration: 20191
[[ 1.99965173]
 [ 4.00915078]
 [-1.07691439]] loss fxn value:  0.13048637077929373 learn rate: 1.5625e-05 iteration: 20192
[[ 1.99965176]
 [ 4.00915079]
 [-1.07691643]] loss fxn value:  0.1304501280158859 learn rate: 1.5625e-05 iteration: 20193
[[ 1.9996518 ]
 [ 4.0091508 ]
 [-1.07691847]] loss fxn value:  0.13041389531753808 learn rate: 1.5625e-05 iteration: 20194
[[ 1.99965183]
 [ 4.00915081]
 [-1.07692051]] loss fxn value:  0.13037767268352457 learn rate: 1.5625e-05 iteration: 20195
[[ 1.99965186]
 [ 4.00915082]
 [-1.07692254]] loss fxn value:  0.1303414601110902 learn rate: 1.5625e-05 iteration: 20196
[[ 1.9996519 ]
 [ 4.00915083]
 [-1.07692458]] loss fxn value:  0.13030525759514874 learn rate: 1.5625e-05 iteration: 20197
[[ 1.99965193]
 [ 4.00915084]
 [-1.07692662]] loss fxn value:  0.1302690651354329 learn rate: 1.5625e-05 iteration: 20198
[[ 1.99965197]
 [ 4.00915085]
 [-1.07692865]] loss fxn value:  0.13023288272846764 learn rate: 1.5625e-05 iteration: 20199
[[ 1.999652  ]
 [ 4.00915087]
 [-1.07693069]] loss fxn value:  0.13019671037041536 learn rate: 1.5625e-05 iteration: 20200
[[ 1.99965203]
 [ 4.00915088]
 [-1.07693272]] loss fxn value:  0.1301605480593856 learn rate: 1.5625e-05 iteration: 20201
[[ 1.99965207]
 [ 4.00915089]
 [-1.07693475]] loss fxn value:  0.13012439579355273 learn rate: 1.5625e-05 iteration: 20202
[[ 1.9996521 ]
 [ 4.0091509 ]
 [-1.07693679]] loss fxn value:  0.13008825356830134 learn rate: 1.5625e-05 iteration: 20203
[[ 1.99965214]
 [ 4.00915091]
 [-1.07693882]] loss fxn value:  0.13005212138142666 learn rate: 1.5625e-05 iteration: 20204
[[ 1.99965217]
 [ 4.00915092]
 [-1.07694085]] loss fxn value:  0.13001599923026 learn rate: 1.5625e-05 iteration: 20205
[[ 1.9996522 ]
 [ 4.00915093]
 [-1.07694288]] loss fxn value:  0.1299798871128261 learn rate: 1.5625e-05 iteration: 20206
[[ 1.99965224]
 [ 4.00915094]
 [-1.07694491]] loss fxn value:  0.12994378502564413 learn rate: 1.5625e-05 iteration: 20207
[[ 1.99965227]
 [ 4.00915095]
 [-1.07694694]] loss fxn value:  0.12990769296492466 learn rate: 1.5625e-05 iteration: 20208
[[ 1.99965231]
 [ 4.00915096]
 [-1.07694897]] loss fxn value:  0.12987161092854396 learn rate: 1.5625e-05 iteration: 20209
[[ 1.99965234]
 [ 4.00915097]
 [-1.076951  ]] loss fxn value:  0.12983553891504773 learn rate: 1.5625e-05 iteration: 20210
[[ 1.99965237]
 [ 4.00915098]
 [-1.07695303]] loss fxn value:  0.12979947691995095 learn rate: 1.5625e-05 iteration: 20211
[[ 1.99965241]
 [ 4.00915099]
 [-1.07695506]] loss fxn value:  0.12976342494133766 learn rate: 1.5625e-05 iteration: 20212
[[ 1.99965244]
 [ 4.009151  ]
 [-1.07695708]] loss fxn value:  0.12972738297706718 learn rate: 1.5625e-05 iteration: 20213
[[ 1.99965247]
 [ 4.00915101]
 [-1.07695911]] loss fxn value:  0.12969135102237442 learn rate: 1.5625e-05 iteration: 20214
[[ 1.99965251]
 [ 4.00915102]
 [-1.07696114]] loss fxn value:  0.12965532907622085 learn rate: 1.5625e-05 iteration: 20215
[[ 1.99965254]
 [ 4.00915103]
 [-1.07696316]] loss fxn value:  0.12961931713462424 learn rate: 1.5625e-05 iteration: 20216
[[ 1.99965258]
 [ 4.00915104]
 [-1.07696519]] loss fxn value:  0.12958331519558972 learn rate: 1.5625e-05 iteration: 20217
[[ 1.99965261]
 [ 4.00915105]
 [-1.07696721]] loss fxn value:  0.1295473232561963 learn rate: 1.5625e-05 iteration: 20218
[[ 1.99965264]
 [ 4.00915106]
 [-1.07696924]] loss fxn value:  0.12951134131386327 learn rate: 1.5625e-05 iteration: 20219
[[ 1.99965268]
 [ 4.00915107]
 [-1.07697126]] loss fxn value:  0.12947536936524903 learn rate: 1.5625e-05 iteration: 20220
[[ 1.99965271]
 [ 4.00915108]
 [-1.07697328]] loss fxn value:  0.1294394074082321 learn rate: 1.5625e-05 iteration: 20221
[[ 1.99965274]
 [ 4.00915109]
 [-1.0769753 ]] loss fxn value:  0.12940345543910328 learn rate: 1.5625e-05 iteration: 20222
[[ 1.99965278]
 [ 4.0091511 ]
 [-1.07697733]] loss fxn value:  0.12936751345698724 learn rate: 1.5625e-05 iteration: 20223
[[ 1.99965281]
 [ 4.00915111]
 [-1.07697935]] loss fxn value:  0.1293315814567822 learn rate: 1.5625e-05 iteration: 20224
[[ 1.99965285]
 [ 4.00915112]
 [-1.07698137]] loss fxn value:  0.12929565943632196 learn rate: 1.5625e-05 iteration: 20225
[[ 1.99965288]
 [ 4.00915113]
 [-1.07698339]] loss fxn value:  0.12925974739375704 learn rate: 1.5625e-05 iteration: 20226
[[ 1.99965291]
 [ 4.00915114]
 [-1.07698541]] loss fxn value:  0.12922384532497597 learn rate: 1.5625e-05 iteration: 20227
[[ 1.99965295]
 [ 4.00915115]
 [-1.07698743]] loss fxn value:  0.1291879532300952 learn rate: 1.5625e-05 iteration: 20228
[[ 1.99965298]
 [ 4.00915116]
 [-1.07698944]] loss fxn value:  0.12915207110244542 learn rate: 1.5625e-05 iteration: 20229
[[ 1.99965301]
 [ 4.00915117]
 [-1.07699146]] loss fxn value:  0.12911619894199228 learn rate: 1.5625e-05 iteration: 20230
[[ 1.99965305]
 [ 4.00915118]
 [-1.07699348]] loss fxn value:  0.12908033674473737 learn rate: 1.5625e-05 iteration: 20231
[[ 1.99965308]
 [ 4.00915119]
 [-1.07699549]] loss fxn value:  0.1290444845081069 learn rate: 1.5625e-05 iteration: 20232
[[ 1.99965311]
 [ 4.0091512 ]
 [-1.07699751]] loss fxn value:  0.1290086422299085 learn rate: 1.5625e-05 iteration: 20233
[[ 1.99965315]
 [ 4.00915121]
 [-1.07699953]] loss fxn value:  0.12897280990679733 learn rate: 1.5625e-05 iteration: 20234
[[ 1.99965318]
 [ 4.00915122]
 [-1.07700154]] loss fxn value:  0.12893698753657418 learn rate: 1.5625e-05 iteration: 20235
[[ 1.99965322]
 [ 4.00915124]
 [-1.07700356]] loss fxn value:  0.12890117511466598 learn rate: 1.5625e-05 iteration: 20236
[[ 1.99965325]
 [ 4.00915125]
 [-1.07700557]] loss fxn value:  0.12886537264119613 learn rate: 1.5625e-05 iteration: 20237
[[ 1.99965328]
 [ 4.00915126]
 [-1.07700758]] loss fxn value:  0.12882958011186119 learn rate: 1.5625e-05 iteration: 20238
[[ 1.99965332]
 [ 4.00915127]
 [-1.0770096 ]] loss fxn value:  0.12879379752268555 learn rate: 1.5625e-05 iteration: 20239
[[ 1.99965335]
 [ 4.00915128]
 [-1.07701161]] loss fxn value:  0.12875802487281693 learn rate: 1.5625e-05 iteration: 20240
[[ 1.99965338]
 [ 4.00915129]
 [-1.07701362]] loss fxn value:  0.12872226215944624 learn rate: 1.5625e-05 iteration: 20241
[[ 1.99965342]
 [ 4.0091513 ]
 [-1.07701563]] loss fxn value:  0.12868650937887208 learn rate: 1.5625e-05 iteration: 20242
[[ 1.99965345]
 [ 4.00915131]
 [-1.07701764]] loss fxn value:  0.12865076652808521 learn rate: 1.5625e-05 iteration: 20243
[[ 1.99965348]
 [ 4.00915132]
 [-1.07701965]] loss fxn value:  0.12861503360515741 learn rate: 1.5625e-05 iteration: 20244
[[ 1.99965352]
 [ 4.00915133]
 [-1.07702166]] loss fxn value:  0.12857931060735367 learn rate: 1.5625e-05 iteration: 20245
[[ 1.99965355]
 [ 4.00915134]
 [-1.07702367]] loss fxn value:  0.1285435975315198 learn rate: 1.5625e-05 iteration: 20246
[[ 1.99965358]
 [ 4.00915135]
 [-1.07702568]] loss fxn value:  0.128507894375844 learn rate: 1.5625e-05 iteration: 20247
[[ 1.99965362]
 [ 4.00915136]
 [-1.07702768]] loss fxn value:  0.1284722011362056 learn rate: 1.5625e-05 iteration: 20248
[[ 1.99965365]
 [ 4.00915137]
 [-1.07702969]] loss fxn value:  0.12843651780941265 learn rate: 1.5625e-05 iteration: 20249
[[ 1.99965369]
 [ 4.00915138]
 [-1.0770317 ]] loss fxn value:  0.12840084439510302 learn rate: 1.5625e-05 iteration: 20250
[[ 1.99965372]
 [ 4.00915139]
 [-1.0770337 ]] loss fxn value:  0.12836518088813023 learn rate: 1.5625e-05 iteration: 20251
[[ 1.99965375]
 [ 4.0091514 ]
 [-1.07703571]] loss fxn value:  0.12832952728773456 learn rate: 1.5625e-05 iteration: 20252
[[ 1.99965379]
 [ 4.00915141]
 [-1.07703771]] loss fxn value:  0.1282938835897221 learn rate: 1.5625e-05 iteration: 20253
[[ 1.99965382]
 [ 4.00915142]
 [-1.07703972]] loss fxn value:  0.12825824979180248 learn rate: 1.5625e-05 iteration: 20254
[[ 1.99965385]
 [ 4.00915143]
 [-1.07704172]] loss fxn value:  0.12822262589042618 learn rate: 1.5625e-05 iteration: 20255
[[ 1.99965389]
 [ 4.00915144]
 [-1.07704373]] loss fxn value:  0.12818701188467926 learn rate: 1.5625e-05 iteration: 20256
[[ 1.99965392]
 [ 4.00915145]
 [-1.07704573]] loss fxn value:  0.12815140777132422 learn rate: 1.5625e-05 iteration: 20257
[[ 1.99965395]
 [ 4.00915146]
 [-1.07704773]] loss fxn value:  0.12811581354575022 learn rate: 1.5625e-05 iteration: 20258
[[ 1.99965399]
 [ 4.00915147]
 [-1.07704973]] loss fxn value:  0.12808022920625733 learn rate: 1.5625e-05 iteration: 20259
[[ 1.99965402]
 [ 4.00915148]
 [-1.07705173]] loss fxn value:  0.1280446547515363 learn rate: 1.5625e-05 iteration: 20260
[[ 1.99965405]
 [ 4.00915149]
 [-1.07705373]] loss fxn value:  0.12800909017681666 learn rate: 1.5625e-05 iteration: 20261
[[ 1.99965409]
 [ 4.0091515 ]
 [-1.07705573]] loss fxn value:  0.12797353548099125 learn rate: 1.5625e-05 iteration: 20262
[[ 1.99965412]
 [ 4.00915151]
 [-1.07705773]] loss fxn value:  0.1279379906597087 learn rate: 1.5625e-05 iteration: 20263
[[ 1.99965415]
 [ 4.00915152]
 [-1.07705973]] loss fxn value:  0.12790245571137873 learn rate: 1.5625e-05 iteration: 20264
[[ 1.99965419]
 [ 4.00915153]
 [-1.07706173]] loss fxn value:  0.12786693063360915 learn rate: 1.5625e-05 iteration: 20265
[[ 1.99965422]
 [ 4.00915154]
 [-1.07706373]] loss fxn value:  0.12783141542279333 learn rate: 1.5625e-05 iteration: 20266
[[ 1.99965425]
 [ 4.00915155]
 [-1.07706572]] loss fxn value:  0.1277959100752152 learn rate: 1.5625e-05 iteration: 20267
[[ 1.99965429]
 [ 4.00915156]
 [-1.07706772]] loss fxn value:  0.12776041459103443 learn rate: 1.5625e-05 iteration: 20268
[[ 1.99965432]
 [ 4.00915157]
 [-1.07706972]] loss fxn value:  0.12772492896372353 learn rate: 1.5625e-05 iteration: 20269
[[ 1.99965435]
 [ 4.00915158]
 [-1.07707171]] loss fxn value:  0.12768945319387986 learn rate: 1.5625e-05 iteration: 20270
[[ 1.99965439]
 [ 4.00915159]
 [-1.07707371]] loss fxn value:  0.12765398727778274 learn rate: 1.5625e-05 iteration: 20271
[[ 1.99965442]
 [ 4.0091516 ]
 [-1.0770757 ]] loss fxn value:  0.12761853121081207 learn rate: 1.5625e-05 iteration: 20272
[[ 1.99965445]
 [ 4.00915161]
 [-1.07707769]] loss fxn value:  0.1275830849936933 learn rate: 1.5625e-05 iteration: 20273
[[ 1.99965449]
 [ 4.00915162]
 [-1.07707969]] loss fxn value:  0.12754764862102305 learn rate: 1.5625e-05 iteration: 20274
[[ 1.99965452]
 [ 4.00915163]
 [-1.07708168]] loss fxn value:  0.1275122220904112 learn rate: 1.5625e-05 iteration: 20275
[[ 1.99965455]
 [ 4.00915164]
 [-1.07708367]] loss fxn value:  0.12747680539990314 learn rate: 1.5625e-05 iteration: 20276
[[ 1.99965459]
 [ 4.00915165]
 [-1.07708566]] loss fxn value:  0.12744139854679712 learn rate: 1.5625e-05 iteration: 20277
[[ 1.99965462]
 [ 4.00915166]
 [-1.07708765]] loss fxn value:  0.12740600152739168 learn rate: 1.5625e-05 iteration: 20278
[[ 1.99965465]
 [ 4.00915167]
 [-1.07708964]] loss fxn value:  0.12737061433999616 learn rate: 1.5625e-05 iteration: 20279
[[ 1.99965469]
 [ 4.00915168]
 [-1.07709163]] loss fxn value:  0.12733523698079027 learn rate: 1.5625e-05 iteration: 20280
[[ 1.99965472]
 [ 4.00915169]
 [-1.07709362]] loss fxn value:  0.12729986944863836 learn rate: 1.5625e-05 iteration: 20281
[[ 1.99965475]
 [ 4.0091517 ]
 [-1.07709561]] loss fxn value:  0.12726451173925546 learn rate: 1.5625e-05 iteration: 20282
[[ 1.99965478]
 [ 4.00915171]
 [-1.0770976 ]] loss fxn value:  0.12722916385092778 learn rate: 1.5625e-05 iteration: 20283
[[ 1.99965482]
 [ 4.00915172]
 [-1.07709959]] loss fxn value:  0.12719382578039154 learn rate: 1.5625e-05 iteration: 20284
[[ 1.99965485]
 [ 4.00915173]
 [-1.07710158]] loss fxn value:  0.1271584975245165 learn rate: 1.5625e-05 iteration: 20285
[[ 1.99965488]
 [ 4.00915174]
 [-1.07710356]] loss fxn value:  0.127123179081524 learn rate: 1.5625e-05 iteration: 20286
[[ 1.99965492]
 [ 4.00915175]
 [-1.07710555]] loss fxn value:  0.12708787044817194 learn rate: 1.5625e-05 iteration: 20287
[[ 1.99965495]
 [ 4.00915176]
 [-1.07710753]] loss fxn value:  0.1270525716226346 learn rate: 1.5625e-05 iteration: 20288
[[ 1.99965498]
 [ 4.00915177]
 [-1.07710952]] loss fxn value:  0.12701728260039385 learn rate: 1.5625e-05 iteration: 20289
[[ 1.99965502]
 [ 4.00915178]
 [-1.0771115 ]] loss fxn value:  0.12698200338005475 learn rate: 1.5625e-05 iteration: 20290
[[ 1.99965505]
 [ 4.00915179]
 [-1.07711349]] loss fxn value:  0.12694673395850548 learn rate: 1.5625e-05 iteration: 20291
[[ 1.99965508]
 [ 4.0091518 ]
 [-1.07711547]] loss fxn value:  0.12691147433336852 learn rate: 1.5625e-05 iteration: 20292
[[ 1.99965512]
 [ 4.00915181]
 [-1.07711745]] loss fxn value:  0.126876224501106 learn rate: 1.5625e-05 iteration: 20293
[[ 1.99965515]
 [ 4.00915182]
 [-1.07711943]] loss fxn value:  0.1268409844598444 learn rate: 1.5625e-05 iteration: 20294
[[ 1.99965518]
 [ 4.00915183]
 [-1.07712142]] loss fxn value:  0.12680575420686802 learn rate: 1.5625e-05 iteration: 20295
[[ 1.99965522]
 [ 4.00915184]
 [-1.0771234 ]] loss fxn value:  0.1267705337384962 learn rate: 1.5625e-05 iteration: 20296
[[ 1.99965525]
 [ 4.00915185]
 [-1.07712538]] loss fxn value:  0.12673532305256283 learn rate: 1.5625e-05 iteration: 20297
[[ 1.99965528]
 [ 4.00915186]
 [-1.07712736]] loss fxn value:  0.1267001221466803 learn rate: 1.5625e-05 iteration: 20298
[[ 1.99965531]
 [ 4.00915187]
 [-1.07712934]] loss fxn value:  0.12666493101914872 learn rate: 1.5625e-05 iteration: 20299
[[ 1.99965535]
 [ 4.00915188]
 [-1.07713132]] loss fxn value:  0.12662974966478843 learn rate: 1.5625e-05 iteration: 20300
[[ 1.99965538]
 [ 4.00915189]
 [-1.07713329]] loss fxn value:  0.12659457808192343 learn rate: 1.5625e-05 iteration: 20301
[[ 1.99965541]
 [ 4.0091519 ]
 [-1.07713527]] loss fxn value:  0.12655941626828957 learn rate: 1.5625e-05 iteration: 20302
[[ 1.99965545]
 [ 4.00915191]
 [-1.07713725]] loss fxn value:  0.1265242642205784 learn rate: 1.5625e-05 iteration: 20303
[[ 1.99965548]
 [ 4.00915192]
 [-1.07713923]] loss fxn value:  0.12648912193667536 learn rate: 1.5625e-05 iteration: 20304
[[ 1.99965551]
 [ 4.00915193]
 [-1.0771412 ]] loss fxn value:  0.1264539894137175 learn rate: 1.5625e-05 iteration: 20305
[[ 1.99965555]
 [ 4.00915194]
 [-1.07714318]] loss fxn value:  0.12641886664911164 learn rate: 1.5625e-05 iteration: 20306
[[ 1.99965558]
 [ 4.00915195]
 [-1.07714515]] loss fxn value:  0.12638375363948534 learn rate: 1.5625e-05 iteration: 20307
[[ 1.99965561]
 [ 4.00915196]
 [-1.07714713]] loss fxn value:  0.12634865038229098 learn rate: 1.5625e-05 iteration: 20308
[[ 1.99965564]
 [ 4.00915197]
 [-1.0771491 ]] loss fxn value:  0.12631355687656448 learn rate: 1.5625e-05 iteration: 20309
[[ 1.99965568]
 [ 4.00915198]
 [-1.07715107]] loss fxn value:  0.1262784731167857 learn rate: 1.5625e-05 iteration: 20310
[[ 1.99965571]
 [ 4.00915199]
 [-1.07715305]] loss fxn value:  0.12624339910165452 learn rate: 1.5625e-05 iteration: 20311
[[ 1.99965574]
 [ 4.009152  ]
 [-1.07715502]] loss fxn value:  0.12620833482795052 learn rate: 1.5625e-05 iteration: 20312
[[ 1.99965578]
 [ 4.00915201]
 [-1.07715699]] loss fxn value:  0.12617328029440217 learn rate: 1.5625e-05 iteration: 20313
[[ 1.99965581]
 [ 4.00915202]
 [-1.07715896]] loss fxn value:  0.1261382354963154 learn rate: 1.5625e-05 iteration: 20314
[[ 1.99965584]
 [ 4.00915203]
 [-1.07716093]] loss fxn value:  0.12610320043338738 learn rate: 1.5625e-05 iteration: 20315
[[ 1.99965587]
 [ 4.00915204]
 [-1.0771629 ]] loss fxn value:  0.12606817509997467 learn rate: 1.5625e-05 iteration: 20316
[[ 1.99965591]
 [ 4.00915205]
 [-1.07716487]] loss fxn value:  0.12603315949535757 learn rate: 1.5625e-05 iteration: 20317
[[ 1.99965594]
 [ 4.00915206]
 [-1.07716684]] loss fxn value:  0.12599815361631328 learn rate: 1.5625e-05 iteration: 20318
[[ 1.99965597]
 [ 4.00915207]
 [-1.07716881]] loss fxn value:  0.1259631574609158 learn rate: 1.5625e-05 iteration: 20319
[[ 1.99965601]
 [ 4.00915208]
 [-1.07717078]] loss fxn value:  0.12592817102517803 learn rate: 1.5625e-05 iteration: 20320
[[ 1.99965604]
 [ 4.00915209]
 [-1.07717274]] loss fxn value:  0.1258931943067432 learn rate: 1.5625e-05 iteration: 20321
[[ 1.99965607]
 [ 4.0091521 ]
 [-1.07717471]] loss fxn value:  0.12585822730339963 learn rate: 1.5625e-05 iteration: 20322
[[ 1.9996561 ]
 [ 4.00915211]
 [-1.07717668]] loss fxn value:  0.12582327001247173 learn rate: 1.5625e-05 iteration: 20323
[[ 1.99965614]
 [ 4.00915212]
 [-1.07717864]] loss fxn value:  0.12578832243016008 learn rate: 1.5625e-05 iteration: 20324
[[ 1.99965617]
 [ 4.00915213]
 [-1.07718061]] loss fxn value:  0.12575338455574125 learn rate: 1.5625e-05 iteration: 20325
[[ 1.9996562 ]
 [ 4.00915214]
 [-1.07718257]] loss fxn value:  0.12571845638399 learn rate: 1.5625e-05 iteration: 20326
[[ 1.99965624]
 [ 4.00915215]
 [-1.07718454]] loss fxn value:  0.1256835379147395 learn rate: 1.5625e-05 iteration: 20327
[[ 1.99965627]
 [ 4.00915216]
 [-1.0771865 ]] loss fxn value:  0.12564862914410227 learn rate: 1.5625e-05 iteration: 20328
[[ 1.9996563 ]
 [ 4.00915217]
 [-1.07718846]] loss fxn value:  0.12561373006902907 learn rate: 1.5625e-05 iteration: 20329
[[ 1.99965633]
 [ 4.00915218]
 [-1.07719043]] loss fxn value:  0.125578840687154 learn rate: 1.5625e-05 iteration: 20330
[[ 1.99965637]
 [ 4.00915219]
 [-1.07719239]] loss fxn value:  0.12554396099539833 learn rate: 1.5625e-05 iteration: 20331
[[ 1.9996564 ]
 [ 4.0091522 ]
 [-1.07719435]] loss fxn value:  0.12550909099236027 learn rate: 1.5625e-05 iteration: 20332
[[ 1.99965643]
 [ 4.00915221]
 [-1.07719631]] loss fxn value:  0.12547423067433383 learn rate: 1.5625e-05 iteration: 20333
[[ 1.99965646]
 [ 4.00915222]
 [-1.07719827]] loss fxn value:  0.12543938003869035 learn rate: 1.5625e-05 iteration: 20334
[[ 1.9996565 ]
 [ 4.00915223]
 [-1.07720023]] loss fxn value:  0.12540453908307314 learn rate: 1.5625e-05 iteration: 20335
[[ 1.99965653]
 [ 4.00915224]
 [-1.07720219]] loss fxn value:  0.12536970780437817 learn rate: 1.5625e-05 iteration: 20336
[[ 1.99965656]
 [ 4.00915225]
 [-1.07720415]] loss fxn value:  0.12533488620027494 learn rate: 1.5625e-05 iteration: 20337
[[ 1.9996566 ]
 [ 4.00915226]
 [-1.07720611]] loss fxn value:  0.12530007426800688 learn rate: 1.5625e-05 iteration: 20338
[[ 1.99965663]
 [ 4.00915227]
 [-1.07720806]] loss fxn value:  0.125265272003596 learn rate: 1.5625e-05 iteration: 20339
[[ 1.99965666]
 [ 4.00915228]
 [-1.07721002]] loss fxn value:  0.125230479407416 learn rate: 1.5625e-05 iteration: 20340
[[ 1.99965669]
 [ 4.00915229]
 [-1.07721198]] loss fxn value:  0.1251956964740061 learn rate: 1.5625e-05 iteration: 20341
[[ 1.99965673]
 [ 4.0091523 ]
 [-1.07721393]] loss fxn value:  0.12516092320203318 learn rate: 1.5625e-05 iteration: 20342
[[ 1.99965676]
 [ 4.00915231]
 [-1.07721589]] loss fxn value:  0.12512615958776258 learn rate: 1.5625e-05 iteration: 20343
[[ 1.99965679]
 [ 4.00915232]
 [-1.07721784]] loss fxn value:  0.12509140562865828 learn rate: 1.5625e-05 iteration: 20344
[[ 1.99965682]
 [ 4.00915233]
 [-1.0772198 ]] loss fxn value:  0.12505666132364973 learn rate: 1.5625e-05 iteration: 20345
[[ 1.99965686]
 [ 4.00915234]
 [-1.07722175]] loss fxn value:  0.1250219266687181 learn rate: 1.5625e-05 iteration: 20346
[[ 1.99965689]
 [ 4.00915235]
 [-1.0772237 ]] loss fxn value:  0.12498720166063823 learn rate: 1.5625e-05 iteration: 20347
[[ 1.99965692]
 [ 4.00915236]
 [-1.07722566]] loss fxn value:  0.12495248629807926 learn rate: 1.5625e-05 iteration: 20348
[[ 1.99965695]
 [ 4.00915237]
 [-1.07722761]] loss fxn value:  0.12491778057786534 learn rate: 1.5625e-05 iteration: 20349
[[ 1.99965699]
 [ 4.00915238]
 [-1.07722956]] loss fxn value:  0.1248830844972021 learn rate: 1.5625e-05 iteration: 20350
[[ 1.99965702]
 [ 4.00915239]
 [-1.07723151]] loss fxn value:  0.12484839805298782 learn rate: 1.5625e-05 iteration: 20351
[[ 1.99965705]
 [ 4.0091524 ]
 [-1.07723346]] loss fxn value:  0.1248137212428727 learn rate: 1.5625e-05 iteration: 20352
[[ 1.99965708]
 [ 4.00915241]
 [-1.07723541]] loss fxn value:  0.12477905406511902 learn rate: 1.5625e-05 iteration: 20353
[[ 1.99965712]
 [ 4.00915242]
 [-1.07723736]] loss fxn value:  0.12474439651558684 learn rate: 1.5625e-05 iteration: 20354
[[ 1.99965715]
 [ 4.00915243]
 [-1.07723931]] loss fxn value:  0.12470974859244822 learn rate: 1.5625e-05 iteration: 20355
[[ 1.99965718]
 [ 4.00915244]
 [-1.07724126]] loss fxn value:  0.1246751102930368 learn rate: 1.5625e-05 iteration: 20356
[[ 1.99965721]
 [ 4.00915245]
 [-1.07724321]] loss fxn value:  0.12464048161405102 learn rate: 1.5625e-05 iteration: 20357
[[ 1.99965725]
 [ 4.00915246]
 [-1.07724515]] loss fxn value:  0.12460586255290552 learn rate: 1.5625e-05 iteration: 20358
[[ 1.99965728]
 [ 4.00915247]
 [-1.0772471 ]] loss fxn value:  0.1245712531081553 learn rate: 1.5625e-05 iteration: 20359
[[ 1.99965731]
 [ 4.00915248]
 [-1.07724905]] loss fxn value:  0.12453665327567043 learn rate: 1.5625e-05 iteration: 20360
[[ 1.99965734]
 [ 4.00915249]
 [-1.07725099]] loss fxn value:  0.12450206305328164 learn rate: 1.5625e-05 iteration: 20361
[[ 1.99965738]
 [ 4.0091525 ]
 [-1.07725294]] loss fxn value:  0.12446748243863998 learn rate: 1.5625e-05 iteration: 20362
[[ 1.99965741]
 [ 4.00915251]
 [-1.07725488]] loss fxn value:  0.12443291142856502 learn rate: 1.5625e-05 iteration: 20363
[[ 1.99965744]
 [ 4.00915252]
 [-1.07725683]] loss fxn value:  0.12439835002129973 learn rate: 1.5625e-05 iteration: 20364
[[ 1.99965747]
 [ 4.00915253]
 [-1.07725877]] loss fxn value:  0.12436379821218317 learn rate: 1.5625e-05 iteration: 20365
[[ 1.99965751]
 [ 4.00915254]
 [-1.07726071]] loss fxn value:  0.12432925600190298 learn rate: 1.5625e-05 iteration: 20366
[[ 1.99965754]
 [ 4.00915255]
 [-1.07726265]] loss fxn value:  0.1242947233836779 learn rate: 1.5625e-05 iteration: 20367
[[ 1.99965757]
 [ 4.00915256]
 [-1.0772646 ]] loss fxn value:  0.12426020035749986 learn rate: 1.5625e-05 iteration: 20368
[[ 1.9996576 ]
 [ 4.00915257]
 [-1.07726654]] loss fxn value:  0.1242256869208579 learn rate: 1.5625e-05 iteration: 20369
[[ 1.99965764]
 [ 4.00915258]
 [-1.07726848]] loss fxn value:  0.12419118307059782 learn rate: 1.5625e-05 iteration: 20370
[[ 1.99965767]
 [ 4.00915259]
 [-1.07727042]] loss fxn value:  0.12415668880260126 learn rate: 1.5625e-05 iteration: 20371
[[ 1.9996577 ]
 [ 4.0091526 ]
 [-1.07727236]] loss fxn value:  0.12412220411561375 learn rate: 1.5625e-05 iteration: 20372
[[ 1.99965773]
 [ 4.00915261]
 [-1.0772743 ]] loss fxn value:  0.12408772900773558 learn rate: 1.5625e-05 iteration: 20373
[[ 1.99965777]
 [ 4.00915262]
 [-1.07727624]] loss fxn value:  0.12405326347393443 learn rate: 1.5625e-05 iteration: 20374
[[ 1.9996578 ]
 [ 4.00915263]
 [-1.07727817]] loss fxn value:  0.12401880751384356 learn rate: 1.5625e-05 iteration: 20375
[[ 1.99965783]
 [ 4.00915264]
 [-1.07728011]] loss fxn value:  0.12398436112422082 learn rate: 1.5625e-05 iteration: 20376
[[ 1.99965786]
 [ 4.00915265]
 [-1.07728205]] loss fxn value:  0.12394992430285451 learn rate: 1.5625e-05 iteration: 20377
[[ 1.99965789]
 [ 4.00915266]
 [-1.07728398]] loss fxn value:  0.12391549704504362 learn rate: 1.5625e-05 iteration: 20378
[[ 1.99965793]
 [ 4.00915267]
 [-1.07728592]] loss fxn value:  0.12388107934911907 learn rate: 1.5625e-05 iteration: 20379
[[ 1.99965796]
 [ 4.00915268]
 [-1.07728786]] loss fxn value:  0.12384667121375459 learn rate: 1.5625e-05 iteration: 20380
[[ 1.99965799]
 [ 4.00915269]
 [-1.07728979]] loss fxn value:  0.12381227263414966 learn rate: 1.5625e-05 iteration: 20381
[[ 1.99965802]
 [ 4.0091527 ]
 [-1.07729172]] loss fxn value:  0.12377788361070768 learn rate: 1.5625e-05 iteration: 20382
[[ 1.99965806]
 [ 4.00915271]
 [-1.07729366]] loss fxn value:  0.12374350413703805 learn rate: 1.5625e-05 iteration: 20383
[[ 1.99965809]
 [ 4.00915272]
 [-1.07729559]] loss fxn value:  0.12370913421363752 learn rate: 1.5625e-05 iteration: 20384
[[ 1.99965812]
 [ 4.00915273]
 [-1.07729752]] loss fxn value:  0.12367477383600518 learn rate: 1.5625e-05 iteration: 20385
[[ 1.99965815]
 [ 4.00915274]
 [-1.07729946]] loss fxn value:  0.1236404230015626 learn rate: 1.5625e-05 iteration: 20386
[[ 1.99965819]
 [ 4.00915275]
 [-1.07730139]] loss fxn value:  0.12360608170814362 learn rate: 1.5625e-05 iteration: 20387
[[ 1.99965822]
 [ 4.00915276]
 [-1.07730332]] loss fxn value:  0.1235717499537698 learn rate: 1.5625e-05 iteration: 20388
[[ 1.99965825]
 [ 4.00915277]
 [-1.07730525]] loss fxn value:  0.12353742773442546 learn rate: 1.5625e-05 iteration: 20389
[[ 1.99965828]
 [ 4.00915278]
 [-1.07730718]] loss fxn value:  0.1235031150482988 learn rate: 1.5625e-05 iteration: 20390
[[ 1.99965831]
 [ 4.00915279]
 [-1.07730911]] loss fxn value:  0.12346881189307636 learn rate: 1.5625e-05 iteration: 20391
[[ 1.99965835]
 [ 4.0091528 ]
 [-1.07731104]] loss fxn value:  0.12343451826607013 learn rate: 1.5625e-05 iteration: 20392
[[ 1.99965838]
 [ 4.00915281]
 [-1.07731297]] loss fxn value:  0.12340023416266471 learn rate: 1.5625e-05 iteration: 20393
[[ 1.99965841]
 [ 4.00915282]
 [-1.07731489]] loss fxn value:  0.12336595958204562 learn rate: 1.5625e-05 iteration: 20394
[[ 1.99965844]
 [ 4.00915282]
 [-1.07731682]] loss fxn value:  0.12333169452142075 learn rate: 1.5625e-05 iteration: 20395
[[ 1.99965847]
 [ 4.00915283]
 [-1.07731875]] loss fxn value:  0.12329743897806666 learn rate: 1.5625e-05 iteration: 20396
[[ 1.99965851]
 [ 4.00915284]
 [-1.07732067]] loss fxn value:  0.12326319294976706 learn rate: 1.5625e-05 iteration: 20397
[[ 1.99965854]
 [ 4.00915285]
 [-1.0773226 ]] loss fxn value:  0.12322895643276573 learn rate: 1.5625e-05 iteration: 20398
[[ 1.99965857]
 [ 4.00915286]
 [-1.07732452]] loss fxn value:  0.1231947294253982 learn rate: 1.5625e-05 iteration: 20399
[[ 1.9996586 ]
 [ 4.00915287]
 [-1.07732645]] loss fxn value:  0.1231605119238705 learn rate: 1.5625e-05 iteration: 20400
[[ 1.99965864]
 [ 4.00915288]
 [-1.07732837]] loss fxn value:  0.12312630392691574 learn rate: 1.5625e-05 iteration: 20401
[[ 1.99965867]
 [ 4.00915289]
 [-1.0773303 ]] loss fxn value:  0.12309210543094899 learn rate: 1.5625e-05 iteration: 20402
[[ 1.9996587 ]
 [ 4.0091529 ]
 [-1.07733222]] loss fxn value:  0.12305791643399495 learn rate: 1.5625e-05 iteration: 20403
[[ 1.99965873]
 [ 4.00915291]
 [-1.07733414]] loss fxn value:  0.1230237369329796 learn rate: 1.5625e-05 iteration: 20404
[[ 1.99965876]
 [ 4.00915292]
 [-1.07733606]] loss fxn value:  0.12298956692464925 learn rate: 1.5625e-05 iteration: 20405
[[ 1.9996588 ]
 [ 4.00915293]
 [-1.07733799]] loss fxn value:  0.12295540640775866 learn rate: 1.5625e-05 iteration: 20406
[[ 1.99965883]
 [ 4.00915294]
 [-1.07733991]] loss fxn value:  0.1229212553790086 learn rate: 1.5625e-05 iteration: 20407
[[ 1.99965886]
 [ 4.00915295]
 [-1.07734183]] loss fxn value:  0.12288711383575893 learn rate: 1.5625e-05 iteration: 20408
[[ 1.99965889]
 [ 4.00915296]
 [-1.07734375]] loss fxn value:  0.12285298177513426 learn rate: 1.5625e-05 iteration: 20409
[[ 1.99965892]
 [ 4.00915297]
 [-1.07734567]] loss fxn value:  0.1228188591950656 learn rate: 1.5625e-05 iteration: 20410
[[ 1.99965896]
 [ 4.00915298]
 [-1.07734759]] loss fxn value:  0.12278474609265365 learn rate: 1.5625e-05 iteration: 20411
[[ 1.99965899]
 [ 4.00915299]
 [-1.0773495 ]] loss fxn value:  0.12275064246485143 learn rate: 1.5625e-05 iteration: 20412
[[ 1.99965902]
 [ 4.009153  ]
 [-1.07735142]] loss fxn value:  0.12271654830970674 learn rate: 1.5625e-05 iteration: 20413
[[ 1.99965905]
 [ 4.00915301]
 [-1.07735334]] loss fxn value:  0.1226824636241441 learn rate: 1.5625e-05 iteration: 20414
[[ 1.99965908]
 [ 4.00915302]
 [-1.07735525]] loss fxn value:  0.12264838840626148 learn rate: 1.5625e-05 iteration: 20415
[[ 1.99965912]
 [ 4.00915303]
 [-1.07735717]] loss fxn value:  0.1226143226515977 learn rate: 1.5625e-05 iteration: 20416
[[ 1.99965915]
 [ 4.00915304]
 [-1.07735909]] loss fxn value:  0.12258026635913158 learn rate: 1.5625e-05 iteration: 20417
[[ 1.99965918]
 [ 4.00915305]
 [-1.077361  ]] loss fxn value:  0.12254621952627309 learn rate: 1.5625e-05 iteration: 20418
[[ 1.99965921]
 [ 4.00915306]
 [-1.07736292]] loss fxn value:  0.12251218214975622 learn rate: 1.5625e-05 iteration: 20419
[[ 1.99965924]
 [ 4.00915307]
 [-1.07736483]] loss fxn value:  0.12247815422682665 learn rate: 1.5625e-05 iteration: 20420
[[ 1.99965928]
 [ 4.00915308]
 [-1.07736674]] loss fxn value:  0.12244413575526343 learn rate: 1.5625e-05 iteration: 20421
[[ 1.99965931]
 [ 4.00915309]
 [-1.07736866]] loss fxn value:  0.12241012673280012 learn rate: 1.5625e-05 iteration: 20422
[[ 1.99965934]
 [ 4.0091531 ]
 [-1.07737057]] loss fxn value:  0.12237612715527599 learn rate: 1.5625e-05 iteration: 20423
[[ 1.99965937]
 [ 4.00915311]
 [-1.07737248]] loss fxn value:  0.12234213702287844 learn rate: 1.5625e-05 iteration: 20424
[[ 1.9996594 ]
 [ 4.00915312]
 [-1.07737439]] loss fxn value:  0.12230815632978576 learn rate: 1.5625e-05 iteration: 20425
[[ 1.99965944]
 [ 4.00915313]
 [-1.0773763 ]] loss fxn value:  0.12227418507644683 learn rate: 1.5625e-05 iteration: 20426
[[ 1.99965947]
 [ 4.00915314]
 [-1.07737821]] loss fxn value:  0.12224022325790376 learn rate: 1.5625e-05 iteration: 20427
[[ 1.9996595 ]
 [ 4.00915315]
 [-1.07738012]] loss fxn value:  0.12220627087172081 learn rate: 1.5625e-05 iteration: 20428
[[ 1.99965953]
 [ 4.00915316]
 [-1.07738203]] loss fxn value:  0.12217232791687216 learn rate: 1.5625e-05 iteration: 20429
[[ 1.99965956]
 [ 4.00915317]
 [-1.07738394]] loss fxn value:  0.1221383943883255 learn rate: 1.5625e-05 iteration: 20430
[[ 1.99965959]
 [ 4.00915318]
 [-1.07738585]] loss fxn value:  0.1221044702856786 learn rate: 1.5625e-05 iteration: 20431
[[ 1.99965963]
 [ 4.00915318]
 [-1.07738776]] loss fxn value:  0.12207055560581968 learn rate: 1.5625e-05 iteration: 20432
[[ 1.99965966]
 [ 4.00915319]
 [-1.07738966]] loss fxn value:  0.12203665034584016 learn rate: 1.5625e-05 iteration: 20433
[[ 1.99965969]
 [ 4.0091532 ]
 [-1.07739157]] loss fxn value:  0.12200275450267377 learn rate: 1.5625e-05 iteration: 20434
[[ 1.99965972]
 [ 4.00915321]
 [-1.07739348]] loss fxn value:  0.12196886807358552 learn rate: 1.5625e-05 iteration: 20435
[[ 1.99965975]
 [ 4.00915322]
 [-1.07739538]] loss fxn value:  0.12193499105816312 learn rate: 1.5625e-05 iteration: 20436
[[ 1.99965979]
 [ 4.00915323]
 [-1.07739729]] loss fxn value:  0.12190112345030837 learn rate: 1.5625e-05 iteration: 20437
[[ 1.99965982]
 [ 4.00915324]
 [-1.07739919]] loss fxn value:  0.12186726525077286 learn rate: 1.5625e-05 iteration: 20438
[[ 1.99965985]
 [ 4.00915325]
 [-1.07740109]] loss fxn value:  0.12183341645378191 learn rate: 1.5625e-05 iteration: 20439
[[ 1.99965988]
 [ 4.00915326]
 [-1.077403  ]] loss fxn value:  0.12179957706004707 learn rate: 1.5625e-05 iteration: 20440
[[ 1.99965991]
 [ 4.00915327]
 [-1.0774049 ]] loss fxn value:  0.12176574706351251 learn rate: 1.5625e-05 iteration: 20441
[[ 1.99965994]
 [ 4.00915328]
 [-1.0774068 ]] loss fxn value:  0.12173192646423991 learn rate: 1.5625e-05 iteration: 20442
[[ 1.99965998]
 [ 4.00915329]
 [-1.0774087 ]] loss fxn value:  0.12169811525904423 learn rate: 1.5625e-05 iteration: 20443
[[ 1.99966001]
 [ 4.0091533 ]
 [-1.07741061]] loss fxn value:  0.1216643134446594 learn rate: 1.5625e-05 iteration: 20444
[[ 1.99966004]
 [ 4.00915331]
 [-1.07741251]] loss fxn value:  0.12163052101895243 learn rate: 1.5625e-05 iteration: 20445
[[ 1.99966007]
 [ 4.00915332]
 [-1.07741441]] loss fxn value:  0.12159673797859787 learn rate: 1.5625e-05 iteration: 20446
[[ 1.9996601 ]
 [ 4.00915333]
 [-1.07741631]] loss fxn value:  0.12156296432098641 learn rate: 1.5625e-05 iteration: 20447
[[ 1.99966013]
 [ 4.00915334]
 [-1.07741821]] loss fxn value:  0.12152920004563025 learn rate: 1.5625e-05 iteration: 20448
[[ 1.99966017]
 [ 4.00915335]
 [-1.0774201 ]] loss fxn value:  0.12149544514743767 learn rate: 1.5625e-05 iteration: 20449
[[ 1.9996602 ]
 [ 4.00915336]
 [-1.077422  ]] loss fxn value:  0.12146169962470875 learn rate: 1.5625e-05 iteration: 20450
[[ 1.99966023]
 [ 4.00915337]
 [-1.0774239 ]] loss fxn value:  0.12142796347514384 learn rate: 1.5625e-05 iteration: 20451
[[ 1.99966026]
 [ 4.00915338]
 [-1.0774258 ]] loss fxn value:  0.12139423669546998 learn rate: 1.5625e-05 iteration: 20452
[[ 1.99966029]
 [ 4.00915339]
 [-1.07742769]] loss fxn value:  0.12136051928356338 learn rate: 1.5625e-05 iteration: 20453
[[ 1.99966032]
 [ 4.0091534 ]
 [-1.07742959]] loss fxn value:  0.12132681123748197 learn rate: 1.5625e-05 iteration: 20454
[[ 1.99966036]
 [ 4.00915341]
 [-1.07743148]] loss fxn value:  0.12129311255270979 learn rate: 1.5625e-05 iteration: 20455
[[ 1.99966039]
 [ 4.00915342]
 [-1.07743338]] loss fxn value:  0.12125942322840148 learn rate: 1.5625e-05 iteration: 20456
[[ 1.99966042]
 [ 4.00915343]
 [-1.07743527]] loss fxn value:  0.12122574326079394 learn rate: 1.5625e-05 iteration: 20457
[[ 1.99966045]
 [ 4.00915344]
 [-1.07743717]] loss fxn value:  0.12119207264867737 learn rate: 1.5625e-05 iteration: 20458
[[ 1.99966048]
 [ 4.00915345]
 [-1.07743906]] loss fxn value:  0.12115841138829325 learn rate: 1.5625e-05 iteration: 20459
[[ 1.99966051]
 [ 4.00915345]
 [-1.07744095]] loss fxn value:  0.12112475947691351 learn rate: 1.5625e-05 iteration: 20460
[[ 1.99966055]
 [ 4.00915346]
 [-1.07744285]] loss fxn value:  0.1210911169128336 learn rate: 1.5625e-05 iteration: 20461
[[ 1.99966058]
 [ 4.00915347]
 [-1.07744474]] loss fxn value:  0.12105748369272806 learn rate: 1.5625e-05 iteration: 20462
[[ 1.99966061]
 [ 4.00915348]
 [-1.07744663]] loss fxn value:  0.12102385981448009 learn rate: 1.5625e-05 iteration: 20463
[[ 1.99966064]
 [ 4.00915349]
 [-1.07744852]] loss fxn value:  0.12099024527561501 learn rate: 1.5625e-05 iteration: 20464
[[ 1.99966067]
 [ 4.0091535 ]
 [-1.07745041]] loss fxn value:  0.1209566400727229 learn rate: 1.5625e-05 iteration: 20465
[[ 1.9996607 ]
 [ 4.00915351]
 [-1.0774523 ]] loss fxn value:  0.12092304420422838 learn rate: 1.5625e-05 iteration: 20466
[[ 1.99966073]
 [ 4.00915352]
 [-1.07745419]] loss fxn value:  0.12088945766666759 learn rate: 1.5625e-05 iteration: 20467
[[ 1.99966077]
 [ 4.00915353]
 [-1.07745608]] loss fxn value:  0.12085588045810765 learn rate: 1.5625e-05 iteration: 20468
[[ 1.9996608 ]
 [ 4.00915354]
 [-1.07745797]] loss fxn value:  0.12082231257493505 learn rate: 1.5625e-05 iteration: 20469
[[ 1.99966083]
 [ 4.00915355]
 [-1.07745985]] loss fxn value:  0.12078875401582354 learn rate: 1.5625e-05 iteration: 20470
[[ 1.99966086]
 [ 4.00915356]
 [-1.07746174]] loss fxn value:  0.12075520477803582 learn rate: 1.5625e-05 iteration: 20471
[[ 1.99966089]
 [ 4.00915357]
 [-1.07746363]] loss fxn value:  0.12072166485784422 learn rate: 1.5625e-05 iteration: 20472
[[ 1.99966092]
 [ 4.00915358]
 [-1.07746551]] loss fxn value:  0.12068813425406981 learn rate: 1.5625e-05 iteration: 20473
[[ 1.99966096]
 [ 4.00915359]
 [-1.0774674 ]] loss fxn value:  0.12065461296287074 learn rate: 1.5625e-05 iteration: 20474
[[ 1.99966099]
 [ 4.0091536 ]
 [-1.07746928]] loss fxn value:  0.12062110098299024 learn rate: 1.5625e-05 iteration: 20475
[[ 1.99966102]
 [ 4.00915361]
 [-1.07747117]] loss fxn value:  0.12058759830989305 learn rate: 1.5625e-05 iteration: 20476
[[ 1.99966105]
 [ 4.00915362]
 [-1.07747305]] loss fxn value:  0.12055410494359615 learn rate: 1.5625e-05 iteration: 20477
[[ 1.99966108]
 [ 4.00915363]
 [-1.07747493]] loss fxn value:  0.12052062087896005 learn rate: 1.5625e-05 iteration: 20478
[[ 1.99966111]
 [ 4.00915364]
 [-1.07747682]] loss fxn value:  0.12048714611525121 learn rate: 1.5625e-05 iteration: 20479
[[ 1.99966114]
 [ 4.00915365]
 [-1.0774787 ]] loss fxn value:  0.12045368064913498 learn rate: 1.5625e-05 iteration: 20480
[[ 1.99966118]
 [ 4.00915366]
 [-1.07748058]] loss fxn value:  0.12042022447800664 learn rate: 1.5625e-05 iteration: 20481
[[ 1.99966121]
 [ 4.00915367]
 [-1.07748246]] loss fxn value:  0.12038677759955738 learn rate: 1.5625e-05 iteration: 20482
[[ 1.99966124]
 [ 4.00915368]
 [-1.07748434]] loss fxn value:  0.12035334001101124 learn rate: 1.5625e-05 iteration: 20483
[[ 1.99966127]
 [ 4.00915368]
 [-1.07748622]] loss fxn value:  0.12031991170916703 learn rate: 1.5625e-05 iteration: 20484
[[ 1.9996613 ]
 [ 4.00915369]
 [-1.0774881 ]] loss fxn value:  0.12028649269328119 learn rate: 1.5625e-05 iteration: 20485
[[ 1.99966133]
 [ 4.0091537 ]
 [-1.07748998]] loss fxn value:  0.12025308295810083 learn rate: 1.5625e-05 iteration: 20486
[[ 1.99966136]
 [ 4.00915371]
 [-1.07749186]] loss fxn value:  0.1202196825029634 learn rate: 1.5625e-05 iteration: 20487
[[ 1.99966139]
 [ 4.00915372]
 [-1.07749374]] loss fxn value:  0.12018629132495573 learn rate: 1.5625e-05 iteration: 20488
[[ 1.99966143]
 [ 4.00915373]
 [-1.07749562]] loss fxn value:  0.12015290942241565 learn rate: 1.5625e-05 iteration: 20489
[[ 1.99966146]
 [ 4.00915374]
 [-1.07749749]] loss fxn value:  0.1201195367910683 learn rate: 1.5625e-05 iteration: 20490
[[ 1.99966149]
 [ 4.00915375]
 [-1.07749937]] loss fxn value:  0.12008617342875673 learn rate: 1.5625e-05 iteration: 20491
[[ 1.99966152]
 [ 4.00915376]
 [-1.07750125]] loss fxn value:  0.12005281933281689 learn rate: 1.5625e-05 iteration: 20492
[[ 1.99966155]
 [ 4.00915377]
 [-1.07750312]] loss fxn value:  0.12001947450218979 learn rate: 1.5625e-05 iteration: 20493
[[ 1.99966158]
 [ 4.00915378]
 [-1.077505  ]] loss fxn value:  0.11998613893238805 learn rate: 1.5625e-05 iteration: 20494
[[ 1.99966161]
 [ 4.00915379]
 [-1.07750687]] loss fxn value:  0.11995281262113365 learn rate: 1.5625e-05 iteration: 20495
[[ 1.99966165]
 [ 4.0091538 ]
 [-1.07750875]] loss fxn value:  0.11991949556718597 learn rate: 1.5625e-05 iteration: 20496
[[ 1.99966168]
 [ 4.00915381]
 [-1.07751062]] loss fxn value:  0.11988618776663681 learn rate: 1.5625e-05 iteration: 20497
[[ 1.99966171]
 [ 4.00915382]
 [-1.07751249]] loss fxn value:  0.11985288921702891 learn rate: 1.5625e-05 iteration: 20498
[[ 1.99966174]
 [ 4.00915383]
 [-1.07751437]] loss fxn value:  0.11981959991593688 learn rate: 1.5625e-05 iteration: 20499
[[ 1.99966177]
 [ 4.00915384]
 [-1.07751624]] loss fxn value:  0.11978631986206069 learn rate: 1.5625e-05 iteration: 20500
[[ 1.9996618 ]
 [ 4.00915385]
 [-1.07751811]] loss fxn value:  0.11975304905221762 learn rate: 1.5625e-05 iteration: 20501
[[ 1.99966183]
 [ 4.00915386]
 [-1.07751998]] loss fxn value:  0.11971978748173054 learn rate: 1.5625e-05 iteration: 20502
[[ 1.99966186]
 [ 4.00915387]
 [-1.07752185]] loss fxn value:  0.11968653514988215 learn rate: 1.5625e-05 iteration: 20503
[[ 1.99966189]
 [ 4.00915388]
 [-1.07752372]] loss fxn value:  0.11965329205569443 learn rate: 1.5625e-05 iteration: 20504
[[ 1.99966193]
 [ 4.00915388]
 [-1.07752559]] loss fxn value:  0.1196200581926615 learn rate: 1.5625e-05 iteration: 20505
[[ 1.99966196]
 [ 4.00915389]
 [-1.07752746]] loss fxn value:  0.11958683356156125 learn rate: 1.5625e-05 iteration: 20506
[[ 1.99966199]
 [ 4.0091539 ]
 [-1.07752933]] loss fxn value:  0.11955361815837363 learn rate: 1.5625e-05 iteration: 20507
[[ 1.99966202]
 [ 4.00915391]
 [-1.07753119]] loss fxn value:  0.11952041198114388 learn rate: 1.5625e-05 iteration: 20508
[[ 1.99966205]
 [ 4.00915392]
 [-1.07753306]] loss fxn value:  0.11948721502687777 learn rate: 1.5625e-05 iteration: 20509
[[ 1.99966208]
 [ 4.00915393]
 [-1.07753493]] loss fxn value:  0.11945402729263245 learn rate: 1.5625e-05 iteration: 20510
[[ 1.99966211]
 [ 4.00915394]
 [-1.07753679]] loss fxn value:  0.1194208487768634 learn rate: 1.5625e-05 iteration: 20511
[[ 1.99966214]
 [ 4.00915395]
 [-1.07753866]] loss fxn value:  0.11938767947508554 learn rate: 1.5625e-05 iteration: 20512
[[ 1.99966218]
 [ 4.00915396]
 [-1.07754052]] loss fxn value:  0.11935451938784379 learn rate: 1.5625e-05 iteration: 20513
[[ 1.99966221]
 [ 4.00915397]
 [-1.07754239]] loss fxn value:  0.1193213685099608 learn rate: 1.5625e-05 iteration: 20514
[[ 1.99966224]
 [ 4.00915398]
 [-1.07754425]] loss fxn value:  0.11928822684024384 learn rate: 1.5625e-05 iteration: 20515
[[ 1.99966227]
 [ 4.00915399]
 [-1.07754612]] loss fxn value:  0.11925509437539364 learn rate: 1.5625e-05 iteration: 20516
[[ 1.9996623 ]
 [ 4.009154  ]
 [-1.07754798]] loss fxn value:  0.11922197111319852 learn rate: 1.5625e-05 iteration: 20517
[[ 1.99966233]
 [ 4.00915401]
 [-1.07754984]] loss fxn value:  0.11918885705087795 learn rate: 1.5625e-05 iteration: 20518
[[ 1.99966236]
 [ 4.00915402]
 [-1.0775517 ]] loss fxn value:  0.11915575218668037 learn rate: 1.5625e-05 iteration: 20519
[[ 1.99966239]
 [ 4.00915403]
 [-1.07755357]] loss fxn value:  0.11912265651687035 learn rate: 1.5625e-05 iteration: 20520
[[ 1.99966242]
 [ 4.00915404]
 [-1.07755543]] loss fxn value:  0.1190895700397364 learn rate: 1.5625e-05 iteration: 20521
[[ 1.99966245]
 [ 4.00915405]
 [-1.07755729]] loss fxn value:  0.11905649275155782 learn rate: 1.5625e-05 iteration: 20522
[[ 1.99966249]
 [ 4.00915405]
 [-1.07755915]] loss fxn value:  0.1190234246510253 learn rate: 1.5625e-05 iteration: 20523
[[ 1.99966252]
 [ 4.00915406]
 [-1.07756101]] loss fxn value:  0.11899036573590327 learn rate: 1.5625e-05 iteration: 20524
[[ 1.99966255]
 [ 4.00915407]
 [-1.07756287]] loss fxn value:  0.11895731600288094 learn rate: 1.5625e-05 iteration: 20525
[[ 1.99966258]
 [ 4.00915408]
 [-1.07756472]] loss fxn value:  0.11892427544789476 learn rate: 1.5625e-05 iteration: 20526
[[ 1.99966261]
 [ 4.00915409]
 [-1.07756658]] loss fxn value:  0.11889124407203916 learn rate: 1.5625e-05 iteration: 20527
[[ 1.99966264]
 [ 4.0091541 ]
 [-1.07756844]] loss fxn value:  0.11885822186956338 learn rate: 1.5625e-05 iteration: 20528
[[ 1.99966267]
 [ 4.00915411]
 [-1.0775703 ]] loss fxn value:  0.11882520883982185 learn rate: 1.5625e-05 iteration: 20529
[[ 1.9996627 ]
 [ 4.00915412]
 [-1.07757215]] loss fxn value:  0.1187922049785397 learn rate: 1.5625e-05 iteration: 20530
[[ 1.99966273]
 [ 4.00915413]
 [-1.07757401]] loss fxn value:  0.11875921028447625 learn rate: 1.5625e-05 iteration: 20531
[[ 1.99966276]
 [ 4.00915414]
 [-1.07757586]] loss fxn value:  0.1187262247543277 learn rate: 1.5625e-05 iteration: 20532
[[ 1.9996628 ]
 [ 4.00915415]
 [-1.07757772]] loss fxn value:  0.1186932483863918 learn rate: 1.5625e-05 iteration: 20533
[[ 1.99966283]
 [ 4.00915416]
 [-1.07757957]] loss fxn value:  0.11866028117791654 learn rate: 1.5625e-05 iteration: 20534
[[ 1.99966286]
 [ 4.00915417]
 [-1.07758143]] loss fxn value:  0.11862732312657147 learn rate: 1.5625e-05 iteration: 20535
[[ 1.99966289]
 [ 4.00915418]
 [-1.07758328]] loss fxn value:  0.11859437422825522 learn rate: 1.5625e-05 iteration: 20536
[[ 1.99966292]
 [ 4.00915419]
 [-1.07758513]] loss fxn value:  0.11856143448218187 learn rate: 1.5625e-05 iteration: 20537
[[ 1.99966295]
 [ 4.0091542 ]
 [-1.07758699]] loss fxn value:  0.11852850388501442 learn rate: 1.5625e-05 iteration: 20538
[[ 1.99966298]
 [ 4.00915421]
 [-1.07758884]] loss fxn value:  0.11849558243412425 learn rate: 1.5625e-05 iteration: 20539
[[ 1.99966301]
 [ 4.00915421]
 [-1.07759069]] loss fxn value:  0.1184626701272002 learn rate: 1.5625e-05 iteration: 20540
[[ 1.99966304]
 [ 4.00915422]
 [-1.07759254]] loss fxn value:  0.11842976696154046 learn rate: 1.5625e-05 iteration: 20541
[[ 1.99966307]
 [ 4.00915423]
 [-1.07759439]] loss fxn value:  0.11839687293531159 learn rate: 1.5625e-05 iteration: 20542
[[ 1.9996631 ]
 [ 4.00915424]
 [-1.07759624]] loss fxn value:  0.11836398804580255 learn rate: 1.5625e-05 iteration: 20543
[[ 1.99966314]
 [ 4.00915425]
 [-1.07759809]] loss fxn value:  0.11833111228929258 learn rate: 1.5625e-05 iteration: 20544
[[ 1.99966317]
 [ 4.00915426]
 [-1.07759994]] loss fxn value:  0.11829824566405552 learn rate: 1.5625e-05 iteration: 20545
[[ 1.9996632 ]
 [ 4.00915427]
 [-1.07760178]] loss fxn value:  0.11826538816783268 learn rate: 1.5625e-05 iteration: 20546
[[ 1.99966323]
 [ 4.00915428]
 [-1.07760363]] loss fxn value:  0.1182325397987621 learn rate: 1.5625e-05 iteration: 20547
[[ 1.99966326]
 [ 4.00915429]
 [-1.07760548]] loss fxn value:  0.11819970055219753 learn rate: 1.5625e-05 iteration: 20548
[[ 1.99966329]
 [ 4.0091543 ]
 [-1.07760733]] loss fxn value:  0.11816687042692457 learn rate: 1.5625e-05 iteration: 20549
[[ 1.99966332]
 [ 4.00915431]
 [-1.07760917]] loss fxn value:  0.11813404942070299 learn rate: 1.5625e-05 iteration: 20550
[[ 1.99966335]
 [ 4.00915432]
 [-1.07761102]] loss fxn value:  0.11810123753062422 learn rate: 1.5625e-05 iteration: 20551
[[ 1.99966338]
 [ 4.00915433]
 [-1.07761286]] loss fxn value:  0.1180684347531342 learn rate: 1.5625e-05 iteration: 20552
[[ 1.99966341]
 [ 4.00915434]
 [-1.07761471]] loss fxn value:  0.11803564108697291 learn rate: 1.5625e-05 iteration: 20553
[[ 1.99966344]
 [ 4.00915435]
 [-1.07761655]] loss fxn value:  0.1180028565296773 learn rate: 1.5625e-05 iteration: 20554
[[ 1.99966347]
 [ 4.00915436]
 [-1.07761839]] loss fxn value:  0.11797008107873064 learn rate: 1.5625e-05 iteration: 20555
[[ 1.99966351]
 [ 4.00915436]
 [-1.07762024]] loss fxn value:  0.11793731473071718 learn rate: 1.5625e-05 iteration: 20556
[[ 1.99966354]
 [ 4.00915437]
 [-1.07762208]] loss fxn value:  0.11790455748356336 learn rate: 1.5625e-05 iteration: 20557
[[ 1.99966357]
 [ 4.00915438]
 [-1.07762392]] loss fxn value:  0.11787180933441539 learn rate: 1.5625e-05 iteration: 20558
[[ 1.9996636 ]
 [ 4.00915439]
 [-1.07762576]] loss fxn value:  0.11783907028202488 learn rate: 1.5625e-05 iteration: 20559
[[ 1.99966363]
 [ 4.0091544 ]
 [-1.0776276 ]] loss fxn value:  0.11780634032257706 learn rate: 1.5625e-05 iteration: 20560
[[ 1.99966366]
 [ 4.00915441]
 [-1.07762945]] loss fxn value:  0.11777361945305036 learn rate: 1.5625e-05 iteration: 20561
[[ 1.99966369]
 [ 4.00915442]
 [-1.07763128]] loss fxn value:  0.1177409076729901 learn rate: 1.5625e-05 iteration: 20562
[[ 1.99966372]
 [ 4.00915443]
 [-1.07763312]] loss fxn value:  0.11770820497815455 learn rate: 1.5625e-05 iteration: 20563
[[ 1.99966375]
 [ 4.00915444]
 [-1.07763496]] loss fxn value:  0.11767551136595834 learn rate: 1.5625e-05 iteration: 20564
[[ 1.99966378]
 [ 4.00915445]
 [-1.0776368 ]] loss fxn value:  0.11764282683547281 learn rate: 1.5625e-05 iteration: 20565
[[ 1.99966381]
 [ 4.00915446]
 [-1.07763864]] loss fxn value:  0.11761015138251561 learn rate: 1.5625e-05 iteration: 20566
[[ 1.99966384]
 [ 4.00915447]
 [-1.07764048]] loss fxn value:  0.11757748500535367 learn rate: 1.5625e-05 iteration: 20567
[[ 1.99966387]
 [ 4.00915448]
 [-1.07764231]] loss fxn value:  0.11754482770222534 learn rate: 1.5625e-05 iteration: 20568
[[ 1.9996639 ]
 [ 4.00915449]
 [-1.07764415]] loss fxn value:  0.11751217946880096 learn rate: 1.5625e-05 iteration: 20569
[[ 1.99966393]
 [ 4.0091545 ]
 [-1.07764599]] loss fxn value:  0.11747954030259464 learn rate: 1.5625e-05 iteration: 20570
[[ 1.99966397]
 [ 4.0091545 ]
 [-1.07764782]] loss fxn value:  0.11744691020405412 learn rate: 1.5625e-05 iteration: 20571
[[ 1.999664  ]
 [ 4.00915451]
 [-1.07764966]] loss fxn value:  0.11741428916700943 learn rate: 1.5625e-05 iteration: 20572
[[ 1.99966403]
 [ 4.00915452]
 [-1.07765149]] loss fxn value:  0.11738167719038424 learn rate: 1.5625e-05 iteration: 20573
[[ 1.99966406]
 [ 4.00915453]
 [-1.07765332]] loss fxn value:  0.11734907427318819 learn rate: 1.5625e-05 iteration: 20574
[[ 1.99966409]
 [ 4.00915454]
 [-1.07765516]] loss fxn value:  0.11731648041032956 learn rate: 1.5625e-05 iteration: 20575
[[ 1.99966412]
 [ 4.00915455]
 [-1.07765699]] loss fxn value:  0.11728389560101551 learn rate: 1.5625e-05 iteration: 20576
[[ 1.99966415]
 [ 4.00915456]
 [-1.07765882]] loss fxn value:  0.11725131984194678 learn rate: 1.5625e-05 iteration: 20577
[[ 1.99966418]
 [ 4.00915457]
 [-1.07766065]] loss fxn value:  0.11721875313099732 learn rate: 1.5625e-05 iteration: 20578
[[ 1.99966421]
 [ 4.00915458]
 [-1.07766249]] loss fxn value:  0.11718619546525165 learn rate: 1.5625e-05 iteration: 20579
[[ 1.99966424]
 [ 4.00915459]
 [-1.07766432]] loss fxn value:  0.11715364684214519 learn rate: 1.5625e-05 iteration: 20580
[[ 1.99966427]
 [ 4.0091546 ]
 [-1.07766615]] loss fxn value:  0.1171211072593336 learn rate: 1.5625e-05 iteration: 20581
[[ 1.9996643 ]
 [ 4.00915461]
 [-1.07766798]] loss fxn value:  0.11708857671597617 learn rate: 1.5625e-05 iteration: 20582
[[ 1.99966433]
 [ 4.00915462]
 [-1.07766981]] loss fxn value:  0.11705605520688402 learn rate: 1.5625e-05 iteration: 20583
[[ 1.99966436]
 [ 4.00915463]
 [-1.07767163]] loss fxn value:  0.11702354272999968 learn rate: 1.5625e-05 iteration: 20584
[[ 1.99966439]
 [ 4.00915463]
 [-1.07767346]] loss fxn value:  0.11699103928528312 learn rate: 1.5625e-05 iteration: 20585
[[ 1.99966442]
 [ 4.00915464]
 [-1.07767529]] loss fxn value:  0.11695854486705445 learn rate: 1.5625e-05 iteration: 20586
[[ 1.99966445]
 [ 4.00915465]
 [-1.07767712]] loss fxn value:  0.11692605947383518 learn rate: 1.5625e-05 iteration: 20587
[[ 1.99966448]
 [ 4.00915466]
 [-1.07767894]] loss fxn value:  0.1168935831044876 learn rate: 1.5625e-05 iteration: 20588
[[ 1.99966452]
 [ 4.00915467]
 [-1.07768077]] loss fxn value:  0.1168611157554668 learn rate: 1.5625e-05 iteration: 20589
[[ 1.99966455]
 [ 4.00915468]
 [-1.0776826 ]] loss fxn value:  0.11682865742401621 learn rate: 1.5625e-05 iteration: 20590
[[ 1.99966458]
 [ 4.00915469]
 [-1.07768442]] loss fxn value:  0.11679620810779383 learn rate: 1.5625e-05 iteration: 20591
[[ 1.99966461]
 [ 4.0091547 ]
 [-1.07768625]] loss fxn value:  0.1167637678051614 learn rate: 1.5625e-05 iteration: 20592
[[ 1.99966464]
 [ 4.00915471]
 [-1.07768807]] loss fxn value:  0.11673133651178694 learn rate: 1.5625e-05 iteration: 20593
[[ 1.99966467]
 [ 4.00915472]
 [-1.07768989]] loss fxn value:  0.11669891422652237 learn rate: 1.5625e-05 iteration: 20594
[[ 1.9996647 ]
 [ 4.00915473]
 [-1.07769172]] loss fxn value:  0.11666650094748729 learn rate: 1.5625e-05 iteration: 20595
[[ 1.99966473]
 [ 4.00915474]
 [-1.07769354]] loss fxn value:  0.11663409666998066 learn rate: 1.5625e-05 iteration: 20596
[[ 1.99966476]
 [ 4.00915475]
 [-1.07769536]] loss fxn value:  0.11660170139378997 learn rate: 1.5625e-05 iteration: 20597
[[ 1.99966479]
 [ 4.00915476]
 [-1.07769718]] loss fxn value:  0.11656931511561602 learn rate: 1.5625e-05 iteration: 20598
[[ 1.99966482]
 [ 4.00915476]
 [-1.077699  ]] loss fxn value:  0.11653693783123638 learn rate: 1.5625e-05 iteration: 20599
[[ 1.99966485]
 [ 4.00915477]
 [-1.07770083]] loss fxn value:  0.1165045695414119 learn rate: 1.5625e-05 iteration: 20600
[[ 1.99966488]
 [ 4.00915478]
 [-1.07770265]] loss fxn value:  0.11647221024036326 learn rate: 1.5625e-05 iteration: 20601
[[ 1.99966491]
 [ 4.00915479]
 [-1.07770446]] loss fxn value:  0.11643985992835197 learn rate: 1.5625e-05 iteration: 20602
[[ 1.99966494]
 [ 4.0091548 ]
 [-1.07770628]] loss fxn value:  0.11640751860204562 learn rate: 1.5625e-05 iteration: 20603
[[ 1.99966497]
 [ 4.00915481]
 [-1.0777081 ]] loss fxn value:  0.11637518625733051 learn rate: 1.5625e-05 iteration: 20604
[[ 1.999665  ]
 [ 4.00915482]
 [-1.07770992]] loss fxn value:  0.11634286289343075 learn rate: 1.5625e-05 iteration: 20605
[[ 1.99966503]
 [ 4.00915483]
 [-1.07771174]] loss fxn value:  0.11631054850751334 learn rate: 1.5625e-05 iteration: 20606
[[ 1.99966506]
 [ 4.00915484]
 [-1.07771356]] loss fxn value:  0.11627824309735735 learn rate: 1.5625e-05 iteration: 20607
[[ 1.99966509]
 [ 4.00915485]
 [-1.07771537]] loss fxn value:  0.11624594665829492 learn rate: 1.5625e-05 iteration: 20608
[[ 1.99966512]
 [ 4.00915486]
 [-1.07771719]] loss fxn value:  0.11621365919193687 learn rate: 1.5625e-05 iteration: 20609
[[ 1.99966515]
 [ 4.00915487]
 [-1.077719  ]] loss fxn value:  0.11618138069209934 learn rate: 1.5625e-05 iteration: 20610
[[ 1.99966518]
 [ 4.00915488]
 [-1.07772082]] loss fxn value:  0.11614911115807972 learn rate: 1.5625e-05 iteration: 20611
[[ 1.99966521]
 [ 4.00915488]
 [-1.07772263]] loss fxn value:  0.1161168505870049 learn rate: 1.5625e-05 iteration: 20612
[[ 1.99966524]
 [ 4.00915489]
 [-1.07772445]] loss fxn value:  0.11608459897623015 learn rate: 1.5625e-05 iteration: 20613
[[ 1.99966527]
 [ 4.0091549 ]
 [-1.07772626]] loss fxn value:  0.1160523563230343 learn rate: 1.5625e-05 iteration: 20614
[[ 1.9996653 ]
 [ 4.00915491]
 [-1.07772807]] loss fxn value:  0.11602012262599164 learn rate: 1.5625e-05 iteration: 20615
[[ 1.99966533]
 [ 4.00915492]
 [-1.07772989]] loss fxn value:  0.1159878978815195 learn rate: 1.5625e-05 iteration: 20616
[[ 1.99966536]
 [ 4.00915493]
 [-1.0777317 ]] loss fxn value:  0.11595568208725887 learn rate: 1.5625e-05 iteration: 20617
[[ 1.9996654 ]
 [ 4.00915494]
 [-1.07773351]] loss fxn value:  0.11592347524108369 learn rate: 1.5625e-05 iteration: 20618
[[ 1.99966543]
 [ 4.00915495]
 [-1.07773532]] loss fxn value:  0.11589127734151576 learn rate: 1.5625e-05 iteration: 20619
[[ 1.99966546]
 [ 4.00915496]
 [-1.07773713]] loss fxn value:  0.11585908838354206 learn rate: 1.5625e-05 iteration: 20620
[[ 1.99966549]
 [ 4.00915497]
 [-1.07773894]] loss fxn value:  0.11582690836632419 learn rate: 1.5625e-05 iteration: 20621
[[ 1.99966552]
 [ 4.00915498]
 [-1.07774075]] loss fxn value:  0.11579473728807427 learn rate: 1.5625e-05 iteration: 20622
[[ 1.99966555]
 [ 4.00915499]
 [-1.07774256]] loss fxn value:  0.11576257514409126 learn rate: 1.5625e-05 iteration: 20623
[[ 1.99966558]
 [ 4.00915499]
 [-1.07774437]] loss fxn value:  0.115730421934037 learn rate: 1.5625e-05 iteration: 20624
[[ 1.99966561]
 [ 4.009155  ]
 [-1.07774618]] loss fxn value:  0.11569827765476184 learn rate: 1.5625e-05 iteration: 20625
[[ 1.99966564]
 [ 4.00915501]
 [-1.07774798]] loss fxn value:  0.11566614230247878 learn rate: 1.5625e-05 iteration: 20626
[[ 1.99966567]
 [ 4.00915502]
 [-1.07774979]] loss fxn value:  0.1156340158769352 learn rate: 1.5625e-05 iteration: 20627
[[ 1.9996657 ]
 [ 4.00915503]
 [-1.0777516 ]] loss fxn value:  0.11560189837378906 learn rate: 1.5625e-05 iteration: 20628
[[ 1.99966573]
 [ 4.00915504]
 [-1.0777534 ]] loss fxn value:  0.11556978979243805 learn rate: 1.5625e-05 iteration: 20629
[[ 1.99966576]
 [ 4.00915505]
 [-1.07775521]] loss fxn value:  0.11553769012802373 learn rate: 1.5625e-05 iteration: 20630
[[ 1.99966579]
 [ 4.00915506]
 [-1.07775701]] loss fxn value:  0.1155055993798936 learn rate: 1.5625e-05 iteration: 20631
[[ 1.99966582]
 [ 4.00915507]
 [-1.07775882]] loss fxn value:  0.11547351754560072 learn rate: 1.5625e-05 iteration: 20632
[[ 1.99966585]
 [ 4.00915508]
 [-1.07776062]] loss fxn value:  0.11544144462108154 learn rate: 1.5625e-05 iteration: 20633
[[ 1.99966588]
 [ 4.00915509]
 [-1.07776243]] loss fxn value:  0.11540938060460758 learn rate: 1.5625e-05 iteration: 20634
[[ 1.99966591]
 [ 4.0091551 ]
 [-1.07776423]] loss fxn value:  0.11537732549523633 learn rate: 1.5625e-05 iteration: 20635
[[ 1.99966594]
 [ 4.0091551 ]
 [-1.07776603]] loss fxn value:  0.11534527928879006 learn rate: 1.5625e-05 iteration: 20636
[[ 1.99966597]
 [ 4.00915511]
 [-1.07776783]] loss fxn value:  0.115313241982624 learn rate: 1.5625e-05 iteration: 20637
[[ 1.999666  ]
 [ 4.00915512]
 [-1.07776963]] loss fxn value:  0.11528121357535252 learn rate: 1.5625e-05 iteration: 20638
[[ 1.99966603]
 [ 4.00915513]
 [-1.07777144]] loss fxn value:  0.11524919406378596 learn rate: 1.5625e-05 iteration: 20639
[[ 1.99966606]
 [ 4.00915514]
 [-1.07777324]] loss fxn value:  0.11521718344613874 learn rate: 1.5625e-05 iteration: 20640
[[ 1.99966609]
 [ 4.00915515]
 [-1.07777504]] loss fxn value:  0.11518518171866156 learn rate: 1.5625e-05 iteration: 20641
[[ 1.99966612]
 [ 4.00915516]
 [-1.07777684]] loss fxn value:  0.11515318888020723 learn rate: 1.5625e-05 iteration: 20642
[[ 1.99966615]
 [ 4.00915517]
 [-1.07777863]] loss fxn value:  0.11512120492828783 learn rate: 1.5625e-05 iteration: 20643
[[ 1.99966618]
 [ 4.00915518]
 [-1.07778043]] loss fxn value:  0.11508922985885912 learn rate: 1.5625e-05 iteration: 20644
[[ 1.99966621]
 [ 4.00915519]
 [-1.07778223]] loss fxn value:  0.11505726367113284 learn rate: 1.5625e-05 iteration: 20645
[[ 1.99966624]
 [ 4.0091552 ]
 [-1.07778403]] loss fxn value:  0.11502530636174575 learn rate: 1.5625e-05 iteration: 20646
[[ 1.99966627]
 [ 4.00915521]
 [-1.07778583]] loss fxn value:  0.11499335792956679 learn rate: 1.5625e-05 iteration: 20647
[[ 1.9996663 ]
 [ 4.00915521]
 [-1.07778762]] loss fxn value:  0.1149614183697398 learn rate: 1.5625e-05 iteration: 20648
[[ 1.99966633]
 [ 4.00915522]
 [-1.07778942]] loss fxn value:  0.11492948768211948 learn rate: 1.5625e-05 iteration: 20649
[[ 1.99966636]
 [ 4.00915523]
 [-1.07779121]] loss fxn value:  0.11489756586235451 learn rate: 1.5625e-05 iteration: 20650
[[ 1.99966639]
 [ 4.00915524]
 [-1.07779301]] loss fxn value:  0.11486565291024942 learn rate: 1.5625e-05 iteration: 20651
[[ 1.99966642]
 [ 4.00915525]
 [-1.0777948 ]] loss fxn value:  0.11483374882142666 learn rate: 1.5625e-05 iteration: 20652
[[ 1.99966645]
 [ 4.00915526]
 [-1.0777966 ]] loss fxn value:  0.11480185359384121 learn rate: 1.5625e-05 iteration: 20653
[[ 1.99966648]
 [ 4.00915527]
 [-1.07779839]] loss fxn value:  0.11476996722556015 learn rate: 1.5625e-05 iteration: 20654
[[ 1.99966651]
 [ 4.00915528]
 [-1.07780018]] loss fxn value:  0.11473808971300319 learn rate: 1.5625e-05 iteration: 20655
[[ 1.99966654]
 [ 4.00915529]
 [-1.07780198]] loss fxn value:  0.11470622105523469 learn rate: 1.5625e-05 iteration: 20656
[[ 1.99966657]
 [ 4.0091553 ]
 [-1.07780377]] loss fxn value:  0.11467436124858177 learn rate: 1.5625e-05 iteration: 20657
[[ 1.9996666 ]
 [ 4.00915531]
 [-1.07780556]] loss fxn value:  0.11464251029131599 learn rate: 1.5625e-05 iteration: 20658
[[ 1.99966663]
 [ 4.00915531]
 [-1.07780735]] loss fxn value:  0.114610668180081 learn rate: 1.5625e-05 iteration: 20659
[[ 1.99966666]
 [ 4.00915532]
 [-1.07780914]] loss fxn value:  0.1145788349137766 learn rate: 1.5625e-05 iteration: 20660
[[ 1.99966669]
 [ 4.00915533]
 [-1.07781093]] loss fxn value:  0.11454701048901329 learn rate: 1.5625e-05 iteration: 20661
[[ 1.99966672]
 [ 4.00915534]
 [-1.07781272]] loss fxn value:  0.11451519490355089 learn rate: 1.5625e-05 iteration: 20662
[[ 1.99966675]
 [ 4.00915535]
 [-1.07781451]] loss fxn value:  0.11448338815376662 learn rate: 1.5625e-05 iteration: 20663
[[ 1.99966678]
 [ 4.00915536]
 [-1.0778163 ]] loss fxn value:  0.1144515902402455 learn rate: 1.5625e-05 iteration: 20664
[[ 1.99966681]
 [ 4.00915537]
 [-1.07781809]] loss fxn value:  0.1144198011572699 learn rate: 1.5625e-05 iteration: 20665
[[ 1.99966684]
 [ 4.00915538]
 [-1.07781987]] loss fxn value:  0.114388020904642 learn rate: 1.5625e-05 iteration: 20666
[[ 1.99966687]
 [ 4.00915539]
 [-1.07782166]] loss fxn value:  0.11435624947901243 learn rate: 1.5625e-05 iteration: 20667
[[ 1.9996669 ]
 [ 4.0091554 ]
 [-1.07782345]] loss fxn value:  0.11432448687721085 learn rate: 1.5625e-05 iteration: 20668
[[ 1.99966693]
 [ 4.00915541]
 [-1.07782523]] loss fxn value:  0.11429273309797729 learn rate: 1.5625e-05 iteration: 20669
[[ 1.99966696]
 [ 4.00915541]
 [-1.07782702]] loss fxn value:  0.11426098813806039 learn rate: 1.5625e-05 iteration: 20670
[[ 1.99966699]
 [ 4.00915542]
 [-1.0778288 ]] loss fxn value:  0.11422925199512966 learn rate: 1.5625e-05 iteration: 20671
[[ 1.99966701]
 [ 4.00915543]
 [-1.07783059]] loss fxn value:  0.11419752466845624 learn rate: 1.5625e-05 iteration: 20672
[[ 1.99966704]
 [ 4.00915544]
 [-1.07783237]] loss fxn value:  0.11416580615230865 learn rate: 1.5625e-05 iteration: 20673
[[ 1.99966707]
 [ 4.00915545]
 [-1.07783416]] loss fxn value:  0.11413409644651216 learn rate: 1.5625e-05 iteration: 20674
[[ 1.9996671 ]
 [ 4.00915546]
 [-1.07783594]] loss fxn value:  0.11410239554909844 learn rate: 1.5625e-05 iteration: 20675
[[ 1.99966713]
 [ 4.00915547]
 [-1.07783772]] loss fxn value:  0.11407070345551146 learn rate: 1.5625e-05 iteration: 20676
[[ 1.99966716]
 [ 4.00915548]
 [-1.0778395 ]] loss fxn value:  0.11403902016587925 learn rate: 1.5625e-05 iteration: 20677
[[ 1.99966719]
 [ 4.00915549]
 [-1.07784129]] loss fxn value:  0.11400734567494893 learn rate: 1.5625e-05 iteration: 20678
[[ 1.99966722]
 [ 4.0091555 ]
 [-1.07784307]] loss fxn value:  0.11397567998163409 learn rate: 1.5625e-05 iteration: 20679
[[ 1.99966725]
 [ 4.0091555 ]
 [-1.07784485]] loss fxn value:  0.11394402308348088 learn rate: 1.5625e-05 iteration: 20680
[[ 1.99966728]
 [ 4.00915551]
 [-1.07784663]] loss fxn value:  0.11391237497882023 learn rate: 1.5625e-05 iteration: 20681
[[ 1.99966731]
 [ 4.00915552]
 [-1.07784841]] loss fxn value:  0.11388073566380566 learn rate: 1.5625e-05 iteration: 20682
[[ 1.99966734]
 [ 4.00915553]
 [-1.07785019]] loss fxn value:  0.11384910513731535 learn rate: 1.5625e-05 iteration: 20683
[[ 1.99966737]
 [ 4.00915554]
 [-1.07785197]] loss fxn value:  0.11381748339594827 learn rate: 1.5625e-05 iteration: 20684
[[ 1.9996674 ]
 [ 4.00915555]
 [-1.07785374]] loss fxn value:  0.11378587043710438 learn rate: 1.5625e-05 iteration: 20685
[[ 1.99966743]
 [ 4.00915556]
 [-1.07785552]] loss fxn value:  0.11375426625990286 learn rate: 1.5625e-05 iteration: 20686
[[ 1.99966746]
 [ 4.00915557]
 [-1.0778573 ]] loss fxn value:  0.11372267086006421 learn rate: 1.5625e-05 iteration: 20687
[[ 1.99966749]
 [ 4.00915558]
 [-1.07785907]] loss fxn value:  0.11369108423550704 learn rate: 1.5625e-05 iteration: 20688
[[ 1.99966752]
 [ 4.00915559]
 [-1.07786085]] loss fxn value:  0.11365950638485117 learn rate: 1.5625e-05 iteration: 20689
[[ 1.99966755]
 [ 4.0091556 ]
 [-1.07786263]] loss fxn value:  0.11362793730387102 learn rate: 1.5625e-05 iteration: 20690
[[ 1.99966758]
 [ 4.0091556 ]
 [-1.0778644 ]] loss fxn value:  0.11359637699319254 learn rate: 1.5625e-05 iteration: 20691
[[ 1.99966761]
 [ 4.00915561]
 [-1.07786618]] loss fxn value:  0.11356482544669814 learn rate: 1.5625e-05 iteration: 20692
[[ 1.99966764]
 [ 4.00915562]
 [-1.07786795]] loss fxn value:  0.11353328266507554 learn rate: 1.5625e-05 iteration: 20693
[[ 1.99966767]
 [ 4.00915563]
 [-1.07786972]] loss fxn value:  0.11350174864267101 learn rate: 1.5625e-05 iteration: 20694
[[ 1.9996677 ]
 [ 4.00915564]
 [-1.0778715 ]] loss fxn value:  0.11347022338104384 learn rate: 1.5625e-05 iteration: 20695
[[ 1.99966773]
 [ 4.00915565]
 [-1.07787327]] loss fxn value:  0.1134387068744879 learn rate: 1.5625e-05 iteration: 20696
[[ 1.99966776]
 [ 4.00915566]
 [-1.07787504]] loss fxn value:  0.11340719912136814 learn rate: 1.5625e-05 iteration: 20697
[[ 1.99966779]
 [ 4.00915567]
 [-1.07787681]] loss fxn value:  0.1133757001198912 learn rate: 1.5625e-05 iteration: 20698
[[ 1.99966782]
 [ 4.00915568]
 [-1.07787859]] loss fxn value:  0.11334420986670397 learn rate: 1.5625e-05 iteration: 20699
[[ 1.99966785]
 [ 4.00915569]
 [-1.07788036]] loss fxn value:  0.11331272836111994 learn rate: 1.5625e-05 iteration: 20700
[[ 1.99966787]
 [ 4.00915569]
 [-1.07788213]] loss fxn value:  0.1132812555992595 learn rate: 1.5625e-05 iteration: 20701
[[ 1.9996679]
 [ 4.0091557]
 [-1.0778839]] loss fxn value:  0.113249791578535 learn rate: 1.5625e-05 iteration: 20702
[[ 1.99966793]
 [ 4.00915571]
 [-1.07788567]] loss fxn value:  0.11321833629807945 learn rate: 1.5625e-05 iteration: 20703
[[ 1.99966796]
 [ 4.00915572]
 [-1.07788743]] loss fxn value:  0.11318688975270169 learn rate: 1.5625e-05 iteration: 20704
[[ 1.99966799]
 [ 4.00915573]
 [-1.0778892 ]] loss fxn value:  0.11315545194268169 learn rate: 1.5625e-05 iteration: 20705
[[ 1.99966802]
 [ 4.00915574]
 [-1.07789097]] loss fxn value:  0.11312402286413518 learn rate: 1.5625e-05 iteration: 20706
[[ 1.99966805]
 [ 4.00915575]
 [-1.07789274]] loss fxn value:  0.11309260251530058 learn rate: 1.5625e-05 iteration: 20707
[[ 1.99966808]
 [ 4.00915576]
 [-1.0778945 ]] loss fxn value:  0.11306119089361097 learn rate: 1.5625e-05 iteration: 20708
[[ 1.99966811]
 [ 4.00915577]
 [-1.07789627]] loss fxn value:  0.11302978799605372 learn rate: 1.5625e-05 iteration: 20709
[[ 1.99966814]
 [ 4.00915577]
 [-1.07789804]] loss fxn value:  0.11299839382157559 learn rate: 1.5625e-05 iteration: 20710
[[ 1.99966817]
 [ 4.00915578]
 [-1.0778998 ]] loss fxn value:  0.11296700836626841 learn rate: 1.5625e-05 iteration: 20711
[[ 1.9996682 ]
 [ 4.00915579]
 [-1.07790157]] loss fxn value:  0.11293563162851332 learn rate: 1.5625e-05 iteration: 20712
[[ 1.99966823]
 [ 4.0091558 ]
 [-1.07790333]] loss fxn value:  0.11290426360493233 learn rate: 1.5625e-05 iteration: 20713
[[ 1.99966826]
 [ 4.00915581]
 [-1.07790509]] loss fxn value:  0.11287290429581322 learn rate: 1.5625e-05 iteration: 20714
[[ 1.99966829]
 [ 4.00915582]
 [-1.07790686]] loss fxn value:  0.11284155369486025 learn rate: 1.5625e-05 iteration: 20715
[[ 1.99966832]
 [ 4.00915583]
 [-1.07790862]] loss fxn value:  0.11281021180246292 learn rate: 1.5625e-05 iteration: 20716
[[ 1.99966835]
 [ 4.00915584]
 [-1.07791038]] loss fxn value:  0.11277887861468688 learn rate: 1.5625e-05 iteration: 20717
[[ 1.99966838]
 [ 4.00915585]
 [-1.07791215]] loss fxn value:  0.11274755413037478 learn rate: 1.5625e-05 iteration: 20718
[[ 1.99966841]
 [ 4.00915586]
 [-1.07791391]] loss fxn value:  0.11271623834570413 learn rate: 1.5625e-05 iteration: 20719
[[ 1.99966843]
 [ 4.00915586]
 [-1.07791567]] loss fxn value:  0.11268493125992209 learn rate: 1.5625e-05 iteration: 20720
[[ 1.99966846]
 [ 4.00915587]
 [-1.07791743]] loss fxn value:  0.11265363286836082 learn rate: 1.5625e-05 iteration: 20721
[[ 1.99966849]
 [ 4.00915588]
 [-1.07791919]] loss fxn value:  0.11262234317213406 learn rate: 1.5625e-05 iteration: 20722
[[ 1.99966852]
 [ 4.00915589]
 [-1.07792095]] loss fxn value:  0.11259106216498618 learn rate: 1.5625e-05 iteration: 20723
[[ 1.99966855]
 [ 4.0091559 ]
 [-1.07792271]] loss fxn value:  0.11255978984680734 learn rate: 1.5625e-05 iteration: 20724
[[ 1.99966858]
 [ 4.00915591]
 [-1.07792446]] loss fxn value:  0.11252852621514828 learn rate: 1.5625e-05 iteration: 20725
[[ 1.99966861]
 [ 4.00915592]
 [-1.07792622]] loss fxn value:  0.11249727126543826 learn rate: 1.5625e-05 iteration: 20726
[[ 1.99966864]
 [ 4.00915593]
 [-1.07792798]] loss fxn value:  0.11246602499820839 learn rate: 1.5625e-05 iteration: 20727
[[ 1.99966867]
 [ 4.00915594]
 [-1.07792974]] loss fxn value:  0.11243478740846642 learn rate: 1.5625e-05 iteration: 20728
[[ 1.9996687 ]
 [ 4.00915594]
 [-1.07793149]] loss fxn value:  0.11240355849570059 learn rate: 1.5625e-05 iteration: 20729
[[ 1.99966873]
 [ 4.00915595]
 [-1.07793325]] loss fxn value:  0.11237233825723761 learn rate: 1.5625e-05 iteration: 20730
[[ 1.99966876]
 [ 4.00915596]
 [-1.07793501]] loss fxn value:  0.11234112669032317 learn rate: 1.5625e-05 iteration: 20731
[[ 1.99966879]
 [ 4.00915597]
 [-1.07793676]] loss fxn value:  0.11230992379122268 learn rate: 1.5625e-05 iteration: 20732
[[ 1.99966882]
 [ 4.00915598]
 [-1.07793852]] loss fxn value:  0.11227872955920729 learn rate: 1.5625e-05 iteration: 20733
[[ 1.99966885]
 [ 4.00915599]
 [-1.07794027]] loss fxn value:  0.11224754399192256 learn rate: 1.5625e-05 iteration: 20734
[[ 1.99966887]
 [ 4.009156  ]
 [-1.07794202]] loss fxn value:  0.11221636708609321 learn rate: 1.5625e-05 iteration: 20735
[[ 1.9996689 ]
 [ 4.00915601]
 [-1.07794378]] loss fxn value:  0.11218519884058356 learn rate: 1.5625e-05 iteration: 20736
[[ 1.99966893]
 [ 4.00915602]
 [-1.07794553]] loss fxn value:  0.11215403925098522 learn rate: 1.5625e-05 iteration: 20737
[[ 1.99966896]
 [ 4.00915602]
 [-1.07794728]] loss fxn value:  0.11212288831625272 learn rate: 1.5625e-05 iteration: 20738
[[ 1.99966899]
 [ 4.00915603]
 [-1.07794903]] loss fxn value:  0.11209174603388666 learn rate: 1.5625e-05 iteration: 20739
[[ 1.99966902]
 [ 4.00915604]
 [-1.07795078]] loss fxn value:  0.11206061240175175 learn rate: 1.5625e-05 iteration: 20740
[[ 1.99966905]
 [ 4.00915605]
 [-1.07795253]] loss fxn value:  0.11202948741606783 learn rate: 1.5625e-05 iteration: 20741
[[ 1.99966908]
 [ 4.00915606]
 [-1.07795428]] loss fxn value:  0.11199837107609681 learn rate: 1.5625e-05 iteration: 20742
[[ 1.99966911]
 [ 4.00915607]
 [-1.07795603]] loss fxn value:  0.11196726337854869 learn rate: 1.5625e-05 iteration: 20743
[[ 1.99966914]
 [ 4.00915608]
 [-1.07795778]] loss fxn value:  0.11193616432068619 learn rate: 1.5625e-05 iteration: 20744
[[ 1.99966917]
 [ 4.00915609]
 [-1.07795953]] loss fxn value:  0.11190507390120465 learn rate: 1.5625e-05 iteration: 20745
[[ 1.9996692 ]
 [ 4.0091561 ]
 [-1.07796128]] loss fxn value:  0.1118739921168596 learn rate: 1.5625e-05 iteration: 20746
[[ 1.99966922]
 [ 4.0091561 ]
 [-1.07796303]] loss fxn value:  0.11184291896593415 learn rate: 1.5625e-05 iteration: 20747
[[ 1.99966925]
 [ 4.00915611]
 [-1.07796478]] loss fxn value:  0.11181185444508436 learn rate: 1.5625e-05 iteration: 20748
[[ 1.99966928]
 [ 4.00915612]
 [-1.07796652]] loss fxn value:  0.11178079855358829 learn rate: 1.5625e-05 iteration: 20749
[[ 1.99966931]
 [ 4.00915613]
 [-1.07796827]] loss fxn value:  0.11174975128670712 learn rate: 1.5625e-05 iteration: 20750
[[ 1.99966934]
 [ 4.00915614]
 [-1.07797001]] loss fxn value:  0.11171871264369268 learn rate: 1.5625e-05 iteration: 20751
[[ 1.99966937]
 [ 4.00915615]
 [-1.07797176]] loss fxn value:  0.11168768262124344 learn rate: 1.5625e-05 iteration: 20752
[[ 1.9996694 ]
 [ 4.00915616]
 [-1.0779735 ]] loss fxn value:  0.11165666121813345 learn rate: 1.5625e-05 iteration: 20753
[[ 1.99966943]
 [ 4.00915617]
 [-1.07797525]] loss fxn value:  0.11162564843149192 learn rate: 1.5625e-05 iteration: 20754
[[ 1.99966946]
 [ 4.00915618]
 [-1.07797699]] loss fxn value:  0.11159464425820015 learn rate: 1.5625e-05 iteration: 20755
[[ 1.99966949]
 [ 4.00915618]
 [-1.07797874]] loss fxn value:  0.11156364869545678 learn rate: 1.5625e-05 iteration: 20756
[[ 1.99966952]
 [ 4.00915619]
 [-1.07798048]] loss fxn value:  0.11153266174303465 learn rate: 1.5625e-05 iteration: 20757
[[ 1.99966954]
 [ 4.0091562 ]
 [-1.07798222]] loss fxn value:  0.11150168339649771 learn rate: 1.5625e-05 iteration: 20758
[[ 1.99966957]
 [ 4.00915621]
 [-1.07798396]] loss fxn value:  0.11147071365436194 learn rate: 1.5625e-05 iteration: 20759
[[ 1.9996696 ]
 [ 4.00915622]
 [-1.0779857 ]] loss fxn value:  0.11143975251457107 learn rate: 1.5625e-05 iteration: 20760
[[ 1.99966963]
 [ 4.00915623]
 [-1.07798745]] loss fxn value:  0.11140879997451122 learn rate: 1.5625e-05 iteration: 20761
[[ 1.99966966]
 [ 4.00915624]
 [-1.07798919]] loss fxn value:  0.1113778560309757 learn rate: 1.5625e-05 iteration: 20762
[[ 1.99966969]
 [ 4.00915625]
 [-1.07799093]] loss fxn value:  0.1113469206825411 learn rate: 1.5625e-05 iteration: 20763
[[ 1.99966972]
 [ 4.00915626]
 [-1.07799267]] loss fxn value:  0.11131599392619589 learn rate: 1.5625e-05 iteration: 20764
[[ 1.99966975]
 [ 4.00915626]
 [-1.0779944 ]] loss fxn value:  0.1112850757598599 learn rate: 1.5625e-05 iteration: 20765
[[ 1.99966978]
 [ 4.00915627]
 [-1.07799614]] loss fxn value:  0.111254166180581 learn rate: 1.5625e-05 iteration: 20766
[[ 1.99966981]
 [ 4.00915628]
 [-1.07799788]] loss fxn value:  0.11122326518737576 learn rate: 1.5625e-05 iteration: 20767
[[ 1.99966984]
 [ 4.00915629]
 [-1.07799962]] loss fxn value:  0.11119237277604799 learn rate: 1.5625e-05 iteration: 20768
[[ 1.99966986]
 [ 4.0091563 ]
 [-1.07800136]] loss fxn value:  0.1111614889454542 learn rate: 1.5625e-05 iteration: 20769
[[ 1.99966989]
 [ 4.00915631]
 [-1.07800309]] loss fxn value:  0.11113061369358138 learn rate: 1.5625e-05 iteration: 20770
[[ 1.99966992]
 [ 4.00915632]
 [-1.07800483]] loss fxn value:  0.11109974701637747 learn rate: 1.5625e-05 iteration: 20771
[[ 1.99966995]
 [ 4.00915633]
 [-1.07800656]] loss fxn value:  0.11106888891302569 learn rate: 1.5625e-05 iteration: 20772
[[ 1.99966998]
 [ 4.00915633]
 [-1.0780083 ]] loss fxn value:  0.11103803938021066 learn rate: 1.5625e-05 iteration: 20773
[[ 1.99967001]
 [ 4.00915634]
 [-1.07801003]] loss fxn value:  0.11100719841621082 learn rate: 1.5625e-05 iteration: 20774
[[ 1.99967004]
 [ 4.00915635]
 [-1.07801177]] loss fxn value:  0.11097636601872655 learn rate: 1.5625e-05 iteration: 20775
[[ 1.99967007]
 [ 4.00915636]
 [-1.0780135 ]] loss fxn value:  0.11094554218405872 learn rate: 1.5625e-05 iteration: 20776
[[ 1.9996701 ]
 [ 4.00915637]
 [-1.07801524]] loss fxn value:  0.1109147269114407 learn rate: 1.5625e-05 iteration: 20777
[[ 1.99967012]
 [ 4.00915638]
 [-1.07801697]] loss fxn value:  0.11088392019751847 learn rate: 1.5625e-05 iteration: 20778
[[ 1.99967015]
 [ 4.00915639]
 [-1.0780187 ]] loss fxn value:  0.11085312203967815 learn rate: 1.5625e-05 iteration: 20779
[[ 1.99967018]
 [ 4.0091564 ]
 [-1.07802043]] loss fxn value:  0.11082233243656262 learn rate: 1.5625e-05 iteration: 20780
[[ 1.99967021]
 [ 4.0091564 ]
 [-1.07802216]] loss fxn value:  0.11079155138537748 learn rate: 1.5625e-05 iteration: 20781
[[ 1.99967024]
 [ 4.00915641]
 [-1.07802389]] loss fxn value:  0.11076077888339698 learn rate: 1.5625e-05 iteration: 20782
[[ 1.99967027]
 [ 4.00915642]
 [-1.07802563]] loss fxn value:  0.1107300149288572 learn rate: 1.5625e-05 iteration: 20783
[[ 1.9996703 ]
 [ 4.00915643]
 [-1.07802736]] loss fxn value:  0.11069925951904158 learn rate: 1.5625e-05 iteration: 20784
[[ 1.99967033]
 [ 4.00915644]
 [-1.07802908]] loss fxn value:  0.11066851265157959 learn rate: 1.5625e-05 iteration: 20785
[[ 1.99967036]
 [ 4.00915645]
 [-1.07803081]] loss fxn value:  0.11063777432380714 learn rate: 1.5625e-05 iteration: 20786
[[ 1.99967038]
 [ 4.00915646]
 [-1.07803254]] loss fxn value:  0.11060704453440577 learn rate: 1.5625e-05 iteration: 20787
[[ 1.99967041]
 [ 4.00915647]
 [-1.07803427]] loss fxn value:  0.1105763232795737 learn rate: 1.5625e-05 iteration: 20788
[[ 1.99967044]
 [ 4.00915647]
 [-1.078036  ]] loss fxn value:  0.11054561055724198 learn rate: 1.5625e-05 iteration: 20789
[[ 1.99967047]
 [ 4.00915648]
 [-1.07803772]] loss fxn value:  0.1105149063658969 learn rate: 1.5625e-05 iteration: 20790
[[ 1.9996705 ]
 [ 4.00915649]
 [-1.07803945]] loss fxn value:  0.11048421070246763 learn rate: 1.5625e-05 iteration: 20791
[[ 1.99967053]
 [ 4.0091565 ]
 [-1.07804118]] loss fxn value:  0.11045352356555145 learn rate: 1.5625e-05 iteration: 20792
[[ 1.99967056]
 [ 4.00915651]
 [-1.0780429 ]] loss fxn value:  0.11042284495094529 learn rate: 1.5625e-05 iteration: 20793
[[ 1.99967059]
 [ 4.00915652]
 [-1.07804463]] loss fxn value:  0.11039217485789864 learn rate: 1.5625e-05 iteration: 20794
[[ 1.99967062]
 [ 4.00915653]
 [-1.07804635]] loss fxn value:  0.11036151328408102 learn rate: 1.5625e-05 iteration: 20795
[[ 1.99967064]
 [ 4.00915654]
 [-1.07804808]] loss fxn value:  0.11033086022581723 learn rate: 1.5625e-05 iteration: 20796
[[ 1.99967067]
 [ 4.00915654]
 [-1.0780498 ]] loss fxn value:  0.11030021568131942 learn rate: 1.5625e-05 iteration: 20797
[[ 1.9996707 ]
 [ 4.00915655]
 [-1.07805152]] loss fxn value:  0.11026957964876657 learn rate: 1.5625e-05 iteration: 20798
[[ 1.99967073]
 [ 4.00915656]
 [-1.07805325]] loss fxn value:  0.11023895212498978 learn rate: 1.5625e-05 iteration: 20799
[[ 1.99967076]
 [ 4.00915657]
 [-1.07805497]] loss fxn value:  0.110208333108642 learn rate: 1.5625e-05 iteration: 20800
[[ 1.99967079]
 [ 4.00915658]
 [-1.07805669]] loss fxn value:  0.11017772259645026 learn rate: 1.5625e-05 iteration: 20801
[[ 1.99967082]
 [ 4.00915659]
 [-1.07805841]] loss fxn value:  0.11014712058666215 learn rate: 1.5625e-05 iteration: 20802
[[ 1.99967084]
 [ 4.0091566 ]
 [-1.07806013]] loss fxn value:  0.11011652707657585 learn rate: 1.5625e-05 iteration: 20803
[[ 1.99967087]
 [ 4.00915661]
 [-1.07806185]] loss fxn value:  0.1100859420634085 learn rate: 1.5625e-05 iteration: 20804
[[ 1.9996709 ]
 [ 4.00915661]
 [-1.07806357]] loss fxn value:  0.11005536554584393 learn rate: 1.5625e-05 iteration: 20805
[[ 1.99967093]
 [ 4.00915662]
 [-1.07806529]] loss fxn value:  0.11002479752019453 learn rate: 1.5625e-05 iteration: 20806
[[ 1.99967096]
 [ 4.00915663]
 [-1.07806701]] loss fxn value:  0.10999423798557953 learn rate: 1.5625e-05 iteration: 20807
[[ 1.99967099]
 [ 4.00915664]
 [-1.07806873]] loss fxn value:  0.10996368693878297 learn rate: 1.5625e-05 iteration: 20808
[[ 1.99967102]
 [ 4.00915665]
 [-1.07807045]] loss fxn value:  0.10993314437714544 learn rate: 1.5625e-05 iteration: 20809
[[ 1.99967105]
 [ 4.00915666]
 [-1.07807216]] loss fxn value:  0.10990261029880814 learn rate: 1.5625e-05 iteration: 20810
[[ 1.99967107]
 [ 4.00915667]
 [-1.07807388]] loss fxn value:  0.10987208470195926 learn rate: 1.5625e-05 iteration: 20811
[[ 1.9996711 ]
 [ 4.00915668]
 [-1.0780756 ]] loss fxn value:  0.10984156758289511 learn rate: 1.5625e-05 iteration: 20812
[[ 1.99967113]
 [ 4.00915668]
 [-1.07807731]] loss fxn value:  0.10981105894131521 learn rate: 1.5625e-05 iteration: 20813
[[ 1.99967116]
 [ 4.00915669]
 [-1.07807903]] loss fxn value:  0.10978055877246377 learn rate: 1.5625e-05 iteration: 20814
[[ 1.99967119]
 [ 4.0091567 ]
 [-1.07808074]] loss fxn value:  0.10975006707562893 learn rate: 1.5625e-05 iteration: 20815
[[ 1.99967122]
 [ 4.00915671]
 [-1.07808246]] loss fxn value:  0.10971958384655654 learn rate: 1.5625e-05 iteration: 20816
[[ 1.99967125]
 [ 4.00915672]
 [-1.07808417]] loss fxn value:  0.10968910908541557 learn rate: 1.5625e-05 iteration: 20817
[[ 1.99967127]
 [ 4.00915673]
 [-1.07808589]] loss fxn value:  0.10965864278796889 learn rate: 1.5625e-05 iteration: 20818
[[ 1.9996713 ]
 [ 4.00915674]
 [-1.0780876 ]] loss fxn value:  0.10962818495384974 learn rate: 1.5625e-05 iteration: 20819
[[ 1.99967133]
 [ 4.00915675]
 [-1.07808931]] loss fxn value:  0.10959773557842112 learn rate: 1.5625e-05 iteration: 20820
[[ 1.99967136]
 [ 4.00915675]
 [-1.07809102]] loss fxn value:  0.10956729466138258 learn rate: 1.5625e-05 iteration: 20821
[[ 1.99967139]
 [ 4.00915676]
 [-1.07809274]] loss fxn value:  0.10953686219748127 learn rate: 1.5625e-05 iteration: 20822
[[ 1.99967142]
 [ 4.00915677]
 [-1.07809445]] loss fxn value:  0.1095064381874495 learn rate: 1.5625e-05 iteration: 20823
[[ 1.99967145]
 [ 4.00915678]
 [-1.07809616]] loss fxn value:  0.1094760226279572 learn rate: 1.5625e-05 iteration: 20824
[[ 1.99967147]
 [ 4.00915679]
 [-1.07809787]] loss fxn value:  0.10944561551578384 learn rate: 1.5625e-05 iteration: 20825
[[ 1.9996715 ]
 [ 4.0091568 ]
 [-1.07809958]] loss fxn value:  0.10941521684972197 learn rate: 1.5625e-05 iteration: 20826
[[ 1.99967153]
 [ 4.00915681]
 [-1.07810129]] loss fxn value:  0.10938482662686301 learn rate: 1.5625e-05 iteration: 20827
[[ 1.99967156]
 [ 4.00915681]
 [-1.078103  ]] loss fxn value:  0.10935444484459768 learn rate: 1.5625e-05 iteration: 20828
[[ 1.99967159]
 [ 4.00915682]
 [-1.07810471]] loss fxn value:  0.10932407150059552 learn rate: 1.5625e-05 iteration: 20829
[[ 1.99967162]
 [ 4.00915683]
 [-1.07810641]] loss fxn value:  0.10929370659402585 learn rate: 1.5625e-05 iteration: 20830
[[ 1.99967165]
 [ 4.00915684]
 [-1.07810812]] loss fxn value:  0.10926335012017527 learn rate: 1.5625e-05 iteration: 20831
[[ 1.99967167]
 [ 4.00915685]
 [-1.07810983]] loss fxn value:  0.1092330020788552 learn rate: 1.5625e-05 iteration: 20832
[[ 1.9996717 ]
 [ 4.00915686]
 [-1.07811153]] loss fxn value:  0.10920266246566505 learn rate: 1.5625e-05 iteration: 20833
[[ 1.99967173]
 [ 4.00915687]
 [-1.07811324]] loss fxn value:  0.10917233128039924 learn rate: 1.5625e-05 iteration: 20834
[[ 1.99967176]
 [ 4.00915688]
 [-1.07811495]] loss fxn value:  0.10914200851881604 learn rate: 1.5625e-05 iteration: 20835
[[ 1.99967179]
 [ 4.00915688]
 [-1.07811665]] loss fxn value:  0.10911169418009171 learn rate: 1.5625e-05 iteration: 20836
[[ 1.99967182]
 [ 4.00915689]
 [-1.07811836]] loss fxn value:  0.10908138826101729 learn rate: 1.5625e-05 iteration: 20837
[[ 1.99967184]
 [ 4.0091569 ]
 [-1.07812006]] loss fxn value:  0.1090510907587652 learn rate: 1.5625e-05 iteration: 20838
[[ 1.99967187]
 [ 4.00915691]
 [-1.07812176]] loss fxn value:  0.10902080167264208 learn rate: 1.5625e-05 iteration: 20839
[[ 1.9996719 ]
 [ 4.00915692]
 [-1.07812347]] loss fxn value:  0.10899052099832514 learn rate: 1.5625e-05 iteration: 20840
[[ 1.99967193]
 [ 4.00915693]
 [-1.07812517]] loss fxn value:  0.10896024873603812 learn rate: 1.5625e-05 iteration: 20841
[[ 1.99967196]
 [ 4.00915694]
 [-1.07812687]] loss fxn value:  0.1089299848805489 learn rate: 1.5625e-05 iteration: 20842
[[ 1.99967199]
 [ 4.00915694]
 [-1.07812857]] loss fxn value:  0.108899729431581 learn rate: 1.5625e-05 iteration: 20843
[[ 1.99967202]
 [ 4.00915695]
 [-1.07813027]] loss fxn value:  0.10886948238628756 learn rate: 1.5625e-05 iteration: 20844
[[ 1.99967204]
 [ 4.00915696]
 [-1.07813198]] loss fxn value:  0.10883924374111908 learn rate: 1.5625e-05 iteration: 20845
[[ 1.99967207]
 [ 4.00915697]
 [-1.07813368]] loss fxn value:  0.10880901349513304 learn rate: 1.5625e-05 iteration: 20846
[[ 1.9996721 ]
 [ 4.00915698]
 [-1.07813538]] loss fxn value:  0.10877879164602984 learn rate: 1.5625e-05 iteration: 20847
[[ 1.99967213]
 [ 4.00915699]
 [-1.07813707]] loss fxn value:  0.10874857819120479 learn rate: 1.5625e-05 iteration: 20848
[[ 1.99967216]
 [ 4.009157  ]
 [-1.07813877]] loss fxn value:  0.10871837312811379 learn rate: 1.5625e-05 iteration: 20849
[[ 1.99967219]
 [ 4.00915701]
 [-1.07814047]] loss fxn value:  0.10868817645435887 learn rate: 1.5625e-05 iteration: 20850
[[ 1.99967221]
 [ 4.00915701]
 [-1.07814217]] loss fxn value:  0.10865798816786991 learn rate: 1.5625e-05 iteration: 20851
[[ 1.99967224]
 [ 4.00915702]
 [-1.07814387]] loss fxn value:  0.108627808266016 learn rate: 1.5625e-05 iteration: 20852
[[ 1.99967227]
 [ 4.00915703]
 [-1.07814556]] loss fxn value:  0.10859763674656153 learn rate: 1.5625e-05 iteration: 20853
[[ 1.9996723 ]
 [ 4.00915704]
 [-1.07814726]] loss fxn value:  0.10856747360761686 learn rate: 1.5625e-05 iteration: 20854
[[ 1.99967233]
 [ 4.00915705]
 [-1.07814896]] loss fxn value:  0.1085373188465179 learn rate: 1.5625e-05 iteration: 20855
[[ 1.99967236]
 [ 4.00915706]
 [-1.07815065]] loss fxn value:  0.10850717246087253 learn rate: 1.5625e-05 iteration: 20856
[[ 1.99967238]
 [ 4.00915707]
 [-1.07815235]] loss fxn value:  0.10847703444858318 learn rate: 1.5625e-05 iteration: 20857
[[ 1.99967241]
 [ 4.00915707]
 [-1.07815404]] loss fxn value:  0.10844690480677908 learn rate: 1.5625e-05 iteration: 20858
[[ 1.99967244]
 [ 4.00915708]
 [-1.07815574]] loss fxn value:  0.10841678353415561 learn rate: 1.5625e-05 iteration: 20859
[[ 1.99967247]
 [ 4.00915709]
 [-1.07815743]] loss fxn value:  0.10838667062706148 learn rate: 1.5625e-05 iteration: 20860
[[ 1.9996725 ]
 [ 4.0091571 ]
 [-1.07815912]] loss fxn value:  0.10835656608463894 learn rate: 1.5625e-05 iteration: 20861
[[ 1.99967252]
 [ 4.00915711]
 [-1.07816082]] loss fxn value:  0.1083264699026255 learn rate: 1.5625e-05 iteration: 20862
[[ 1.99967255]
 [ 4.00915712]
 [-1.07816251]] loss fxn value:  0.10829638208035859 learn rate: 1.5625e-05 iteration: 20863
[[ 1.99967258]
 [ 4.00915713]
 [-1.0781642 ]] loss fxn value:  0.10826630261542443 learn rate: 1.5625e-05 iteration: 20864
[[ 1.99967261]
 [ 4.00915713]
 [-1.07816589]] loss fxn value:  0.10823623150502401 learn rate: 1.5625e-05 iteration: 20865
[[ 1.99967264]
 [ 4.00915714]
 [-1.07816758]] loss fxn value:  0.10820616874660745 learn rate: 1.5625e-05 iteration: 20866
[[ 1.99967267]
 [ 4.00915715]
 [-1.07816927]] loss fxn value:  0.10817611433818015 learn rate: 1.5625e-05 iteration: 20867
[[ 1.99967269]
 [ 4.00915716]
 [-1.07817096]] loss fxn value:  0.10814606827813937 learn rate: 1.5625e-05 iteration: 20868
[[ 1.99967272]
 [ 4.00915717]
 [-1.07817265]] loss fxn value:  0.10811603056253917 learn rate: 1.5625e-05 iteration: 20869
[[ 1.99967275]
 [ 4.00915718]
 [-1.07817434]] loss fxn value:  0.10808600118989556 learn rate: 1.5625e-05 iteration: 20870
[[ 1.99967278]
 [ 4.00915719]
 [-1.07817603]] loss fxn value:  0.10805598015860003 learn rate: 1.5625e-05 iteration: 20871
[[ 1.99967281]
 [ 4.00915719]
 [-1.07817772]] loss fxn value:  0.10802596746559325 learn rate: 1.5625e-05 iteration: 20872
[[ 1.99967284]
 [ 4.0091572 ]
 [-1.07817941]] loss fxn value:  0.10799596310806146 learn rate: 1.5625e-05 iteration: 20873
[[ 1.99967286]
 [ 4.00915721]
 [-1.07818109]] loss fxn value:  0.10796596708474565 learn rate: 1.5625e-05 iteration: 20874
[[ 1.99967289]
 [ 4.00915722]
 [-1.07818278]] loss fxn value:  0.10793597939281967 learn rate: 1.5625e-05 iteration: 20875
[[ 1.99967292]
 [ 4.00915723]
 [-1.07818447]] loss fxn value:  0.107906000030075 learn rate: 1.5625e-05 iteration: 20876
[[ 1.99967295]
 [ 4.00915724]
 [-1.07818615]] loss fxn value:  0.10787602899328799 learn rate: 1.5625e-05 iteration: 20877
[[ 1.99967298]
 [ 4.00915725]
 [-1.07818784]] loss fxn value:  0.10784606628202094 learn rate: 1.5625e-05 iteration: 20878
[[ 1.999673  ]
 [ 4.00915725]
 [-1.07818952]] loss fxn value:  0.10781611189264566 learn rate: 1.5625e-05 iteration: 20879
[[ 1.99967303]
 [ 4.00915726]
 [-1.07819121]] loss fxn value:  0.10778616582334112 learn rate: 1.5625e-05 iteration: 20880
[[ 1.99967306]
 [ 4.00915727]
 [-1.07819289]] loss fxn value:  0.10775622807184318 learn rate: 1.5625e-05 iteration: 20881
[[ 1.99967309]
 [ 4.00915728]
 [-1.07819457]] loss fxn value:  0.10772629863440339 learn rate: 1.5625e-05 iteration: 20882
[[ 1.99967312]
 [ 4.00915729]
 [-1.07819626]] loss fxn value:  0.10769637751127316 learn rate: 1.5625e-05 iteration: 20883
[[ 1.99967314]
 [ 4.0091573 ]
 [-1.07819794]] loss fxn value:  0.10766646469800636 learn rate: 1.5625e-05 iteration: 20884
[[ 1.99967317]
 [ 4.00915731]
 [-1.07819962]] loss fxn value:  0.1076365601936146 learn rate: 1.5625e-05 iteration: 20885
[[ 1.9996732 ]
 [ 4.00915731]
 [-1.0782013 ]] loss fxn value:  0.10760666399463205 learn rate: 1.5625e-05 iteration: 20886
[[ 1.99967323]
 [ 4.00915732]
 [-1.07820298]] loss fxn value:  0.10757677609937573 learn rate: 1.5625e-05 iteration: 20887
[[ 1.99967326]
 [ 4.00915733]
 [-1.07820467]] loss fxn value:  0.10754689650651711 learn rate: 1.5625e-05 iteration: 20888
[[ 1.99967328]
 [ 4.00915734]
 [-1.07820635]] loss fxn value:  0.10751702521175044 learn rate: 1.5625e-05 iteration: 20889
[[ 1.99967331]
 [ 4.00915735]
 [-1.07820803]] loss fxn value:  0.10748716221344441 learn rate: 1.5625e-05 iteration: 20890
[[ 1.99967334]
 [ 4.00915736]
 [-1.0782097 ]] loss fxn value:  0.10745730751035378 learn rate: 1.5625e-05 iteration: 20891
[[ 1.99967337]
 [ 4.00915737]
 [-1.07821138]] loss fxn value:  0.10742746109983956 learn rate: 1.5625e-05 iteration: 20892
[[ 1.9996734 ]
 [ 4.00915737]
 [-1.07821306]] loss fxn value:  0.10739762297807114 learn rate: 1.5625e-05 iteration: 20893
[[ 1.99967342]
 [ 4.00915738]
 [-1.07821474]] loss fxn value:  0.10736779314510245 learn rate: 1.5625e-05 iteration: 20894
[[ 1.99967345]
 [ 4.00915739]
 [-1.07821642]] loss fxn value:  0.10733797159655684 learn rate: 1.5625e-05 iteration: 20895
[[ 1.99967348]
 [ 4.0091574 ]
 [-1.07821809]] loss fxn value:  0.10730815833139573 learn rate: 1.5625e-05 iteration: 20896
[[ 1.99967351]
 [ 4.00915741]
 [-1.07821977]] loss fxn value:  0.10727835334572025 learn rate: 1.5625e-05 iteration: 20897
[[ 1.99967354]
 [ 4.00915742]
 [-1.07822145]] loss fxn value:  0.10724855664018944 learn rate: 1.5625e-05 iteration: 20898
[[ 1.99967356]
 [ 4.00915742]
 [-1.07822312]] loss fxn value:  0.10721876820911194 learn rate: 1.5625e-05 iteration: 20899
[[ 1.99967359]
 [ 4.00915743]
 [-1.0782248 ]] loss fxn value:  0.1071889880527847 learn rate: 1.5625e-05 iteration: 20900
[[ 1.99967362]
 [ 4.00915744]
 [-1.07822647]] loss fxn value:  0.1071592161677897 learn rate: 1.5625e-05 iteration: 20901
[[ 1.99967365]
 [ 4.00915745]
 [-1.07822815]] loss fxn value:  0.10712945255287477 learn rate: 1.5625e-05 iteration: 20902
[[ 1.99967368]
 [ 4.00915746]
 [-1.07822982]] loss fxn value:  0.1070996972034075 learn rate: 1.5625e-05 iteration: 20903
[[ 1.9996737 ]
 [ 4.00915747]
 [-1.07823149]] loss fxn value:  0.10706995011899494 learn rate: 1.5625e-05 iteration: 20904
[[ 1.99967373]
 [ 4.00915748]
 [-1.07823316]] loss fxn value:  0.10704021129742305 learn rate: 1.5625e-05 iteration: 20905
[[ 1.99967376]
 [ 4.00915748]
 [-1.07823484]] loss fxn value:  0.10701048073535717 learn rate: 1.5625e-05 iteration: 20906
[[ 1.99967379]
 [ 4.00915749]
 [-1.07823651]] loss fxn value:  0.10698075843060721 learn rate: 1.5625e-05 iteration: 20907
[[ 1.99967382]
 [ 4.0091575 ]
 [-1.07823818]] loss fxn value:  0.10695104438191091 learn rate: 1.5625e-05 iteration: 20908
[[ 1.99967384]
 [ 4.00915751]
 [-1.07823985]] loss fxn value:  0.10692133858584106 learn rate: 1.5625e-05 iteration: 20909
[[ 1.99967387]
 [ 4.00915752]
 [-1.07824152]] loss fxn value:  0.10689164104036643 learn rate: 1.5625e-05 iteration: 20910
[[ 1.9996739 ]
 [ 4.00915753]
 [-1.07824319]] loss fxn value:  0.10686195174448512 learn rate: 1.5625e-05 iteration: 20911
[[ 1.99967393]
 [ 4.00915753]
 [-1.07824486]] loss fxn value:  0.10683227069446716 learn rate: 1.5625e-05 iteration: 20912
[[ 1.99967396]
 [ 4.00915754]
 [-1.07824653]] loss fxn value:  0.1068025978881934 learn rate: 1.5625e-05 iteration: 20913
[[ 1.99967398]
 [ 4.00915755]
 [-1.0782482 ]] loss fxn value:  0.10677293332374796 learn rate: 1.5625e-05 iteration: 20914
[[ 1.99967401]
 [ 4.00915756]
 [-1.07824987]] loss fxn value:  0.1067432769974695 learn rate: 1.5625e-05 iteration: 20915
[[ 1.99967404]
 [ 4.00915757]
 [-1.07825153]] loss fxn value:  0.10671362890999317 learn rate: 1.5625e-05 iteration: 20916
[[ 1.99967407]
 [ 4.00915758]
 [-1.0782532 ]] loss fxn value:  0.1066839890569893 learn rate: 1.5625e-05 iteration: 20917
[[ 1.99967409]
 [ 4.00915759]
 [-1.07825487]] loss fxn value:  0.10665435743632491 learn rate: 1.5625e-05 iteration: 20918
[[ 1.99967412]
 [ 4.00915759]
 [-1.07825653]] loss fxn value:  0.10662473404570498 learn rate: 1.5625e-05 iteration: 20919
[[ 1.99967415]
 [ 4.0091576 ]
 [-1.0782582 ]] loss fxn value:  0.1065951188827898 learn rate: 1.5625e-05 iteration: 20920
[[ 1.99967418]
 [ 4.00915761]
 [-1.07825987]] loss fxn value:  0.10656551194588408 learn rate: 1.5625e-05 iteration: 20921
[[ 1.99967421]
 [ 4.00915762]
 [-1.07826153]] loss fxn value:  0.10653591323168628 learn rate: 1.5625e-05 iteration: 20922
[[ 1.99967423]
 [ 4.00915763]
 [-1.07826319]] loss fxn value:  0.10650632273937034 learn rate: 1.5625e-05 iteration: 20923
[[ 1.99967426]
 [ 4.00915764]
 [-1.07826486]] loss fxn value:  0.10647674046570106 learn rate: 1.5625e-05 iteration: 20924
[[ 1.99967429]
 [ 4.00915764]
 [-1.07826652]] loss fxn value:  0.10644716640846906 learn rate: 1.5625e-05 iteration: 20925
[[ 1.99967432]
 [ 4.00915765]
 [-1.07826818]] loss fxn value:  0.10641760056572992 learn rate: 1.5625e-05 iteration: 20926
[[ 1.99967434]
 [ 4.00915766]
 [-1.07826985]] loss fxn value:  0.10638804293395807 learn rate: 1.5625e-05 iteration: 20927
[[ 1.99967437]
 [ 4.00915767]
 [-1.07827151]] loss fxn value:  0.10635849351270805 learn rate: 1.5625e-05 iteration: 20928
[[ 1.9996744 ]
 [ 4.00915768]
 [-1.07827317]] loss fxn value:  0.10632895229870921 learn rate: 1.5625e-05 iteration: 20929
[[ 1.99967443]
 [ 4.00915769]
 [-1.07827483]] loss fxn value:  0.1062994192902593 learn rate: 1.5625e-05 iteration: 20930
[[ 1.99967445]
 [ 4.0091577 ]
 [-1.07827649]] loss fxn value:  0.10626989448447598 learn rate: 1.5625e-05 iteration: 20931
[[ 1.99967448]
 [ 4.0091577 ]
 [-1.07827815]] loss fxn value:  0.10624037787778125 learn rate: 1.5625e-05 iteration: 20932
[[ 1.99967451]
 [ 4.00915771]
 [-1.07827981]] loss fxn value:  0.10621086947078862 learn rate: 1.5625e-05 iteration: 20933
[[ 1.99967454]
 [ 4.00915772]
 [-1.07828147]] loss fxn value:  0.10618136926010172 learn rate: 1.5625e-05 iteration: 20934
[[ 1.99967457]
 [ 4.00915773]
 [-1.07828313]] loss fxn value:  0.10615187724213328 learn rate: 1.5625e-05 iteration: 20935
[[ 1.99967459]
 [ 4.00915774]
 [-1.07828479]] loss fxn value:  0.10612239341601865 learn rate: 1.5625e-05 iteration: 20936
[[ 1.99967462]
 [ 4.00915775]
 [-1.07828645]] loss fxn value:  0.10609291777953458 learn rate: 1.5625e-05 iteration: 20937
[[ 1.99967465]
 [ 4.00915775]
 [-1.0782881 ]] loss fxn value:  0.1060634503302673 learn rate: 1.5625e-05 iteration: 20938
[[ 1.99967468]
 [ 4.00915776]
 [-1.07828976]] loss fxn value:  0.10603399106326782 learn rate: 1.5625e-05 iteration: 20939
[[ 1.9996747 ]
 [ 4.00915777]
 [-1.07829142]] loss fxn value:  0.10600453998144467 learn rate: 1.5625e-05 iteration: 20940
[[ 1.99967473]
 [ 4.00915778]
 [-1.07829307]] loss fxn value:  0.10597509707807369 learn rate: 1.5625e-05 iteration: 20941
[[ 1.99967476]
 [ 4.00915779]
 [-1.07829473]] loss fxn value:  0.10594566235302112 learn rate: 1.5625e-05 iteration: 20942
[[ 1.99967479]
 [ 4.0091578 ]
 [-1.07829638]] loss fxn value:  0.1059162358034254 learn rate: 1.5625e-05 iteration: 20943
[[ 1.99967481]
 [ 4.0091578 ]
 [-1.07829804]] loss fxn value:  0.10588681742649443 learn rate: 1.5625e-05 iteration: 20944
[[ 1.99967484]
 [ 4.00915781]
 [-1.07829969]] loss fxn value:  0.10585740722151636 learn rate: 1.5625e-05 iteration: 20945
[[ 1.99967487]
 [ 4.00915782]
 [-1.07830135]] loss fxn value:  0.10582800518508242 learn rate: 1.5625e-05 iteration: 20946
[[ 1.9996749 ]
 [ 4.00915783]
 [-1.078303  ]] loss fxn value:  0.10579861131414796 learn rate: 1.5625e-05 iteration: 20947
[[ 1.99967492]
 [ 4.00915784]
 [-1.07830465]] loss fxn value:  0.10576922560826521 learn rate: 1.5625e-05 iteration: 20948
[[ 1.99967495]
 [ 4.00915785]
 [-1.07830631]] loss fxn value:  0.1057398480651083 learn rate: 1.5625e-05 iteration: 20949
[[ 1.99967498]
 [ 4.00915786]
 [-1.07830796]] loss fxn value:  0.10571047868005726 learn rate: 1.5625e-05 iteration: 20950
[[ 1.99967501]
 [ 4.00915786]
 [-1.07830961]] loss fxn value:  0.10568111745377803 learn rate: 1.5625e-05 iteration: 20951
[[ 1.99967504]
 [ 4.00915787]
 [-1.07831126]] loss fxn value:  0.10565176438103625 learn rate: 1.5625e-05 iteration: 20952
[[ 1.99967506]
 [ 4.00915788]
 [-1.07831291]] loss fxn value:  0.10562241946246245 learn rate: 1.5625e-05 iteration: 20953
[[ 1.99967509]
 [ 4.00915789]
 [-1.07831456]] loss fxn value:  0.10559308269430041 learn rate: 1.5625e-05 iteration: 20954
[[ 1.99967512]
 [ 4.0091579 ]
 [-1.07831621]] loss fxn value:  0.10556375407345303 learn rate: 1.5625e-05 iteration: 20955
[[ 1.99967515]
 [ 4.00915791]
 [-1.07831786]] loss fxn value:  0.10553443359940623 learn rate: 1.5625e-05 iteration: 20956
[[ 1.99967517]
 [ 4.00915791]
 [-1.07831951]] loss fxn value:  0.10550512126950055 learn rate: 1.5625e-05 iteration: 20957
[[ 1.9996752 ]
 [ 4.00915792]
 [-1.07832116]] loss fxn value:  0.10547581708136315 learn rate: 1.5625e-05 iteration: 20958
[[ 1.99967523]
 [ 4.00915793]
 [-1.0783228 ]] loss fxn value:  0.10544652103093508 learn rate: 1.5625e-05 iteration: 20959
[[ 1.99967526]
 [ 4.00915794]
 [-1.07832445]] loss fxn value:  0.10541723311830424 learn rate: 1.5625e-05 iteration: 20960
[[ 1.99967528]
 [ 4.00915795]
 [-1.0783261 ]] loss fxn value:  0.10538795334111628 learn rate: 1.5625e-05 iteration: 20961
[[ 1.99967531]
 [ 4.00915796]
 [-1.07832775]] loss fxn value:  0.10535868169614834 learn rate: 1.5625e-05 iteration: 20962
[[ 1.99967534]
 [ 4.00915796]
 [-1.07832939]] loss fxn value:  0.10532941818076721 learn rate: 1.5625e-05 iteration: 20963
[[ 1.99967537]
 [ 4.00915797]
 [-1.07833104]] loss fxn value:  0.1053001627945136 learn rate: 1.5625e-05 iteration: 20964
[[ 1.99967539]
 [ 4.00915798]
 [-1.07833268]] loss fxn value:  0.10527091553318124 learn rate: 1.5625e-05 iteration: 20965
[[ 1.99967542]
 [ 4.00915799]
 [-1.07833433]] loss fxn value:  0.10524167639458468 learn rate: 1.5625e-05 iteration: 20966
[[ 1.99967545]
 [ 4.009158  ]
 [-1.07833597]] loss fxn value:  0.10521244537832632 learn rate: 1.5625e-05 iteration: 20967
[[ 1.99967547]
 [ 4.00915801]
 [-1.07833761]] loss fxn value:  0.1051832224811 learn rate: 1.5625e-05 iteration: 20968
[[ 1.9996755 ]
 [ 4.00915801]
 [-1.07833926]] loss fxn value:  0.10515400769927753 learn rate: 1.5625e-05 iteration: 20969
[[ 1.99967553]
 [ 4.00915802]
 [-1.0783409 ]] loss fxn value:  0.10512480103345863 learn rate: 1.5625e-05 iteration: 20970
[[ 1.99967556]
 [ 4.00915803]
 [-1.07834254]] loss fxn value:  0.10509560247894686 learn rate: 1.5625e-05 iteration: 20971
[[ 1.99967558]
 [ 4.00915804]
 [-1.07834418]] loss fxn value:  0.10506641203489225 learn rate: 1.5625e-05 iteration: 20972
[[ 1.99967561]
 [ 4.00915805]
 [-1.07834583]] loss fxn value:  0.1050372296980573 learn rate: 1.5625e-05 iteration: 20973
[[ 1.99967564]
 [ 4.00915806]
 [-1.07834747]] loss fxn value:  0.10500805546676831 learn rate: 1.5625e-05 iteration: 20974
[[ 1.99967567]
 [ 4.00915806]
 [-1.07834911]] loss fxn value:  0.1049788893389906 learn rate: 1.5625e-05 iteration: 20975
[[ 1.99967569]
 [ 4.00915807]
 [-1.07835075]] loss fxn value:  0.10494973131221899 learn rate: 1.5625e-05 iteration: 20976
[[ 1.99967572]
 [ 4.00915808]
 [-1.07835239]] loss fxn value:  0.10492058138308101 learn rate: 1.5625e-05 iteration: 20977
[[ 1.99967575]
 [ 4.00915809]
 [-1.07835403]] loss fxn value:  0.10489143955170237 learn rate: 1.5625e-05 iteration: 20978
[[ 1.99967578]
 [ 4.0091581 ]
 [-1.07835567]] loss fxn value:  0.10486230581347229 learn rate: 1.5625e-05 iteration: 20979
[[ 1.9996758 ]
 [ 4.00915811]
 [-1.0783573 ]] loss fxn value:  0.10483318016750763 learn rate: 1.5625e-05 iteration: 20980
[[ 1.99967583]
 [ 4.00915811]
 [-1.07835894]] loss fxn value:  0.10480406261105409 learn rate: 1.5625e-05 iteration: 20981
[[ 1.99967586]
 [ 4.00915812]
 [-1.07836058]] loss fxn value:  0.10477495314281858 learn rate: 1.5625e-05 iteration: 20982
[[ 1.99967589]
 [ 4.00915813]
 [-1.07836222]] loss fxn value:  0.10474585175957596 learn rate: 1.5625e-05 iteration: 20983
[[ 1.99967591]
 [ 4.00915814]
 [-1.07836385]] loss fxn value:  0.10471675845938871 learn rate: 1.5625e-05 iteration: 20984
[[ 1.99967594]
 [ 4.00915815]
 [-1.07836549]] loss fxn value:  0.1046876732387976 learn rate: 1.5625e-05 iteration: 20985
[[ 1.99967597]
 [ 4.00915816]
 [-1.07836712]] loss fxn value:  0.10465859609683852 learn rate: 1.5625e-05 iteration: 20986
[[ 1.99967599]
 [ 4.00915816]
 [-1.07836876]] loss fxn value:  0.10462952703217591 learn rate: 1.5625e-05 iteration: 20987
[[ 1.99967602]
 [ 4.00915817]
 [-1.07837039]] loss fxn value:  0.10460046604055888 learn rate: 1.5625e-05 iteration: 20988
[[ 1.99967605]
 [ 4.00915818]
 [-1.07837203]] loss fxn value:  0.10457141312130552 learn rate: 1.5625e-05 iteration: 20989
[[ 1.99967608]
 [ 4.00915819]
 [-1.07837366]] loss fxn value:  0.10454236827103874 learn rate: 1.5625e-05 iteration: 20990
[[ 1.9996761 ]
 [ 4.0091582 ]
 [-1.07837529]] loss fxn value:  0.1045133314885511 learn rate: 1.5625e-05 iteration: 20991
[[ 1.99967613]
 [ 4.00915821]
 [-1.07837693]] loss fxn value:  0.1044843027705079 learn rate: 1.5625e-05 iteration: 20992
[[ 1.99967616]
 [ 4.00915821]
 [-1.07837856]] loss fxn value:  0.10445528211526627 learn rate: 1.5625e-05 iteration: 20993
[[ 1.99967619]
 [ 4.00915822]
 [-1.07838019]] loss fxn value:  0.1044262695208054 learn rate: 1.5625e-05 iteration: 20994
[[ 1.99967621]
 [ 4.00915823]
 [-1.07838182]] loss fxn value:  0.10439726498457312 learn rate: 1.5625e-05 iteration: 20995
[[ 1.99967624]
 [ 4.00915824]
 [-1.07838345]] loss fxn value:  0.1043682685041703 learn rate: 1.5625e-05 iteration: 20996
[[ 1.99967627]
 [ 4.00915825]
 [-1.07838508]] loss fxn value:  0.10433928007839871 learn rate: 1.5625e-05 iteration: 20997
[[ 1.99967629]
 [ 4.00915825]
 [-1.07838671]] loss fxn value:  0.10431029970288398 learn rate: 1.5625e-05 iteration: 20998
[[ 1.99967632]
 [ 4.00915826]
 [-1.07838834]] loss fxn value:  0.10428132737795852 learn rate: 1.5625e-05 iteration: 20999
[[ 1.99967635]
 [ 4.00915827]
 [-1.07838997]] loss fxn value:  0.10425236310019512 learn rate: 1.5625e-05 iteration: 21000
[[ 1.99967638]
 [ 4.00915828]
 [-1.0783916 ]] loss fxn value:  0.10422340686647501 learn rate: 1.5625e-05 iteration: 21001
[[ 1.9996764 ]
 [ 4.00915829]
 [-1.07839323]] loss fxn value:  0.10419445867598602 learn rate: 1.5625e-05 iteration: 21002
[[ 1.99967643]
 [ 4.0091583 ]
 [-1.07839486]] loss fxn value:  0.10416551852492954 learn rate: 1.5625e-05 iteration: 21003
[[ 1.99967646]
 [ 4.0091583 ]
 [-1.07839648]] loss fxn value:  0.10413658641251732 learn rate: 1.5625e-05 iteration: 21004
[[ 1.99967648]
 [ 4.00915831]
 [-1.07839811]] loss fxn value:  0.10410766233692832 learn rate: 1.5625e-05 iteration: 21005
[[ 1.99967651]
 [ 4.00915832]
 [-1.07839974]] loss fxn value:  0.10407874629439164 learn rate: 1.5625e-05 iteration: 21006
[[ 1.99967654]
 [ 4.00915833]
 [-1.07840136]] loss fxn value:  0.104049838282789 learn rate: 1.5625e-05 iteration: 21007
[[ 1.99967657]
 [ 4.00915834]
 [-1.07840299]] loss fxn value:  0.10402093830120325 learn rate: 1.5625e-05 iteration: 21008
[[ 1.99967659]
 [ 4.00915835]
 [-1.07840461]] loss fxn value:  0.10399204634583581 learn rate: 1.5625e-05 iteration: 21009
[[ 1.99967662]
 [ 4.00915835]
 [-1.07840624]] loss fxn value:  0.10396316241550313 learn rate: 1.5625e-05 iteration: 21010
[[ 1.99967665]
 [ 4.00915836]
 [-1.07840786]] loss fxn value:  0.10393428650781303 learn rate: 1.5625e-05 iteration: 21011
[[ 1.99967667]
 [ 4.00915837]
 [-1.07840949]] loss fxn value:  0.10390541862112726 learn rate: 1.5625e-05 iteration: 21012
[[ 1.9996767 ]
 [ 4.00915838]
 [-1.07841111]] loss fxn value:  0.10387655875193531 learn rate: 1.5625e-05 iteration: 21013
[[ 1.99967673]
 [ 4.00915839]
 [-1.07841273]] loss fxn value:  0.10384770689829385 learn rate: 1.5625e-05 iteration: 21014
[[ 1.99967676]
 [ 4.0091584 ]
 [-1.07841436]] loss fxn value:  0.10381886305910386 learn rate: 1.5625e-05 iteration: 21015
[[ 1.99967678]
 [ 4.0091584 ]
 [-1.07841598]] loss fxn value:  0.10379002723034413 learn rate: 1.5625e-05 iteration: 21016
[[ 1.99967681]
 [ 4.00915841]
 [-1.0784176 ]] loss fxn value:  0.10376119941155076 learn rate: 1.5625e-05 iteration: 21017
[[ 1.99967684]
 [ 4.00915842]
 [-1.07841922]] loss fxn value:  0.10373237959952633 learn rate: 1.5625e-05 iteration: 21018
[[ 1.99967686]
 [ 4.00915843]
 [-1.07842084]] loss fxn value:  0.10370356779197665 learn rate: 1.5625e-05 iteration: 21019
[[ 1.99967689]
 [ 4.00915844]
 [-1.07842246]] loss fxn value:  0.10367476398767263 learn rate: 1.5625e-05 iteration: 21020
[[ 1.99967692]
 [ 4.00915844]
 [-1.07842408]] loss fxn value:  0.1036459681822206 learn rate: 1.5625e-05 iteration: 21021
[[ 1.99967694]
 [ 4.00915845]
 [-1.0784257 ]] loss fxn value:  0.10361718037602706 learn rate: 1.5625e-05 iteration: 21022
[[ 1.99967697]
 [ 4.00915846]
 [-1.07842732]] loss fxn value:  0.10358840056508356 learn rate: 1.5625e-05 iteration: 21023
[[ 1.999677  ]
 [ 4.00915847]
 [-1.07842894]] loss fxn value:  0.10355962874877538 learn rate: 1.5625e-05 iteration: 21024
[[ 1.99967703]
 [ 4.00915848]
 [-1.07843055]] loss fxn value:  0.10353086492224722 learn rate: 1.5625e-05 iteration: 21025
[[ 1.99967705]
 [ 4.00915849]
 [-1.07843217]] loss fxn value:  0.10350210908628853 learn rate: 1.5625e-05 iteration: 21026
[[ 1.99967708]
 [ 4.00915849]
 [-1.07843379]] loss fxn value:  0.10347336123751212 learn rate: 1.5625e-05 iteration: 21027
[[ 1.99967711]
 [ 4.0091585 ]
 [-1.07843541]] loss fxn value:  0.10344462137227135 learn rate: 1.5625e-05 iteration: 21028
[[ 1.99967713]
 [ 4.00915851]
 [-1.07843702]] loss fxn value:  0.10341588948972087 learn rate: 1.5625e-05 iteration: 21029
[[ 1.99967716]
 [ 4.00915852]
 [-1.07843864]] loss fxn value:  0.10338716558807282 learn rate: 1.5625e-05 iteration: 21030
[[ 1.99967719]
 [ 4.00915853]
 [-1.07844025]] loss fxn value:  0.1033584496640519 learn rate: 1.5625e-05 iteration: 21031
[[ 1.99967721]
 [ 4.00915853]
 [-1.07844187]] loss fxn value:  0.10332974171732913 learn rate: 1.5625e-05 iteration: 21032
[[ 1.99967724]
 [ 4.00915854]
 [-1.07844348]] loss fxn value:  0.10330104174271335 learn rate: 1.5625e-05 iteration: 21033
[[ 1.99967727]
 [ 4.00915855]
 [-1.0784451 ]] loss fxn value:  0.10327234973948028 learn rate: 1.5625e-05 iteration: 21034
[[ 1.9996773 ]
 [ 4.00915856]
 [-1.07844671]] loss fxn value:  0.10324366570665888 learn rate: 1.5625e-05 iteration: 21035
[[ 1.99967732]
 [ 4.00915857]
 [-1.07844832]] loss fxn value:  0.10321498964007372 learn rate: 1.5625e-05 iteration: 21036
[[ 1.99967735]
 [ 4.00915858]
 [-1.07844993]] loss fxn value:  0.10318632153853204 learn rate: 1.5625e-05 iteration: 21037
[[ 1.99967738]
 [ 4.00915858]
 [-1.07845155]] loss fxn value:  0.10315766140003922 learn rate: 1.5625e-05 iteration: 21038
[[ 1.9996774 ]
 [ 4.00915859]
 [-1.07845316]] loss fxn value:  0.10312900922147657 learn rate: 1.5625e-05 iteration: 21039
[[ 1.99967743]
 [ 4.0091586 ]
 [-1.07845477]] loss fxn value:  0.10310036500065166 learn rate: 1.5625e-05 iteration: 21040
[[ 1.99967746]
 [ 4.00915861]
 [-1.07845638]] loss fxn value:  0.10307172873608171 learn rate: 1.5625e-05 iteration: 21041
[[ 1.99967748]
 [ 4.00915862]
 [-1.07845799]] loss fxn value:  0.10304310042559509 learn rate: 1.5625e-05 iteration: 21042
[[ 1.99967751]
 [ 4.00915862]
 [-1.0784596 ]] loss fxn value:  0.10301448006681202 learn rate: 1.5625e-05 iteration: 21043
[[ 1.99967754]
 [ 4.00915863]
 [-1.07846121]] loss fxn value:  0.1029858676570422 learn rate: 1.5625e-05 iteration: 21044
[[ 1.99967756]
 [ 4.00915864]
 [-1.07846282]] loss fxn value:  0.10295726319361925 learn rate: 1.5625e-05 iteration: 21045
[[ 1.99967759]
 [ 4.00915865]
 [-1.07846443]] loss fxn value:  0.10292866667609081 learn rate: 1.5625e-05 iteration: 21046
[[ 1.99967762]
 [ 4.00915866]
 [-1.07846603]] loss fxn value:  0.10290007810111759 learn rate: 1.5625e-05 iteration: 21047
[[ 1.99967764]
 [ 4.00915867]
 [-1.07846764]] loss fxn value:  0.10287149746612112 learn rate: 1.5625e-05 iteration: 21048
[[ 1.99967767]
 [ 4.00915867]
 [-1.07846925]] loss fxn value:  0.10284292477019208 learn rate: 1.5625e-05 iteration: 21049
[[ 1.9996777 ]
 [ 4.00915868]
 [-1.07847086]] loss fxn value:  0.10281436001006439 learn rate: 1.5625e-05 iteration: 21050
[[ 1.99967772]
 [ 4.00915869]
 [-1.07847246]] loss fxn value:  0.10278580318397411 learn rate: 1.5625e-05 iteration: 21051
[[ 1.99967775]
 [ 4.0091587 ]
 [-1.07847407]] loss fxn value:  0.10275725428916 learn rate: 1.5625e-05 iteration: 21052
[[ 1.99967778]
 [ 4.00915871]
 [-1.07847567]] loss fxn value:  0.10272871332432436 learn rate: 1.5625e-05 iteration: 21053
[[ 1.99967781]
 [ 4.00915871]
 [-1.07847728]] loss fxn value:  0.10270018028665118 learn rate: 1.5625e-05 iteration: 21054
[[ 1.99967783]
 [ 4.00915872]
 [-1.07847888]] loss fxn value:  0.10267165517437654 learn rate: 1.5625e-05 iteration: 21055
[[ 1.99967786]
 [ 4.00915873]
 [-1.07848049]] loss fxn value:  0.1026431379842822 learn rate: 1.5625e-05 iteration: 21056
[[ 1.99967789]
 [ 4.00915874]
 [-1.07848209]] loss fxn value:  0.10261462871558914 learn rate: 1.5625e-05 iteration: 21057
[[ 1.99967791]
 [ 4.00915875]
 [-1.07848369]] loss fxn value:  0.10258612736480843 learn rate: 1.5625e-05 iteration: 21058
[[ 1.99967794]
 [ 4.00915876]
 [-1.0784853 ]] loss fxn value:  0.10255763393048231 learn rate: 1.5625e-05 iteration: 21059
[[ 1.99967797]
 [ 4.00915876]
 [-1.0784869 ]] loss fxn value:  0.10252914841013298 learn rate: 1.5625e-05 iteration: 21060
[[ 1.99967799]
 [ 4.00915877]
 [-1.0784885 ]] loss fxn value:  0.10250067080150636 learn rate: 1.5625e-05 iteration: 21061
[[ 1.99967802]
 [ 4.00915878]
 [-1.0784901 ]] loss fxn value:  0.10247220110376172 learn rate: 1.5625e-05 iteration: 21062
[[ 1.99967805]
 [ 4.00915879]
 [-1.0784917 ]] loss fxn value:  0.10244373931316911 learn rate: 1.5625e-05 iteration: 21063
[[ 1.99967807]
 [ 4.0091588 ]
 [-1.0784933 ]] loss fxn value:  0.10241528542702434 learn rate: 1.5625e-05 iteration: 21064
[[ 1.9996781]
 [ 4.0091588]
 [-1.0784949]] loss fxn value:  0.10238683944403433 learn rate: 1.5625e-05 iteration: 21065
[[ 1.99967813]
 [ 4.00915881]
 [-1.0784965 ]] loss fxn value:  0.10235840136231636 learn rate: 1.5625e-05 iteration: 21066
[[ 1.99967815]
 [ 4.00915882]
 [-1.0784981 ]] loss fxn value:  0.10232997117913775 learn rate: 1.5625e-05 iteration: 21067
[[ 1.99967818]
 [ 4.00915883]
 [-1.0784997 ]] loss fxn value:  0.10230154889273915 learn rate: 1.5625e-05 iteration: 21068
[[ 1.99967821]
 [ 4.00915884]
 [-1.0785013 ]] loss fxn value:  0.10227313450031383 learn rate: 1.5625e-05 iteration: 21069
[[ 1.99967823]
 [ 4.00915884]
 [-1.0785029 ]] loss fxn value:  0.10224472800005775 learn rate: 1.5625e-05 iteration: 21070
[[ 1.99967826]
 [ 4.00915885]
 [-1.07850449]] loss fxn value:  0.10221632939077267 learn rate: 1.5625e-05 iteration: 21071
[[ 1.99967829]
 [ 4.00915886]
 [-1.07850609]] loss fxn value:  0.10218793866802482 learn rate: 1.5625e-05 iteration: 21072
[[ 1.99967831]
 [ 4.00915887]
 [-1.07850769]] loss fxn value:  0.10215955583078491 learn rate: 1.5625e-05 iteration: 21073
[[ 1.99967834]
 [ 4.00915888]
 [-1.07850928]] loss fxn value:  0.1021311808775038 learn rate: 1.5625e-05 iteration: 21074
[[ 1.99967837]
 [ 4.00915889]
 [-1.07851088]] loss fxn value:  0.10210281380596749 learn rate: 1.5625e-05 iteration: 21075
[[ 1.99967839]
 [ 4.00915889]
 [-1.07851247]] loss fxn value:  0.1020744546115528 learn rate: 1.5625e-05 iteration: 21076
[[ 1.99967842]
 [ 4.0091589 ]
 [-1.07851407]] loss fxn value:  0.10204610329584289 learn rate: 1.5625e-05 iteration: 21077
[[ 1.99967845]
 [ 4.00915891]
 [-1.07851566]] loss fxn value:  0.1020177598539816 learn rate: 1.5625e-05 iteration: 21078
[[ 1.99967847]
 [ 4.00915892]
 [-1.07851726]] loss fxn value:  0.1019894242844071 learn rate: 1.5625e-05 iteration: 21079
[[ 1.9996785 ]
 [ 4.00915893]
 [-1.07851885]] loss fxn value:  0.10196109658467248 learn rate: 1.5625e-05 iteration: 21080
[[ 1.99967853]
 [ 4.00915893]
 [-1.07852044]] loss fxn value:  0.10193277675352783 learn rate: 1.5625e-05 iteration: 21081
[[ 1.99967855]
 [ 4.00915894]
 [-1.07852203]] loss fxn value:  0.10190446478870208 learn rate: 1.5625e-05 iteration: 21082
[[ 1.99967858]
 [ 4.00915895]
 [-1.07852363]] loss fxn value:  0.10187616068735299 learn rate: 1.5625e-05 iteration: 21083
[[ 1.9996786 ]
 [ 4.00915896]
 [-1.07852522]] loss fxn value:  0.10184786444725502 learn rate: 1.5625e-05 iteration: 21084
[[ 1.99967863]
 [ 4.00915897]
 [-1.07852681]] loss fxn value:  0.10181957606623426 learn rate: 1.5625e-05 iteration: 21085
[[ 1.99967866]
 [ 4.00915897]
 [-1.0785284 ]] loss fxn value:  0.10179129554283413 learn rate: 1.5625e-05 iteration: 21086
[[ 1.99967868]
 [ 4.00915898]
 [-1.07852999]] loss fxn value:  0.101763022874298 learn rate: 1.5625e-05 iteration: 21087
[[ 1.99967871]
 [ 4.00915899]
 [-1.07853158]] loss fxn value:  0.10173475805844043 learn rate: 1.5625e-05 iteration: 21088
[[ 1.99967874]
 [ 4.009159  ]
 [-1.07853317]] loss fxn value:  0.10170650109380483 learn rate: 1.5625e-05 iteration: 21089
[[ 1.99967876]
 [ 4.00915901]
 [-1.07853476]] loss fxn value:  0.10167825197587296 learn rate: 1.5625e-05 iteration: 21090
[[ 1.99967879]
 [ 4.00915901]
 [-1.07853635]] loss fxn value:  0.10165001070522751 learn rate: 1.5625e-05 iteration: 21091
[[ 1.99967882]
 [ 4.00915902]
 [-1.07853793]] loss fxn value:  0.10162177727895763 learn rate: 1.5625e-05 iteration: 21092
[[ 1.99967884]
 [ 4.00915903]
 [-1.07853952]] loss fxn value:  0.10159355169442318 learn rate: 1.5625e-05 iteration: 21093
[[ 1.99967887]
 [ 4.00915904]
 [-1.07854111]] loss fxn value:  0.10156533394835116 learn rate: 1.5625e-05 iteration: 21094
[[ 1.9996789 ]
 [ 4.00915905]
 [-1.0785427 ]] loss fxn value:  0.10153712404143612 learn rate: 1.5625e-05 iteration: 21095
[[ 1.99967892]
 [ 4.00915905]
 [-1.07854428]] loss fxn value:  0.10150892196877725 learn rate: 1.5625e-05 iteration: 21096
[[ 1.99967895]
 [ 4.00915906]
 [-1.07854587]] loss fxn value:  0.10148072773029786 learn rate: 1.5625e-05 iteration: 21097
[[ 1.99967898]
 [ 4.00915907]
 [-1.07854745]] loss fxn value:  0.10145254132155869 learn rate: 1.5625e-05 iteration: 21098
[[ 1.999679  ]
 [ 4.00915908]
 [-1.07854904]] loss fxn value:  0.10142436274281431 learn rate: 1.5625e-05 iteration: 21099
[[ 1.99967903]
 [ 4.00915909]
 [-1.07855062]] loss fxn value:  0.10139619199078168 learn rate: 1.5625e-05 iteration: 21100
[[ 1.99967906]
 [ 4.00915909]
 [-1.07855221]] loss fxn value:  0.1013680290612669 learn rate: 1.5625e-05 iteration: 21101
[[ 1.99967908]
 [ 4.0091591 ]
 [-1.07855379]] loss fxn value:  0.10133987395587388 learn rate: 1.5625e-05 iteration: 21102
[[ 1.99967911]
 [ 4.00915911]
 [-1.07855537]] loss fxn value:  0.10131172667127254 learn rate: 1.5625e-05 iteration: 21103
[[ 1.99967913]
 [ 4.00915912]
 [-1.07855696]] loss fxn value:  0.10128358720282588 learn rate: 1.5625e-05 iteration: 21104
[[ 1.99967916]
 [ 4.00915913]
 [-1.07855854]] loss fxn value:  0.10125545555119526 learn rate: 1.5625e-05 iteration: 21105
[[ 1.99967919]
 [ 4.00915913]
 [-1.07856012]] loss fxn value:  0.10122733171253426 learn rate: 1.5625e-05 iteration: 21106
[[ 1.99967921]
 [ 4.00915914]
 [-1.0785617 ]] loss fxn value:  0.10119921568572102 learn rate: 1.5625e-05 iteration: 21107
[[ 1.99967924]
 [ 4.00915915]
 [-1.07856328]] loss fxn value:  0.10117110746778758 learn rate: 1.5625e-05 iteration: 21108
[[ 1.99967927]
 [ 4.00915916]
 [-1.07856486]] loss fxn value:  0.10114300705751725 learn rate: 1.5625e-05 iteration: 21109
[[ 1.99967929]
 [ 4.00915917]
 [-1.07856644]] loss fxn value:  0.10111491445163472 learn rate: 1.5625e-05 iteration: 21110
[[ 1.99967932]
 [ 4.00915918]
 [-1.07856802]] loss fxn value:  0.10108682964890399 learn rate: 1.5625e-05 iteration: 21111
[[ 1.99967935]
 [ 4.00915918]
 [-1.0785696 ]] loss fxn value:  0.10105875264595028 learn rate: 1.5625e-05 iteration: 21112
[[ 1.99967937]
 [ 4.00915919]
 [-1.07857118]] loss fxn value:  0.10103068344212024 learn rate: 1.5625e-05 iteration: 21113
[[ 1.9996794 ]
 [ 4.0091592 ]
 [-1.07857276]] loss fxn value:  0.1010026220353507 learn rate: 1.5625e-05 iteration: 21114
[[ 1.99967942]
 [ 4.00915921]
 [-1.07857434]] loss fxn value:  0.1009745684212044 learn rate: 1.5625e-05 iteration: 21115
[[ 1.99967945]
 [ 4.00915922]
 [-1.07857592]] loss fxn value:  0.1009465225996883 learn rate: 1.5625e-05 iteration: 21116
[[ 1.99967948]
 [ 4.00915922]
 [-1.07857749]] loss fxn value:  0.10091848456853822 learn rate: 1.5625e-05 iteration: 21117
[[ 1.9996795 ]
 [ 4.00915923]
 [-1.07857907]] loss fxn value:  0.10089045432355104 learn rate: 1.5625e-05 iteration: 21118
[[ 1.99967953]
 [ 4.00915924]
 [-1.07858065]] loss fxn value:  0.10086243186443095 learn rate: 1.5625e-05 iteration: 21119
[[ 1.99967956]
 [ 4.00915925]
 [-1.07858222]] loss fxn value:  0.10083441718927823 learn rate: 1.5625e-05 iteration: 21120
[[ 1.99967958]
 [ 4.00915926]
 [-1.0785838 ]] loss fxn value:  0.10080641029492483 learn rate: 1.5625e-05 iteration: 21121
[[ 1.99967961]
 [ 4.00915926]
 [-1.07858537]] loss fxn value:  0.10077841117947563 learn rate: 1.5625e-05 iteration: 21122
[[ 1.99967963]
 [ 4.00915927]
 [-1.07858695]] loss fxn value:  0.10075041984125463 learn rate: 1.5625e-05 iteration: 21123
[[ 1.99967966]
 [ 4.00915928]
 [-1.07858852]] loss fxn value:  0.1007224362774813 learn rate: 1.5625e-05 iteration: 21124
[[ 1.99967969]
 [ 4.00915929]
 [-1.07859009]] loss fxn value:  0.10069446048527103 learn rate: 1.5625e-05 iteration: 21125
[[ 1.99967971]
 [ 4.0091593 ]
 [-1.07859167]] loss fxn value:  0.10066649246397823 learn rate: 1.5625e-05 iteration: 21126
[[ 1.99967974]
 [ 4.0091593 ]
 [-1.07859324]] loss fxn value:  0.1006385322111652 learn rate: 1.5625e-05 iteration: 21127
[[ 1.99967977]
 [ 4.00915931]
 [-1.07859481]] loss fxn value:  0.10061057972317836 learn rate: 1.5625e-05 iteration: 21128
[[ 1.99967979]
 [ 4.00915932]
 [-1.07859638]] loss fxn value:  0.10058263500063355 learn rate: 1.5625e-05 iteration: 21129
[[ 1.99967982]
 [ 4.00915933]
 [-1.07859795]] loss fxn value:  0.10055469803971057 learn rate: 1.5625e-05 iteration: 21130
[[ 1.99967984]
 [ 4.00915933]
 [-1.07859953]] loss fxn value:  0.10052676883676737 learn rate: 1.5625e-05 iteration: 21131
[[ 1.99967987]
 [ 4.00915934]
 [-1.0786011 ]] loss fxn value:  0.10049884739204842 learn rate: 1.5625e-05 iteration: 21132
[[ 1.9996799 ]
 [ 4.00915935]
 [-1.07860267]] loss fxn value:  0.10047093370252873 learn rate: 1.5625e-05 iteration: 21133
[[ 1.99967992]
 [ 4.00915936]
 [-1.07860424]] loss fxn value:  0.10044302776613238 learn rate: 1.5625e-05 iteration: 21134
[[ 1.99967995]
 [ 4.00915937]
 [-1.0786058 ]] loss fxn value:  0.10041512958141663 learn rate: 1.5625e-05 iteration: 21135
[[ 1.99967998]
 [ 4.00915937]
 [-1.07860737]] loss fxn value:  0.10038723914426081 learn rate: 1.5625e-05 iteration: 21136
[[ 1.99968   ]
 [ 4.00915938]
 [-1.07860894]] loss fxn value:  0.10035935645381037 learn rate: 1.5625e-05 iteration: 21137
[[ 1.99968003]
 [ 4.00915939]
 [-1.07861051]] loss fxn value:  0.10033148150827285 learn rate: 1.5625e-05 iteration: 21138
[[ 1.99968005]
 [ 4.0091594 ]
 [-1.07861208]] loss fxn value:  0.10030361430483682 learn rate: 1.5625e-05 iteration: 21139
[[ 1.99968008]
 [ 4.00915941]
 [-1.07861364]] loss fxn value:  0.10027575484168127 learn rate: 1.5625e-05 iteration: 21140
[[ 1.99968011]
 [ 4.00915941]
 [-1.07861521]] loss fxn value:  0.10024790311667786 learn rate: 1.5625e-05 iteration: 21141
[[ 1.99968013]
 [ 4.00915942]
 [-1.07861678]] loss fxn value:  0.10022005912686321 learn rate: 1.5625e-05 iteration: 21142
[[ 1.99968016]
 [ 4.00915943]
 [-1.07861834]] loss fxn value:  0.10019222287163188 learn rate: 1.5625e-05 iteration: 21143
[[ 1.99968018]
 [ 4.00915944]
 [-1.07861991]] loss fxn value:  0.10016439434795191 learn rate: 1.5625e-05 iteration: 21144
[[ 1.99968021]
 [ 4.00915945]
 [-1.07862147]] loss fxn value:  0.10013657355233319 learn rate: 1.5625e-05 iteration: 21145
[[ 1.99968024]
 [ 4.00915945]
 [-1.07862304]] loss fxn value:  0.10010876048529903 learn rate: 1.5625e-05 iteration: 21146
[[ 1.99968026]
 [ 4.00915946]
 [-1.0786246 ]] loss fxn value:  0.10008095514258925 learn rate: 1.5625e-05 iteration: 21147
[[ 1.99968029]
 [ 4.00915947]
 [-1.07862616]] loss fxn value:  0.10005315752340316 learn rate: 1.5625e-05 iteration: 21148
[[ 1.99968032]
 [ 4.00915948]
 [-1.07862773]] loss fxn value:  0.10002536762497956 learn rate: 1.5625e-05 iteration: 21149
[[ 1.99968034]
 [ 4.00915949]
 [-1.07862929]] loss fxn value:  0.09999758544512143 learn rate: 1.5625e-05 iteration: 21150

