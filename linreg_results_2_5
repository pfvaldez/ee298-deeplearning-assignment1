Input: 
2 5

Output:

[[2.45662797]
 [0.27797887]] loss fxn value:  634.0151918154002 learn rate: 0.001 iteration: 1
[[1.85246293]
 [0.47022834]] loss fxn value:  271.319699943418 learn rate: 0.001 iteration: 2
[[2.05678071]
 [0.64874619]] loss fxn value:  185.79109523817513 learn rate: 0.001 iteration: 3
[[1.99011943]
 [0.82216651]] loss fxn value:  167.55416922651946 learn rate: 0.001 iteration: 4
[[2.01418516]
 [0.98798339]] loss fxn value:  159.55343389820186 learn rate: 0.001 iteration: 5
[[2.00778131]
 [1.14740826]] loss fxn value:  153.02953387785698 learn rate: 0.001 iteration: 6
[[2.01152085]
 [1.3003921 ]] loss fxn value:  146.90213931433343 learn rate: 0.001 iteration: 7
[[2.01179794]
 [1.44729398]] loss fxn value:  141.0352882504603 learn rate: 0.001 iteration: 8
[[2.01317414]
 [1.58832255]] loss fxn value:  135.4045202324329 learn rate: 0.001 iteration: 9
[[2.0141234 ]
 [1.72372374]] loss fxn value:  129.99876590907886 learn rate: 0.001 iteration: 10
[[2.01515941]
 [1.85371838]] loss fxn value:  124.80884981644438 learn rate: 0.001 iteration: 11
[[2.01611229]
 [1.97852359]] loss fxn value:  119.82613260378436 learn rate: 0.001 iteration: 12
[[2.01704113]
 [2.09834613]] loss fxn value:  115.04233968503844 learn rate: 0.001 iteration: 13
[[2.01792819]
 [2.21338505]] loss fxn value:  110.44952914093777 learn rate: 0.001 iteration: 14
[[2.01878141]
 [2.32383128]] loss fxn value:  106.04007638732483 learn rate: 0.001 iteration: 15
[[2.01960005]
 [2.4298682 ]] loss fxn value:  101.80666126643257 learn rate: 0.001 iteration: 16
[[2.02038617]
 [2.53167182]] loss fxn value:  97.74225586528942 learn rate: 0.001 iteration: 17
[[2.02114086]
 [2.62941116]] loss fxn value:  93.84011284521334 learn rate: 0.001 iteration: 18
[[2.02186543]
 [2.72324848]] loss fxn value:  90.09375424012147 learn rate: 0.001 iteration: 19
[[2.02256107]
 [2.81333955]] loss fxn value:  86.496960702381 learn rate: 0.001 iteration: 20
[[2.02322894]
 [2.89983393]] loss fxn value:  83.0437611780352 learn rate: 0.001 iteration: 21
[[2.02387015]
 [2.98287522]] loss fxn value:  79.72842299422798 learn rate: 0.001 iteration: 22
[[2.02448576]
 [3.06260126]] loss fxn value:  76.54544234236641 learn rate: 0.001 iteration: 23
[[2.02507679]
 [3.13914442]] loss fxn value:  73.48953514122212 learn rate: 0.001 iteration: 24
[[2.02564423]
 [3.21263177]] loss fxn value:  70.55562826480312 learn rate: 0.001 iteration: 25
[[2.02618901]
 [3.28318529]] loss fxn value:  67.7388511204331 learn rate: 0.001 iteration: 26
[[2.02671204]
 [3.35092212]] loss fxn value:  65.03452756305788 learn rate: 0.001 iteration: 27
[[2.02721419]
 [3.41595471]] loss fxn value:  62.4381681323545 learn rate: 0.001 iteration: 28
[[2.0276963 ]
 [3.47839102]] loss fxn value:  59.945462599757256 learn rate: 0.001 iteration: 29
[[2.02815916]
 [3.5383347 ]] loss fxn value:  57.552272813026725 learn rate: 0.001 iteration: 30
[[2.02860354]
 [3.59588525]] loss fxn value:  55.25462582648363 learn rate: 0.001 iteration: 31
[[2.02903017]
 [3.65113823]] loss fxn value:  53.04870730550295 learn rate: 0.001 iteration: 32
[[2.02943978]
 [3.70418536]] loss fxn value:  50.930855194319136 learn rate: 0.001 iteration: 33
[[2.02983303]
 [3.75511469]] loss fxn value:  48.89755363662976 learn rate: 0.001 iteration: 34
[[2.03021059]
 [3.80401079]] loss fxn value:  46.94542713890606 learn rate: 0.001 iteration: 35
[[2.03057307]
 [3.85095482]] loss fxn value:  45.07123496672008 learn rate: 0.001 iteration: 36
[[2.03092108]
 [3.89602471]] loss fxn value:  43.271865764786135 learn rate: 0.001 iteration: 37
[[2.03125519]
 [3.93929529]] loss fxn value:  41.54433239178518 learn rate: 0.001 iteration: 38
[[2.03157597]
 [3.98083838]] loss fxn value:  39.885766961397444 learn rate: 0.001 iteration: 39
[[2.03188394]
 [4.02072296]] loss fxn value:  38.2934160813107 learn rate: 0.001 iteration: 40
[[2.03217962]
 [4.05901523]] loss fxn value:  36.76463628230072 learn rate: 0.001 iteration: 41
[[2.03246349]
 [4.09577877]] loss fxn value:  35.29688962979561 learn rate: 0.001 iteration: 42
[[2.03273603]
 [4.13107461]] loss fxn value:  33.887739510638404 learn rate: 0.001 iteration: 43
[[2.03299768]
 [4.16496134]] loss fxn value:  32.53484658805427 learn rate: 0.001 iteration: 44
[[2.0332489 ]
 [4.19749522]] loss fxn value:  31.235964918106287 learn rate: 0.001 iteration: 45
[[2.03349008]
 [4.22873025]] loss fxn value:  29.988938221193465 learn rate: 0.001 iteration: 46
[[2.03372163]
 [4.25871829]] loss fxn value:  28.791696302400705 learn rate: 0.001 iteration: 47
[[2.03394394]
 [4.28750913]] loss fxn value:  27.642251614758347 learn rate: 0.001 iteration: 48
[[2.03415738]
 [4.31515056]] loss fxn value:  26.538695959706267 learn rate: 0.001 iteration: 49
[[2.03436229]
 [4.34168846]] loss fxn value:  25.479197319284204 learn rate: 0.001 iteration: 50
[[2.03455902]
 [4.3671669 ]] loss fxn value:  24.46199681479016 learn rate: 0.001 iteration: 51
[[2.0347479 ]
 [4.39162817]] loss fxn value:  23.48540578685755 learn rate: 0.001 iteration: 52
[[2.03492924]
 [4.41511287]] loss fxn value:  22.547802992103954 learn rate: 0.001 iteration: 53
[[2.03510334]
 [4.43766001]] loss fxn value:  21.647631911697033 learn rate: 0.001 iteration: 54
[[2.03527049]
 [4.45930699]] loss fxn value:  20.783398167370475 learn rate: 0.001 iteration: 55
[[2.03543096]
 [4.48008977]] loss fxn value:  19.953667040599488 learn rate: 0.001 iteration: 56
[[2.03558503]
 [4.50004284]] loss fxn value:  19.157061090817727 learn rate: 0.001 iteration: 57
[[2.03573295]
 [4.51919933]] loss fxn value:  18.392257868721966 learn rate: 0.001 iteration: 58
[[2.03587496]
 [4.53759104]] loss fxn value:  17.657987720867276 learn rate: 0.001 iteration: 59
[[2.03601131]
 [4.5552485 ]] loss fxn value:  16.953031681909888 learn rate: 0.001 iteration: 60
[[2.0361422 ]
 [4.57220103]] loss fxn value:  16.276219450996653 learn rate: 0.001 iteration: 61
[[2.03626788]
 [4.58847676]] loss fxn value:  15.626427448943312 learn rate: 0.001 iteration: 62
[[2.03638854]
 [4.60410273]] loss fxn value:  15.00257695297521 learn rate: 0.001 iteration: 63
[[2.03650437]
 [4.61910486]] loss fxn value:  14.403632305934561 learn rate: 0.001 iteration: 64
[[2.03661559]
 [4.63350806]] loss fxn value:  13.828599196981237 learn rate: 0.001 iteration: 65
[[2.03672236]
 [4.64733625]] loss fxn value:  13.276523010932392 learn rate: 0.001 iteration: 66
[[2.03682488]
 [4.66061237]] loss fxn value:  12.746487243501576 learn rate: 0.001 iteration: 67
[[2.0369233 ]
 [4.67335848]] loss fxn value:  12.237611979805454 learn rate: 0.001 iteration: 68
[[2.03701779]
 [4.68559573]] loss fxn value:  11.749052433612851 learn rate: 0.001 iteration: 69
[[2.03710851]
 [4.69734443]] loss fxn value:  11.279997544911472 learn rate: 0.001 iteration: 70
[[2.0371956 ]
 [4.70862409]] loss fxn value:  10.82966863346294 learn rate: 0.001 iteration: 71
[[2.03727922]
 [4.71945344]] loss fxn value:  10.397318106112316 learn rate: 0.001 iteration: 72
[[2.0373595 ]
 [4.72985045]] loss fxn value:  9.9822282157052 learn rate: 0.001 iteration: 73
[[2.03743658]
 [4.73983238]] loss fxn value:  9.583709869552093 learn rate: 0.001 iteration: 74
[[2.03751058]
 [4.7494158 ]] loss fxn value:  9.20110148546244 learn rate: 0.001 iteration: 75
[[2.03758162]
 [4.75861663]] loss fxn value:  8.833767893448925 learn rate: 0.001 iteration: 76
[[2.03764983]
 [4.76745013]] loss fxn value:  8.481099281278883 learn rate: 0.001 iteration: 77
[[2.03771532]
 [4.77593098]] loss fxn value:  8.142510182121804 learn rate: 0.001 iteration: 78
[[2.03777819]
 [4.78407325]] loss fxn value:  7.817438502613528 learn rate: 0.001 iteration: 79
[[2.03783855]
 [4.79189045]] loss fxn value:  7.50534458972205 learn rate: 0.001 iteration: 80
[[2.0378965 ]
 [4.79939557]] loss fxn value:  7.205710334867074 learn rate: 0.001 iteration: 81
[[2.03795214]
 [4.80660107]] loss fxn value:  6.918038313805477 learn rate: 0.001 iteration: 82
[[2.03800555]
 [4.8135189 ]] loss fxn value:  6.641850960855152 learn rate: 0.001 iteration: 83
[[2.03805684]
 [4.82016055]] loss fxn value:  6.37668977608567 learn rate: 0.001 iteration: 84
[[2.03810607]
 [4.82653705]] loss fxn value:  6.12211456416066 learn rate: 0.001 iteration: 85
[[2.03815334]
 [4.83265898]] loss fxn value:  5.877702703567176 learn rate: 0.001 iteration: 86
[[2.03819873]
 [4.83853651]] loss fxn value:  5.6430484450199705 learn rate: 0.001 iteration: 87
[[2.0382423 ]
 [4.84417939]] loss fxn value:  5.417762237875057 learn rate: 0.001 iteration: 88
[[2.03828413]
 [4.84959699]] loss fxn value:  5.201470083434818 learn rate: 0.001 iteration: 89
[[2.03832429]
 [4.85479831]] loss fxn value:  4.993812914071169 learn rate: 0.001 iteration: 90
[[2.03836285]
 [4.85979197]] loss fxn value:  4.794445997135512 learn rate: 0.001 iteration: 91
[[2.03839987]
 [4.86458627]] loss fxn value:  4.603038362666378 learn rate: 0.001 iteration: 92
[[2.03843541]
 [4.86918918]] loss fxn value:  4.419272253945004 learn rate: 0.001 iteration: 93
[[2.03846954]
 [4.87360832]] loss fxn value:  4.242842599985409 learn rate: 0.001 iteration: 94
[[2.0385023 ]
 [4.87785103]] loss fxn value:  4.073456509084967 learn rate: 0.001 iteration: 95
[[2.03853375]
 [4.88192437]] loss fxn value:  3.9108327825934386 learn rate: 0.001 iteration: 96
[[2.03856394]
 [4.88583508]] loss fxn value:  3.754701448093528 learn rate: 0.001 iteration: 97
[[2.03859294]
 [4.88958967]] loss fxn value:  3.604803311218765 learn rate: 0.001 iteration: 98
[[2.03862077]
 [4.89319437]] loss fxn value:  3.4608895253634024 learn rate: 0.001 iteration: 99
[[2.03864749]
 [4.89665516]] loss fxn value:  3.3227211785712396 learn rate: 0.001 iteration: 100
[[2.03867315]
 [4.89997778]] loss fxn value:  3.1900688969164364 learn rate: 0.001 iteration: 101
[[2.03869778]
 [4.90316775]] loss fxn value:  3.0627124637191234 learn rate: 0.001 iteration: 102
[[2.03872143]
 [4.90623037]] loss fxn value:  2.94044045396248 learn rate: 0.001 iteration: 103
[[2.03874413]
 [4.90917073]] loss fxn value:  2.8230498833050053 learn rate: 0.001 iteration: 104
[[2.03876593]
 [4.91199369]] loss fxn value:  2.7103458711053086 learn rate: 0.001 iteration: 105
[[2.03878686]
 [4.91470396]] loss fxn value:  2.602141316900046 learn rate: 0.001 iteration: 106
[[2.03880695]
 [4.91730602]] loss fxn value:  2.4982565897971045 learn rate: 0.001 iteration: 107
[[2.03882624]
 [4.9198042 ]] loss fxn value:  2.3985192302699394 learn rate: 0.001 iteration: 108
[[2.03884476]
 [4.92220265]] loss fxn value:  2.3027636638564237 learn rate: 0.001 iteration: 109
[[2.03886254]
 [4.92450535]] loss fxn value:  2.2108309262881254 learn rate: 0.001 iteration: 110
[[2.03887961]
 [4.92671611]] loss fxn value:  2.122568399592662 learn rate: 0.001 iteration: 111
[[2.038896  ]
 [4.92883862]] loss fxn value:  2.0378295587323003 learn rate: 0.001 iteration: 112
[[2.03891173]
 [4.93087638]] loss fxn value:  1.9564737283566391 learn rate: 0.001 iteration: 113
[[2.03892684]
 [4.9328328 ]] loss fxn value:  1.8783658492670858 learn rate: 0.001 iteration: 114
[[2.03894134]
 [4.93471111]] loss fxn value:  1.8033762542042766 learn rate: 0.001 iteration: 115
[[2.03895527]
 [4.93651443]] loss fxn value:  1.7313804525868965 learn rate: 0.001 iteration: 116
[[2.03896864]
 [4.93824576]] loss fxn value:  1.662258923844325 learn rate: 0.001 iteration: 117
[[2.03898147]
 [4.93990797]] loss fxn value:  1.5958969189998893 learn rate: 0.001 iteration: 118
[[2.03899379]
 [4.94150382]] loss fxn value:  1.5321842701756379 learn rate: 0.001 iteration: 119
[[2.03900562]
 [4.94303596]] loss fxn value:  1.4710152077020193 learn rate: 0.001 iteration: 120
[[2.03901698]
 [4.94450693]] loss fxn value:  1.4122881845292858 learn rate: 0.001 iteration: 121
[[2.03902789]
 [4.94591918]] loss fxn value:  1.355905707648519 learn rate: 0.001 iteration: 122
[[2.03903836]
 [4.94727504]] loss fxn value:  1.3017741762434003 learn rate: 0.001 iteration: 123
[[2.03904841]
 [4.94857678]] loss fxn value:  1.2498037263026451 learn rate: 0.001 iteration: 124
[[2.03905806]
 [4.94982654]] loss fxn value:  1.199908081436672 learn rate: 0.001 iteration: 125
[[2.03906732]
 [4.95102641]] loss fxn value:  1.1520044096494637 learn rate: 0.001 iteration: 126
[[2.03907622]
 [4.95217838]] loss fxn value:  1.1060131858291002 learn rate: 0.001 iteration: 127
[[2.03908476]
 [4.95328437]] loss fxn value:  1.06185805972742 learn rate: 0.001 iteration: 128
[[2.03909296]
 [4.95434619]] loss fxn value:  1.0194657292108635 learn rate: 0.001 iteration: 129
[[2.03910083]
 [4.95536563]] loss fxn value:  0.9787658185711146 learn rate: 0.001 iteration: 130
[[2.03910839]
 [4.95634436]] loss fxn value:  0.939690761694061 learn rate: 0.001 iteration: 131
[[2.03911564]
 [4.95728403]] loss fxn value:  0.9021756898930773 learn rate: 0.001 iteration: 132
[[2.03912261]
 [4.95818618]] loss fxn value:  0.8661583242201963 learn rate: 0.001 iteration: 133
[[2.0391293 ]
 [4.95905231]] loss fxn value:  0.8315788720762445 learn rate: 0.001 iteration: 134
[[2.03913572]
 [4.95988386]] loss fxn value:  0.7983799279493121 learn rate: 0.001 iteration: 135
[[2.03914188]
 [4.96068222]] loss fxn value:  0.7665063781152546 learn rate: 0.001 iteration: 136
[[2.0391478]
 [4.9614487]] loss fxn value:  0.735905309143341 learn rate: 0.001 iteration: 137
[[2.03915348]
 [4.96218458]] loss fxn value:  0.7065259200542844 learn rate: 0.001 iteration: 138
[[2.03915894]
 [4.96289109]] loss fxn value:  0.6783194379853426 learn rate: 0.001 iteration: 139
[[2.03916417]
 [4.96356939]] loss fxn value:  0.6512390372222944 learn rate: 0.001 iteration: 140
[[2.0391692 ]
 [4.96422061]] loss fxn value:  0.6252397614637968 learn rate: 0.001 iteration: 141
[[2.03917403]
 [4.96484583]] loss fxn value:  0.6002784491893047 learn rate: 0.001 iteration: 142
[[2.03917867]
 [4.96544609]] loss fxn value:  0.5763136620062017 learn rate: 0.001 iteration: 143
[[2.03918312]
 [4.96602239]] loss fxn value:  0.5533056158580648 learn rate: 0.001 iteration: 144
[[2.03918739]
 [4.96657568]] loss fxn value:  0.5312161149786527 learn rate: 0.001 iteration: 145
[[2.03919149]
 [4.96710688]] loss fxn value:  0.5100084884832043 learn rate: 0.001 iteration: 146
[[2.03919543]
 [4.96761687]] loss fxn value:  0.48964752949062273 learn rate: 0.001 iteration: 147
[[2.03919921]
 [4.9681065 ]] loss fxn value:  0.4700994366766882 learn rate: 0.001 iteration: 148
[[2.03920284]
 [4.96857659]] loss fxn value:  0.4513317581600351 learn rate: 0.001 iteration: 149
[[2.03920632]
 [4.96902791]] loss fxn value:  0.433313337628923 learn rate: 0.001 iteration: 150
[[2.03920967]
 [4.96946121]] loss fxn value:  0.4160142626181867 learn rate: 0.001 iteration: 151
[[2.03921288]
 [4.96987721]] loss fxn value:  0.39940581485158183 learn rate: 0.001 iteration: 152
[[2.03921596]
 [4.9702766 ]] loss fxn value:  0.3834604225664787 learn rate: 0.001 iteration: 153
[[2.03921892]
 [4.97066005]] loss fxn value:  0.36815161474179037 learn rate: 0.001 iteration: 154
[[2.03922177]
 [4.97102819]] loss fxn value:  0.3534539771532758 learn rate: 0.001 iteration: 155
[[2.0392245 ]
 [4.97138164]] loss fxn value:  0.3393431101832184 learn rate: 0.001 iteration: 156
[[2.03922712]
 [4.97172097]] loss fxn value:  0.32579558831471184 learn rate: 0.001 iteration: 157
[[2.03922963]
 [4.97204675]] loss fxn value:  0.3127889212426537 learn rate: 0.001 iteration: 158
[[2.03923205]
 [4.97235953]] loss fxn value:  0.3003015165374597 learn rate: 0.001 iteration: 159
[[2.03923437]
 [4.97265983]] loss fxn value:  0.28831264379966665 learn rate: 0.001 iteration: 160
[[2.03923659]
 [4.97294813]] loss fxn value:  0.2768024002448791 learn rate: 0.001 iteration: 161
[[2.03923873]
 [4.97322492]] loss fxn value:  0.2657516776633682 learn rate: 0.001 iteration: 162
[[2.03924078]
 [4.97349067]] loss fxn value:  0.2551421306983966 learn rate: 0.001 iteration: 163
[[2.03924275]
 [4.9737458 ]] loss fxn value:  0.24495614639082475 learn rate: 0.001 iteration: 164
[[2.03924464]
 [4.97399075]] loss fxn value:  0.23517681493989695 learn rate: 0.001 iteration: 165
[[2.03924646]
 [4.97422592]] loss fxn value:  0.2257879016313655 learn rate: 0.001 iteration: 166
[[2.0392482]
 [4.9744517]] loss fxn value:  0.2167738198857878 learn rate: 0.001 iteration: 167
[[2.03924988]
 [4.97466847]] loss fxn value:  0.20811960538340427 learn rate: 0.001 iteration: 168
[[2.03925148]
 [4.97487658]] loss fxn value:  0.19981089122189177 learn rate: 0.001 iteration: 169
[[2.03925303]
 [4.97507639]] loss fxn value:  0.19183388406550358 learn rate: 0.001 iteration: 170
[[2.03925451]
 [4.97526822]] loss fxn value:  0.18417534124701923 learn rate: 0.001 iteration: 171
[[2.03925593]
 [4.97545239]] loss fxn value:  0.1768225487832668 learn rate: 0.001 iteration: 172
[[2.03925729]
 [4.9756292 ]] loss fxn value:  0.16976330026872594 learn rate: 0.001 iteration: 173
[[2.03925861]
 [4.97579896]] loss fxn value:  0.16298587661150618 learn rate: 0.001 iteration: 174
[[2.03925986]
 [4.97596194]] loss fxn value:  0.15647902657863735 learn rate: 0.001 iteration: 175
[[2.03926107]
 [4.97611842]] loss fxn value:  0.1502319481176046 learn rate: 0.001 iteration: 176
[[2.03926223]
 [4.97626864]] loss fxn value:  0.1442342704238589 learn rate: 0.001 iteration: 177
[[2.03926335]
 [4.97641287]] loss fxn value:  0.1384760367243094 learn rate: 0.001 iteration: 178
[[2.03926441]
 [4.97655135]] loss fxn value:  0.13294768774806345 learn rate: 0.001 iteration: 179
[[2.03926544]
 [4.97668429]] loss fxn value:  0.12764004585675784 learn rate: 0.001 iteration: 180
[[2.03926643]
 [4.97681193]] loss fxn value:  0.12254429980904365 learn rate: 0.001 iteration: 181
[[2.03926737]
 [4.97693447]] loss fxn value:  0.11765199013273119 learn rate: 0.001 iteration: 182
[[2.03926828]
 [4.97705212]] loss fxn value:  0.11295499508152862 learn rate: 0.001 iteration: 183
[[2.03926915]
 [4.97716507]] loss fxn value:  0.10844551715170553 learn rate: 0.001 iteration: 184
[[2.03926999]
 [4.97727351]] loss fxn value:  0.10411607013754502 learn rate: 0.001 iteration: 185
[[2.0392708 ]
 [4.97737762]] loss fxn value:  0.09995946670366791 learn rate: 0.001 iteration: 186
[[2.03927157]
 [4.97747758]] loss fxn value:  0.09596880645306298 learn rate: 0.001 iteration: 187
[[2.03927231]
 [4.97757354]] loss fxn value:  0.09213746447172264 learn rate: 0.001 iteration: 188
[[2.03927302]
 [4.97766568]] loss fxn value:  0.08845908033077153 learn rate: 0.001 iteration: 189
[[2.0392737 ]
 [4.97775414]] loss fxn value:  0.08492754752727093 learn rate: 0.001 iteration: 190
[[2.03927436]
 [4.97783906]] loss fxn value:  0.08153700334698757 learn rate: 0.001 iteration: 191
[[2.03927499]
 [4.9779206 ]] loss fxn value:  0.07828181913138871 learn rate: 0.001 iteration: 192
[[2.03927559]
 [4.97799888]] loss fxn value:  0.07515659093384887 learn rate: 0.001 iteration: 193
[[2.03927617]
 [4.97807403]] loss fxn value:  0.07215613054824638 learn rate: 0.001 iteration: 194
[[2.03927673]
 [4.97814618]] loss fxn value:  0.0692754568960506 learn rate: 0.001 iteration: 195
[[2.03927726]
 [4.97821546]] loss fxn value:  0.06650978775741767 learn rate: 0.001 iteration: 196
[[2.03927778]
 [4.97828196]] loss fxn value:  0.06385453183184162 learn rate: 0.001 iteration: 197
[[2.03927827]
 [4.97834582]] loss fxn value:  0.061305281116452094 learn rate: 0.001 iteration: 198
[[2.03927874]
 [4.97840712]] loss fxn value:  0.058857803588105995 learn rate: 0.001 iteration: 199
[[2.0392792 ]
 [4.97846598]] loss fxn value:  0.0565080361777299 learn rate: 0.001 iteration: 200
[[2.03927964]
 [4.97852248]] loss fxn value:  0.05425207802537632 learn rate: 0.001 iteration: 201
[[2.03928005]
 [4.97857673]] loss fxn value:  0.052086184004225045 learn rate: 0.001 iteration: 202
[[2.03928046]
 [4.97862882]] loss fxn value:  0.050006758503343414 learn rate: 0.001 iteration: 203
[[2.03928084]
 [4.97867882]] loss fxn value:  0.04801034945877214 learn rate: 0.001 iteration: 204
[[2.03928121]
 [4.97872683]] loss fxn value:  0.04609364262228581 learn rate: 0.001 iteration: 205
[[2.03928157]
 [4.97877292]] loss fxn value:  0.04425345605977772 learn rate: 0.001 iteration: 206
[[2.03928191]
 [4.97881718]] loss fxn value:  0.04248673486894891 learn rate: 0.001 iteration: 207
[[2.03928224]
 [4.97885966]] loss fxn value:  0.040790546107561436 learn rate: 0.001 iteration: 208
[[2.03928255]
 [4.97890045]] loss fxn value:  0.039162073924573035 learn rate: 0.001 iteration: 209
[[2.03928286]
 [4.97893961]] loss fxn value:  0.03759861488567408 learn rate: 0.001 iteration: 210
[[2.03928315]
 [4.97897721]] loss fxn value:  0.036097573485063206 learn rate: 0.001 iteration: 211
[[2.03928343]
 [4.97901331]] loss fxn value:  0.0346564578368741 learn rate: 0.001 iteration: 212
[[2.03928369]
 [4.97904796]] loss fxn value:  0.033272875538196564 learn rate: 0.001 iteration: 213
[[2.03928395]
 [4.97908123]] loss fxn value:  0.03194452969748275 learn rate: 0.001 iteration: 214
[[2.0392842 ]
 [4.97911318]] loss fxn value:  0.030669215121555224 learn rate: 0.001 iteration: 215
[[2.03928443]
 [4.97914385]] loss fxn value:  0.02944481465464901 learn rate: 0.001 iteration: 216
[[2.03928466]
 [4.97917329]] loss fxn value:  0.02826929566375698 learn rate: 0.001 iteration: 217
[[2.03928488]
 [4.97920156]] loss fxn value:  0.027140706664204005 learn rate: 0.001 iteration: 218
[[2.03928509]
 [4.9792287 ]] loss fxn value:  0.0260571740801446 learn rate: 0.001 iteration: 219
[[2.03928529]
 [4.97925475]] loss fxn value:  0.025016899133982615 learn rate: 0.001 iteration: 220
[[2.03928548]
 [4.97927977]] loss fxn value:  0.02401815486033249 learn rate: 0.001 iteration: 221
[[2.03928567]
 [4.97930379]] loss fxn value:  0.02305928323908751 learn rate: 0.001 iteration: 222
[[2.03928585]
 [4.97932685]] loss fxn value:  0.02213869244299704 learn rate: 0.001 iteration: 223
[[2.03928602]
 [4.97934898]] loss fxn value:  0.021254854194896783 learn rate: 0.001 iteration: 224
[[2.03928618]
 [4.97937024]] loss fxn value:  0.020406301230708798 learn rate: 0.001 iteration: 225
[[2.03928634]
 [4.97939064]] loss fxn value:  0.019591624863710754 learn rate: 0.001 iteration: 226
[[2.03928649]
 [4.97941024]] loss fxn value:  0.01880947264572896 learn rate: 0.001 iteration: 227
[[2.03928664]
 [4.97942904]] loss fxn value:  0.018058546122227813 learn rate: 0.001 iteration: 228
[[2.03928677]
 [4.9794471 ]] loss fxn value:  0.017337598676519485 learn rate: 0.001 iteration: 229
[[2.03928691]
 [4.97946444]] loss fxn value:  0.01664543346036303 learn rate: 0.001 iteration: 230
[[2.03928704]
 [4.97948108]] loss fxn value:  0.01598090140693969 learn rate: 0.001 iteration: 231
[[2.03928716]
 [4.97949706]] loss fxn value:  0.015342899323568769 learn rate: 0.001 iteration: 232
[[2.03928728]
 [4.97951241]] loss fxn value:  0.014730368059871053 learn rate: 0.001 iteration: 233
[[2.03928739]
 [4.97952714]] loss fxn value:  0.014142290749790332 learn rate: 0.001 iteration: 234
[[2.0392875 ]
 [4.97954128]] loss fxn value:  0.01357769112348045 learn rate: 0.001 iteration: 235
[[2.03928761]
 [4.97955486]] loss fxn value:  0.013035631886408338 learn rate: 0.001 iteration: 236
[[2.03928771]
 [4.97956789]] loss fxn value:  0.012515213163422334 learn rate: 0.001 iteration: 237
[[2.0392878 ]
 [4.97958041]] loss fxn value:  0.012015571005017493 learn rate: 0.001 iteration: 238
[[2.0392879 ]
 [4.97959242]] loss fxn value:  0.011535875952835374 learn rate: 0.001 iteration: 239
[[2.03928799]
 [4.97960396]] loss fxn value:  0.011075331662824055 learn rate: 0.001 iteration: 240
[[2.03928807]
 [4.97961503]] loss fxn value:  0.01063317358325291 learn rate: 0.001 iteration: 241
[[2.03928815]
 [4.97962567]] loss fxn value:  0.01020866768545964 learn rate: 0.001 iteration: 242
[[2.03928823]
 [4.97963587]] loss fxn value:  0.009801109245142289 learn rate: 0.001 iteration: 243
